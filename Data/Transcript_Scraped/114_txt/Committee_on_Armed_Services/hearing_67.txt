- [H.A.S.C. No. 114-67] ADVANCING THE SCIENCE AND ACCEPTANCE OF AUTONOMY FOR FUTURE DEFENSE SYSTEMS

[House Hearing, 114 Congress]
[From the U.S. Government Publishing Office]

[H.A.S.C. No. 114-67]

ADVANCING THE SCIENCE AND

ACCEPTANCE OF AUTONOMY FOR

FUTURE DEFENSE SYSTEMS

__________

HEARING

BEFORE THE

SUBCOMMITTEE ON EMERGING THREATS AND CAPABILITIES

OF THE

COMMITTEE ON ARMED SERVICES

HOUSE OF REPRESENTATIVES

ONE HUNDRED FOURTEENTH CONGRESS

FIRST SESSION

__________

HEARING HELD

NOVEMBER 19, 2015

[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

______

U.S. GOVERNMENT PUBLISHING OFFICE

97-823                         WASHINGTON : 2016
-----------------------------------------------------------------------
For sale by the Superintendent of Documents, U.S. Government Publishing
Office Internet: bookstore.gpo.gov Phone: toll free (866) 512-1800;
DC area (202) 512-1800 Fax: (202) 512-2104 Mail: Stop IDCC,
Washington, DC 20402-0001

SUBCOMMITTEE ON EMERGING THREATS AND CAPABILITIES

JOE WILSON, South Carolina, Chairman

JOHN KLINE, Minnesota                JAMES R. LANGEVIN, Rhode Island
BILL SHUSTER, Pennsylvania           JIM COOPER, Tennessee
DUNCAN HUNTER, California            JOHN GARAMENDI, California
RICHARD B. NUGENT, Florida           JOAQUIN CASTRO, Texas
RYAN K. ZINKE, Montana               MARC A. VEASEY, Texas
TRENT FRANKS, Arizona, Vice Chair    DONALD NORCROSS, New Jersey
DOUG LAMBORN, Colorado               BRAD ASHFORD, Nebraska
MO BROOKS, Alabama                   PETE AGUILAR, California
BRADLEY BYRNE, Alabama
ELISE M. STEFANIK, New York
Kevin Gates, Professional Staff Member
Lindsay Kavanaugh, Professional Staff Member
Neve Schadler, Clerk

C O N T E N T S

----------
Page

STATEMENTS PRESENTED BY MEMBERS OF CONGRESS

Langevin, Hon. James R., a Representative from Rhode Island,
Ranking Member, Subcommittee on Emerging Threats and
Capabilities...................................................     2
Wilson, Hon. Joe, a Representative from South Carolina, Chairman,
Subcommittee on Emerging Threats and Capabilities..............     1

WITNESSES

Bornstein, Dr. Jonathan, Chief, Autonomous Systems Division,
Vehicle Technology Directorate, Army Research Laboratory.......     7
Kelley, Frank, Deputy Assistant Secretary of the Navy for
Unmanned Systems...............................................     5
Zacharias, Dr. Greg L., Chief Scientist of the United States Air
Force..........................................................     3

APPENDIX

Prepared Statements:

Bornstein, Dr. Jonathan......................................    52
Kelley, Frank................................................    38
Wilson, Hon. Joe.............................................    21
Zacharias, Dr. Greg L........................................    22

Documents Submitted for the Record:

[There were no Documents submitted.]

Witness Responses to Questions Asked During the Hearing:

[There were no Questions submitted during the hearing.]

Questions Submitted by Members Post Hearing:

Mr. Langevin.................................................    65
Mr. Wilson...................................................    61

ADVANCING THE SCIENCE AND ACCEPTANCE OF AUTONOMY FOR FUTURE DEFENSE
SYSTEMS

----------

House of Representatives,
Committee on Armed Services,
Subcommittee on Emerging Threats and Capabilities,
Washington, DC, Thursday, November 19, 2015.
The subcommittee met, pursuant to call, at 10:35 a.m., in
room 2212, Rayburn House Office Building, Hon. Joe Wilson
(chairman of the subcommittee) presiding.

OPENING STATEMENT OF HON. JOE WILSON, A REPRESENTATIVE FROM
SOUTH CAROLINA, CHAIRMAN, SUBCOMMITTEE ON EMERGING THREATS AND
CAPABILITIES

Mr. Wilson. Ladies and gentlemen, I call this hearing of
Emerging Threats and Capabilities Subcommittee of the House
Armed Services Committee to order.
I am pleased to welcome everyone here today for today's
hearing on advancing the science and acceptance of autonomy for
future defense systems. The military necessity for autonomous
systems is obvious. Many of us recognize that our military is
not large enough, and it is not likely to grow sufficiently
over the next few years to handle all the threats we face.
On top of this, shrinking budgets will shrink our military,
stretch our military men and women and platforms even further
to be able to accomplish their ever-changing and challenging
missions. The promise of autonomous systems is becoming more
evident every day. From self-driving cars to smart buildings to
increasing presence of robotics, the full potential of
autonomous systems is nearly endless. What is less understood
are the technical and policy challenges that must be identified
and solved to make those visions a reality.
Most of us are more likely to understand what is possible
with examples provided from television and movies. So I am
looking forward to having real experts shed light on what the
actual state-of-the-art technology is, and what the path to
acceptance looks like for the military services. And with this
backdrop, we look forward to hearing from today's panel of
witnesses who will educate members on many of the issues
related to autonomy research and the development of
increasingly autonomous systems.
And we do have a challenge. Votes have just been called,
and we will be introducing everyone, and then we will recess
and then come back.
And so our witnesses today, Dr. Greg L. Zacharias, Chief
Scientist of the U.S. Air Force; Mr. Frank Kelley, Deputy
Assistant Secretary of the Navy for Unmanned Systems; Dr.
Jonathan Bornstein, Chief, Autonomous Systems Division, Vehicle
Technology Directorate, Army Research Laboratory.
And before we recess, I would like to turn to my friend,
the ranking member, James Langevin from Rhode Island, for any
comments he'd like to make.
[The prepared statement of Mr. Wilson can be found in the
Appendix on page 21.]

STATEMENT OF HON. JAMES R. LANGEVIN, A REPRESENTATIVE FROM
RHODE ISLAND, RANKING MEMBER, SUBCOMMITTEE ON EMERGING THREATS
AND CAPABILITIES

Mr. Langevin. Well, thank you, Mr. Chairman. And I want to
thank you for convening this hearing. I will welcome our
witnesses. It is certainly always a pleasure diving into these
issues with you. And I appreciate you and your convening this
hearing this morning. So again, thank you to our witnesses for
appearing before the subcommittee to provide your insights
regarding advancing the science of autonomy as well as the
challenges with its acceptance.
Increasingly, autonomous systems and capabilities have
provided a significant advantage to our warfighters by
augmenting the skills while also decreasing the risk to their
lives. Some of those systems, such as the human supervised
Aegis Combat System, point defense systems such as Phalanx, and
ISR [intelligence, surveillance, and reconnaissance] systems,
have been such game changers that they have fundamentally
altered our strategies and doctrine.
For just one example, as members of the ETC [Emerging
Threats and Capabilities] Subcommittee, we are extraordinarily
familiar with how remotely piloted aircraft and identifying,
tracking, and killing capabilities they carry have not only
changed tactic, techniques, and procedures, but also shaped our
counterterrorism strategy.
Although we have begun to realize the potential of unmanned
systems for military applications, we have yet to grasp the
full potential of autonomous systems. Incorporation of unmanned
platforms has been driven by demands in current areas of
operations, and those same demands will drive us towards usage
of increasingly sophisticated autonomy in all domains: air,
ground, sea, space, and cyberspace.
Bearing that in mind, it is troubling that the 2012 Defense
Science Board [DSB] report entitled ``The Report of Autonomy in
DOD [Department of Defense] Systems'' concluded that there are
several hurdles precluding broad acceptance of autonomous
systems in the Department, thereby hindering advances in
science and technology.
I do recognize that there have been changes and progress on
the subject and science of autonomy in the Department since the
DSB report was issued. In the fall of 2014, Under Secretary
Kendall announced the commissioning of a new study focused on
the science, engineering, and policy problems that must be
solved to permit greater operational use of autonomy across all
warfighting domains. Most recently, the Secretary of the Navy
established a new Deputy Assistant Secretary of the Navy for
autonomous systems, and a new office to coordinate all aspects
of unmanned systems. And Deputy Secretary Work has indicated
autonomous systems will play a significant role in the Third
Offset Strategy.
Today, I hope to have a robust dialogue on how we can
advance the science, utility, and acceptance of autonomous
systems. I hope that we can discuss the following.
First of all, definition. How should we define autonomy?
How should we distinguish between the degrees of complexity of
autonomous systems? And how should we distinguish future
autonomous capabilities?
Next, command and control. Who is ultimately responsible in
the chain of command as systems become more independent from
operators? Should certain lethal capabilities remain with a
human in the loop or become autonomous, akin to point defense
systems? When and how should we revisit these determinations?
Next, integration. How will we integrate autonomous systems
and capabilities with manned and other unmanned systems across
all domains?
Next, science and technology. How do we better transition
advancements in capabilities? How will the Department create a
cohesive testing and training strategy that provides confidence
at the strategic, tactical, and operational levels for maximum
employment of the capability? And what hurdles must be overcome
to formulate those strategies?
Given that such autonomy research is being undertaken in
the private sector, and in our labs and academic institutions,
how, and to what degree, do we leverage that work?
And, finally, security and risk. How do we ensure software
and hardware systems are secure and verified? How will we
understand and measure the risks associated with employment of
autonomous systems?
So with that, Mr. Chairman, I look forward to our
conversation and our witnesses' testimony. And with that I
yield back.
Mr. Wilson. Thank you very much, Mr. Langevin.
And as indicated, we are having votes on the floor at this
time. There are four votes. There will be, sadly, a significant
delay. But we are recessed.
[Recess.]
Mr. Wilson. Ladies and gentlemen, I would like to welcome
everybody back to a meeting of the Emerging Threats
Subcommittee on the House Armed Services Committee. We have
recessed for votes, and the votes are concluded. And we can
proceed. And I would like to remind every one of our witnesses
that your written statements will be submitted for the record.
So that we ask that you summarize your comments in 5 minutes or
less. Thank you for being here today. We will begin with Dr.
Zacharias.

STATEMENT OF DR. GREG L. ZACHARIAS, CHIEF SCIENTIST OF THE
UNITED STATES AIR FORCE

Dr. Zacharias. Chairman Wilson, Ranking Member Langevin,
members of the subcommittee, thank you for the opportunity to
provide testimony on how the Air Force is advancing science in
autonomy and the acceptance of the autonomy for future defense
systems. I deeply appreciate your devoting time to this topic.
Just as a little addition to my background, I have been
working in the manned machine area for over 40 years, first
helping to design the space shuttle autopilot, later working
with flight simulation, and most recently, with systems
providing computational intelligence to help humans make better
decisions.
The current focus on autonomous systems calls on many of
these technology areas, and I am delighted to be in the middle
of it right now in my current role as chief scientist. I hope I
can help explain today some of the issues involved in
development of these systems.
In the Air Force's vision for autonomy in future systems,
we seek the right balance of human and machine teaming to meet
future operational challenges by combining increasingly capable
hardware and software systems with unique human abilities in
perception, judgment, and innovation. The goal is to have human
autonomy teams operate effectively in high tempo, uncertain,
and complex decision environments where humans and machines can
work together effectively, efficiently, predictably, and
robustly. Boiled down to its essentials, the Air Force's
autonomy, science, and technology vision is intelligent
machines seamlessly integrated with humans maximizing mission
performance in complex and contested environments.
So as machine capabilities advance, the Air Force's
technology development approach is to keep the airmen at the
center of the system design. Likewise, the Air Force's
operational vision is to keep the airmen at the center of the
critical decisions that occur throughout a mission and
engagement. The ultimate goal is to ensure effective teaming of
the airmen with the autonomous system for better agility,
effectiveness, and mission success.
Embedded in this vision are three strategic objectives, if
you will. First, the development of sensors and data-gathering
technology that can provide the needed information for a system
to better understand its operating environment and mission
goals. Basically, the context. Second, the development of
reasoning systems and software environments to assess
situations to make recommendations or decisions. The
computational intelligence part of it, if you will. And then
finally, the refinement of different ways for carrying out
those recommendations and decisions, whether through direct
action, such as guiding an unmanned platform, or through
recommendations to another human or a machine teammate. The
overall goal here is to enable systems to react appropriately
to their environment and perform situationally appropriate
tasks, synchronized and integrated with other autonomous human
or machine systems.
The payoffs include a greater ability to prevail in
increasingly tested environments over greater ranges and time
spans; protection of airmen from dangerous and harsh
environments while increasing their mission effectiveness;
reducing the time to conduct time-critical operations, such as
in defending our air, space, and cyberspace assets against high
tempo threats; providing increased levels of reliability,
persistence, and resilience; and then, finally, reducing
manning costs, as was mentioned earlier.
In your invitation to me to testify, you asked me to
comment on how the Air Force has implemented the
recommendations of the 2012 Defense Science Board Autonomy
Report. And I hope that between my written statement provided
earlier and my comments here today, I will have demonstrated
that the Air Force has been very responsive to the DSB
recommendations, and is leading the way in terms of autonomy
research and use of autonomous systems.
Thanks for letting me speak on this exciting topic and for
your interest in this game-changing technology. I look forward
to answering any questions you may have.
[The prepared statement of Dr. Zacharias can be found in
the Appendix on page 22.]
Mr. Wilson. Thank you very much, Dr. Zacharias. And,
indeed, it is game changing. And I appreciate your enthusiasm
and recognition of how important what you are doing. Thank you
very much.
Dr. Zacharias. Thank you.
Mr. Wilson. Mr. Kelley.

STATEMENT OF FRANK KELLEY, DEPUTY ASSISTANT SECRETARY OF THE
NAVY FOR UNMANNED SYSTEMS

Mr. Kelley. Chairman Wilson, Ranking Member Langevin, and
distinguished members of the subcommittee, thank you for the
opportunity to speak with you today. It is my pleasure to
testify this morning beside my Army and Air Force counterparts
as the Navy's first Deputy Assistant Secretary of the Navy for
Unmanned Systems.
I would also like to thank Mr. Gates for coming down and
seeing us at the Pentagon. Really appreciate that. And it is
not lost on me, gentlemen, that in my past life, I would find
comfort being flanked by two Ph.D.s, and have grown accustomed
to the safety of such intellectual supervision. So thank you,
gentlemen, for doing that for me.
Unmanned and autonomous systems are going to transform the
future of how we operate as a Navy and as a military. However,
unmanned technology will not diminish the importance of our
most fundamental asset, our people. Instead, unmanned and
autonomous systems which allow us to exceed human limitations
will be used as powerful force multipliers across our fleet.
Using autonomous systems in roles for which machines are best
suited allows us to strategically employ sailors and marines
for roles in which people are best suited.
The research and development work the Navy and Marine Corps
is conducting to improve our autonomous capabilities for future
military systems is impressive, from the early research in
cooperative behavior to autonomous takeoffs and landings of our
unmanned aircraft. These innovations in autonomy, however, need
to be nurtured and introduced in a manner which will gain the
trust of our sailors and marines, and the public we are here to
protect.
I hope the committee will come to appreciate the deliberate
and disciplined nature in which the Navy and Marine Corps are
investing time and resources in the development and
experimentation with this technology.
It is also important to understand that realizing the
vision of a fully integrated unmanned and manned naval force
will depend as much on significant military cultural evolution
as on the technology innovation. We have to change the way we
think to evolve the way we fight.
The strong leadership within the Navy today is laying down
the foundation that will allow us to realize the vision of a
fully integrated future force.
This past April, the Secretary of the Navy announced that
he was creating a new organization to focus and guide the
Navy's efforts on unmanned systems under the strong leadership
of the Assistant Secretary of the Navy for Research,
Development, and Acquisition, in order to create the Office of
the Deputy Assistant Secretary of the Navy for Unmanned
Systems, and to bring together all the many stakeholders and
operators who are currently working on this technology in order
to streamline their efforts.
Additionally, a new resource sponsor was established under
the Chief of Naval Operations. OPNAV [Office of the Chief of
Naval Operations] N-99, or unmanned warfare systems, was
created so that all aspects of unmanned in all domains will be
coordinated and championed. As of the 2nd of November, both
organizations have been officially stood up and populated with
highly qualified individuals from across our Navy and Marine
Corps. Prior to our official establishment, the groundwork
commenced over the summer, and the two organizations have
collaborated with the DASN [Deputy Assistant Secretary of the
Navy] for Research, Development, Test, and Evaluation [RDT&E]
to develop a cross-Department prototyping and experimentation
approach that embraces innovation.
To work rapidly to harness the potential of unmanned
technology into deployable systems is built upon the incredible
foundation laid by our Office of Naval Research [ONR] and the
Naval Research Laboratory. These two organizations have a rich
history of basic and fundamental research in autonomous and
unmanned systems conducted by world-class personnel in world-
class facilities.
However, despite the ample research that has been done, and
despite the claims of some, autonomy is not a solved problem.
There is much work to be done before we can realize our vision
of a fully integrated manned and unmanned force. Autonomy still
provides a host of unique challenges. Furthermore, autonomy
alone will not ensure a secure America. We must understand the
limits of autonomy, and, in so doing, come to more fully
appreciate the advantages of being human.
In this way we will be able to build an effective teaming
relationship between people and autonomous systems. The
development of trust within this team will be critical to the
success of all of our missions. We have a moral imperative to
equip our sailors and marines with the best capabilities to do
their missions. However, we also have a moral imperative to
ensure that in addition to the technology innovation we develop
an ethical, legal, and policy framework for how we will employ
unmanned and autonomous systems.
Even as we carefully and deliberately build this framework,
we also recognize that we have to be able to robustly defend
against adversaries who do not play by our rules. Unmanned and
autonomous technology will transform the way we operate. Your
Navy and Marine Corps are committed to understanding and
forging an effective relationship between man and machine that
will unlock our full potential of both.
Chairman Wilson, Ranking Member Langevin, and distinguished
members of the subcommittee, thank you again for the
opportunity to speak with you today. And I look forward to
answering your questions.
[The prepared statement of Mr. Kelley can be found in the
Appendix on page 38.]
Mr. Wilson. Thank you, Mr. Kelley. And we appreciate your
prior Marine service, too.
We now proceed to Dr. Bornstein.

STATEMENT OF DR. JONATHAN BORNSTEIN, CHIEF, AUTONOMOUS SYSTEMS
DIVISION, VEHICLE TECHNOLOGY DIRECTORATE, ARMY RESEARCH
LABORATORY

Dr. Bornstein. Chairman Wilson, Ranking Member Langevin,
and other distinguished members of the subcommittee, thank you
for the opportunity to speak with you about the research and
development work currently being pursued by the Army to improve
autonomy capabilities for future military systems. The recently
published Army Operating Concept notes that the application of
emerging autonomy technology creates the potential for
affordable, interoperable systems that improve the
effectiveness of soldiers and units. That document provides
vision that, quote, ``Autonomous and semiautonomous operational
capabilities may increase lethality, improve protection and
extend soldiers' and units' reach,'' unquote. The Army Training
and Doctrine Command [TRADOC], together with the Army's science
and technology, acquisition, and test and evaluation
communities, is developing the robotics and autonomous systems
strategy to implement this vision, creating a road map for
autonomy technology development, materiel acquisition, and
training for the next 30 years.
In his recent presentation at the Reagan Presidential
Library, the Deputy Secretary of Defense noted that the
autonomy--I am sorry--that autonomy technology has reached an
``inflection point.'' The technology is now being pursued
widely. It is being pursued globally and by the commercial
sector. There are differences, however, between the commercial
and military application of this technology. Commercial usage
generally focuses on benign, permissive, and structured
environments. The military must design for adversarial, highly
dynamic, and structured environments.
In the near term, the Army community has undertaken efforts
to gain experience with these complex software systems. TRADOC
Centers of Excellence have utilized the ongoing Network
Integration Evaluation and beginning this fiscal year the
Robotics Enhancement Program to place surrogate experimental
autonomous systems in the hands of soldiers. Such
experimentation will inform and aid development of future
requirements, doctrine, tactics, techniques, and procedures
required to effectively employ this new capability.
For the mid and far term, the science and technology
enterprise's efforts are focused on seven main thrusts. It is
focused on the maturation and demonstration of advanced
unmanned--I am sorry--advanced manned/unmanned teaming for both
air vehicles and ground vehicles to permit unmanned assets to
serve as wingmen to manned elements of the force. It is
exploring the effective teaming of unmanned air and ground
vehicles. It is developing robotic technologies and
capabilities that will enable unit resupply and sustainment
operations using optionally manned and unmanned vehicles, and
it is developing the cognitive decision tools for effectively
commanding teams of advanced unmanned systems.
In addition, it is conducting research focused on creating
the technology to seamlessly integrate unmanned elements, both
air and ground, into small unit teams, and research to enable
the development of swarms of unmanned systems capable of
effectively conducting military missions at range. Taken as a
whole, these efforts will provide the underpinnings for
autonomous systems that can operate side by side with our
soldiers on the battlefield in applications ranging from
resupply to reconnaissance.
Although the autonomy technologies available today work
well for the sets of conditions for which they were designed
and tested, they lack the flexibility and adaptability that
would enable them to work well for other situations. Systems
using today's technologies must be teamed with humans to supply
the cognitive capability required for complex missions, while
the unmanned components of the force performs repetitive or
persistent tasks. Significantly advancing autonomy technology,
taking machines from tool to teammate, will require technology
advancement beyond what is available today.
In conclusion, once again, I would like to thank Chairman
Wilson, Ranking Member Langevin, and the other distinguished
members of the committee for the opportunity to discuss the
Army's role in pursuing autonomous capabilities for future
military systems. The Army is committed to developing
autonomous systems that can, one day, work side by side with
our soldiers. I look forward to your questions.
[The prepared statement of Dr. Bornstein can be found in
the Appendix on page 52.]
Mr. Wilson. Thank you, Mr. Bornstein. And with three sons
serving in the Army, I want you to be very successful.
And we now will proceed to 5 minutes of questioning by each
member of the panel. And fortunately we have Kevin Gates as our
staff person who is very strict on maintaining the 5-minute
rule, beginning with me.
And so we will begin with Dr. Zacharias. You mentioned in
your testimony the concept of autonomy at rest. Could you
explain that in more detail for the members so we can better
understand what is important?
Dr. Zacharias. Yes, sir. Yes, sir. And I should give credit
to Dr. Craig Fields, the past director of DARPA [Defense
Advanced Research Projects Agency], for--that is where I heard
the phrases originally, but the notion is that we tend to think
of autonomy in motion because of the RPAs [remotely piloted
aircraft] and the UAVs [unmanned aerial vehicles] that we
recognize, or Google's cars, or the Navy's unmanned underwater
vehicles. And so all these systems, these autonomy in motion
systems, have sensors or databases that tell them what is going
on in the environment, like a GPS sensor, a global positioning
sensor for an RPA position. They also have onboard some kind of
smarts, autonomous smarts that--embedded in an onboard computer
that tells it how to act based on, say, an objective to fly
from one way point to another.
And then they also have some sort of motor or locomotion
subsystem that allows it to move around in its environment. And
this could be for an RPA, a remotely piloted aircraft, the
throttle or the ailerons or the control system. So while the
sensors are very important to these systems and the motor parts
are very important, the real advances in autonomy are happening
in the middle part, the brain part, the onboard smarts. So if
you think about removing those onboard smarts to a ground-based
system, and putting them, say, in a command and control center
or a planning center, then you have got autonomy at rest. So
many of the advances that we are going to see in this area
are--may come from data feeds or other sensors or satellite
imagery, but they are going to be in these ground-base
situations. And they will have a sense part and a think part
and an output part. It might be a natural language generator
like a SIRI [Speech Interpretation and Recognition Interface]
interface or a visualization. But once you have done this, you
have converted an autonomy in motion system to an autonomy at
rest system.
So our community right now is beginning to realize that
autonomy is not limited to systems that move about or locomote,
but they are also very useful in decision-aiding systems,
visualization systems, and so forth. And we can multiply the
effectiveness of a lot of--if we could go to a modular
approach, we could use one module in other areas, and we may
also gain some efficiencies in test and validation as well. I
hope that helps explain.
Mr. Wilson. And thank you very much.
And, Dr. Bornstein, in your testimony you mentioned
commercial usage for some autonomy technologies. Where do you
see the military driving technology development? And where do
you see you will be to draw from the commercial sector for
needed technologies?
Dr. Bornstein. Sir, in my testimony I also mentioned that
commercial applications tend to work in structured environments
where there is less dynamicism. So despite what you might think
about driving on the highways today, there is structure in the
highway system. The Google cars, the Uber taxis, those are
applications which are dealing with structure.
The military, however, is dealing with the dynamic
environment, one that where we don't know things in advance. We
have to have organic sensing and reasoning powers onboard the
vehicle. So there is a distinct difference there. Where the
military can leverage heavily is for those applications that
are in more structured environments. Think in terms of
logistics, many aspects of convoy operations, forward operating
bases. Those are all items where there is structure, where
there are commercial entities that are involved with
development of systems, and the Army can leverage those
capabilities. Or I should say the services can leverage those
capabilities. I apologize.
Mr. Wilson. Well, thank you very much.
And, Mr. Kelley, the Navy has a unique challenge, and that
is air, land, or sea operation. Would you describe some of the
technical challenges specific to autonomous systems for each of
the domains?
Mr. Kelley. Thank you, sir. And that is true, that we do
note that we operate in all domains and simultaneously in many
cases. I was reminded today by Dr. Schuette, who is the
director of research at ONR, that one of the ways to overcome
some of the challenges is to start our S&T [science and
technology] and make most of our S&T investments in domain
agnostic and also platform agnostic. So that is one way that we
are going to approach that.
If I can just real quick, I spent a lot of my time as a
young guy doing electronic warfare, and I was told it was one
of the toughest missions that you would ever participate in.
Complex, dense, can be very confusing. It requires quite a bit
of training. Not until I got exposed to what it was like in the
mine and undersea warfare of how cluttered that environment is
did I come to appreciate that my electronic warfare environment
might be the number two most complex combat environment.
The way that that is also compounded is that the things we
take advantage of in--when you operate above the surface,
ability to communicate in the clear, taking advantage of things
like the GPS, are not available to you. So these are going to
be really big challenges for the Navy, particularly
communication underwater and our precision navigation solutions
that will provide to those solutions.
Mr. Wilson. Well, thank you very much. And Mr. Gates is
again very precise. My time is up.
Mr. Langevin.
Mr. Langevin. Thank you, Mr. Chairman. And I want to thank
our witnesses for your testimony today.
So to all of our witnesses, what policy and operational
concept issues at the tactical and strategic level are most
pressing and must be addressed before deployment of more
capable autonomous systems? For instance, the unmanned aerial
systems concepts of operations requires an operator for takeoff
and landing, and airspace restrictions of the U.S. impede
testing and training. Integration into the airspace is still an
issue, and systems must be able to detect, sense, and avoid.
But this is not unique to air, of course.
So, Secretary Kelley, do you want to start from the Navy's
perspective?
Mr. Kelley. Certainly, sir. Thank you. You have listed off
quite an array of challenges. One thing that I would like to
mention. When I had a chance to get a hint that the Secretary
was going to stand up a Deputy Assistant Secretary of the Navy
for Unmanned Systems, one of the first places that I went to
was an association called AUVSI, the Association of Unmanned
Vehicle Systems International. They had tagged on the ``I'' on
that point. I had a chance to talk to the president and CEO
[chief executive officer] of AUVSI, a gentleman by the name of
Brian Wynne, who did not spend any time in the military. And
one of the things that we quickly found out in our dialogue was
that we have many of the same problems. And so here is an
organization not necessarily associated with DOD that is
willing to team with us within the defense sector to solve some
of these issues that you mentioned, sir, like the airspace
issues, the sense and avoid issue. So there is a great
opportunity, I think, to team with the commercial sector.
I think one of the other areas that, if I can think back in
my own time. Back in the day as a young guy in flight school,
sometimes systems were not as reliable as we see our systems
today. And so sometimes you would be in the cockpit and you
would just pray to God that a piece of gear was actually going
to function. I think some of the young people today take that
for granted. The reliability of our equipment today is
unprecedented. They don't question the fact that it is going to
work. I think what I am finding today that is remarkable is,
that our young people are really concerned about the ethical
and moral implications of how these unmanned systems are going
to be used.
This will also help us in getting the trust that I spoke
about in my oral statement of our sailors and marines. The
trust issue is sort of an implied task. We do have DOD
directives that talk about certainly weaponizing platforms, but
I think the biggest issue is sort of an intangible, and it is
this ethical and moral element of what it means to put unmanned
systems in combat.
Mr. Langevin. Okay. Other panelists? Anybody else want to
comment?
Dr. Bornstein. I will make one off-the-cuff statement if--
and one of the things that I see in the commercial sector is
the issue of responsibility. We talk about an unmanned system.
So if there is an accident in the national airspace or an
accident on the road, who is liable for the action? As was just
mentioned by my colleague, Mr. Kelley, we talked about--he
talked about the ethical responsibility that many people see in
the use of unmanned systems.
Will the liability for their use, will the responsibility
of their use, who will that fall upon? That is a personal
opinion that it will be a major issue in the future going
forward both for the commercial sector and for the military
sector.
Mr. Langevin. That actually kind of touches on my next
question. You kind of beat me to it there. But, again, I will
pose it to the other members of the panel.
As I mentioned in my testimony, command and control becomes
more challenging as systems become more autonomous. So how will
you address chain of command as systems become more autonomous,
particularly when you are talking about lethality in systems?
Dr. Zacharias. Maybe I can start on that. This is a little
out of my scope since I am on the S&T side. But I think, as Mr.
Kelley said, I think much of it has to do with trust and
proficiency. So one of the things is to try and design trust
into these systems, including engineering the system so it
performs well within its scope of operations, knowing when it
is exceeding its scope of operations or the human operator
knowing that, making sure they are knowledgeable of mutual
understanding of their goals if they are working as a team or
their sub tasks, and providing for natural interfaces.
Transparency and explainability of their systems. It may be
better to not have them be optimum, but rather be adequate and
be able to explain what they are doing.
And, finally, training and practicing together just like
any team would win. And, finally, I think the notion is that if
you can get these systems to codevelop concepts of operations
and organizational design. I think the basic issue we are not
going to just throw things over the transom and expect them to
be perfectly integrated into the organization. And I think
concepts will be codeveloped with the technology.
Mr. Langevin. Mr. Kelley, do you have anything to add?
Mr. Kelley. Yes, sir. Thank you. I really--one of the great
things about coming to hearings like this is you learn so much.
And I love the phrase of ``codevelop.'' I just had a chance to
sit down with the PEO [Program Executive Officer] for C4I
[Command, Control, Communications, Computers, and Intelligence]
for the Navy, Admiral Chris Becker, and we were talking
yesterday about the organizations that provide the
infrastructure, so the C2 [command and control junction] nodes,
the network, the com pipes. How important it is to get with
those organizations quickly. Because that can bring a concept
of operations down to its knees even though that you have the,
you know, the finest autonomous system, the autonomous platform
that, you know, that the, you know, greatest engineers in the
world could have designed.
I also think when we start coming up with what are those
essential elements of information that a commander, and at the
end of the day, it is going to be a commander who is going to
be held accountable for how these systems are used, what are
those elements of information that they are going to need in
order to exercise judgment. We have got to come up with these
priority schemes, a way to make sure that that kind of
information and data gets to the commander on the scene.
Mr. Langevin. Very good. Thank you. And I yield back, Mr.
Chairman.
Mr. Wilson. Thank you, Mr. Langevin.
We will now proceed on a second round. We really appreciate
you being here today, each of you.
For each of you, beginning with Dr. Zacharias, how are you
drawing on or integrating technology efforts being funded by
industry through their internal research and development
process or from international S&T efforts being funded through
foreign governments' science funding agencies?
Dr. Zacharias. Thank you, sir. Well, let me start with the
international efforts first. So we are exploring agreements
with international partners, collaborative technical exchanges.
The Air Force Research Lab has agreements out with--a
multilateral agreement under--there is a technical cooperation
effort with the U.K. [United Kingdom], Australia, New Zealand,
Canada, and working on the grand challenge in autonomy
research. And we are also participating heavily in the V&V
[verification and validation] issues because eventually if we
are having coalition operations, we will have these systems
working with one another, and they will have to be cooperating,
clearly.
So on the commercial side, we are working with the DIUx
[Defense Innovation Unit Experimental] out in the--I apologize.
I can't remember what it stands for, but the DOD initiative out
in the West Coast, Silicon Valley, to try and work with some of
the folks that are doing some of the advance technologies in
machine learning, pattern recognition, robotics, and so forth.
And we will be reaching out additionally with more Air Force
Research Lab personnel in that direction.
Mr. Wilson. Thank you. And Mr. Kelley.
Mr. Kelley. So I think one of the responsibilities of our
office is also to work across the entire enterprise and provide
opportunities for industry to participate in demonstrations and
exercises. Even though we have been in combat in Afghanistan, I
think that the Marine Corps and the Office of Naval Research
can be very, very proud of a program that was started a while
back.
I can't exactly remember when it was. But it was in terms
of an unmanned logistics UAV that would deliver, you know,
cargo out on the battlefield. And to date, the cargo UAV was
able to deliver, you know, over--could have the potential to
deliver over 6,000 pounds of cargo a day. Transitioning that
into, you know, more formalized programs like AACUS, the
autonomous aerial cargo utility system, a K-MAX bird
[helicopter]. I think that that is an important opportunity for
industry to be able to demonstrate their understanding of what
the environment is like.
I already described our association with AUVSI. We did have
a chance in October to speak. It was the first time we could
speak as an organization at their AUVSI defense. And I see many
people sitting behind me that were actually there as well, both
Army and Air Force. And it was a great opportunity for folks to
actually show what was going on, in not only commercially, but
in each of the services.
Mr. Wilson. Thank you very much.
And Dr. Bornstein.
Dr. Bornstein. Like the other services, the Army maintains
bilateral arrangements with many countries through the TTCP
[The Technical Cooperation Program], the Five Eyes, through
countries such as France, Germany, Israel, where we try to
develop programs of common interest. In addition, my own
organization, the Army Research Lab, has embarked upon a new
initiative over the course of the past 2 years that we call
Open Campus, which is focused not on giving contracts to
companies but rather developing cooperative research and
development agreements where there is a mutual interest on the
part of both parties.
Letting small business who are usually the furnaces of
innovation and technology come to our site to utilize DOD
facilities to further what they are doing together with
researchers from the laboratory. We do similar activities with
other organizations throughout the Army, and we invite the
other services to participate as well.
Thank you, sir.
Mr. Wilson. Thank you very much. And for anyone who would
like to answer, what defenses exist to protect autonomy
technologies from being hacked, resulting in losing control?
Mr. Kelley. I will take a stab at it, sir. And I think one
of the most important things here is a new testing paradigm for
autonomous systems that would lean heavy on the cyber side of
the house I think is the most critical piece.
Now, one of the challenges, I think, with autonomous
systems is that it becomes very challenging to try to test all
of the possible scenarios that you could possibly encounter.
And so we will have to work through that. But the VV&A, the
verification, validation, and accreditation of these systems
and, of course the accreditation will also will have a cyber
element to it means that, you know, that we have been able to
test and make sure that, you know, that it can't be hacked into
and taken over.
Mr. Wilson. We just wish you the best addressing, sadly,
people who have such ill intent, as we see every day in the
world.
We will now proceed to Mr. Langevin.
Mr. Langevin. Thank you, Mr. Chairman. And as usual, the
chairman and I are very much on the same page on asking these
kinds of questions. And I wanted to get to the cyber question
or the security question as well. Just to build on that, if you
could elaborate, what role do trusted foundries and third party
manufacturer agreements play in the security?
Dr. Zacharias. I will take a stab at that one, too. So my
understanding is, what role will trusted foundries and supply
chains?
Mr. Langevin. Yes.
Dr. Zacharias. Clearly it will be, I think--we are planning
an upcoming study on looking at issues that Mr. Kelley raised
both in terms of embedded systems, reliability, and authority
authenticity, if you will. Coms links, vulnerabilities. Because
in terms of over and above--vulnerabilities over and above our
normal embedded systems, which we also have those issues of
coms links and cyber vulnerabilities, and there are efforts
ongoing. I am not intimately familiar with them, but in terms
of establishing trusted foundries now, and certainly many more
regulations, say, going out to industry in terms of protecting
government IP [intellectual property] and making sure that
outsiders don't exfiltrate our designs and compromise our
embedded systems.
In fact, there was a large summer study, excuse me, by the
Science Advisory Board for the Air Force this summer looking
specifically at embedded systems' vulnerability. And clearly
that will have an impact on autonomous systems.
Mr. Langevin. Thank you.
To all of our witnesses, the Defense Science Board
identified transition or lack thereof as an obstacle for
utilization of autonomous capabilities. What steps are you
taking to improve transition of technologies?
Dr. Bornstein. I will start. In my opening remarks, I
mentioned ongoing activity looking at near-term applications of
the technology. Those are key and critical to transition and
adoption by the force. As I have said many times, it is very
difficult to write requirements for a revolutionary technology
in which you have no experience. The use of those activities is
to try to build that experience base on the operational, the
training and doctrine community, so they can begin to build the
requirements, the techniques, tactics, and procedures that will
ultimately be used and facilitate the transition of technology
in that way.
Mr. Langevin. Okay. Mr. Kelley.
Mr. Kelley. Thank you, sir. So also within the DSB 2012
study they also talked about the autonomous reference
framework, which in my discussions with folks at ONR, they are
very receptive to that concept. And actually, when I think
about it, it makes a lot of sense.
It is the three level--a cognitive level, a mission level,
and a complex--complex systems trade space level. So that goes
right to the heart that I think that Dr. Bornstein was talking
about in terms of the design of these systems.
In the Navy right now we--with the stand-up of DASN
Unmanned Systems and the renewed emphasis of DASN RDT&E to
energize a naval research development enterprise, and with the
stand-up of OP 99, our resource sponsor, we are taking a really
rigorous stab at prototyping and experimentation. And this is
to better inform the requirements at the front end of our
acquisition framework. And so the most important thing here is
to get the requirements right.
So what we envision is that this will be an iterative cycle
constantly going back to the warfighter in terms of making sure
that we got those requirements right.
Mr. Langevin. Thank you.
Dr. Zacharias. And if I could follow up, my colleagues
covered most of the points, I think. I think this is--again, I
think the Air Force has learned a lot with its RPA experience
being the lead service in establishing so many thousands of
hours of operation in that area. And it has led to a change in
operations and how they are used and issues to do with manning
and manpower.
And it has also raised other issues going from how do you
pilot these things to actually how you process the information,
the thousands of hours of video that you get off of them. And
so they raise other areas and opportunities for autonomy.
And one last thing I would say, these will be again
codeveloped and embraced more fully with good human systems
integration technologies. Again, I think something Mr. Work
mentioned a couple weeks ago, how you get these systems to work
closely with humans and make them more understandable and
reliable and trustworthy, appropriately trustworthy. You don't
want to encourage trust where it isn't deserved.
Mr. Langevin. Okay. Very good. And I guess to all of you,
you've touched on it a little bit already, but how well are you
coordinating your autonomous systems investment strategies in
lessons learned across the services?
Mr. Kelley. I'll try. So I think that is the reason--I
don't think, I know--that is the reason why our office was
stood up, to be quite honest. And one of the things that is
different about the DASN for unmanned shop is I have
counterparts within the Assistant Secretary of the Navy for
Research, Development, and Acquisition, other DASNs. And if you
could sort of picture them as being vertically oriented within
a domain. Say DASN air, guy by the name of Gary Kessler is DASN
air. Gloria Valdez, DASN ships. They have the whole portfolio
of those particular platforms, air and ships.
In our shop we will be cutting across. We will be cutting
across, essentially generating and now supervising, providing
oversight, managing a portfolio of just unmanned systems and
how that fits into the broader naval operational concepts.
Dr. Bornstein. I would be remiss if I didn't try to answer
that question since I am currently acting as the lead for the
Autonomy Community of Interest [COI] within OSD [Office of the
Secretary of Defense]. And Larry Schuette is my deputy sitting
behind me there. OSD basically recognizes that there needs to
be coordination among all the services. It is part of Reliance
21. And ideally the community of interest should be a forum
where subject matter experts can get together and really begin
to understand not only what each other are doing, but have the
opportunity to cross-fertilize thoughts and concepts concerning
the technology.
Next Wednesday the Autonomy COI will hold a workshop at
ONR, really bringing together a large number of people to
discuss three topics: modeling and simulation; test and
evaluation, verification, validation; and trust in automation.
And those will be three topics. Community members will be there
talking about it. I can't tell you what will come out of it,
but I almost guarantee that there will be some cross-
fertilization, and it will be agnostic, service agnostic, in
that regard. So there is that definite thrust towards cross-
fertilization among all the services, at least at the S&T
level.
Mr. Langevin. That is encouraging. Thank you.
Well, if nothing else on that, I will thank our witnesses
and I will yield back. I have additional questions I will
submit for the record, but thank you, Mr. Chairman.
Mr. Wilson. Thank you, Mr. Langevin. And thank each of you
for being here today and in the future. I am very, very
grateful, Kevin Gates has been a lead on this. He has actually
been working in this field for many years. And I am really
grateful for his professionalism, and we look forward to
hearing and working with you in the future.
And with that in mind, we are adjourned.
[Whereupon, at 12:26 p.m., the subcommittee was adjourned.]

=======================================================================

A P P E N D I X

November 19, 2015

=======================================================================

PREPARED STATEMENTS SUBMITTED FOR THE RECORD

November 19, 2015

=======================================================================

[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

=======================================================================

QUESTIONS SUBMITTED BY MEMBERS POST HEARING

November 19, 2015

=======================================================================

QUESTIONS SUBMITTED BY MR. WILSON

Mr. Wilson. In your testimony, you discuss the 4-year study you are
doing to understand pilot trust in the Auto Ground Collision Avoidance
Systems. How will the lessons of this study be applied to other
platforms or domains?
Dr. Zacharias. The AFRL Auto Ground Collision Avoidance Systems
(AGCAS) acceptance study seeks to gauge pilot trust of the AGCAS system
and to identify and validate the antecedents of trust for this highly-
automated Air Force system. The lessons learned from this study will
benefit the existing AGCAS system in the F-16 and will feed into the F-
35 AGCAS implementation.
The study also investigates pilot attitudes toward a broad range of
future automated technologies such as the Automatic Air Collision
Avoidance System (AACAS), automated missile avoidance technologies,
automated station keeping and refueling capabilities, and future
concepts for autonomy such as autonomous Wingmen. These results garner
insight into the factors that make a pilot more or less trusting of
future automated technologies. Such information will be instrumental in
avoiding pilot distrust of near-term capabilities such as the
Integrated Collision Avoidance System, which integrates AGCAS and
AACAS, as well as long-term capabilities such as autonomous Wingmen.
While the focus of the study is heavily focused on the air domain,
I can easily see the lessons learned being folded into building space
operator trust towards more automated station keeping algorithms and
mission allocation. While this domain does not have the same risk to
operator life that the air domain has, the long-term and financial
consequences of mistakes are high. We will also examine the lessons
learned for applicability to the cyber domain.
Mr. Wilson. In your testimony, you discuss the Low Cost Attritable
Strike Unmanned Aerial System. What is the timeline for this program?
What are some of the policy challenges that you think you will
encounter as you demonstrate the technology?
Dr. Zacharias. The currently open Broad Agency Announcement (BAA)
for the Low Cost Attritable Strike Unmanned Aerial System seeks to
provide a benchmark vehicle concept that we will build upon and use for
future demonstration activities in an experimentation campaign plan.
Contract award is targeted at January 2016 with the program challenging
its participants to achieve first flight 24 months after contract
award.
There are a number of policy challenges that will likely be
encountered as we demonstrate this technology. The acquisition and
ownership model of an attritable aircraft is a significant departure
from traditional processes and policies, and is akin to treating the
aircraft as a consumable or commodity product that can be procured with
a short development cycle and significantly less emphasis on support
and maintenance requirements.
With a short development and ownership timeline, life cycle
operators will be able to acquire assets tailored for requirements as
they evolve instead of lengthy modification of existing systems, which
will enable quick tech refresh--common to the automotive industry. At
the same time, these platforms will require an agile acquisition
system, novel training systems that are more reliant on simulation, new
roles and responsibilities for operators and maintainers, storage, and
disposal. In addition, highly tailored air worthiness and certification
considerations will pose challenges to the current acceptance practices
and could change how and where we approach the use of unmanned systems.
Mr. Wilson. In dealing with test, evaluation, validation and
verification, how are you working with the Test Resource Management
Center to better understand where investments are needed for testing
infrastructure, as well as where changes to the test ``process'' might
be needed?
Dr. Zacharias. The Air Force is working with the Test Resource
Management Center (TRMC) primarily through the Test, Evaluation,
Verification, and Validation (TEVV) Working Group of the DOD Autonomy
Community of Interest (COI), of which both are active participants.
The Air Force is also supporting the TRMC Unmanned Autonomous
Systems Test (UAST) Group--through the Autonomy COI TEVV working
group--on a study designed specifically to answer the question ``How do
we change our T&E infrastructure to accommodate future autonomous
systems''. This study, led by Georgia Institute of Technology, was a 20
month effort whose final report is scheduled to be delivered to TRMC by
Jan 2016.
Finally, an example of collaboration between the Air Force, TRMC,
and many others in identifying changes to the test process is a joint
TRMC, AF Institute of Technology, and AFTC sponsored study on ``How to
conduct test and evaluation of autonomous systems and what specific
testing methodologies and capabilities need to be addressed?'' The
study is led by the Scientific Test and Analysis Techniques Test and
Evaluation Center of Excellence at AFIT in direct response to an
inquiry by Dr. Brown (ASD/DT&E).
Mr. Wilson. What opportunities exist to conduct testing or
experimentation with our international partners, including
international non-governmental organizations?
Dr. Zacharias. The U.S. engages in a wide range of T&E activities
with partner nations. These opportunities include Reciprocal Use of
Test Facilities, test range usage, weapons testing, and research.
Collaborative work is codified in various forms. Government-to-
Government agreements include provisions for information sharing legal
liabilities, and shared funding. Cooperative Research and Development
Agreements (CRADAs) are written agreements between private companies
and government agencies to work together on projects. The Research
Grants and Contracts program directly funds University and Foreign
Laboratory basic research overseas through the Air Force Office of
Scientific Research (AFOSR).
The Air Force continues to explore with those international
partners, via collaborative technical exchanges, opportunities to
advance autonomous research. The Air Force Research Laboratory has
International agreements that facilitate collaborative autonomy
research with our key partners. One example of effective collaboration
is a multi-lateral under The Technical Cooperation Program (US/UK/CA/
AU/NZ) agreement which is facilitating a Grand Challenge in autonomy
research. AFRL is participating heavily in this effort focused on how
best to approach Testing, Evaluation, Verification, and Validation
internationally.
Mr. Wilson. The Navy and Marine Corps both have long histories of
fleet experimentation, independently and as a naval team, as a way to
test new technologies, new concepts and new ways of doing business.
What resources do you expect to have to conduct experimentation? How
will you integrate these activities into broader fleet exercises?
Mr. Kelley. To accelerate the development and Fleet introduction of
unmanned systems, the Department of the Navy recently established the
Deputy Assistant Secretary of the Navy for Unmanned Systems (DASN
(UxS)), the Director, Unmanned Warfare Systems Division (OPNAV N99),
and the Naval Rapid Prototyping, Experimentation, and Demonstration
Office, within Deputy Assistant Secretary of the Navy for Research,
Development, Test and Evaluation (DASN(RDT&E)). Working together, these
new organizations will accelerate the practice of experimenting with
developmental and operational prototypes to address Navy and Marine
Corps operational needs. DASN (RDT&E) will leverage the Naval Research
and Development Establishment's (NR&DE) vast technical capabilities,
laboratories, major ranges, and test facilities to develop, integrate
and experiment with advanced naval prototypes. DASN (RDT&E) provides
the avenue to focus and integrate resources from across the DON and the
DOD programs working closely with Fleet Forces, Warfighting Development
Centers, and the Marine Corps Combat Development Command. Prototypes
will be incorporated into Fleet experiments, such as: RIMPAC, Trident
Warrior, Bold Alligator, Unmanned Warrior, etc., enabling technical and
operational assessments of emerging operational concepts, technologies,
and/or engineering innovations.
Mr. Wilson. The subcommittee is familiar with the DARPA investments
in Anti-Submarine Warfare Continuous Trail Unmanned Vessel, or ACTUV,
program. What plans does the Navy have to experiment with that
platform?
Mr. Kelley. The Office of Naval Research will integrate ONR-
developed payloads and autonomous control components and perform at-sea
testing of the DARPA ACTUV vessel, in its ``Medium Displacement
Unmanned Surface Vessel (MDUSV)'' program. The payloads are for mine
countermeasures, anti-submarine warfare and electronic warfare
missions. The at-sea testing will be focused on these payloads, the
mission capability they provide, as well as extensive testing of
ACTUV's autonomous control system.
Mr. Wilson. In dealing with test, evaluation, validation and
verification, how are you working with the Test Resource Management
Center to better understand where investments are needed for testing
infrastructure, as well as where changes to the test ``process'' might
be needed?
Mr. Kelley. DASN UxS will leverage the existing construct within
DON that is responsible for ensuring the test community is ready to
support required testing. This construct, led by DON T&E, is
responsible for collaborating across the ranges/labs/warfare centers,
programs/PEOs and the rest of the test community to determine
requirements for future autonomous systems, gaps in current T&E
Infrastructure, and identification of future investments and/or changes
to the test process.
a. DON T&E will continue to be the primary interface with TRMC who
is sponsoring an Autonomy T&E Study with an objective of assessing the
adequacy of the test resources and infrastructure required to test
autonomous systems. The study, which is being conducted by Georgia
Tech, will also develop a time-phased investment strategy to address
potential shortfalls in T&E capabilities.
b. The study team is coordinating closely with the Autonomy
Community of Interest (COI), Test & Evaluation and Verification &
Validation (ATEVV) Working Group.
c. The Navy is actively engaged in the study with participation
from OPNAV, ONR, NRL, NAVAIR and NAVSEA.
i. Several Naval programs are being considered in the study such as
the Autonomous Aerial Cargo Utility System (AACUS), Unmanned Carrier-
Launched Airborne Surveillance and Strike system (UCLASS), and Large
Displacement Unmanned Undersea Vehicle (LDUUV). In addition, DARPA's
Anti-Submarine Warfare Continuous Trail Unmanned Vehicle (ACTUV) is
also a key consideration.
ii. NAWC-AD, NAWC-WD, NSWC Keyport, and NSWC Newport T&E personnel
are working with the study team to examine the future state of
autonomous systems, and identify the required T&E/experimentation/
assessment/certification infrastructure, technology, capabilities and
workforce required to address future autonomous systems.
Mr. Wilson. What opportunities exist to conduct testing or
experimentation with our international partners, including
international non-governmental organizations?
Mr. Kelley. Joint Warrior is a United Kingdom led bi-annual (spring
and autumn) multi-national exercise which takes place in Scottish
Exercise Areas. In October 2016 an additional exercise will be
conducted in coordination with the Joint Warrior Exercise, referred to
as Unmanned Warrior. The objective of this exercise is to experiment
with the tactical employment of unmanned and autonomous systems in the
maritime and littoral environments. Significant UK defense industry and
NATO participation is anticipated, and this will be an opportunity for
the Navy to conduct testing with our international partners.
Mr. Wilson. You mentioned in your testimony that the Army will be
continuing work to increase the capabilities offered as part of the
Autonomous Mobility Applique Systems (AMAS) Joint Concept Technology
Demonstration and addressing some of the technology gaps in autonomous
convoy resupply. What are some of those gaps as you see them?
Dr. Bornstein. The AMAS JCTD, and subsequent demonstrations,
focused upon an incremental approach for the creation of a ``fail-safe
architecture'' that would permit the reduction of crew size from two
Soldiers to a single individual. In effect, this program was utilizing
technology to create driver's aids analogous to the safety features
that are now beginning to appear in both private and commercial
vehicles. While having direct benefits, especially under tactical
situations, significant technology gaps exist that prevent immediate
deployment of autonomous vehicles. These gaps include the development
of an appropriate software architecture, algorithms for perception and
vehicle behaviors, and the integration of those algorithms into the
software architecture so that they can operate in real time, i.e.,
permitting vehicles to operate at appropriate tactical speeds. Some of
the required technology will benefit from research and development
activities currently being conducted in the private sector, e.g.,
Google and others. However, Google and others are depending on robust
wireless networks to support their applications. Unfortunately, these
networks may not be available in the dynamic and complex tactical
environments the Army may be working which creates additional
challenges.
Mr. Wilson. In dealing with test, evaluation, validation and
verification, how are you working with the Test Resource Management
Center to better understand where investments are needed for testing
infrastructure, as well as where changes to the test ``process'' might
be needed?
Dr. Bornstein. The OSD Autonomy Community of Interest (COI) has
recognized that the test and evaluation/validation and verification
(T&E/V&V) of future intelligent systems that incorporate learning
leading to emergent behaviors is critical to future employment of
systems incorporating this technology. It therefore created the T&E/V&V
working group. Since the COI is a ``grass roots'' organization that
incorporates all individuals with common interests, it has worked hand-
in-hand with the Test Resource Management Center (TRMC) Unmanned and
Autonomous System Test (UAST) program in furthering common goals.
Members of the T&E/V&V working group are part of the UAST working
group, while members of the UAST, including the executing agent,
participate in the Autonomy COI T&E/V&V effort.
The functions that the T&E/V&V working group set for itself are to
foster community collaboration; develop an S&T strategic roadmap,
including an assessment of current autonomy T&E and V&V standards,
procedures, infrastructure, and capabilities; identify gaps where those
capabilities, infrastructure, and policy are misaligned or deficient;
coordinate with Major Range Test and Facility Base (MRTFB) to produce a
database baseline of T&E infrastructure; and support standards
development unique to the V&V of autonomous systems.
The working group has established five goals: (1) creation of
methods and tools assisting in T&E/V&V requirements development and
analysis, (2) further adoption of evidence-based design and
implementation, (3) employment of cumulative evidence through the
research and development, test and evaluation, developmental testing,
and operational testing phases of system life cycle, (4) adoption of
methods for run-time behavior prediction and recovery, and (5)
development of assurance arguments for autonomous systems. The working
group has established a charter, published an investment strategy, and
developed a strategic roadmap. The working group has presented its
investment strategy to the UAST and each group has presented its
projects to the other group. The Autonomy COI is directly supporting
the ongoing TRMC sponsored T&E study administered by the Georgia Tech
Research Institute. The study's objective is to evaluate the adoption
of a pedigree-based licensure paradigm, vice certification, for future
autonomous systems.
Mr. Wilson. What opportunities exist to conduct testing or
experimentation with our international partners, including
international non-governmental organizations?
Dr. Bornstein. The Department of Defense (DOD), through the
Services or jointly through the Office of the Secretary of Defense
(OSD), maintains a robust set of relations with international partners
under established cooperative research, development, testing and
evaluation bilateral or multilateral agreements. On the topic of
robotics, the Army maintains agreements with Australia, Canada, France,
Germany, Israel, Japan, Korea, and the United Kingdom. In past years,
the Army conducted a joint competition with the Australian Defense
Science and Technology Office specifically focused on small autonomous
ground robotic vehicles conducting intelligence, surveillance, and
reconnaissance (ISR) missions in complex environments; the final
competition was held in Adelaide, Australia. Over the course of the
next few months, Army personnel are scheduled to visit their government
counterparts in France and Israel to discuss specific collaborative
research opportunities in robotics, autonomy and unmanned vehicles. The
Army is also conducting exploratory discussions in the area of robotics
with potential new partners, such as India and Singapore. Over the past
18 months, two projects have been under discussion between DOD and
India's Center for Artificial Intelligence and Robotics (CAIR) focusing
on ``Improving Cognitive and Artificial Cognition Models'' and ``Small
Intelligent Autonomous System for Situational Awareness.''
DOD researchers are actively involved in The Technical Cooperation
Program (TTCP), a joint research collaboration among the defense
establishments of the US, UK, Canada, Australia, and New Zealand. The
Autonomy Strategic Challenge Group within the TTCP envisions manned and
unmanned assets working in concert, employing autonomy technologies to
efficiently and cost-effectively support joint coalition force
structures. To this end, the group is developing a set of challenge
problems to collectively advance autonomy technology.
In addition, initiatives such as the Engineer and Scientist
Exchange Program (ESEP) and Cooperative Research and Development
Agreements (CRADA) offer DOD researchers the opportunity to conduct
joint projects addressing technology gaps and interoperability
solutions with foreign partners, either in government, academia or the
commercial sector. Under the ESEP, U.S. Defense personnel are
temporarily assigned to work in allied and friendly country defense
establishments on topics of shared strategic interest. CRADAs are
formal agreements between one or more Federal laboratories and one or
more non-Federal parties under which the parties provide personnel,
funds, facilities, equipment or other resources to conduct specific
research or development efforts.
Lastly, The Army uses two OSD programs in order to collaborate with
foreign partners--Coalition Warfare Program (CWP) and Foreign
Comparative Test (FCT). CWP supplements Army funding for specific
cooperative development projects with our allies and foreign partners.
The projects accomplish mutual research, development, and
interoperability goals through equitable contributions from all
partnering nations. The FCT program typically involves U.S. purchase of
foreign materials/products in order to test and evaluate novel
technologies.
______

QUESTIONS SUBMITTED BY MR. LANGEVIN
Mr. Langevin. All witnesses, how are you leveraging the
Department's laboratory enterprise and academic relations for advances
in autonomous capabilities, in addition to industry?
Dr. Zacharias. The Air Force is leveraging the Department's
laboratory enterprise and academic relations extensively for advances
in autonomous capabilities. As mentioned in my written statement, the
Air Force's primary agent for autonomy research, the Air Force Research
Laboratory (AFRL), commissioned the development of the AFRL Science and
Technology (S&T) Autonomy Vision and Strategy in 2013. This document
identifies the major goals, technical challenges, and investment
strategies needed to discover, develop, and demonstrate warfighter-
relevant autonomy S&T to maintain and enhance air, space, and
cyberspace dominance. This strategy has been coordinated with the other
services and with OSD through the Assistant Secretary of Defense for
Research and Engineering's (ASD(R&E)) Autonomy Community of Interest
(COI). My written statement also went into detail on AFRL's autonomous
systems research and development efforts, on-going or planned. Some
examples of how the Air Force is leveraging the laboratory include:

AFRL's Human Effectiveness Directorate has an ISR Analyst
Test Bed which provides a research-representative Processing,
Exploitation and Dissemination (PED) cell for developing interfaces and
technologies. Outputs of this research, the Internet Relay Chat
Coordinate Extractor (ICE) and Enhanced Reporting Narrative Event
Streaming Tool (ERNEST), not only improve manpower efficiencies and
reduce airman workload, but also lay the groundwork for integrated
multi-INT autonomous processing and advance analyst cuing via
autonomous decision-aiding.

The current integration of an Auto Ground Collision
Avoidance System (Auto GCAS) into the Air Force's operational F-16
fleet is an example of how the focus on human-machine teaming and the
need to develop trust across the team can build acceptance of
autonomous systems within the Air Force. The system was developed
jointly by five organizations working closely together: AFRL; Lockheed
Martin's Advanced Development Programs (ADP), also known as the Skunk
Works; the Office of the Undersecretary for Personnel and Readiness;
NASA's Armstrong Flight Research Center; and the Air Force Test Center.

AFRL is currently collecting proposals for a Low Cost
Attritable Strike Unmanned Aerial System (UAS) Demonstration that will
design, develop, assemble, and test a technical baseline for a high
speed, long range, low cost, limited-life strike Unmanned Aerial System
(UAS). The program will also identify key enabling technologies for
future low cost attritable aircraft demonstrations, and provide a
vehicle for future capability and technology demonstrations. AFRL's
primary agent for interfacing with academia is the Air Force Office of
Scientific Research (AFOSR) which has two primary portfolios supporting
the advancement of autonomous capabilities: Computational Cognition and
Machine Intelligence and Trust and Influence. The Computational
Cognition and Machine Intelligence portfolio supports experimental
studies and computational modeling to allow autonomous systems and
mixed human-agent teams to achieve human-level performance with minimal
interaction and provide warfighters with decision-making support in
C4ISR environments. Examples of projects funded by this portfolio
include ``Neurocognitive Information Processing'' with Columbia
University, ``Circuit Models for Robust, Adaptive Neural Control'' with
Tulsa University, and ``Making and Keeping Informed Commitments in
Human-Machine Systems'' with the University of Michigan.
The Trust and Influence portfolio explores the sciences of reliance
(how do humans establish, maintain, and repair trust, in others and in
autonomous systems) and influence (how to shape the behavior,
attitudes, or beliefs of others). Examples of projects funded by this
portfolio include ``Stochastic Logical Reasoning for Autonomous Mission
Planning'' with Rensselaer Polytechnic Institute (RPI) and ``Findings
on Universal, Cross-Cultural Linguistic Features Associated with
Veracity and Deception'' with San Francisco State University.
Additionally, AFOSR has several portfolios with grants that are
directly applicable to autonomy. The Human Performance and Biosystems
portfolio has several grants on autonomy-related topics to include a
Center of Excellence named the Nature Inspired Sciences Flight
Technologies and Ideas (NIFTI). A Center of Excellence is a 5-year
program where an AFRL Technical Directorate partners with AFOSR to co-
fund a university or group of universities to develop a particular area
of science that the lab wants to eventually internalize. This
particular Center is at the University of Washington, but also includes
Maryland, Case Western Reserve, and Johns Hopkins Universities. There
is also a Partnership Agreement with the United Kingdom entitled
``Biologically Inspired Technologies for Unmanned Autonomous Systems.''
The Computational Mathematics and Optimization portfolios have
funded several tasks with the key-words of ``autonomous decision'',
``automated routing'', ``autonomous navigation'', ``automatic task
assignment'', and ``flocking''. From 2010 on, AFOSR has made between
$4M and $5M investment towards these topics. This includes a $500K/year
``lab-task'' (a 5-year award) to AFRL's Munitions Directorate which
operates as a Center of Excellence with multiple tasks performed by the
University of Florida and collaborators. The scope of work of the
Mathematical Modeling and Optimization Institute (MMOI) is varied and
was recently reviewed by the Air Force's Scientific Advisory Board with
positive feedback.
Mr. Langevin. All witnesses, have you received guidance or
direction on advancing autonomous capabilities as part of the Third
Offset Strategy?
Dr. Zacharias. The Air Force has not as of yet received official
guidance or direction on advancing autonomous capabilities as part of
the Third Offset Strategy but is posturing itself to be responsive to
any provided guidance and/or direction from the Office of the Secretary
of Defense.
In a recent speech at the Reagan Defense Forum, Deputy Secretary of
Defense Bob Work stated that the ``big idea'' behind the Third Offset
Strategy was ``human-machine collaboration and combat teaming.'' \1\ He
then said that this realization came from two major efforts: the Long
Range Research and Development Planning Program (LRRDPP) and the 2015
Defense Science Board summer study on autonomy.
---------------------------------------------------------------------------
\1\ ``Reagan Defense Forum: The Third Offset Strategy,'' As
Delivered by Deputy Secretary of Defense Bob Work, Reagan Presidential
Library, Simi Valley, CA, November 7, 2015
---------------------------------------------------------------------------
The AF was involved in LRRDPP over the last calendar year and is
currently awaiting guidance on what portions of the program to
implement. In his FY18 Air Force Science and Technology (S&T)
Programming Guidance (dated 27 Oct 2015), the Assistant Secretary of
the Air Force (Acquisition), Dr. William LaPlante, directed AFRL to
place emphasis on the LRRDPP as detailed in the FY17-21 Defense
Planning Guidance as it builds its FY18 budget input for its S&T
Program.
Based on AFRL's extensive portfolio for advancing autonomous
capabilities, as discussed in my written statement, I do not expect
that supporting LRRDPP recommendations will require significant changes
to existing programs.
Mr. Langevin. All witnesses, to what extent are you exploring
autonomy in cyber capabilities?
Dr. Zacharias. AFRL is exploring autonomy primarily for defensive
cyber capabilities. The two main efforts are the Autonomous Defensive
Cyber Operations program and the Cyber Grand Challenge (in
collaboration with DARPA), both of which are described below.
Additionally, we are beginning to apply machine learning capabilities
to the Command and Control (C2) cycle, allowing for multi-domain C2 to
occur across air, space, and cyberspace operations by having systems
make recommendations based off prior experience throughout the
planning, targeting, weaponeering, tasking, and assessment process.
We are moving from ``man in-the-loop'' to ``man on-the-loop'' and
allowing computers to carry out more of the workload, which provides
the potential to increase current decision-loop speed and quality.
Currently, effective cyber operations require that human operators make
complex decisions from massive amounts of data in near real time.
Incorrect decisions can arise from an operator missing a piece of
information. Correct conclusions may be reached manually, but if they
are not acted on in a certain timeframe (milliseconds or less), they
may not deliver the intended effect. Simply put, outpacing the decision
cycle of an adversary requires machine speeds. The Autonomous Defensive
Cyber Operations (ADCO) program's goal is to research approaches and
technologies to create force multipliers for cyber operations through
the use of machine learning and artificial intelligence. The team is
developing and demonstrating proofs of concept that integrate machine
leaning and artificial intelligence into defensive cyber operations
processes for the purposes of reducing the manual burden on Cyber
Protection Teams (CPTs). These proofs of concept will be used to assess
the effectiveness in these approaches, to understand the level of
confidence in autonomous defensive systems, and to identify legal and
policy challenges that must be overcome for the successful integration
of autonomy into defensive cyber operations. The Cyber Grand Challenge
(CGC) program requires teams to build fully automated systems that can
find vulnerabilities in software, prove that they have found the
vulnerability by synthesizing an input that will trigger the
vulnerability, patch and nullify the vulnerability with acceptable
performance overheads, and incorporate game theory to win a competition
where these machines are competing against each other.
The CGC's Qualification Event took place in June of 2015 with the
following highlights:
1.  Machines can find, prove, and fix almost all of the vulnerable
programs in the test space.
2.  Most vulnerabilities were patched within the first two hours of
the 24-hour competition. The machines found unintended vulnerabilities
that evaded even the software's authors without the need for source
code or debug symbols.
AFRL was involved in all aspects of the Qualification Event, but
specifically led the infrastructure design and post mortem analysis of
submissions. The machine versus machine competition will take place in
August of 2016.
Mr. Langevin. All witnesses, how are you leveraging the
Department's laboratory enterprise and academic relations for advances
in autonomous capabilities, in addition to industry?
Mr. Kelley. The Navy has a long history of advancing autonomous
Naval warfighting capabilities across all domains: air, ground, sea,
space, and cyber space. However, as the rate of change in the global
environment accelerates and the landscape of potential threats shifts
more rapidly than ever before, the DON recognizes that we must
accelerate the adoption of technological advances, to include
autonomous capabilities. To accelerate the development and Fleet
introduction of unmanned systems, the Department of the Navy recently
established the Deputy Assistant Secretary of the Navy for Unmanned
Systems (DASN (UxS)) and the Director, Unmanned Warfare Systems
Division (OPNAV N99). OPNAV N99, working closely with DASN (UxS), are
the Navy's innovation leaders to get emerging unmanned systems and
related capabilities to the Fleet quickly. Additionally, the Department
of the Navy (DON) has recently established the Naval Rapid Prototyping,
Experimentation, and Demonstration Office, within Deputy Assistant
Secretary of the Navy for Research, Development, Test and Evaluation
(DASN (RDT&E)). In this role, DASN (RDT&E) has been given authority to
leverage the Naval Science and Technology (S&T) community, the Naval
Research and Development Establishment (NR&DE), and our talented
Sailors and Marines.
The Navy also plans on leveraging its established business
processes and contracting vehicles to reach out to industry and
academia (including University-Affiliated Research Centers and
Federally Funded Research Centers). These processes are in place
through a variety of organizations such SYSCOMs, PEOs, and Warfare
Centers among others.
OPNAV N99, in coordination with DASN (UxS), is developing an
unmanned system autonomy strategy focused on a common, multi-domain
autonomy architecture which will leverage many of the autonomy
developments to date. The goal is to capitalize on these individual
system developments to form a more complete, modular system that is
capable of operating on not just a single system, but rather across
systems and across domains. With the increasing numbers of expected
unmanned systems coming in the future years, this is a sustainable
method for autonomy development.
Mr. Langevin. All witnesses, have you received guidance or
direction on advancing autonomous capabilities as part of the Third
Offset Strategy?
Mr. Kelley. The Navy is aware of the key role of autonomous
capabilities as part of the Third Offset Strategy. The Navy has been
advancing autonomous capabilities for several years through science and
technology investments and our unmanned system programs. The Navy will
continue to identify how we can further advance these capabilities and
rapidly introduce them to the Fleet in order to achieve the Third
Offset Strategy.
Mr. Langevin. All witnesses, to what extent are you exploring
autonomy in cyber capabilities?
Mr. Kelley. Adversarial cyber interaction occurs at a speed beyond
what human can comprehend. The complexity and internal operating speed
of cyber systems are many orders of magnitude beyond what human
operator can timely observe, comprehend and response, resulting in the
defender total reliance to forensic (after the fact) process, which may
result in significant damage and expensive recovery.
Full autonomy in cyber space is a long term goal of the Navy's
cyber security research at ONR for both the computing devices and the
networking infrastructure. By full autonomy, we mean a system that
closes the loop of sensing, analyzing, planning and taking action at
cyber speed. Autonomic cyber systems employ machine-situational
awareness and advanced machine reasoning to understand their operating
status and environment, plan for actions, mitigate and inoculate
against cyber exploits.
For near and mid-term, we are developing technologies for
automating sensing, analysis and recommending plans for actions to
human operator.
Mr. Langevin. All witnesses, how are you leveraging the
Department's laboratory enterprise and academic relations for advances
in autonomous capabilities, in addition to industry?
Dr. Bornstein. The U.S. Army Research Development and Engineering
Command's (RDECOM) Army Research Lab's (ARL) Open Campus is a
collaborative business model, with the goal of building a science and
technology ecosystem that will support groundbreaking advances in basic
and applied research areas of relevance to the Army. The global
academic community, industry, small businesses, and other government
laboratories benefit from this collaboration with ARL's specialized
research staff and unique technical facilities. These collaborations
will build research networks, explore complex and singular problems,
enable self-forming expertise-driven team building that will be well-
positioned for competitive research opportunities, and expose
scientists, engineers, including professors and students, to realistic
research applications and perspectives. Specific to autonomous
capabilities research, ARL's campus features a 9,800 square foot Urban
Experimental Facility for autonomous systems and sensing.
The tools available to aid the laboratory in its collaborative
business model through Open Campus include Educational Partnership
Agreements (EPAs) and Cooperative Research and Development Agreements
(CRADAs).
EPAs are used to encourage and enhance education and research
opportunities with academia in science, technology, engineering and
mathematics disciplines relevant to ARL science and technology
programs. Under EPAs, visiting students have access to world-class
research facilities and are able to work side-by-side with subject-
matter experts in their fields of interest. In turn, ARL is able to
increase the awareness and visibility of technologies developed by the
military and to encourage and enhance study in scientific disciplines
at all levels of education.
CRADAs provide an easy way to collaborate with ARL. A CRADA is a
formal agreement between one or more Federal laboratories and one or
more non-Federal parties under which the Government, through its
laboratories, provides personnel, facilities, equipment or other
resources with or without reimbursement (but not funds to non-Federal
parties). The non-Federal parties provide personnel, funds, services,
facilities, equipment or other resources to conduct specific research
or development efforts that are consistent with the mission of the
laboratory.
Mr. Langevin. All witnesses, have you received guidance or
direction on advancing autonomous capabilities as part of the Third
Offset Strategy?
Dr. Bornstein. At this time, there has not been any specific
guidance nor direction on advancing autonomous capabilities
specifically as part of the Third Offset Strategy. However, the Army is
leading the DOD's revolutionary approach to aviation development with
Future Vertical Lift (FVL), an initiative to develop the next
generation of vertical lift aircraft for the Joint Warfighter, with the
goal of getting to low-rate production by 2030. The Army Science and
Technology Joint Multi-Role Technology Demonstrator (JMR TD) effort
will inform technology options and reduce risk for the FVL program of
record. The JMR TD effort will demonstrate optionally piloted or
autonomous flight capabilities. The Army is also involved in manned-
unmanned teaming efforts such as flying AH-64 Apache helicopters
together with Gray Eagle and Shadow UAVs as, effectively, remotely
controlled extensions of the manned Apache's onboard sensors.
Mr. Langevin. All witnesses, to what extent are you exploring
autonomy in cyber capabilities?
Dr. Bornstein. The Army is conducting R&D efforts on a number of
topics that will help enhance autonomous capabilities of cyber
technologies, such as autonomous agents operating on the network to
detect, mitigate, and prevent cyber threats. These efforts include the
following:

Research on unsupervised learning for detection of cyber
compromises, particularly relevant to autonomous systems that operate
for a relatively prolonged time under cyber threats and possibly with
limited opportunities for human intervention.

Research on ``light-weight'' cyber intrusion detection
agents, which can be deployed on platforms with constrained
computational power.

Research on autonomous self-patching of cyber
vulnerabilities as they are uncovered, especially on mobile tactical
devices.

Research on agile (and largely autonomous)
reconfiguration of networks and entities on the networks, to minimize
exposure to cyber threats or contain an already inflicted cyber damage.

Development of algorithms that can map cyber threat to
mission impact to provide traceability between intruder actions and
Brigade Combat Team (BCT) networks and autonomy enabled platforms.

Development of correlation algorithms to fuse defensive
cyber, spectrum awareness, offensive cyber, and network awareness
information to enable BCT analysts to perform internal hunt activities
in an incident friendly environment.
The Army is also assessing the impact of the cyber threat to future
autonomous systems; developing cyber behavior monitoring models/
techniques for tactical radio waveforms to enable anomalous behavior
detection; developing trusted authentication techniques that do not
rely on reach-back to centralized authorities; conducting research to
track data flows, monitor data modification, and ensure trusted
pedigree of information across the tactical network; and researching
cyber containerization techniques to block and restrict the spread of
malware on tactical mission platforms.

[all]
