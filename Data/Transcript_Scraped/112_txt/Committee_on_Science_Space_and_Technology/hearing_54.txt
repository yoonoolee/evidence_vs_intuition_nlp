- FOSTERING QUALITY SCIENCE AT EPA: PERSPECTIVES ON COMMON SENSE REFORM (PART I AND PART II)

[House Hearing, 112 Congress]
[From the U.S. Government Publishing Office]

FOSTERING QUALITY SCIENCE AT EPA:
PERSPECTIVES ON COMMON SENSE REFORM
(PART I AND PART II)

=======================================================================

HEARING

BEFORE THE

SUBCOMMITTEE ON ENERGY AND
ENVIRONMENT

COMMITTEE ON SCIENCE, SPACE, AND TECHNOLOGY
HOUSE OF REPRESENTATIVES

ONE HUNDRED TWELFTH CONGRESS

FIRST & SECOND SESSION

__________

WEDNESDAY, NOVEMBER 30, 2011
and
FRIDAY, FEBRUARY 3, 2012

__________

Serial No. 112-54
and
Serial No. 112-59

__________

Printed for the use of the Committee on Science, Space, and Technology

Available via the World Wide Web: http://science.house.gov

U.S. GOVERNMENT PRINTING OFFICE
71-346                    WASHINGTON : 2011
-----------------------------------------------------------------------
For sale by the Superintendent of Documents, U.S. Government Printing Office,
http://bookstore.gpo.gov. For more information, contact the GPO Customer Contact Center, U.S. Government Printing Office. Phone 202�09512�091800, or 866�09512�091800 (toll-free). E-mail,
[email protected]
.

COMMITTEE ON SCIENCE, SPACE, AND TECHNOLOGY

HON. RALPH M. HALL, Texas, Chair
F. JAMES SENSENBRENNER, JR.,         EDDIE BERNICE JOHNSON, Texas
Wisconsin                        JERRY F. COSTELLO, Illinois
LAMAR S. SMITH, Texas                LYNN C. WOOLSEY, California
DANA ROHRABACHER, California         ZOE LOFGREN, California
ROSCOE G. BARTLETT, Maryland         BRAD MILLER, North Carolina
FRANK D. LUCAS, Oklahoma             DANIEL LIPINSKI, Illinois
JUDY BIGGERT, Illinois               GABRIELLE GIFFORDS, Arizona
W. TODD AKIN, Missouri                   (Resigned from Congress on
RANDY NEUGEBAUER, Texas                  January 25, 2012)
MICHAEL T. McCAUL, Texas             DONNA F. EDWARDS, Maryland
PAUL C. BROUN, Georgia               MARCIA L. FUDGE, Ohio
SANDY ADAMS, Florida                 BEN R. LUJAN, New Mexico
BENJAMIN QUAYLE, Arizona             PAUL D. TONKO, New York
CHARLES J. ``CHUCK'' FLEISCHMANN,    JERRY McNERNEY, California
Tennessee                        JOHN P. SARBANES, Maryland
E. SCOTT RIGELL, Virginia            TERRI A. SEWELL, Alabama
STEVEN M. PALAZZO, Mississippi       FREDERICA S. WILSON, Florida
MO BROOKS, Alabama                   HANSEN CLARKE, Michigan
ANDY HARRIS, Maryland                VACANCY
RANDY HULTGREN, Illinois
CHIP CRAVAACK, Minnesota
LARRY BUCSHON, Indiana
DAN BENISHEK, Michigan
VACANCY
------

Subcommittee on Energy and Environment

HON. ANDY HARRIS, Maryland, Chair
DANA ROHRABACHER, California         BRAD MILLER, North Carolina
ROSCOE G. BARTLETT, Maryland         LYNN C. WOOLSEY, California
FRANK D. LUCAS, Oklahoma             BEN R. LUJAN, New Mexico
JUDY BIGGERT, Illinois               PAUL D. TONKO, New York
W. TODD AKIN, Missouri               ZOE LOFGREN, California
RANDY NEUGEBAUER, Texas              JERRY McNERNEY, California
PAUL C. BROUN, Georgia
CHARLES J. ``CHUCK'' FLEISCHMANN,
Tennessee
RALPH M. HALL, Texas                 EDDIE BERNICE JOHNSON, Texas

C O N T E N T S

November 30, 2011

Page
Witness List.....................................................     2

Hearing Charter..................................................     3

Opening Statements

Statement by Representative Andy Harris, Chairman, Subcommittee
on Energy and Environment, Committee on Science, Space, and
Technology, U.S. House of Representatives......................     9
Written Statement............................................    10

Statement by Representative Brad Miller, Ranking Member,
Subcommittee on Energy and Environment, Committee on Science,
Space, and Technology, U.S. House of Representatives...........    11
Written Statement............................................    12

Witnesses:

Ms. Susan Dudley, Director, Regulatory Studies Center, and
Research Professor of Public Policy & Public Administration,
The George Washington University
Oral Statement...............................................    14
Written Statement............................................    15

Dr. Alan Moghissi, President, Institute for Regulatory Science
Oral Statement...............................................    19
Written Statement............................................    20

Dr. Kenneth Green, Resident Scholar, American Enterprise
Institute
Oral Statement...............................................    26
Written Statement............................................    28

Dr. Gary Marchant, Professor of Law and Executive Director,
Center for Law, Science & Innovation, Arizona State University
Oral Statement...............................................    31
Written Statement............................................    33

Discussion
...............................................................    36

Appendix I: Answers to Post-Hearing Questions

Ms. Susan Dudley, Director, Regulatory Studies Center, and
Research Professor of Public Policy & Public Administration,
The George Washington University...............................    54

Dr. Alan Moghissi, President, Institute for Regulatory Science...    57

Dr. Kenneth Green, Resident Scholar, American Enterprise
Institute......................................................    61

Dr. Gary Marchant, Professor of Law and Executive Director,
Center for Law, Science & Innovation, Arizona State University.    67

C O N T E N T S

February 3, 2012

Page
Witness List.....................................................    70

Hearing Charter..................................................    71

Opening Statements

Statement by Representative Andy Harris, Chairman, Subcommittee
on Energy and Environment, Committee on Science, Space, and
Technology, U.S. House of Representatives......................    76
Written Statement............................................    76

Statement by Representative Brad Miller, Ranking Minority Member,
Subcommittee on Energy and Environment, Committee on Science,
Space, and Technology, U.S. House of Representatives...........    77
Written Statement............................................    78

Witnesses:

Mr. Daniel Greenbaum, President and Chief Executive Officer,
Health Effects Institute
Oral Statement...............................................    80
Written Statement............................................    81

Dr. Deborah Swackhamer, Professor, Environmental Health Sciences,
University of Minnesota, and Chairwoman, EPA Science Advisory
Board
Oral Statement...............................................    85
Written Statement............................................    86

Mr. Michael Walls, Vice President, Regulatory and Technical
Affairs, American Chemistry Council
Oral Statement...............................................    88
Written Statement............................................    89

Dr. Richard Belzer, President, Regulatory Checkbook
Oral Statement...............................................    96
Written Statement............................................    98

Dr. Jerald Schnoor, Allen S. Henry Chair in Engineering,
Department of Civil and Environmental Engineering, University
of Iowa
Oral Statement...............................................   115
Written Statement............................................   116

Dr. S. Stanley Young, Assistant Director for Bioinformatics,
National Institute of Statistical Sciences
Oral Statement...............................................   123
Written Statement............................................   124

Discussion
...............................................................   125

Appendix I: Answers to Post-Hearing Questions

Mr. Daniel Greenbaum, President and Chief Executive Officer,
Health Effects Institute.......................................   140

Dr. Deborah Swackhamer, Professor, Environmental Health Sciences,
University of Minnesota, and Chairwoman, EPA Science Advisory
Board..........................................................   144

Mr. Michael Walls, Vice President, Regulatory and Technical
Affairs, American Chemistry Council............................   147

Dr. Richard Belzer, President, Regulatory Checkbook..............   155

Dr. Jerald Schnoor, Allen S. Henry Chair in Engineering,
Department of Civil and Environmental Engineering, University
of Iowa........................................................   179

Dr. S. Stanley Young, Assistant Director for Bioinformatics,
National Institute of Statistical Sciences.....................   188

Appendix II: Additional Materials for the Record

Reprint from American Journal of Entomology: ``Reproducible
Epidemiologic Research''.......................................   194

``Deming, Data and Observational Studies'': Article by S. Stanley
Young and Alan Karr............................................   201

FOSTERING QUALITY SCIENCE AT EPA:
PERSPECTIVES ON COMMON SENSE REFORM
(PART I)

----------

WEDNESDAY, NOVEMBER 30, 2011

House of Representatives,
Subcommittee on Energy and Environment,
Committee on Science, Space, and Technology,
Washington, D.C.

The Subcommittee met, pursuant to call, at 2:13 p.m., in
Room 2318 of the Rayburn House Office Building, Hon. Andy
Harris [Chairman of the Subcommittee] presiding.

Chairman Harris. The Subcommittee on Energy and Environment
will come to order. Good afternoon. Welcome to today's hearing
entitled ``Fostering Quality Science at EPA: Perspectives on
Commonsense Reform.'' In front of you are packets containing
the written testimony, biographies, and truth in testimony
disclosures for today's witness panel.
I now recognize myself for five minutes for an opening
statement.
I want to welcome everyone to this afternoon's hearing.
This is the second in a series of hearings this Subcommittee
will be conducting to provide ideas and guidance to reform
science at EPA. Unfortunately, the Environmental Research,
Development, and Demonstration Authorization Act or ERDDA,
which is the statute authorizing R&D at EPA, as well as the
Science Advisory Board, was last reauthorized for fiscal year
1981. Thirty years of Congressional neglect and the aggressive
and unjustified regulatory train wreck being pursued by this
Administration make the time right to evaluate reforms to
environmental science at the agency.
Many things have changed since 1981 that demand renewed
Congressional attention. Funds appropriated to EPA science and
technology account have more than tripled from 1981 to 2010,
and the agency's overall budget has ballooned to almost $9
billion. The agency now employs almost 18,000 people and
maintains nearly 40 laboratories.
According to the Office of Management and Budget the
overall effect of all major federal regulations in 1981, were a
net cost savings of $1 billion. In contrast, in 2010, EPA's
major rules alone represented over 23 billion in costs, a
figure itself that many believe is a significant underestimate,
and there have been disagreements as to the real benefits of
these regulations.
There are also very pragmatic reasons for us to be keenly
interested in reforming and reauthorizing science activities at
the EPA. Given the dire fiscal straits that our country is
facing, programs, activities, and agencies that are operating
under expired or outdated authorizations will have targets on
their backs as we seek to get our budgetary house in order.
In light of this the right reforms to EPA R&D programs will
not only improve trust in the science that informs regulatory
decisions but will also provide a framework to prioritize the
most important functions and reduce unnecessary and wasteful
spending elsewhere.
For instance, despite 1.2 million examples of successful
hydraulically-fractured wells, the agency is moving forward
with an unnecessary study in the area.
Some basic questions need to be asked. What should the role
of EPA be in conducting research? Should it be limited to
fundamental research? Should R&D be limited to supporting the
agency's regulatory agenda? What is the relationship between
EPA's science and policymaking missions? And how do we prevent
the politicizing of scientific activities? How can Congress
best ensure regulatory science that is reliable, peer-reviewed,
transparent, understandable, and objective? Are structural
changes necessary to improve the quality and independence of
the agency's scientific advisory bodies? And do we have our
environmental priorities right? And are we getting the most
environmental bang for our buck?
This hearing follows up on testimony received two weeks ago
from officials at the EPA's Office of Research and Development,
Office of the Inspector General, and the Government
Accountability Office.
Furthermore, in order to build a substantive record this is
actually the ninth hearing on science and process at the EPA
that this Committee has held so far in the 112th Congress. The
Committee has also sent a series of letters to EPA and the
Administration requesting further information about policies on
transparency, cost benefit analysis, and peer review.
Unfortunately, we are still waiting for responses to four
letters sent since September.
Reforming environmental science should not be a partisan
issue, as the 2009 report by the Bipartisan Policy Center's
Science for Policy Project co-chaired by the former chair of
the full Science Committee, Sherry Boehlert, explained, ``A
tendency to frame regulatory issues as debates solely about
science, regardless of the actual subject in dispute, is at the
root of the stalemate and acrimony all too present in the
regulatory system today.''
The report went on to recommend that Congress should
include their recommendations, ``In legislation as relevant
programs are reauthorized,'' including suggesting the studies
used in developing regulations should be subject to data access
requirements, agencies and advisory bodies should be
transparent in their approach to evaluating weighing studies,
and that agencies should explicitly differentiate between
scientific judgments and policy judgments.
These are reasonable core principles that I hope both sides
can agree upon and which will advance fulfillment of the
President's executive order requiring that, ``Our regulatory
system must be based on the best available science.''
The diverse set of witnesses with us today will offer their
views on these and other EPA scientific reform ideas and offer
recommendations for improving and clarifying environmental R&D
priorities. I hope these suggestions will highlight some
potential avenues for bipartisan cooperation as our
Subcommittee continues its work on these issues.
Again, I want to thank all the witnesses for appearing
before the Subcommittee, and I look forward to a constructive
discussion.
[The prepared statement of Mr. Harris follows:]

Prepared Statement of Chairman Andy Harris

I want to welcome everyone to this afternoon's hearing on Fostering
Quality Science at EPA: Perspectives on Common Sense Reform.
This is the second in a series of hearings this Subcommittee will
be conducting to provide ideas and guidance to reform science at EPA.
Unfortunately, the Environmental Research, Development and
Demonstration Authorization Act, or ERDDAA (ERDDA), which is the
statute authorizing R&D at EPA as well as the Science Advisory Board,
was last reauthorized for fiscal year 1981. Thirty years of
Congressional neglect and the aggressive and unjustified regulatory
train wreck being pursued by this administration make the time ripe to
evaluate reforms to environmental science at the Agency.
Many things have changed since 1981 that demand renewed
Congressional attention. Funds appropriated to EPA's science and
technology account have more than tripled from 1981 to 2010, and the
Agency's overall budget has ballooned to almost $9 billion dollars. The
Agency now employs almost 18,000 people, and maintains nearly 40
laboratories. According to the Office of Management and Budget, the
overall effect of all major federal regulations in 1981 was a net cost
savings of $1 billion. In contrast, in 2010, EPA's major rules alone
represented over $23 billion in costs--a figure itself that many
believe is a significant underestimate and there have been
disagreements as to the real benefits of these regulations.
There are also very pragmatic reasons for us to be keenly
interested in reforming and reauthorizing science activities at the
EPA. Given the dire fiscal straits that our country is facing,
programs, activities, and agencies that are operating under expired or
outdated authorizations will have targets on their backs as we seek to
get our budgetary house in order. In light of this, the right reforms
to EPA R&D programs will not only improve trust in the science that
informs regulatory decisions, it will also provide a framework to
prioritize the most important functions and reduce unnecessary and
wasteful spending elsewhere. For instance, despite 1.2 million examples
of successful hydraulically-fractured wells, the Agency is moving
forward with an unnecessary study in this area.
Some basic questions need to be asked: What should be the role of
EPA in conducting research? Should it be limited to fundamental
research? Should R&D be limited to supporting the Agency's regulatory
agenda? What is the relationship between EPA's science and policymaking
mission, and how do we prevent the politicizing of scientific
activities? How can Congress best ensure regulatory science that is
reliable, peer reviewed, transparent, understandable, and objective?
Are structural changes necessary to improve the quality and
independence of the Agency's scientific advisory bodies? And do we have
our environmental priorities right, and are we getting the most
environmental bang-for-our-buck?
This hearing follows up on testimony received two weeks ago from
officials from EPA's Office of Research and Development, Office of the
Inspector General, and the Government Accountability Office.
Furthermore, in order to build a substantive record, this is actually
the ninth hearing on science and process at the Environmental
Protection Agency that this Committee has held so far in the 112th
Congress. The Committee has also sent a series of letters to EPA and
the Administration requesting further information about policies on
transparency, cost-benefit analysis, and peer review. Unfortunately, we
are still waiting for responses to four letters sent since September.
Reforming environmental science should not be a partisan issue. As
a 2009 report by the Bipartisan Policy Center's Science for Policy
Project, co-chaired by the former Chair of the full Science Committee,
Sherry Boehlert, explained: ``A tendency to frame regulatory issues as
debates solely about science, regardless of the actual subject in
dispute, is at the root of the stalemate and acrimony all too present
in the regulatory system today.'' The report went on to recommend that
Congress should include their recommendations ``in legislation as
relevant programs are reauthorized,'' including suggesting that studies
used in developing regulations should be subject to data access
requirements, agencies and advisory bodies should be transparent in
their approach to evaluating and weighing studies, and that agencies
should explicitly differentiate between scientific judgments and policy
judgments.
These are reasonable core principles that I hope both sides can
agree on and which will advance fulfillment of the President's
executive order requiring that ``Our regulatory system . . . must be
based on the best available science.''
The diverse set of witnesses with us today will offer their views
on these and other EPA scientific reform ideas, and offer
recommendations for improving and clarifying environmental R&D
priorities. I hope these suggestions will highlight some potential
avenues for bipartisan cooperation as our Subcommittee continues its
work on these issues.
I want to thank the witnesses for appearing before the Subcommittee
and I look forward to a constructive discussion.

Chairman Harris. The chair now recognizes Mr. Miller, the
Ranking Member, for five minutes for an opening statement.
Mr. Miller. Thank you, Mr. Chairman. I appreciate your
accommodating me by beginning slightly early this afternoon to
allow me to cast votes in the Financial Services Committee, and
I would also like to make this Committee's efforts in rewriting
the authorization statute to be a bipartisan effort. I
appreciate your willingness to work with us to try to make
future hearings more useful to the Committee in informing that
important work.
Today the Subcommittee meets again for part two of the EPA
research and science, series of hearings. The first hearing two
weeks ago was disappointing and a missed opportunity. The
stated purpose of the hearing a couple weeks ago was to examine
the ability of EPA's research enterprise to meet the agency's
mission to protect public health and the environment.
However, many of my colleagues decided instead to use their
time to focus on EPA's hydraulic fracturing study rather than
on that stated purpose. I believe the goal of this series of
hearings should be to establish a useful Committee record to
prepare the right legislation to reauthorize the Environmental
Research, Development, and Demonstration Authorization Act,
ERDDA.
Today's hearing does not appear to be any more likely to
inform the Committee about structural and substantive concerns
of stakeholders related to EPA's research activities, and it is
not a balanced, comprehensive, or even a helpful hearing. This
hearing looks like what we are seeing on the House Floor this
week, a platform for anti-regulation, anti-science talking
points, and as I said a couple of weeks ago, I hope that my
Republican counterparts are truly interested in reform that
will lead to better research to enhance public health and
protect the environment.
Although we all agree that there are legitimate concerns
related to EPA's research enterprise, this hearing doesn't
really help us understand or address those issues. The agency's
scientific research is important as more complex environmental
issues emerge and evolve that need to be understood and
addressed. Scientific research knowledge and technical
information are fundamental to EPA's mission and inform its
standard setting, regulatory compliance, and enforcement
functions. That is why Congress saw fit to create advisory
bodies at EPA like the Clean Air Scientific Advisory Committee,
which was created to provide independent advice on the science
and allow the Administrator to make regulatory decisions.
I really hope today that we would have a productive
conversation about how best to position EPA to perform that
mission, protecting human health and the environment. And if we
are really serious about working towards reauthorizing ERDDA,
which does need to be done as the Chairman said, after 30 years
perhaps it is wise to revisit that statute, we must establish a
Committee record that will offer us a wide range of views on
how best to draft legislation that would serve the agency
better, as well as the people that we all represent.
If that is the case, I hope that we can commit to working
together after today to put together hearings and panels that
will serve that purpose.
And with that, Chairman Harris, I yield back.
[The prepared statement of Mr. Miller follows:]

Prepared Statement of Ranking Member Brad Miller

Thank you Chairman Harris. Today the Subcommittee meets again for
part two of the EPA research and science series of hearings. The first
hearing two weeks ago was pretty disappointing and a missed
opportunity. The stated purpose of our hearing a couple of weeks ago
was to examine the ability of EPA's research enterprise to meet the
agency's mission to protect public health and the environment. However
many of my colleagues on the other side of the aisle decided to use
their time to focus on EPA's hydraulic fracturing study rather than on
that stated purpose. I believe the goal of this series of hearings is
to establish a useful Committee record in preparation of writing
legislation to reauthorize the Environmental Research, Development, and
Demonstration Authorization Act (ERDDA).
Today's hearing does not appear to be any more likely to inform the
Committee about structural and substantive concerns of stakeholders
related to EPA's research activities. It is not balanced,
comprehensive, or even helpful. This hearing looks just like what we
are seeing on the House floor this week--the anti-regulation, anti-
science talking points of the far right. As I said a couple of weeks
ago, I hoped that my Republican counterparts were really interested in
reform that will lead to better research to enhance public health and
protect the environment. Although we all agree that there are
legitimate concerns related to EPA's research enterprise, this hearing
doesn't come close to helping us understand or address these issues.
The agency's scientific research is important as more complex
environmental issues emerge and evolve that need to be understood and
addressed. Scientific research, knowledge, and technical information
are fundamental to EPA's mission and inform its standard-setting,
regulatory, compliance, and enforcement functions. That is why Congress
saw fit to create advisory bodies at EPA, such as the Clean Air
Scientific Advisory Committee (CASAC), which was created to provide
independent advice on the science which allows the Administrator to
make regulatory decisions.
I really hoped that today we would have a productive conversation
about how best to position the EPA to perform its mission of protecting
human health and the environment. If we are really serious about
working towards reauthorizing ERDDA, we must establish a Committee
record that will offer us a wide-range of views on how best to draft
legislation to better serve the agency as well as the people that we
all represent. If that is the case, I hope that we can commit to
working together after today in formulating hearings and panels that
will serve that purpose.
With that, Chairman Harris, I yield back.

Chairman Harris. Thank you very much, Mr. Miller.
If there are Members who wish to submit additional opening
statements, your statements will be added to the record at this
point.
At this time I would like to introduce our witness panel.
Again, I want to thank you for your patience. For the slightly
delayed start. Our first witness today is the Honorable Susan
Dudley, Director of the Regulatory Studies Center and Research
Professor of Public Policy and Public Administration at the
George Washington University. From April, 2007 through January,
2009, Professor Dudley served as the Presidentially-appointed
Administrator of the Office of Information and Regulatory
Affairs in the U.S. Office of Management and Budget.
The next witness will be Dr. Alan Moghissi, the President
of the Institute for Regulatory Science. Previously working for
EPA Dr. Moghissi managed numerous programs, including the Bio-
Environmental Radiological Program at the National
Environmental Research Center in Las Vegas, the Health and
Environmental Risk Analysis Program in Washington, DC. He was
also the Principle Science Advisor for Radiation and Hazardous
Materials and represented the Office of Research and
Development in a number of work groups responsible for drafting
environmental regulations.
The next witness is Dr. Kenneth Green, a Resident Scholar
at the American Enterprise Institute. Dr. Green has studied
public policy and regulation at Free Enterprise Think Tanks
across North America for nearly 20 years. An environmental
scientist by training, Dr. Green focuses on policy and
regulations involving energy and environmental health.
And the final witness today is Dr. Gary Marchant, Professor
of Law and Executive Director of the Center for Law, Science,
and Innovation at Arizona State University. Prior to joining
the ASU faculty in 1999, he was a partner in the Washington,
DC, law firm, Kirkland & Ellis, where his practice focused on
regulatory issues.
Thank you all for appearing before the Subcommittee today.
As our witnesses should know, spoken testimony is limited to
five minutes each, after which the Members of the Committee
will have five minutes each to ask questions.
I now recognize our first witness, Ms. Susan Dudley,
Director of the Regulatory Studies Center and Research
Professor of Public Policy and Public Administration at the
George Washington University.
Ms. Dudley.

STATEMENT OF MS. SUSAN DUDLEY, DIRECTOR,

REGULATORY STUDIES CENTER, AND RESEARCH PROFESSOR

OF PUBLIC POLICY AND PUBLIC ADMINISTRATION,

GEORGE WASHINGTON UNIVERSITY

Ms. Dudley. Thank you, Chairman Harris, Ranking Member
Miller, and Members of the Subcommittee. As you mentioned I am
at G.W. but my remarks here today are my own.
EPA regulations are often the subject of heated debate
involving accusations of politicized science and advocacy
science. While it is legitimate to be wary of policy officials
and politicians trying to influence scientific studies, more
often than not, these debates center on issues that science can
inform but not decide.
And I am actually going to read a quote from the Bipartisan
Policy Center Report that the chairman mentioned. In fact, you
read the same quote, but I am going to repeat it again. This is
the Bipartisan Policy Center Report, ``Improving the Use of
Science and Regulatory Policy.'' `` A tendency to frame
regulatory issues as debates solely about science, regardless
of the actual subject in dispute, is at the root of the
stalemate and acrimony all too present in the regulatory system
today.''
And I do highly recommend that report. I think it does show
that these issues are not partisan. Framing issues as debates
solely about science is problematic for two reasons.
First, while science is essential for understanding the
positive question of what is, it is less helpful for the
normative policy question of what should be. Sound policy
decisions depend not only on scientific assessments of risk but
also on other factors such as economics, ethics, law, and, yes,
politics, the will of the people.
Second, scientists will never have complete information to
predict outcomes with absolute certainty, so even the risk
assessment as opposed to the risk management phase of an
analysis depend on assumptions and judgments that guide the use
of scientific information.
Policymakers and the public are often unaware of the
influence of these risk assessment policy choices or the
existence of alternative assessments that are equally
plausible. Instead, assessments often generate precise-sounding
predictions that hide considerable uncertainty about the actual
risk and heavily are influenced by hidden judgments about what
policies should look like.
Institutional arrangements in the regulatory development
process tend to aggravate these problems, perpetuating the
charade that policies are based purely on science, insulating
experts involved in a particular rulemaking from dissenting
views, reinforcing preconceptions and biases, and leading to
regulatory policy decisions that are not at all transparent.
As the Committee evaluates approaches to address perceived
problems in the quality of EPA science, it is important to
identify whether the source of the problem is politicians
attempting to control science or the politicization of science,
or scientists attempting to control policy, something that
David Goldston, who was the Executive Director of the
Bipartisan Policy Center Project on this and now at NRDC, calls
that the scientification of policy.
My own experience supports the Bipartisan Policy Center's
conclusion that the latter problem is behind much of the
controversy related to science-based regulation. So with that
in mind, let me offer three modest recommendations.
One, recognize that science is a positive discipline that
can inform but not decide appropriate policy. Avoid the
temptation to delegate decisions to agencies on the pretense
that science alone can make the normative decision of what the
policy should be. I was going to quote again from the
Bipartisan Policy Center report, but I won't in the interest of
time.
My second recommendation to recognize that risk assessment
necessarily involves assumptions and judgments as well as pure
scientific inputs and establish procedures and incentives to
make more transparent risk assessment inputs in the range of
plausible outcomes.
The National Academies of Science has offered numerous
recommendations in this regard for improving the quality and
transparency of the EPA risk assessment, including in its
recent report earlier this year on the formaldehyde IRIS
process.
And my final recommendation is to increase the robustness
of regulatory science by institutionalizing feedback mechanisms
along with checks and balances. The scientific method depends
on falsifiable hypotheses, data gathering, dissent, and
challenge to ensure objective analysis to minimize bias in the
interpretation of results.
Now, no one is truly objective, so institutional reforms
that engage and encourage competing views could go a long way
to improve the clarity of the risk assessment process and the
decisions that depend on scientific input.
President Obama has taken some positive steps in this
regard, reinforcing interagency review and calling for more
open exchange with the public.
Other successful reforms might involve pre-rulemaking
disclosure of risk assessment information to engage broad
public comment on the proper choice of studies, models,
assumptions, et cetera, long before any policy decisions are
framed and positions are set in stone.
And with 1 second left I will stop. Thank you.
[The prepared statement of Ms. Dudley follows:]

Prepared Statement of Ms. Susan Dudley, Director,
Regulatory Studies Center, and Research Professor of Public Policy
& Public Administration, The George Washington University

Chairman Harris, Ranking Member Miller, and Members of the
Subcommittee, thank you for inviting me to testify today on ``Fostering
Quality Science at EPA: Perspectives on Common Sense Reforms.'' I am
Director of the George Washington University Regulatory Studies Center
and Research Professor in the Trachtenberg School of Public Policy and
Public Administration. \1\
---------------------------------------------------------------------------
\1\ The George Washington University Regulatory Studies Center
raises awareness of regulations' effects with the goal of improving
regulatory policy through research, education, and outreach. This
statement reflects my views, and does not represent an official
position of the GW Regulatory Studies Center or the George Washington
University.
---------------------------------------------------------------------------
From April 2007 to January 2009, I oversaw the executive branch
regulations of the federal government as Administrator of the Office of
Information and Regulatory Affairs (OIRA) in the Office of Management
and Budget (OMB). I have devoted my career to trying to improve both
the framework for developing regulations and our understanding of
regulations' effects, and for over three decades have examined
regulations from perspectives in government (as both a career civil
servant and political appointee), academia, consulting, and the non-
profit world.
***
EPA regulations intended to address public health and environmental
risks depend on scientific information. They are often the subject of
heated debate involving accusations of ``politicized science'' and
``advocacy science,'' as everyone--including scientists and agency
officials--wields scientific information in the service of advocacy.
While it is legitimate to be wary of politicians or policy officials
trying to influence scientific studies, more often than not, these
debates center on issues that science can inform, but not decide.
As the Bipartisan Policy Center, in its 2009 report, Improving the
Use of Science in Regulatory Policy, observed:

Political decision-makers should never dictate what scientific
studies should conclude, and they should base policy on a thorough
review of all relevant research and the provisions of the relevant
statutes. But some disputes over the ``politicization'' of science
actually arise over differences about policy choices that science can
inform, but not determine. (BPC 2009, 4)

Science is rarely sufficient for making policy decisions for two
reasons. First, while science is essential for understanding the
positive question of what is, or predicting what outcomes might derive
under different scenarios, it is less helpful for the normative
(policy) decisions regarding what should be. Sound policy decisions
depend not only on scientific assessments of risk, but also on other
factors, such as economics, ethics, law, and politics--the will of the
people.
Second, scientists will never have complete information to predict
outcomes with absolute certainty, so risk assessors use what the
National Research Council (NRC 1983) called ``risk assessment
policy''--assumptions and rules of thumb--to guide the use of
scientific information in analyses that inform policy in the face of
uncertainty.

In each step [of the risk assessment process], a number of decision
points (components) occur where risk to human health can only be
inferred from the available evidence. Both scientific judgments and
policy choices may be involved in selecting from among possible
inferential bridges, and we have used the term risk assessment policy
to differentiate those judgments and choices from the broader social
and economic policy issues that are inherent in risk management
decisions. (NRC)

Policymakers and the public are often unaware of the influence of
these risk assessment policy choices or the existence of alternative
assessments that are equally plausible. Instead, assessments often
generate precise-sounding predictions that hide considerable
uncertainty about the actual risk. Since EPA's stated policy is to err
on the side of overstating risk, it relies on one-sided policy choices
at each node in the risk assessment process. Policy decisions that are
reported as if they are based on science are heavily are influenced by
these hidden staff judgments about what policies should be.
While some judgment is necessary to translate scientific evidence
into risk assessment, current risk assessment policies lead to
distortions in risk estimates and false precision in the presentation
of scientific information. This threatens the scientific credibility of
the process, hiding rather than making transparent the uncertainty in
assessments of risk, putting key policy choices in the hands of staff,
and allowing policy makers to avoid making hard decisions.
When questions involving policy judgment and values are falsely
characterized as scientific, a small number of people have an effective
monopoly on the information that is used and how it is characterized,
leading to decisions that are not as accountable or as transparent as
they should be. ``When regulators purport to rely on science as the
sole basis for their policy choices, the real reasons justifying their
choices remain hidden from public view.'' (Coglianese 2009) This is
exacerbated by the adversarial nature of rulemaking, and group dynamics
that discourage differences of opinion and lead to poor decisions that
mask uncertainty and give short shrift to important factors and
perspectives.
Institutional arrangements in the regulatory development process
tend to aggravate these problems, perpetuating the charade that
policies are based purely on science, insulating experts involved in a
particular rulemaking from dissenting views, reinforcing preconceptions
and biases, and leading to regulatory policy decisions that are not at
all transparent.
Statutory mandates, such as those directing EPA to set National
Ambient Air Quality Standards (NAAQS) for ``criteria pollutants'' under
the Clean Air Act, can make inevitable the ``science charade,'' where
regulatory agencies ``camouflag[e] controversial policy decisions as
science.'' (Wagner 1995, 1614) Congress directs EPA to set NAAQS at a
level that is ``requisite to protect public health with an adequate
margin of safety,'' but restricts the agency from considering key
factors, establishing instead the pretense that science is sufficient
to determine a single point concentration that is ``requisite to
protect public health.'' The courts have reinforced a limited
interpretation of the Act, as well as tight deadlines for issuing
revised standards. Executive branch career and policy officials respond
by developing scientific-sounding explanations to justify one standard
over another. Analysts have an incentive to downplay rather than reveal
the implications of key risk assessment policy choices, and decision
makers point to science as either requiring a new standard or as being
so uncertain that a new standard cannot be set. The interagency review
process is often truncated by very short timeframes established by the
statute and reviewing courts, and constrained by the limited range of
options presented by EPA and its Clean Air Science Advisory Committee.
Public interveners vigorously defend alternative standards based on
their own interpretation of the science.
This has evolved into an adversarial process, characterized by
harsh rhetoric in which each party claims the science supports its
recommended policy outcome and questions opponents' credibility and
motives, rather than a constructive discussion regarding appropriate
assumptions and data and the reasonableness of the statutory goal. The
real reasons for selecting a non-zero standard are not transparent.
***
As the Subcommittee evaluates approaches to address perceived
problems with the ``quality, usefulness and objectivity of EPA
science,'' it is important to identify whether the source of the
problem is:

A.  politicians attempting to control science (``politicization of
science''), or

B.  scientists attempting to control policy (``scientification of
policy.'')

My own experience supports the BPC conclusion that this latter
problem is behind much of the controversy related to science-based
regulation, and is the main contributor to the science charade:

A tendency to frame regulatory issues as debates solely about
science, regardless of the actual subject in dispute, is at the root of
the stalemate and acrimony all too present in the regulatory system
today. (BPC 2009, 10)
Current procedures for developing regulations addressing health and
environmental risk blur the lines between science and policy, hindering
not only public policy decisions, but development of scientific
knowledge itself. Current institutions provide incentives to bury
policy judgments in analyses that are presented as science,
perpetuating the science charade.
Altering these incentives is challenging, and I appreciate this
Subcommittee's interest in this subject. In a chapter of a forthcoming
book, \2\ my coauthor Professor George Gray and I offer modest
suggestions aimed at increasing transparency in regulatory science,
strengthening the checks and balances provided by different
participants in the rulemaking process, and engaging a broad range of
expertise and perspectives to counter the problems insular decision-
making brings. Those suggestions are the basis for a few
recommendations to the Subcommittee.
---------------------------------------------------------------------------
\2\ Institutions and Incentives in Regulatory Science, Lexington
Books, Jason Johnston ed., forthcoming spring 2012.

1.  Recognize that ``science'' is a positive discipline that can
inform, but not decide, appropriate policy. Avoid the temptation to
delegate decisions to agencies on the pretense that ``science'' alone
---------------------------------------------------------------------------
can make the normative determination of what policy should be.

The BPC observed:

The first impulse of those concerned with regulatory policy should
not be to claim ``the science made me do it'' or to dismiss or discount
scientific results, but rather to publicly discuss the policies and
values that legitimately affect how science gets applied in decision
making. (BPC 2009, 4)
Distinguishing between science and policy is not always easy or
straightforward, and scientists may make choices based on values in the
course of their work. Nonetheless, policy debate would be clarified and
enhanced if a systematic effort were made to distinguish between
questions that can be resolved through scientific judgments and those
that involve judgments about values and other matters of policy when
regulatory issues comprise both. This transparency would both help
force values debates into the open and could limit spurious claims
about, and attacks on science. (BPC 2009, 15)

Legislators should also take care to limit the role of scientific
advisory panels to advising on science, and not to embed their policy
views in their scientific recommendations. The BPC recommended:

In general, scientific advisory panels should not be asked to
recommend specific regulatory policies. (BPC 2009, 5)

2.  Recognize that risk assessment necessarily involves assumptions
and judgments as well as pure scientific inputs, and establish
procedures and incentives to make more transparent risk assessment
inputs and the range of plausible outcomes.

Efforts to identify and characterize the uncertainty in scientific
evidence by quantifying the range of outcomes of potential regulatory
actions may provide useful data for improving risk assessment policy
choices and increasing confidence in decisions.

The BPC recommended:

In presenting the conclusions of literature reviews, agencies and
their scientific advisory committees need to be as open and precise as
possible in discussing levels of risk and uncertainty. Policy makers
should be wary of conclusions about risk that are expressed as a single
number. (BPC 2009, 8)

3.  Increase the robustness of regulatory science by
institutionalizing feedback mechanisms, checks, and balances.

Greater transparency in the models, assumptions, and risk
assessment policy choices could encourage more open, constructive
debate on those choices. The scientific method depends on falsifiable
hypotheses, data gathering, dissent, and challenge to ensure objective
analysis to minimize bias in the interpretation of results.
No one is truly objective. We all approach problems with our own
``priors'' and, particularly when faced with new or incomplete
information, we tend to look to others in whom we trust to help form
our opinions and make decisions. Cass Sunstein's interesting research
on ``why groups go to extremes'' shows that individuals form more
extreme views when surrounded by others with similar perspectives.
Institutional reforms that engage competing views could go a long way
to improve the clarity of the risk assessment process and the decisions
that depend on scientific input.
President Obama has built on his predecessors' efforts to provide
for interagency review of different aspects of regulatory decisions,
including the underlying science. He has directed agencies to encourage
an ``open exchange of information and perspectives among State, local,
and tribal officials, experts in relevant disciplines, affected
stakeholders in the private sector, and the public as a whole,
including relevant scientific and technical findings.''
Successful reforms might involve pre-rulemaking disclosure of risk
assessment information, to engage broad public comment on the proper
choice of studies, models, assumptions, etc. long before any policy
decisions are framed, and ``positions'' established.
***
I appreciate this Subcommittee's interest in improving how science
informs environmental regulation, and welcome opportunities to discuss
the likely effects of different reforms.
***

References

Breyer, S. (1993). Breaking the vicious circle: toward
effective risk regulation. Harvard Univ Pr.

The Bipartisan Policy Center (2009). Improving the Use of Science
in Regulatory Policy. http://www.bipartisanpolicy.org/library/report/
science-policy-project-final-report

Coglianese, C. U.S. House of Representatives, The
Committee on Science and Technology (2009). Testimony on the role of
science in regulatory reform. http://democrats.science.house.gov/Media/
file/Commdocs/hearings/2009/Oversight/30apr/Coglianese--Testimony.pdf

National Research Council (1983). Risk Assessment in the
Federal Government: Managing the Process. National Academy Press.

Sunstein, C. (2009). Going to Extremes: How Like Minds
Unite and Divide. Oxford University Pr.

Wagner, W.E. (1995). The science charade in toxic risk
regulation. Columbia Law Review, 95(1613).

Chairman Harris. Thank you very much.
I now recognize our second witness, Dr. Alan Moghissi, the
President of the Institute for Regulatory Science.

STATEMENT OF DR. ALAN MOGHISSI, PRESIDENT, INSTITUTE FOR
REGULATORY SCIENCE

Dr. Moghissi. Chairman Dr. Harris, Ranking Member Miller,
Members of the Subcommittee, as the chairman said my name is
Alan Moghissi, and I am the President of Institute for
Regulatory Science. We are not for profit organization
established in 1985, and we are in Alexandria, Virginia. We are
dedicated to the idea that societal decisions notably
environmental regulations must be based on what we call best
available science, and Mr. Chairman, you used that term, and
that was music to my ear.
And we define best available science if you go to our
website at www.nars.org, you will find upon the description of
BAS, my testimony to you is based on that, however, my--it is--
what I am doing today is my personal interpretation of BAS
rather than official pronouncement of the Institute for
Regulatory Science.
Although the term regulatory science is used extensively in
the interest of transparency, let me define it again.
Regulatory science consists of the scientific foundation of
policy, notably regulatory decisions. It is the science part of
the subject rather than societal implications of the regulatory
side.
Based on this definition the scientific activity of the EPA
are overwhelmingly regulatory science. I appreciate the
opportunity to testify before your Committee, and I am
proposing the Congress to enact the Regulatory Science Sunshine
Act, Regulatory Science Sunshine Act as a segment of the EPA
Authorization Appropriation or as a separate act.
My written testimony includes metrics for evaluation of
regulatory science information and regulatory science ethics.
My apologies that I cannot describe them because I needed more
than 1 hour to do so, and I have only five minutes.
Please note that the regulatory science information at best
in the metrics that I included partially reproducible evolving
science and often at lower maturity going all the way to scadon
to scientific judgment or even speculation. A characteristic of
the class I just described a partially reproducible evolving
science is that although its foundation is proven science and
uncontested, it often uses a macolic on the right side
described, assumptions, judgment, default data, and values if
the relevant data or values aren't all available and most
unfortunately as Mr. Chairman pointed out, on occasion it uses
societal adjustments that are outside the purview of science.
The proposed Regulatory Science Sunshine Act would require
that within the R&D Program EPA makes a concerted effort to
double up procedures, processes, and methods for each
regulatory science, regulatory decision that is based on or
includes science, one, identification of assumptions, judgment,
default data, any other similar system used in the regulatory
process, identification of potential alternatives, and how the
conclusions would be different if an alternative assumption,
judgment or similar parameters are used.
Two, description of the content of all mathematical
equations in words.
Three, information identified above must be written in a
language that is understandable to knowledgeable non-
specialists or better yet to an average person.
Clear and unambiguous justification for the inclusion of
societal objectives in science rather than addressing societal
objectives in the administrative decision process.
And obligation of EPA to comply with ethical requirement of
regulatory science.
I am a proud member of the--proud charter member of the EPA
and believe that EPA has done an outstanding job in protecting
human health and the environment. However, I would be less than
frank if I would not express my concern over certain decisions
that have had adverse societal including environmental
consequences.
There are those in the regulatory science community who
believe that members of the other scientific disciplines have
settled the general public without difficulties understanding
the complex nature of regular--of scientific--of regulations.
They are wrong. They are dead wrong.
Quoting Sir Thomas Jefferson as did my boss, Ruckelshaus,
``If we think the people are not enlightened enough to exercise
their control with a wholesome discretion, the remedy is not to
take it away from them but to inform their discretion.''
Thank you much.
[The prepared statement of Mr. Moghissi follows:]

Prepared Statement of Dr. Alan Moghissi, President, Institute for
Regulatory Science

Chairman Dr. Harris, Ranking Member Miller, and Members of the
Subcommittee; I am A. Alan Moghissi, President of Institute for
Regulatory Science (RSI). We were established in 1985 as a not-for-
profit organization located in Alexandria, VA and. We are dedicated to
the idea that societal decisions notably environmental regulations must
be based on what we call ``Best Available Science'' or BAS. I am a
proud charter member of the U.S. Environmental Protection Agency (EPA)
and believe that EPA has done an outstanding job in protecting human
health and the environment but I am less proud that EPA has missed some
opportunities to use BAS in its decisions. I appreciate the opportunity
to testify before your Committee and intend to suggest that the time
has come for the EPA to substantially expand transparency in the
scientific foundation of its regulatory activities.

Science at the EPA and the Establishment of Regulatory Science

Looking back at the history when EPA was formed, although there
were laws dealing with air, water, and food, the ability of government
to adequately regulate emission of toxic agents was limited. For
example, there was no law that provided government for regulating
manufacturing of chemicals. During that period the Congress quickly
passed a number of laws mandating promulgation of regulations at a
rapid pace. Upon the formation of the EPA, the managers and scientists
at that Agency were faced with the urgent need to promulgate a large
number of regulations based on deadlines mandated by legislative
actions or judicial decisions. This problem caused the EPA to rely upon
the judgment of scientists, short cutting scientific issues, and use
their best to meet the deadlines. During this initial phase of the EPA
the phrase regulatory science appeared describing the scientific
segments or parts of regulations. Meanwhile regulatory science is
defined as follows:

Regulatory science consists of the scientific foundation of policy
notably regulatory decisions

Regulatory science, sometimes called regulatory sciences, covers
many disciplines (Moghissi et al, 2011). It includes regulatory
toxicology, regulatory ecology, regulatory hydrology, and regulatory
atmospheric sciences, to mention a few. It is no different than other
disciplines such as chemistry discipline that covers, inorganic
chemistry, organic chemistry, biochemistry, physical chemistry,
chemical engineering, and medicinal chemistry, to mention a few.
As expected virtually all regulatory agencies must deal with
regulatory science in promulgating their regulations. For example the
Food and Drug Administration (FDA) has not only used that term to
describe its scientific objectives but also has devoted significant
funds for R&D devoted to regulatory science in areas of its regulatory
authority. Similarly, the EPA has an extensive regulatory science
program both in its R&D and program offices, although that term is not
always used in its pronouncements.
With the maturity of the EPA's regulatory process the EPA is
provided significant funding for R&D. A discussion of relevancy of
EPA's R&D to its mission, the quality of science used in its regulatory
process and related issues have been addressed numerous times and most
recently, in testimonies before this Committee (Anastas 2011, Trimble
2011, Elkins 2011). Therefore, this testimony will address the
transparency issue, a subject that appears to have been insufficiently
addressed. As stated above, during its initial phases of operation, EPA
was facing deadlines and had to go through shortcuts. Meanwhile, the
EPA has time to thoroughly evaluate the scientific foundation of its
regulations. An example of these regulations is emission limits being
considered for greenhouse gases. EPA did not face a deadline and based
on its own desire undertook the laborious and highly contested decision
to regulate greenhouse gases.
Subsequent to the formulation of the term regulatory science, my
colleagues and I tried to develop a systematic process for evaluation
of regulatory science information. We had to identify fundamental
principles not only for regulatory science but also for any scientific
claim. We had also to address how does an organization including a
regulatory agency assesses the reliability of a scientific claim
regardless of its origin. We struggled for many years to address the
level of maturity of scientific information. Finally, we had to address
the issue of science vs. areas outside the purview of science. These
efforts took over three decades and have reached sufficient maturity
that can be described here.

Metrics for Evaluation of Regulatory Science Information

As stated above, the development of the BAS system and Metrics for
Evaluation of Regulatory Science Information (MERSI) derived from BAS
was the result of extensive efforts to systematically evaluate a number
of issues addressing the needs of a large segment of the affected
communities, notably regulatory science. The development of MERSI was
the consequence of three previous publications. The first formal effort
Best Available Science; Its Evolution, Taxonomy and Applications
(Moghissi et al 2008) contained the fundamental concept of BAS. The
next attempt led to the publication of the book: Best Available
Science: Fundamental Metrics for Evaluation of Scientific Claims
(Moghissi et al 2010) that in many respect, was the second edition of
the first book. A new version of that book by Moghissi and Swetnam is
in preparation. During all of these activities the dominant role of
independent peer review in regulatory science was unambiguously
described. Consequently, it was logical to prepare a book Peer Review
and Scientific Assessment: A Handbook for Funding Organizations,
Regulator Agencies and Editors (Moghissi et al, in press) with
significant applicability to regulatory science.

Fundamental Principles of MERSI

Open-Mindedness Principle: This principle implies that the regulatory
science community and the general public must be willing to consider
new knowledge and new scientific claims.

Skepticism Principle: This principle requires that it is incumbent upon
those who make a scientific claim to provide sufficient evidence
supporting their claim. The Skepticism Principle provides balance and
ensures that the Open-Mindedness principle is not misused.

Universal Scientific Principles: The Universal Scientific Principles
are a set of basic principles and standards that apply to virtually all
of the scientific disciplines including regulatory sciences.

Transparency Principle: Those who make a scientific claim have not only
the intellectual but also the ethical obligation to identify the level
of maturity and reliability of each segment, and if societal or other
areas outside the purview of science are included in the claim.

Reproducibility Principle: Reproducibility is the proof of validity of
any scientific claim, and separates undisputed areas of science from
those that include assumptions and interpretations.

Pillar: Classification of Scientific Information

It is well established that science evolves and that new
discoveries, advancement of scientific knowledge, and numerous
technologies result from the evolution of science. Therefore, it is
necessary to classify scientific information (SI) in terms of its level
of maturity and its reproducibility.

Class I: Proven SI: This class consists of scientific laws (or
principles) and their application. The scientific foundation of
information included in this class is understood and meets the
requirements of the Reproducibility Principle. Scientific laws or
principles are predictable and reliable. As the majority of SI covered
in regulatory sciences seldom qualifies as Proven SI, further
discussion is not required.

Class II: Evolving SI. The overwhelming majority of scientific
advancements and virtually all regulatory science information are
included in this class.

Reproducible Evolving SI: Reliable and reproducible information
dealing with a subject that is not completely understood constitutes
the core of this class. Much of medical science provides a good example
of Reproducible Evolving Science. Like Class I (Proven SI) information
in this class meets the Reproducibility Principle. However unlike
Proven SI, the scientific foundation of information in this class is
often either unknown or the knowledge is incomplete.

Partially Reproducible SI: Sometimes referred to as Rationalized SI
or Scientific Extrapolation this class includes a large segment of
regulatory science information including predictive models. Although it
builds upon Proven or Reproducible Evolving SI, it uses assumptions,
extrapolations, and default data to derive its results. An important
characteristic of this class is its level of reproducibility. Whereas
the scientific foundation of this class meets the Reproducibility
Principle the choice of assumptions, mathematical processes, default
data, and numerous other prerequisites are inherently arbitrary and
thus are not necessarily reproducible.

Correlation-Based SI: This class attempts to correlate systematic
observations performed in accordance with Universal Scientific
Principles to an effect. There is an extensive literature covering this
class including a large segment of epidemiology. Experience shows that
correlation does not necessarily imply causation and as expected, some
correlations have correctly identified their cause but others have
proven to be unrelated. A segment of evidence-based medicine belongs to
this class.

Hypothesized SI: An organized response to an observation, an idea, or
any other initiating thought process constitutes the core of this
class. This class seldom if ever has a scientific foundation.
Obviously, this class does not comply with the Reproducibility
Principle.

SI based on Judgment: In the absence of scientific information,
decision makers may call upon scientific experts to make an educated
judgment. There is an accepted methodology for this process that
involves asking multiple qualified and knowledgeable individuals to
answer specific questions and statistically assessing the results. Even
so, the results are still tantamount to an educated guess.

Speculation: Speculation does not meet the standards for any of the
discussed classes of scientific information addressed above. It is
based solely on the opinion and intuition of an individual. Often the
objective of speculation is to initiate a research project or stimulate
a scientific discussion.

Fallacious Information: Most unfortunately, the scientific community
and the general public are often provided fallacious information
presented as science. Often called ``junk science'' or ``pseudo
science,'' some of the information provided to the regulators by
special interest groups qualifies as fallacious information.

Pillar: Reliability of SI

This Pillar requires a formal and generally acceptable process to
categorize the reliability of SI. Consequently, SI is divided into
several distinct categories in ascending level of reliability

Category I: Personal Opinions. Expression of views by individuals
regardless of their training, experience, and social agenda are seldom
reliable.

Category II: Gray Literature. Reports prepared by government
agencies, advocacy groups, and others that have not been subjected to
an independent peer review are included in this category. Gray
Literature is often no more reliable that personal opinion.

Category III: Peer-Reviewed SI. The acceptability of a scientific
claim requires that it has been subjected to independent peer review
and has passed the strict scrutiny by independent scientific peers.
Peer review is a well established process and issued extensively in
scientific publications and grant submission. Briefly, an acceptable
peer reviewer is an individual who is capable of understanding and
performing the project under review with little or no additional study.
Furthermore, the reviewer must also be independent and without conflict
of interest. Finally, (ASME/RSI2002) those who have a stake in the
outcome of the review may not act as reviewers or participate in the
selection of the reviewers. Despite its acknowledged shortcomings peer
review is the only available mechanism to assess the validity of a
scientific claim, aside from reproducing the actual claim.

CategoryIV: Consensus-Processed SI. In the consensus process an
expert panel, convened in a manner similar to that described for Review
Panels, evaluates the proposed information. Since much of regulatory
science falls into the Rationalized, Correlation-Based, or Hypothesized
SI, it is not surprising that contradictory information can be found in
peer-reviewed literature covering a specific subject. In such cases,
the consensus process increases the likelihood that its outcome would
be consistent with the information that will result from relevant
future studies.

Pillar: Outside the Purview of Science

One of the most often violated requirements of regulatory science
is the inclusion of societal objectives, ideology, beliefs, and
numerous other non-scientific issues. On occasion, the regulators claim
that they must include societal objectives in their scientific
activities to be protective of human health, the ecosystem, and
numerous other worthwhile goals. What is being overlooked is that all
of these goals, as desirable as they might be, are outside the purview
of science and must be addressed after the scientific issues have been
resolved. The confirmation of this Pillar is provided by the
Ruckelshaus Effect (Ruckelshaus 1983, Moghissi et al in press) which
states that `` . . . all scientists must make it clear when they are
speaking as scientists -ex cathedra-and when they are recommending
policy they believe should flow from scientific information . . . ''

Ethics of Regulatory Science

One of the key issues needing the consideration of legislators and
regulators is compliance with ethical principles of regulatory science.
Only these principles were only recently formulated, they are readily
derivable from ethical principles of virtually all professions notably
scientific, engineering, and medical professions.

Principle I:

A scientific issue is settled when anyone with the necessary scientific
skills, required equipment, and facilities can reproduce it.

On more than one occasion proponents of an issue claim that ``science
has spoken'' or ``science is settled'' or several other phrases
indicating that the scientific part of a regulatory process has been
clarified. In effect, those who make such a claim must provide evidence
that the science is reproducible and in the MERSI system, falls into
Proven or Reproducible Evolving SI.

Principle II:

Those who prepare a regulatory science document must provide to the
affected community assumptions, judgments, and similar parts in a
language understandable to a knowledgeable non-specialist.

This principle includes the consequences of using ``assumptions,
judgments, and similar parts,'' the justification of using them, and
potential alternatives that were not used. This principle is based on
the MERSI principle on transparency. The regulated community, the
scientists and their organizations, and the interested members of the
public are entitled to know the regulatory science is used in a
specific decision.

Principle III:

Regulatory science information must exclude societal objectives thus
violation the MERSI Pillar ``Areas Outside the Purview of Science.''

During the initial phases of the EPA, the need for rapid promulgation
of regulations led to ``being protective'' and included societal
judgments in the scientific process. One can argue if during that
period those actions were justified. However the inclusion of societal
objectives or ant other subject that is included in ``areas outside the
purview of science'' is not justified.

Principle IV:

Regulatory science information is only then acceptable if it has been
subjected to independent peer review and the review criteria (questions
provided to peer reviewers) include compliance with principles I, II,
and III of regulatory science ethics.

There is a consensus within the scientific community that peer review
is a prerequisite for acceptability of scientific claims. However, the
peer review of regulatory science information is particularly important
because of the usage of ``assumptions, judgments, and similar parts.''
It is crucial to ensure that the selection of ``assumptions, judgments,
and similar parts'' is not based on a preconceived desire of the
regulatory science participants to promote a specific goal. Similarly,
if societal objectives are included in regulatory science information,
they should be not only identified but also justified.

Proposed Roadmap for Fostering Quality Science at the EPA

Before addressing the proposed roadmap, it is imperative to
recognize that the establishment of the EPA and actions taken by that
agency, resulted in a cleaner and healthier environment. It would not
be constructive to evaluate the performance of the EPA with the
objective to see if EPA could have done a better job. Instead, it is
more productive to propose relevant R&D with the objective to improve
EPA's performance by enhancing the transparency of the regulatory
science used by that agency.
It is proposed to enact the Regulatory Science Sunshine Act as a
segment of the EPA authorization/Appropriation or as a separate Act.
The proposed Act would require that EPA develop processes, procedures,
and methods for each regulatory decision that is based on or includes
science:

1.  Identification of assumption judgments, default data, or other
similar systems used in the regulatory process, identification
potential alternatives, and how the conclusion would be different if
alternative assumptions, judgments, and similar parameters were used.
2.  Description of the content of all mathematical formulations in
words.
3.  The information identified above must be written in a language
that is understandable to a knowledgeable non specialist or, better
yet, to an average person.
4.  Clear and unambiguous justification for the inclusion of
societal objectives in science rather than addressing societal
objectives in the administrative decision process.
5.  Obligation of the EPA to comply with ethical requirements of
regulatory science

The Regulatory Science Sunshine Act would require that EPA makes a
concerted effort to develop relevant processes, procedures, and methods
to respond to the needs identified above. As many other regulatory
agencies face the same problem, such an effort would also benefit
numerous other agencies.

Consequences of Regulatory Science Sunshine Act

The opposition to transparency in regulatory science is based on the
following:

1.  There are those who believe that the ``average citizen'' is
not educated enough or smart enough to appreciate the intricacies of
regulatory science.

2.  Some of the staff members of regulatory agencies consider that
items identified under Regulatory Science Sunshine Act to be
burdensome. After all, whereas scientists in regulatory agencies have a
unique competency, others do not have relevant experience and
competency.

3.  The identification of potential uncertainties would result in
the opposition of the public to the relevant regulation. It is being
claimed that people would suggest that in view of these uncertainties
no money should be spent to promulgate or comply with a specific
regulation.

4.  Certain lobbyists with access to regulatory agencies prefer
the current situation because they can impact the regulations without
the remainder of the society having the ability to judge the foundation
of decisions without significant efforts.

5.  Members of a variety of advocacy groups also prefer the
current situation, as long as the political leadership is supporting
them.

6.  There are numerous other individuals and groups who are either
opposed to transparency or do not care one way or another.

A closer look at the items identified indicates that the following
issues are legitimate and must be addressed:

Ability of the Public to Follow Regulatory Science: It is true that a
segment of population will have difficulties following the intricacies
of regulatory science. However, other segments are capable of
comprehending the subject. In addition using as my former boss William
Ruckelshaus quoted Thomas Jefferson ``If we think [the people are] not
enlightened enough to exercise their control with a wholesome
discretion, the remedy is not to take it from them, but to inform their
discretion.''

Competency of Regulatory Agency Staff: There is ample evidence
indicating that there are scientists outside the regulatory agency who
are as competent or more competent in relevant areas of regulatory
science than the staff members of the relevant agency. This subject is
well recognized by reliance upon peer review.

Decisions Based on Uncertain Scientific Information: By far the most
critical issue in the proposed legislation in the legitimate issue of
convincing the public that a decision is necessary in the interest of
the society. It should be recognized that societal decisions based on
incomplete and uncertain scientific information is more common than may
appear.

The example of meteorology can be used to demonstrate the point, a
discipline that provides short term weather forecasting. Most cities
rely upon forecasts on snow and its severity and use them to mobilize
the necessary personnel and ensure availability of relevant equipment.
Similarly, governmental agencies make decisions on both positive and
negative consequences of the predicted rainfall.
Let us use the example of Hurricane Irene to demonstrate the point.
Events related to this hurricane started at about August 15, 2011 and a
few days later, it became clear that Irene would impact the U.S. The
pathway of Irene was modified as the hurricane moved closer and its
severity was modified several times from category I to category II and
Category III but as Irene landed it was largely category I. Many cities
and communities had to make decisions based on the information they
received at any given time in every case the information was uncertain
and incomplete until Irene landed. Should the decision makers wait
until they had complete and fully reliable information? No responsible
decision maker would do so. Conversely, often the predicted weather
proves to be wrong. How often a sunny day is predicted and how often
rain or snow is predicted but the predictions prove to be wrong.
The EPA and other regulatory agencies have the legal and ethical
obligation to inform the public to the best of their ability the status
of the science used in their regulatory decisions. The information must
include assumptions, judgments, the inclusion of default data, and any
other information that impacted the scientific aspects of their
decision.

Conclusions

The Regulatory Science Sunshine Act would require a reorientation
of the EPA's R&D with the objective to develop processes, procedures,
and methods for transparency in regulatory decisions. EPA should be
required to identify assumptions, judgments, default data, or other
similar systems used in the regulatory process, identify potential
alternatives, and how the conclusion would be different if alternative
assumptions, judgments, and similar parameters were used. In addition,
EPA should attempt to describe the content of all mathematical
formulations in words. Furthermore, the Act should mandate that EPA
makes a concerted effort to describe these activities in a language
that is understandable to a knowledgeable non specialist or, better
yet, to an average person.

References

Ananstas P. Written testimony before the U.S. House of Representatives;
Committee on Science, Space and Technology; Subcommittee on Energy and
Environment. (November 17) 2011

ASME/RSI(American Society of Mechanical Engineers/Institute for
Regulatory Science) Assessment of Technologies supported by the Office
of Science and Technology Department of Energy; Results of peer review
for fiscal year New 2002. York, NY, ASME 2002.

Elkins Jr. AA. Fostering quality science at EPA. Statement before the
Subcommittee on Energy and Environment, Committee on Science, Space and
Technology; U.S. House of Representatives, (November 17) 2011.

Moghissi AA, Straja SR, Love BR, McBride DK, Swentnam M. Best Available
Science; its evolution, taxonomy, and application. Arlington,
VA:Potomac Institute for Policy Studies; 2008

Moghissi AA, Swentnam M, Love BR, Straja SR. Best Available Science;
its evolution, taxonomy, and application, second edition. Arlington,
VA: Potomac Institute Press; 2010

Moghissi AA, McBrideDK, Amin MA. Regulatory Sciences: Description of
the disciplines ,education, and ethics. Tokyo; Japan Science and
Technology Agency, 2011

Moghissi AA, Straja SR, Love BR. Peer review and scientific assessment:
A handbook for funding organizations, regulatory agencies, and editors.
Cambridge, UK Cambridge University Press (in press)

Moghissi AA, Swetnam M. Best Available Science; A systematic process
for the development and application of metrics for evaluation of
scientific claims (in preparation)

Ruckelshaus WD. Science, risk, and public policy. Science 221; 1026-
1028: 1983

Trimble DC. Environmental Protection Agency; Actions needed to improve
planning, coordination, and leadership of EPA laboratories. Testimony
before the Subcommittee on Energy and Environment, Committee on
Science, Space and Technology; U.S. House of Representatives, (November
17) 2011.

Chairman Harris. Thank you very much.
I now recognize our third witness, Dr. Kenneth Green, a
Resident Scholar at the American Enterprise Institute.

STATEMENT OF DR. KENNETH GREEN, RESIDENT SCHOLAR, AMERICAN
ENTERPRISE INSTITUTE

Dr. Green. Thank you. Chairman Harris, Ranking Member
Miller, Members of the Subcommittee, I thank you for inviting
me to testify today. I am as the chairman said Kenneth Green, a
Resident Scholar with the American Enterprise Institute. I am a
biologist and environmental policy analyst by training, and I
have studied public policy with a science component for about
20 years now, mostly in non-profit and non-partisan public
policy research institutions across North America.
My testimony represents only my views and should not be
associated or construed as the official position of anybody
else, and my spoken testimony is an abstract from the written
testimony I submitted, which is a little bit lengthier, and I
wouldn't have time for it today.
For the sake of complete disclosure, I want to mention that
verbally what I submitted in my truth in testimony form, I have
served as a grant reviewer for the U.S. EPA on three or four
occasions and was paid their customary per-diem for
participating in such reviews in 2008, and 2009. Other than
offering my judgment on the quality and soundness and relevance
of potential grant proposals, I had no other involvement with
the award process, nor any involvement to my knowledge of any
grant recipients or applicants in any way.
In fact, I would like to take a second to compliment EPA on
the rigor of the process they use to evaluate these outside
grant proposals and innovative grant requests. I was quite
impressed with the level of rigor and discipline involved in
analyzing the proposals, ranking them, discussing them, the
knowledge ability of the panelists and so forth, and I commend
that process.
I wish I could say that all of EPA's science-related
activities were equally satisfying to think about, but
unfortunately, I can't. My own research, both my own research
and reading in the literature suggests that EPA has serious
problems in the way that it employs scientific information when
it assesses both the potential benefits and potential costs of
existing and proposed public policies.
As is common in the public health community, EPA's science
culture seems highly risk averse, so much so that when
confronted with a range of possible risks, they tend to accept
assumptions and design protocols, analytical protocols and
frameworks in ways that lead to ever-greater estimations of
health risk from ever-lower levels of exposure to environmental
pollutants. This is sometimes referred to simply as being
conservative or precautionary. In a medical context that can be
beneficial, and indeed, nobody wants the agency to blithely
dismiss risks, but when such artificially-elevated risk
estimates are translated into economic estimates of regulatory
benefit and cost and used to prioritize agency efforts and
activities, the product is increasingly costly regulations that
do increasingly little good, or worse in some cases, actually
impose costs to society greater than the benefits that they
produce.
That is where things diverge from a harmless precautionary
exercise into poor public policy, and I think it is a serious
problem. Without a sound understanding of the proposed benefits
and costs of regulations, it is impossible to have a rational
public policy development process.
It is also difficult for agencies without that to determine
their regulatory priorities. Thus, even where an agency's
proposals might do more harm than good, they can't optimally
bring their resources to bear where they can do benefit to
secure the biggest bang for the regulatory dollar without
wasting public revenues, public resources.
My own experience with EPA is partly back in 1997, when I
was looking at the National Ambient Air Quality Standards, and
I noticed some of the problems with the way EPA handles risk
assessment. While EPA on one hand was saying that, well, if we
reduce--we want to stop the reduction of high-level ozone in
the atmosphere because that ozone protects people from
cataracts and skin cancer, they did not want to account for
that same phenomenon when they said they want to reduce ozone
in lower levels of the atmosphere. And yet the reduction of
ozone would have the same effect.
So they didn't want to net out the benefits and harm,
possible harms of the regulation, and that was pointed out by
others, and I think eventually was discussed in the Supreme
Court, that you have to do a net assessment of health and risks
and benefits.
Others have documented bigger problems. Garrett Vaughn in
2006 examined EPA's claims about the benefits and costs of
their air quality regulations and observed that EPA's estimate
of having saved the country some $22 trillion through public
health protection from 1970 to 1990 would, if accurate, roughly
equal the aggregate net worth of all U.S. households in 1990.
Vaughn points out that by EPA claims net benefits equal to
nearly three times the profits of all U.S. corporations and a
return on capital by the EPA regulations of 500 percent,
comparing to a seven percent rate return on investment in the
private sector.
Economist Anne Smith recently testified to this Committee,
Subcommittee, one associated interesting effect of EPA's
benefits inflation is that the degree to which it makes the
total number of deaths attributable to particulates
implausible. EPA's presumption that fully 320,000 deaths in the
United States were due to particulate matter in 2005 represents
over 13 percent of all deaths in the United States on average.
And behind this average is the presumption that in large
expanses of the Eastern U.S., between 16 and 22 percent of all
deaths in 2005 were due to particulate matter.
The distortions go on, and I could continue, but I am
running out of time. I am sure we all agree that protecting the
environment is very important. Having grown up with asthma
myself in the San Fernando Valley in California, smog capital
of North America at the time, I am very aware of the role that
poor air quality can play in determining one's quality of life.
But I hope we also agree there is no benefit in
overprotection, and there is no benefit in misallocation of
resources, and there is no benefit in the misdirection of
attention to small risks at the expense of large risks, which
we face elsewhere in the economy, and that getting the science
right is important.
EPA's use of science tends to overestimate the risks humans
face, I believe, and underestimate the cost of compliance and
regulations, leading to poor public policy development.
With that I look forward to your questions. Thank you very
much.
[The prepared statement of Mr. Green follows:]
Prepared Statement of Dr. Kenneth Green, Resident Scholar, American
Enterprise Institute
The views expressed in this testimony are those of the author alone and
do not necessarily represent those of the American Enterprise
Institute.

Chairman Harris, Ranking Member Miller, Members of the
Subcommittee:
Thank you for inviting me to testify today. I am Kenneth P. Green,
a Resident Scholar at the American Enterprise Institute.
I am a biologist and environmental policy analyst by training, and
I have studied public policies with a science component for nearly 20
years now, mostly at non-profit, non-partisan public policy research
institutions across North America. I began career studying air quality
regulations in California, and later expanded that focus to national
air quality policy, climate policy, and energy policy, which are
inextricably related.
My testimony represents my personal views only, and should not be
construed as the official position any other persons or organizations
with which I may be affiliated.
For the sake of complete disclosure, I want to mention verbally
what I submitted in my ``Truth in Testimony'' form: I have served as a
grant reviewer for the United States Environmental Protection Agency on
3 or 4 occasions, and was paid their customary per-diem for
participating in such reviews in 2008 and 2009. Other than offering my
judgment on the quality, soundness, relevance, and potential of grant
proposals, I had no other involvement with the award process, nor, to
my knowledge, have I had any involvement with any grant recipient or
applicant in any way.
In fact, I would like to take this opportunity to compliment EPA on
the rigor of the process employed for the reviews in which I
participated, which involved assessing relatively low-cost research
proposals by university researchers and small businesses in the area of
environmental technology, energy technology, and related research. The
level of professionalism I encountered in my review sessions was
refreshing. The reviewers selected were clearly knowledgeable, diverse,
and applied serious effort to the analysis of research proposals that
sought taxpayer funding. These were satisfying exercises after which I
felt confident that, if the EPA followed the conclusions of the
reviewers, taxpayer money might provide some net social benefit.
I wish I could say that all of EPA's science-related exercises are
equally satisfying to think about, but unfortunately, I cannot. Both my
own research and reading in the literature suggests that EPA has
serious problems in the way it employs scientific information when it
assesses both the potential benefits, and potential costs of existing
and proposed public policies.
As is common in the Public Health community, EPA's science-culture
seems highly risk-averse, so much so that when confronted with a range
of possible risks, they tend to accept assumptions and design
analytical protocols and frameworks in ways that lead to ever-greater
estimations of health risk from ever-lower levels of pollution
exposure. This is sometimes referred to as being ``conservative,'' or
``precautionary.'' In a medical context, this can be beneficial, and
indeed, nobody wants an agency to blithely dismiss proclaimed risks to
the public health.
However, when such artificially elevated risk estimates are
translated into economic estimates of regulatory benefit and cost, the
product is increasingly costly regulations that do increasingly little
good, or worse, actually imposes costs greater than the benefits it
produces.
This is where things diverge from harmless (if excessive) ``risk-
aversion'' into poor public policy, and it is, I think, a serious
problem: having a sound understanding of the proposed benefits and
costs of regulation is a pre-requisite for rational public policy
development.
Without rigorous benefit-cost estimates, it is impossible for an
agency to determine regulatory priorities. Thus, even where an agency's
proposals might do more harm than good, they cannot optimally bring
resources to bear to secure the biggest safety return-on-investment for
regulatory investments potentially wasting scarce public tax resources.
This applies between agencies as well. If agency A uses methodologies
that inflate the risk posed by the things they regulate, they may well
draw public resources away from agency B, which uses more
scientifically accurate risk-assessment methods.
As researchers such as Anne E. Smith, Garrett A. Vaughn and others
have observed, the tendency to overstate risk, leading to over-
estimates of regulatory benefits have afflicted what many would
consider EPA's most important mission: ensuring that air quality is
kept at a level that protects the public health with an adequate margin
of safety.
In my own research looking at the proposed 1997 revisions to the
National Ambient Air Quality Standards, I noted similar problems. For
example, while EPA was arguing that preserving ozone levels in the
upper atmosphere offered protection against cataracts and skin cancer
caused by UV exposure, they did not account for the fact that ozone
anywhere in the atmosphere offers similar protections. Thus, they did
not consider that lowering ozone levels would increase some risks while
decreasing others.
Others have documented even larger absurdities, and things have not
improved over time.
In 2006, Garrett A. Vaughn examined EPA's claims about the benefits
and costs of their air quality regulations.

Vaughn points out that the EPA's estimate of having saved the
country some $22 trillion dollars through public health protection from
1970 to1990, ``If accurate, that sum would equal ``roughly the
aggregate net worth of all U.S. households in 1990.'' Vaughn points out
that by EPA's self-promoting calculations, ``In 1990, for instance, the
EPA claims net benefits equal to nearly three times the profits of all
U.S. corporations.'' Given how little EPA claimed its regulations cost,
the implication was that ``EPA's rate of return on capital exceeded
500%, compared to the private sector's 7 percent.'' That is an absurd
thought which should have triggered an agency ``reality check,'' but
clearly did not. \1\
---------------------------------------------------------------------------
\1\ Garrett A. Vaughn (2006). ``Regulatory Sleight of Hand: How the
EPA's Benefit-Cost Analyses Promote More Regulation and Burden
Manufacturers. (VA: Manufacturers Alliance)
---------------------------------------------------------------------------
As economist Anne E. Smith recently testified to this Subcommittee \2\:
---------------------------------------------------------------------------
\2\ Anne E. Smith (2011). ``Prepared Statement of Anne E. Smith,
Ph.D. at a Hearing on''Quality Science for Quality Air'' by the
Subcommittee on Energy and the Environment , Committee on Science,
Space, and Technology, United States House of Representatives,
Washington, DC, October 4, 2011

EPA is relying to an extreme degree on coincidental ``co-
benefits'' from PM2.5 reductions to create the impression of benefit-
cost justification for many air regulations that are not intended to
---------------------------------------------------------------------------
address PM2.5.

In 2009, EPA vastly increased the levels of mortality
risks that it attributes to PM2.5 simply by starting to assign risks to
levels of PM2.5 down to zero exposure, thus ``creating'' risks from
ambient exposures that are well within the safe range established by
the PM2.5 NAAQS.

This single change nearly quadrupled the pool of
purported US deaths due to PM2.5 that RIAs can now count as ``saved''
by minor incremental reductions in already-low ambient PM2.5 levels
projected under new rules.

This additional pool of PM2.5-related mortality consists
of the most noncredible sort of risk estimate, as it is derived from an
assumption that a unit of exposure at PM2.5 levels well below any
observed in the epidemiological studies poses just as much risk as a
unit of exposure at the higher PM2.5 levels where associations have
been detected.

With this change, EPA is now assuming that 13% to 22% of
all deaths in the Eastern U.S. were due to PM2.5 in 2005, and that 25%
of all deaths nationwide were due to PM2.5 as recently as 1980.

The decision to inflate the PM2.5 risk estimates by
presuming risks continue down to zero has its greatest impact on co-
benefits estimates because--for rules that do not address PM2.5
directly--a much greater share of their incremental reduction of PM2.5
will occur in areas that are already in attainment with the PM2.5 NAAQS
(and thus that have PM2.5 levels that EPA has deemed safe). Yet, EPA
now attributes about 200,000 more PM2.5-related deaths per year to
exposures in those areas.

If it were viewed as credible that such large effects
exist below the level of the PM2.5 NAAQS, the appropriate policy remedy
would be to tighten the PM2.5 standard, and not to regulate something
else altogether in order to obtain those benefits through
``coincidence.''

Smith further observed that:

``One associated and interesting effect of this benefits
inflation, however, is the degree to which it makes the total number of
deaths attributed to PM2.5 implausible. EPA's presumption that fully
320,000 deaths in the U.S. were ``due to PM2.5'' in 2005 represents
over 13% of all deaths in the U.S. on average. And behind that average
is the presumption that in large expanses of the Eastern US, between
16% and 22% of all deaths in 2005 were ``due to PM2.5''. By extension
(although EPA has not reported this calculation), EPA's estimates imply
that about 25% of all deaths nationwide were due to PM2.5 as recently
as 1980.''

I am sure that we all agree that protecting the environment and the
health of all Americans is an important pursuit. Having grown up with
asthma myself, I'm keenly aware of the role that poor air quality can
play in determining one's quality of life.
But I hope we also agree that there is no benefit in over-
protection, especially when such over-protection costs society a great
deal of money that could be put to better uses elsewhere, such as, in
the general economy where it might create jobs, which are also
important determinants in people's quality of life.
EPA's use of science tends to systematically over-estimate the
risks humans face from environmental exposures to pollutants such as
particulate matter. Combined this with under-estimated compliance and
regulatory costs, EPA's use of science leads to inefficient use of
scarce public resources, and imposes regulatory burdens that may well
do more harm than good. To me, this is the core of EPA's science-policy
problem, and is probably where any reform efforts should begin.
I thank you again for this opportunity to testify, and look forward
to your questions.

Chairman Harris. Thank you.
I now recognize our fourth and final witness, Dr. Gary
Marchant, Professor of Law and Executive Director of the Center
for Law, Science, and Innovation at Arizona State University.

STATEMENT OF DR. GARY MARCHANT,

PROFESSOR OF LAW AND EXECUTIVE DIRECTOR,

CENTER FOR LAW, SCIENCE AND INNOVATION,

ARIZONA STATE UNIVERSITY

Dr. Marchant. Thank you, Mr. Chairman Harris and Ranking
Member Miller and Members of the Committee. I am delighted to
be here. My name is Gary Marchant. As was said I am a law
professor at ASU, and I direct our Center for Law, Science, and
Innovation, which we bill ourselves as the oldest and largest
academic center in the country looking at the intersection of
law with science and technology. And one of the major issues we
focus on is to try and improve the use of science in various
types of legal institutions and decision making, including
regulatory agencies. I am delighted to be here.
I really want to make two points today. The first one is
the importance of science in our environmental regulatory
decision making has never been higher both from the demand and
supply side. From the demand side that the easy problems in
environmental policy have been addressed, the things we can
smell and see with our own eyes and ears and nose. We pretty
much have dealt with the problems.
The problems we have left are much more subtle, much more
long term, and they really require science to tell us the
answers. We are not going to detect it with our own senses. We
can't tell as individuals what is a problem of what we are
exposed to. We really need science to tell us that.
So science from a demand side has never been in greater
need, and then from the supply side we have a lot of new
science methods coming forward today of toxicogenomics and
biomarkers and model ecosystem effects and so on.
So we are getting a lot of new scientific methods coming
into our environmental policy world as well, and the
combination of those two I think have made science really
critical more than ever before in how we deal with
environmental policymaking.
Now, two caveats about that, one, as Ms. Dudley has
mentioned, science can't answer the questions. Science is an
extremely important input in our environmental decision making,
but the decisions that EPA has to make are at the end
normative. They incorporate science but a lot of other factors
as well.
And the second point is that science is always going to
have uncertainty. You know, there is always going to be things
we don't know in science that is inherent to science. And so it
is almost as important for scientists and science to tell us
what we don't know as much as we do know so that the decision
makers at EPA and elsewhere can make informed decisions based
on that uncertainty. That is inherent to their decision making.
So my second point is that the context and the
institutional environment in which science is dealt with really
matters. Science has these norms of how it works in and of
itself, of objectivity, of neutrality, of looking at the data
and making our decisions based on the data, not on personal
values and interests and so on.
And because scientists are humans we never get that
perfectly right, but there are different ways in which science
is done and different institutional contexts that make a big
difference. If you don't believe me, you know, just go into a
courtroom these days and watch how science is delivered there.
It is completely adversarial, and you are not getting the way
science is supposed to be done. They are getting two hired guns
on opposite extremes.
What you need is a type of process that encourages sort of
the consensual way that science works best, and when it is done
in an adversarial or politicized environment, it doesn't work
as good as it should.
And so you get two kinds of problems. You get a blending of
science and policy, the two overlap, and it is hard to draw the
line, what Wendy Wagner has called the Science Charade, often
where agencies will explain a decision as a scientific decision
that involves a lot of science but also involves some normative
decisions that should also be expressly recognized.
And the second one is you get both conscious but even more
importantly subconscious change in your view on the science
based on the policy preferences of the organization you are in.
So I think both of those are problems that EPA faces
because EPA is at root a very political and policy
organization. I don't mean that in a derogatory--they have to
be that way. They are making these complex decisions that
involve science but also politics and policy and values and all
kinds of different factors, and they have to work in that sort
of messy world. That is not a good world for science, and so
the idea I would like you to consider is the idea of creating
some kind of separate institution to deal with the science.
This was brought up way back in the '80s, in the so-called
Red Book, the National Academy of Science considered that, that
it is important to separate the science and the policy but
didn't agree we should put them in separate institutions.
But what I would like to suggest is that it might be time
to reexamine that, to put the science in a separate
organization. I have written a couple of articles I suggest
something called an Institute for Scientific Assessments, that
would basically do these type of assessments in a neutral
organization that runs on a scientific model rather than a more
policy-type model. And from the bottom to the top, from the DNA
of that organization, it works on the scientific model.
And I think there is a couple of really good examples of
that we can look at. The Health Effects Institute here in the
United States, Europe created something called the European
Food Safety Authority that works that same way, and both of
those organizations inculcate sort of scientific values top to
bottom, and the result is a product coming out of them that is
respected across the board.
And so if we can do that, we can start with this baseline
of what science can tell us and what it can't, and then we can
go from there and make our political and policy decisions, and
if we can do that, I think we will end up with both good
science and good regulation.
Thank you.
[The prepared statement of Dr. Marchant follows:]

Prepared Statement of Dr. Gary Marchant, Professor of Law and Executive
Director, Center for Law, Science & Innovation, Arizona State
University

Good afternoon Mr. Chairman and Members of the Committee. I am Gary
Marchant, a tenured Professor of Law at the Sandra Day O'Connor College
of Law at Arizona State University. Among other responsibilities, I am
the Faculty Director of the Center for Law, Science & Innovation at
ASU, the nation's oldest and largest academic center studying the
intersection of law with science and technology. One of the central
missions of my Center is to promote better use of scientific evidence
in legal institutions, including legislatures, regulatory agencies and
courts. My testimony today is therefore closely aligned with that
mission, although the views expressed here represent my own personal
perspective on the question of improving science at EPA.

The Critical Role of Science at EPA

Science plays a critical role in EPA's mission to protect human
health and the environment. Over the past couple decades, the agency's
focus has shifted from the ``low hanging fruit'' of obvious pollution
problems that we can all see billowing out of pipes and smokestacks to
more subtle and uncertain environmental problems that we cannot detect
with our own senses. Increasingly we have to rely on science to inform
us about the risks (or lack thereof) from chronic exposure to
individual (or combinations of) chemicals, low-level exposures to
ionizing or electromagnetic radiation, new materials such as
nanotechnology, ecological disruptions, and climate change, to name but
a handful of the almost unlimited inventory of possible environmental
risks. As the demand for scientific inputs into environmental
regulatory decision-making has grown, so too has the supply of new
scientific models, techniques and methods that could be used in
environmental decisions. This trend of an increasing demand for, and
the supply of, scientific inputs into environmental regulatory
decision-making will surely continue and even accelerate for the
foreseeable future.
While science is critical to EPA's decision-making, there are two
important caveats about the role of science. First, science alone can
rarely if ever decide an environmental issue on its own. While sound
science can and should inform the regulatory decision, the ultimate
decision on whether, how, and to what level to regulate an
environmental problem is an inherently normative decision that goes
beyond science. \1\ Thus, agency attempts to justify or defend
regulatory decisions as being dictated by science is a fallacy that
Wendy Wagner and others have described as the ``science charade.'' \2\
The second caveat is that, without diminishing the role of science, the
practical reality is that science is always full of uncertainties and
gaps. Thus, it is almost as important to know what science can't tell
us as it is to know what science can tell us.
---------------------------------------------------------------------------
\1\ Cary Coglianese and Gary E. Marchant, Shifting Sands: The
Limits of Science in Setting Risk Standards, 152 PENN. L. REV. 1255-
1360 (2004).
\2\ Wendy E. Wagner, The Science Charade in Toxic Risk Regulation,
95 COLUMBIA LAW REVIEW 1613-1723 (1995).

The Institutional Context of Science

While science is critical to EPA's activities, many have been
critical of EPA's treatment of science. Former Deputy Administrator of
EPA Robert Sussman wrote: ``The bottom line is that nobody likes EPA
science. Congress does not like it, the scientific community does not
like it, the environmental groups do not like it, and industry
certainly does not like it.'' \3\ Even the EPA, in a 1992 assessment of
the role of science in its own decision-making, concluded that ``EPA
science is of uneven quality, and the agency's policies and regulations
are frequently perceived as lacking a sound scientific foundation.''
\4\
---------------------------------------------------------------------------
\3\ Robert M. Sussman, Science and EPA Decision-making, 12 JOURNAL
OF LAW AND POLICY 573-587 (2004).
\4\ Environmental Protection Agency, Safeguarding the Future:
Credible Science, Credible Decisions, Report of the Expert Panel on the
Role of Science at EPA. Washington, D.C.: Government Printing Office
(1992).
---------------------------------------------------------------------------
The central focus of my testimony is that the institutional context
in which EPA considers and incorporates science into its regulatory
decision-making inevitably tilts, and/or is perceived as tilting, its
scientific findings in the direction of the agency's political and
policy preferences. Science is not supposed to be influenced by such
policy preferences--that is a recipe for the actual and perceived bias
and distortion of science. At its ideal, science strives to be as
neutral and objective as possible, driven by the data itself rather
than extrinsic considerations such as politics, policy preferences,
personal values, and bias. \5\ The closer science approaches that
ideal, the more useful it is, because it is then informing the
decision-maker what we know and what we don't know. Of course, since
science is a human undertaking, it never achieves its absolute ideal,
but my primary comment is that the institutional context in which
science is presented and considered is a key factor for how closely
science approaches its objective ideal.
---------------------------------------------------------------------------
\5\ See, e.g., ROBERT K. MERTON, THE SOCIOLOGY OF SCIENCE:
THEORETICAL AND EMPIRICAL INVESTIGATIONS. Chicago: Chicago University
Press (1973).
---------------------------------------------------------------------------
When science is addressed in an advocacy or partisan institutional
context, it tends to be distorted to fit preferred outcomes, with
selective reliance on the data, one-sided inferences and assumptions,
and uncertainties dismissed or downplayed. Science much more closely
approaches its objective ideal when it is addressed in an institutional
context that emphasizes the norms of the scientific community - with a
preference for consensus-based decisions, an emphasis on the actual
data (especially if it has been peer reviewed and published in good
scientific journals), express recognition of the inappropriateness of
relying on personal or institutional preferences or interests, and
openly acknowledging uncertainties and limitations of the data and
resulting findings.
EPA is an inherently partisan and political organization. This
statement is not intended to be derogatory or critical. Rather, EPA
necessarily and appropriately makes decisions that are based on a messy
mix of politics, policy, economics, law, interests, and values, with a
clear and important institutional mission to protect the environment
and human health. This mixing bowl of facts/policy/values is necessary
for making ultimate environmental regulatory decisions, but is not a
good environment in which to develop and evaluate science. Of course,
EPA should and does also bring science into its decision-making mix,
but it would be better if the scientific input injected into that
decision-making process was developed in a more objective, reliable,
and credible forum than within the political cauldron itself. In other
words, it would be best if the science was developed and evaluated
separately, and in particular in a separate institutional context, from
the more political decision-making process.
This issue of whether and how science should be separated from
policy and everything else was addressed in an influential 1983 report
by the National Research Council (NRC), which is often referred to as
the ``Red Book.'' \6\ That report set forth a framework for regulatory
risk analysis that has generally been followed ever since by U.S. and
many foreign regulatory agencies. A central issue in the report was
that of separating risk assessment, a primarily scientific undertaking,
from risk management, a more policy-related undertaking. The Red Book
found that ``[a]t least some of the controversy surrounding regulatory
actions has resulted from a blurring of the distinctions between risk
assessment policy and risk management policy,'' and accordingly
recommended that ``regulatory agencies take steps to establish and
maintain a clear conceptual distinction between assessment of risks and
consideration of risk management alternatives'' (p.3).
---------------------------------------------------------------------------
\6\ NATIONAL RESEARCH COUNCIL, RISK ASSESSMENT AND RISK MANAGEMENT
IN THE FEDERAL GOVERNMENT. Washington, D.C.: National Academy Press
(1983).
---------------------------------------------------------------------------
While recommending the separation of risk assessment from risk
management within a regulatory agency, the NRC report recommended
against dividing risk assessment and risk management into separate
institutions because of the need for risk assessors and risk managers
to communicate with each other. While there are some benefits to
integrating science with policy within an institution, there are also
clear disadvantages with regard to the objectivity and credibility of
science produced from such a hybrid organization. As the role of
science becomes ever more important to EPA's mission, and as the
perception of EPA's science continues to be skeptical across the
political spectrum, it may be time to consider a different model that
institutionally separates the generation and assessment of science from
the application of that science in regulatory decision-making.

Successful Examples of Separating Science from Policy

There are some useful precedents of institutionally separating
science from policy-making. Two entities that have been successful in
this regard are the Health Effects Institute and the European Food
Safety Authority.
The Health Effects Institute (HEI) is a nonprofit corporation
created in 1980 to provide independent research on air pollution issues
that is co-funded by EPA and the automobile industry. The objective of
the HEI was to provide ``high-quality, impartial, and relevant science
on the health effects of air pollution.'' \7\ Although HEI was
initially a purely research organization, it subsequently assumed a
secondary function of providing neutral scientific assessments of
controversial issues. The HEI's commitment to providing a neutral,
objective scientific assessment of controversial air pollution issues,
implemented through both its organizational structure and procedures,
has made it a highly-regarded and credible ``honest broker'' on air
pollution science. \8\
---------------------------------------------------------------------------
\7\ HEALTH EFFECTS INSTITUTE, ABOUT HEI, http://
www.healtheffects.org/about.htm (last visited Aug. 22, 2008).
\8\ Terry J. Keating, Lessons from the Recent History of the Health
Effects Institute, 26 SCI TECH. HUM. VALUES 409-430 (2001).9 EUROPEAN
FOOD SAFETY AUTHORITY, ABOUT EFSA, http://www.efsa.europa.eu/EFSA/
efsa_locale-1178620753812_AboutEfsa.htm .
---------------------------------------------------------------------------
The European Food Safety Authority (EFSA) was created by the
European Union in 2002 to serve as ``an independent source of
scientific advice and communication on risks associated with the food
chain.'' \9\ The structure of EFSA is explicitly based on separating
science-based risk assessment and policy-based risk management into
separate institutions:
---------------------------------------------------------------------------
\9\

In the European food safety system, risk assessment is done
independently from risk management. As the risk assessor, EFSA produces
scientific opinions and advice to provide a sound foundation for
European policies and legislation and to support the European
Commission, European Parliament and EU Member States in taking
effective and timely risk management decisions . . . EFSA's most
critical commitment is to provide objective and independent science-
based advice and clear communication grounded in the most up-to-date
scientific information and knowledge. \10\
---------------------------------------------------------------------------
\10\ Id.

EFSA therefore provides scientific and risk assessments relating to
food safety to the regulatory bodies of the European Union (i.e., the
EU Commission and the EU Council of Ministers) as well as individual
member nations, and issues such assessments in response to specific
requests or ``questions'' from its ``clients.'' While the EFSA has not
been without some controversy, it has generally been perceived as
responsible for restoring credibility and public trust to the European
regulation of food safety after a series of European food
controversies. \11\ Again, the primary reason for EFSA's success is an
institutional commitment to scientific objectivity, as seen by the
commitment in its Mission Statement ``to the core standards of
scientific excellence, openness, transparency, independence and
responsiveness.'' \12\
---------------------------------------------------------------------------
\11\ See, e.g., Ragnar E. Lofstedt, A European Perspective on the
NRC ``Red Book,'' Risk Assessment in the Federal Government: Managing
the Process, 9 HUM. & ECOLOGICAL RISK ASSESSMENT 1327, 1332 (2003).
\12\ Europeon Food Safety Administration, Management Plan of the
European Food Safety Authority for 2008 7 (2007), available at http://
www.efsa.europa.eu/cs/BlobServer/DocumentSet/mb_managementplan2008-
adopted,3.pdf?ssbinary=true.

A Proposed Institute for Scientific Assessments

To separate institutionally science from policy in environmental
regulation decision-making, my colleague Angus Macbeth and I proposed
in 2008, as part of the ``Breaking the Logjam'' project, the creation
of an Institute for Scientific Assessments (ISA). \13\ I have since
elaborated on this proposal in an upcoming chapter written for a new
book to be published in 2012 edited by Professor Jason Johnston at the
University of Virginia School of Law on the broader topic of improving
regulatory science tentatively titled ``Institutions and Incentives in
Regulatory Science.''
---------------------------------------------------------------------------
\13\ Angus Macbeth and Gary Marchant. Improving the Government's
Environmental Science. 17 N.Y.U. ENVTL L.J. 134-169 (2008).
---------------------------------------------------------------------------
The ISA would be an independent, stand-alone scientific assessment
body that can provide highly valuable and credible scientific input
into the regulatory process. It would be structurally and procedurally
designed to limit its activities to scientific matters and to resist
any temptation to stray into policy advocacy. The ISA would be staffed
and managed by full-time federal employee scientists hired using an
independent process based on scientific merit, and overseen by an
external advisory board that would include prominent national
scientific experts, such as the leaders of the National Academy of
Sciences (NAS) and the American Association for the Advancement of
Science (AAAS).
As Angus Macbeth and I initially described the operation and
function of the proposed ISA:

This new scientific assessment agency would not conduct its own
research, but rather would gather, evaluate and assess the existing
data in a manner that could be used by a regulatory agency in making
decisions. The regulatory agencies could identify questions on which
they needed scientific assessments through an annual regulatory agenda,
supplemented with ad hoc requests as they arise throughout the year
(similar to the EU Commission's requests to EFSA or EPA's occasional
requests for scientific reviews by the National Research Council or its
own Science Advisory Board). In addition to requesting risk assessments
for specific rulemakings, an agency may also request a scientific
analysis from the ISA on a more general or cross-cutting issue.
Congress could also request a scientific opinion from the ISA, helping
to fill the gap in Congressional science advice since the demise of the
Office of Technology Assessment in 1995 (pp. 162-163).

In conducting its assessment, the ISA would be committed to
following the norms of scientific inquiry as closely as possible,
including objectivity, disclosure of uncertainties and competing
hypotheses, and consensus-seeking.
As has been the experience with both EFSA and HEI, instilling a
culture of scientific objectivity from top to bottom of the
organization will be critical to the ISA's success. In my new chapter
about the ISA, I describe the potential benefits of the ISA: ``First,
the ISA structure, limiting consideration to scientific data and issue
only, would squeeze out much of the perceived or actual political and
policy influence currently afflicting regulatory agency science . . .
Second, the ISA approach could reduce the ``science charade'' . . .
Because the ISA would provide a credible independent assessment about
what the science does and cannot tell us, it will be much harder for
regulatory agencies to camouflage their policy preferences as science.
Thus, regulatory decision-making will be more transparent. A third
potential benefit of the ISA would be to harmonize scientific
assessments of the same issue between different federal agencies . . .
''
I also acknowledge in my new chapter that the ``creation of an ISA
would no doubt raise a number of administrative and procedural issues.
For example, what if a regulatory agency wanted to depart from the
scientific findings of the ISA? What opportunity would there be for
public comment and perhaps even judicial review of ISA assessments?
Could a party challenging in court an agency regulation that relied on
an ISA assessment raise claims against the ISA assessment on the
merits? These and other issues would require careful consideration.''
However, there are models and approaches to address these
implementation issues, and the potential benefits for improving the
credibility of EPA's science may justify this type of institutional
change.
In summary, a proposed Institute for Scientific Assessments,
staffed and designed to follow the scientific model of objectivity,
could enhance the utility and credibility of the scientific inputs into
EPA's regulatory decisions. Thank you for considering my suggestion,
and I will be happy to address any questions you may have.

Chairman Harris. Thank you very much for your testimony,
and we will start the round of questions--reminding Members
Committee rules limit questioning to five minutes.
The chair will at this point will open the round of
questions, and I recognize myself for five minutes.
Dr. Marchant, by the way, it is an excellent point, you
know. In medicine we have the NIH to do the research. Totally
separate, about as not politicized as you get, and then, of
course, the information is public and can be interpreted
whatever way it needs to be interpreted.
Ms. Dudley, you know, one thing that has kind of bothered
me about some of the science that is presented, because we have
had science used as justification for policy decisions, and you
know, phrases such as, well, you would save up to, you know,
300,000 cases of asthma a year if only you lowered this
particulate matter standard or mercury standard or some co-
benefit or whatever.
And as scientist, I mean, if I ever made a presentation at
a scientific meeting and in my results section I said up to
something, I would be laughed off the stage. You know, they
want the mean, they want the standard error, the standard error
of the mean, standard deviation, whatever.
But you know, with something like that I wasn't--I have
only been here a year. I wasn't here at the last round of
reductions in pollution, but I will bet you the claim was made
that if only we reduced that pollution, asthma will go down by
hundreds of thousands of cases a year, and of course, we all
know asthma hasn't gone done. It has gone up.
So do you think that more of the agency's science funds
should go actually toward retrospective research to figure out
whether EPA regulations in the past, what the exact impact has
been and whether they have accomplished their environmental and
health goals? Because I bet you we go look at some claims made
ten years ago about the incidence of asthma if only we could
reduce pollution, and we would be very surprised by the lack of
result.
Ms. Dudley. I think that is a very interesting proposal. I
think one thing that is lacking is the feedback mechanism. I
think one of the reasons it may be hard to do is that even
though there are large benefits, and we would all recognize
there are large benefits, they still may not be observable in
the number of asthma cases.
For example, we have observed tremendous reductions in
lead. We have reduced lead in the atmosphere, we have reduced
it in children's blood, and the reason that we do all that is
because there is a real link between child blood levels and IQ,
and yet even though we have done tremendous things, we can't
measure that change in IQ even with huge changes in lead
levels.
So it is hard, but I think it is certainly worth doing. I
think it is a very intriguing idea.
Chairman Harris. Okay. Dr. Marchant, you had said that, you
know, that one of the problems is that you would change, you
might change the view. Say if you blend two things, you change
the view of science based on policy preference, and I got to
tell you we have had testimony from the head of research at EPA
about, you know, outlining, for instance, the need for
hydrofracturing research to figure out if it is safe.
Dr. Marchant. Uh-huh.
Chairman Harris. And I asked them at the last panel, I
said, look. There have been 1.2 million applications of
hydrofracturing. Zero incidences of documented drinking water
contamination. Now, a scientist would say in my--wearing my hat
as my old profession as a physician, we applied the therapy 1.2
million times, and it was good, and it didn't have an adverse
consequence, we would call it a miracle drug, and we would sell
it everywhere around the world.
Here the EPA scientist says, no. We have to study the
safety of it. Is that one incidence where perhaps if you had
separated the science from the policy preference we might have
a cleaner scientific method or a justification for scientific
projects?
Dr. Marchant. Possibly. I am not an expert on that
particular issue, but I think there is, just as it is human
nature that when you are working for an organization that has a
policy mission, which EPA does, that your view of the world is
affected by that. Just like when I was a practicing lawyer, it
is affected by what client I worked for. My view of the issue
is changed when I start working for a client.
There is just a fundamental matter of human nature, and so
I might deliberately skew my views to favor my institution, my
employer, but even more subtle, which I think a lot of good
scientists will have happen to them, even though they try not
to have their view intentionally skewed, would be this
implicit, this subconscious way of how you look at the world
affected by your organization you are in.
And so if your organization is one that says, all we want
to know is what the science tells us, don't--we don't care
about the policy, you might get a different answer than one
that very much has an important policy.
Chairman Harris. Yes. Thank you. Dr. Moghissi, you think
the EPA's federal, the Scientific Federal Advisory Committee,
standing committees, ad hoc panels should be recommending
policy decisions in addition to advising of scientific or
technical issues, or should there be a firewall between that?
Dr. Moghissi. I believe it should be a firewall. As you can
see from my accent I wasn't born in Alexandria, Virginia, and
believe me I have--where I come from I recall--I was too young
during the second World War, but there was a number of
exceptionally competent scientists who where when it came to
policy issues or came to the societal issues, were frankly
stupid. Johannes Stark was an Nobel-prize winning, the Stark
Effect in physics, one of the most important ones, and he was a
Nazi. How do you explain that?
I believe there is a place for science, and there is a
place for policymakers, and I believe it would be bad idea to
mix them.
Chairman Harris. Okay. Thank you. Let me just ask one last
quick question. Dr. Green, you know, testimony--I recall
testimony I think it was one panel or two ago that every dollar
spent on regulation we have $40 in benefit, economic benefit. I
just suggested, well, it is simple. Let us just go and spend a
trillion dollars and pay off our debt and then gain some to
that.
Do you think part of the problem is that, again, because
the testimony in front of the Committee in the past has been,
well, you know, you are going to save up to 300,000 of this or
up to 10,000 of this, and I don't know what the range is. Maybe
the range of the real science was you actually might lose
lives, you know, to save lives. I don't know.
Where are they getting these estimates of 30, $40? I mean,
how do they come up with something--because when I talk to
business people, they know the real cost of regulation, and
they say, no. There is a real cost to these regulations. This
disparity between what the two opposing philosophies believe,
that regulation costs a lot or regulation saves us a lot.
Dr. Green. Well, I think you ask an important question, and
you raise--use an important word, which is estimates. These are
estimates of lives saved, estimates of illness averted, and
increasingly as others have pointed out, including Anne Smith,
who has testified for your Subcommittee in the past, EPA bases
these estimates on what are called willingness to pay surveys
in which they ask people, what would you pay to avoid losing a
day at work because your lungs are too tight? What would you
pay to not have a case of bronchitis or to not have a case of
lung cancer?
And the problem is this willingness to pay surveys, not
only do they not make sense when they compare to each other,
the evaluations you get from them are often nonsensical, the
literature on willingness to pay surveys specifically says that
they really are not indicators of what people would actually
pay in the real world.
And so you are using a methodology that you are not--you
know is not going to get you what you want but representing it
as if somebody has actually been challenged to pay. What would
you pay, and would you pay more to avoid cancer than you would
bronchitis? Well, logically you would say yes, but some of
these willingness to pay surveys don't necessarily bear that
out.
Chairman Harris. Good. Thank you very much.
And I now recognize Mr. Miller and give you a couple extra
minutes here.
Mr. Miller. Don't worry about it overly much, Mr. Chairman.
I am puzzled by the testimony. I think I agree with the
fundamental idea that science should not be the only criteria.
It should inform decisions that policymakers will apply, the
information that comes from science, the ways in which science
informs policy, but then there are other criteria, other
considerations that come into affect.
But what I did not really get from your testimony is how
does that then happen? Ms. Dudley said that she didn't think
that the agency should make the decision. The EPA has criteria
set by Congress, passed by statute. We are policymakers. Our
names actually appear on ballets. It is right in the
Constitution, Article 1, and it sets out how to decide what the
criteria are and then apply those--apply science to those
statutory criteria and reach a result.
If not the agency, who? And on what basis? Ms. Dudley?
Ms. Dudley. I didn't mean to say that agencies shouldn't
make a decision. I am not sure what I said that led you to
suggest that. I certainly think that agencies should make a
decision as delegated under the constraints delegated from
Congress.
My recommendation was that when Congress delegate authority
to agencies, don't do so under the pretense a decision can be
made solely based on science. Allow the agency to consider, to
be able to separate the science from a policy decision and base
the policy on the range of factors that are relevant for making
policy.
Mr. Miller. But those factors should be set out in statute,
right, and they should be decided by Congress and then applied
by the agency. Isn't that the way you think it should proceed?
Ms. Dudley. By Congress and applied by the Executive
Branch. Certainly.
Mr. Miller. Okay.
Ms. Dudley. And so my recommendation to you was when
delegating to agencies, recognize that there are there are
three things to think of. One is the pure science. Then there
is the risk assessment that brings together those different
assumptions and judgments, make that transparent and separate
that from the policy decision.
Mr. Miller. Okay. I really did not hear from anyone's
testimony how to coordinate science and research at the EPA so
that it neither creates a bias against regulation or for
regulation. How do we make sure that it provides useful,
detached information that policymakers who wish to apply all
the proper criteria can rely upon? And I did not really hear
that.
I know that you have an hour-long presentation, Doctor.
Dr. Moghissi. No, no. My apologies if I wasn't clear.
Mr. Miller. Okay.
Dr. Moghissi. It is the responsibility of the scientists to
say that is what the science says and the chairman brought it
up, he said up to so much blah, blah, blah. What do you mean up
to so much? What is the scientists--we have a statistical
process. There is a middle point, there is an upper 95
percentile, there is a lower five percentiles. The task of the
scientist said this is the science. The administrator in
Ruckelshaus is good at it. You go to the public and say me, the
administrator, based on the authority provided to me by
Congress, I am taking this number, and that is my decision. The
hearing process as you will know is a little more complicated
than I make it be. In fact, it is, you know, you have to have--
announce it on 30 days and so on and so forth.
But he went and said--there was famous hearings in
someplace in I think in Seattle or in Tacoma, in which he
exactly did that. This is the science. My conclusion from the
science is--that is the decision. Like it or not that is my
decision.
Mr. Miller. Any of you really want to address how, in
statute, we can revise the ERDDAA statute to make sure that we
get the science that does not have a bias one way or the other?
Dr. Green, and the bias should also not be anti-regulatory.
Dr. Green. Well, I agree, and far be it from me to tell you
how to do you job. I am not a legislator, I never have been.
Mr. Miller. That is actually what the people at that table
do all the time. That is your job.
Dr. Green. I will eschew the activity myself. What I would
say is there are some problems with transparency that have been
mentioned before and transparency and timeliness. One issue I
could suggest, for example, when EPA does regulatory impact
analyses, I remember in the 1997, revisions to the National
Ambient Air Quality Standards, the regulatory impact analysis
was not final until after the rules were passed and written.
Therefore, there really was no opportunity for an outside
analysis of whether or not you would be getting the right
return on investment. That should not be allowed. I don't see
where you can allow a draft regulatory impact assessment to be
the only assessment available before passing something of such
far-reaching consequences.
So, a suggestion of greater transparency and slowing things
down. I mean, if you look at the length of the regulations we
are getting, the complexity levels, as we say, as was mentioned
earlier, the really easy stuff, getting the photochemical smog
out of the air, the things you can see. That is done. The
things we are working on now are much more complicated and yet
the regulatory process has gotten compressed by timelines that
are very tight and make it very hard to review and also there
are burdens, more obstacles being placed in people who do the
reviews. It is not a career-building activity for you to
participate in reviews for the agency, especially when you have
to drop everything to scramble to evaluate a rule that is put
out the evening before Thanksgiving weekend, which is all too
frequently the case as well.
Mr. Miller. Okay. Using my last minute of my extended time,
we will have additional hearings on this subject. We have--the
majority and minority have been in conversation, have been in
discussions about how to have a balanced panel that will
present views on how to amend the statute, how to revise the
statute that has been on the books for 30 years now.
And who should be at that table to present the proper range
of use? I mean, now, obviously, for various reasons this panel
is of one mind, but there are certainly other points of views,
and who should be at that table to present the proper range of
views for future hearings?
Dr. Marchant. I don't think we are of one mind, but I think
that it is important to separate out two different issues here,
so I am not really talking about the research that EPA does. I
am talking about the science that includes some of their own
research but a lot of other research and making a regulatory
decision.
And those are sort of two different issues. How they do
their research, what type of research EPA should do itself
intramurally is one set of issues, which I think is what this
statute addresses. The issue I address and some of my
colleagues here is more how does EPA incorporate science from
its own laboratories but also outside those laboratories in
making a regulatory decision?
Those are two separate issues. You might want to separate
them.
Chairman Harris. Thank you very much.
The gentleman from California, Mr. Rohrabacher, is
recognized. You want Mr. Hall? It is your turn but--okay. Mr.
Rohrabacher.
Mr. Rohrabacher. All right. Thank you very much.
You know, I would just like to start out by reading a quote
from President Eisenhower in his farewell address, and people
always look at that address, and I had it--I Googled it up the
other night. It is 15 minutes long. I just would recommend
taking a look at the insights of this man who helped defeat the
Nazis and saved the world from that terrible threat and then
came on as leader of our country and did in retrospect a pretty
good job as President of the United States. But he had an
incredible vision of things that were happening, both before he
became President and when he was younger and what it might look
like in the future. And he warned us, yes, against the military
industrial complex. Everybody knows that. That is a famous part
of his speech, but he also spent just as much time warning us
about the corruption of science.
And let me read a part of that. ``The prospect of
domination of the Nation's scholars by federal employment,
project allocations, and the power of money is ever present and
is gravely to be regarded. Yet in holding scientific research
and discovery in respect, as we should, we should also be alert
to the equal and opposite danger that public policy could
itself become captive of a scientific technological elite.''
And we have lots of evidence of that since Eisenhower left,
and I just know that we--just in my lifetime I have seen--I
remember when we didn't eat cranberries for Thanksgiving and
Christmas because some scientist came up with the idea that it
was going to cause cancer. Of course, it didn't cause cancer.
We also, we know that--and these aren't things that are
necessarily being done intentionally. Maybe this scientist at
that moment thinks it is really important. We have outlawed
DDT, and the scientific, all sorts of scientific evidence, and
I bet the scientific league got behind this because it became
very trendy because bird shells do, indeed, become less able to
protect the developing bird with--if DDT is in the environment.
But we also know now that DDT kills mosquitoes, yeah, and
mosquitoes cause malaria, and by making sure we protected
birds, a number of hundreds of thousands of birds, we have
condemned millions of children in Africa to a horrible death of
malaria.
Just examples like this where, you know, you have got
scientists being used basically to determine policy, and a lot
of times their policy is wrong. Maybe the science might even be
right, but the policy is wrong.
And so I am very sympathetic with Ms. Dudley's suggestion
there. I take it from what you are trying to do is trying to
separate policy decisions from scientific research so the
scientists should just be answering to the policymakers as to
what the exact science is. Is that what we are saying here
today?
Ms. Dudley. I think that is part of it, and that has been
accepted since I think it was 1983, when the National Academies
of Sciences issued a report that said let us separate the risk
assessment from the risk management. So that is part of it, and
I think some of our statutes don't allow us to do that.
But I think then the second part is even in a risk
assessment--Professor Marchant was talking about this--even in
a risk assessment you have pure science but then you also have
some of these judgments. And that--you can't totally separate
that, but we should at least make transparent where the science
ends.
Mr. Rohrabacher. Well, Malthus was supposedly a scientist.
I mean, he was the mathematician of his day, and he gave us a
chart that said that the entire world would starve to death 50
years ago if Malthus was correct, and I remember the
cyclamates. Remember cyclamates? The industry put hundreds of
millions of dollars into developing a synthetic type of
sweetener and somebody said, well, it might cause cancer. Then
scientists became a trendy thing. They outlawed it, by the way,
they never outlawed it in Canada. Ten years after research they
found out it wasn't cancer causing and what ended up, what was
the problem then? Well, the fact is high fructose corn syrup
was developed in-between and put into place, and if you want to
add--and most of us know, I hope this isn't trendy science as
well, but high fructose corn syrup isn't really good for
people. My wife has outlawed it in our household anyway.
So with that said, Mr. Chairman, I want to thank you for
making sure you had a secondary follow up because it is the EPA
decision making on science that really can affect so many
people's lives in a positive way but also in a negative way.
Thank you very much.
Chairman Harris. I thank you.
I recognize the gentleman from New York, Mr. Tonko.
Mr. Tonko. Thank you, Mr. Chair. I thank the panelists for
appearing before the Committee, and you have all stated your
support for environmental protection, but you have also offered
harsh criticism for EPA's science and EPA's regulations.
Could you offer specific illustration of one specific
example of good regulation and one specific example of bad
regulation?
Ms. Dudley. Do you want me to start? I will start.
At EPA I would say an example of good regulations was the
removal of lead from gasoline. That was one that was really
based on clear science and then a clear risk management
analysis as well. So the science informed the risk assessment,
which informed the risk management regulatory decision, and I
think that has brought about dramatic improvements. It is
probably the biggest success story at EPA.
I think the Ambient Air Quality Standards are an example of
decisions where we do blur the lines between the science and
the policy, and that frankly is because the statute says EPA
must make its decision based on public health and public health
alone, and yet in the analysis there is no way to draw that
line. If you have a linear dose response curve that goes to
zero, how do you set a standard that is requisite to protect
public health and choose anything other than zero?
And so that forces, EPA to kind of wave their hands and
make up all kinds of reasons why they are setting a non-zero
standard. And so the real reasons for making that decision is
obscured.
Mr. Tonko. Dr. Moghissi.
Dr. Moghissi. I am glad you asked. The date is 1970-
something when the Toxic Substance Control Act was passed, and
up to that time there were no regulations relative to
manufacturing of chemicals, and for all practical purposes the
industry could just release chemicals as they saw fit.
The regulations were excellent. They came at the right time
and resulted in limitations of what the chemical industry could
do. And they proved to be cost effective, and they were useful.
Let me give you a bad one. The date is about 1990-
something. There is a place called Waste Isolation Pilot Plan
in New Mexico and in which radioactive waste from reprocessing
of weapons transuranic waste is disposed. Now, the way it is
set up, transuranic waste and chemical waste, hazardous waste
were combined. That is just the way it worked. And the poor
guys had to go and open up this highly-radioactive 55--the
container and analyze for chemicals, the chemicals disposal
facility is intended to, I don't know, maybe a couple of
hundred years, Waste Isolation Pilot Plan is intended to--for
thousand years. And, yes, they had to do it. And finally my
organization based on the request of someone who, some
government agency, we developed way back, we developed a panel,
which included the guy who wrote hazardous waste regulations,
and they said, don't do it. But the EPA had problems and
finally the only way it happened was the Congress, through
appropriations, said you can't do it.
So that was the end of it, and it saved a lot of human
life, a lot of enormous costs. Can you imagine the requests--
requirements for opening up the damn, excuse my French, the 55-
gallon container and radioactive waste to analyze for a little
Benzene or something like that?
Good two examples.
Mr. Tonko. Dr. Green.
Dr. Green. Thank you. I think there are two points. I agree
with Susan, first of all, Professor Dudley, that the handling
of lead is an example of good regulation. We had an event not
that long ago in which that was discussed at some length, and I
would say there is also a distinction that needs to be made
between early rounds of the National Ambient Air Quality
Standards and later rounds, in that you are going to have a
greater return on your investment when you are casing high
levels of pollutants, and you have higher level effects.
The wisdom of a regulation can go from being good to being
bad based on the rounds and evolution of the problem, and a lot
of times the regulations are not written with end feedback
evolutionary mechanisms in mind to prevent that from happening.
And so I think it is important these things be made. As for
things that go wrong, it is not just EPA, but you have things
where it is asbestos regulations which required greater
exposures that walls had to be torn open that otherwise humans
wouldn't be exposed to that created risks for the clean-up
workers for example. That would have to be offset against the
risks that people might face in exposure to it.
And finally, approach matters, which is I might agree with
you that--we might agree on there is a problem. We might even
agree that there is a regulatory or a need for the government
to intervene to address that problem, but there is choice
options. I can go with an eco tax, I could go with a direct
emission fee, or I can go with a regulation or a technology
standard or picking and choosing an approach or technology
approach.
And those are going to have different costs and benefit
return on investment profiles as well as influencing people's
lives and individual liberty and commercial liberty and so
forth.
Dr. Marchant. I think most environmental regulations have
done more good than harm. My main concern is how they are
explained to the public and really at the margins, but I think
if you are looking at beneficial ones, you would have to start
with the Ambient Air Quality Standards. They have by far the
biggest bang that we have spent on them, and particularly I
think there is some issues with the ozone one at the margin,
but particulate matter and lead and carbon monoxide have all
been tremendously beneficial. The Sewage Treatment Program has
been tremendously beneficial. So there is a lot of examples of
good ones.
There are ones that are bad, and I think it is interesting
looking at the bad ones to see where it went wrong, but I mean,
my favorite is one, the DC. Circuit struck down a chemical
manufacturing versus EPA case a few--about a decade ago where
EPA modeled these high-risk chemicals under the Hazardous Air
Program and one particular chemical, basically a solid at the
modeling characteristics that EPA used, and the company, you
know, gave them clear data that that was a fact, that there
would be no exposure, and EPA simply ignored it and says, you
have got to be regulated like this because we are going to
assume that at this level, this temperature you are not a
solid, and they was just clearly scientifically wrong, and yet
they just went ahead with the regulation anyhow.
And fortunately, the DC. Circuit struck it down as lacking
any plausibility in science whatsoever.
Chairman Harris. Thank you very much.
The Chairman, Mr. Hall, is recognized.
Chairman Hall. Thank you very much.
Ms. Dudley, you are exactly right when you delegated
authority solely on science. I am sure--I think, I don't think
that anybody in here disagrees with that, but I know you didn't
intend to say that you ignore good and reliable science, and I
respect every one of you that are here. You are Professor of
Public Policy, Regulatory Science, Enterprise, Center for Law,
Science, and Innovation. You are not with the Administration,
and I think Dr. Green did his best to compliment the
Environmental Protection Agency. I didn't read enough of it. I
quit reading it when I gathered that.
Talk just a minute about the EPA. Maybe--I don't know how
long ago, but I was here when we passed the Clean Air Act and
the Clean Water Act, and we gave the EPA a place in the sun in
that legislation and had expectations that they would use
science and use other knowledge that was available to them. And
it is my opinion that they have deviated from that, and they
have deviated it to the extent that it is very damaging to
institutions in my district and all across this country.
Dr. Moghissi, in September I sent EPA a letter requesting
information on their Integrated Planning Model. You all call it
the IPM. This is the model that the agency used to analyze the
Cross-State Air Pollution Rule. You are familiar with that,
aren't you?
And the assumptions driving this model have never been made
public, and their knowledge of the model itself has never been
peer reviewed.
Now, how would the IPM model fare if evaluated by the
ethics principle of regulatory science that you described in
your testimony?
Dr. Moghissi. What they would have to do, they would
announce the assumptions, every piece of an assumption, and I
am familiar with half of them but not all of them, many of
those assumptions on the extreme side of the scientific
business, they would have to say what would happen if I make a
different assumption on the other side of it and but how would
the conclusion be different.
That would be subject to independent peer review and if I
might add, the peer review says you have to be qualified if you
are a peer reviewer. You do not--may have conflict of interest
but those who have a stake in the outcome of the peer review
may not be peer reviewers nor may participate in the selection
of the reviewers.
And in my opinion that is very often violated. Therefore,
it is imperative that this Sunshine Act that I am suggesting
open up to the public. Let them--if the people know what they
are doing as you are suggesting, if the model, the assumptions
in the model are described, if the judgments are described, if
the--if alternative assumptions on judgments are described, and
the conclusions that are from it described, then the role of
the science is done. The next step is the Administrator has to
go and say, I pick up this because in my opinion this is the
right choice. This is my opinion as an Administrator of the
EPA. That is what I would like to do. It is not poor
regulation. It is not anti-regulation. It is just the truth in
regulation.
Chairman Hall. How would the IPM model fare if evaluated by
the ethics principle or regulatory science that you described
in your testimony? How would that be?
Dr. Moghissi. Thank you, sir.
Chairman Hall. If you can't knock that one out of the park,
I will give you another one in a minute.
Dr. Moghissi. In other words, the peer review must say,
include in the peer review not I picked up this assumption, I
picked up this alternatives, these are why I did it. I did
not--if I include societal objective in it, that is why I did
it. Could I have done without it? The openness, the
transparency is the key issue. Again, it does not change
anything in terms of pro regulations or anti regulations.
What it says is you should tell the public. You gentlemen
over there are a hell of a lot more qualified on policy than I
am, and I am a scientist, and I am not necessarily all that
modest, but I am not qualified. You are qualified.
So, therefore, in my opinion these ethical requirements and
it took several years to develop them, are very important to
comply with.
Chairman Hall. IPM is the model that the agency used to
analyze the Cross-State Air Pollution Rule, as you know, and it
affected adversely all over this country but it particularly
affected an entity in my District at Mount Pleasant, Texas,
Luminant case. I think you may be familiar with that, but it
cost them 500 jobs almost immediately, and it is my opinion and
my opinion alone that there was such an outcry from that and
how it affected a lot of other states, not just Luminant, but
they began to make some kind of a realization that they might
have made a mistake in leaving, in bypassing or ignoring some
science in arriving at their opinions.
This--we had an EPA assistant administrator, Gina McCarthy,
here before us, and when she was pressed for some reason, she
did something there and gave some ruling without her applying
the proper science to it, but she gave us the arrogant answer,
we are not in the business of creating jobs, and I left her
space to make an apology for that in the testimony, but it
never came.
And that is what we get from EPA today. Should EPA continue
its path to implement the Cross-State Rule given that the IPM
model is not peer reviewed and it is not transparent, or should
EPA discontinue their current efforts until such a time that
the IMP model is peer reviewed and transparent? Is that the way
you think they ought to go?
Dr. Moghissi. The way to remedy that, sir, to pass the
Regulatory Science Sunshine Act to impose upon the EPA they
have to be transparent, they have to pass the peer review
consistent with the requirement of ethics of the regulatory
science.
People are not stupid. The people understand it. The
arrogance of some of the science within or in policymaking I
know better what is best for the country. No. The people of the
United States know what is best for the country, and therefore,
the Sunshine Act open up to the public, and again, this is not
pro or against regulations. It just opens it up.
Chairman Harris. Thank you very much.
Chairman Hall. My time is up. Thank you, Mr. Chairman.
Chairman Harris. Thank you very much.
I recognize the gentleman from California, Mr. McNerney.
Mr. McNerney. Thank you, Mr. Chairman. Mr. Chairman, I
would like to address one of the issues you bring up often,
hydraulic fracturing. The EPA was authorized by Congress in
2010 to open up a study in hydraulic fracturing and its
potential impact on groundwater.
Now, maybe you disagree with that decision, but we saw when
we were discussing nuclear waste a few weeks before that if the
public doesn't buy into a procedure in their district, you are
going to end up in courts, there is going to be fights, it is
going to go nowhere. And so it was wise, I think, for Congress
to authorize the EPA because there is a groundswell of public
concern about potential pollution from hydraulic fracturing.
So if we can prove that it is not a problem, that is good.
If we can prove it is a problem, it needs to be done, and so I
just wanted to address your continued concern about that.
Now, about the issue that we are discussing today, I didn't
necessarily disagree with what was said by the panel. I think
Ms. Dudley's use of the word, charade, regarding a policy in
science was needlessly inflammatory. But, one of the things
that I kept hearing was that we need to have science separated
from policy. An example we have of that in the 1990s, we have
the Office of Technology Assessment did unbiased work, and the
then Speaker of the House of Representative, Newt Gingrich,
disbanded that organization because in my opinion he didn't
like what they were doing.
So separating science and policy is not really possible in
this sort of political environment. I don't know exactly where
to go from there, but the objective of this hearing to decide
how we should empower or enable scientific research to inform
regulatory decision making.
Now, one of the things that Ms. Dudley says is--and all of
you, I think, really is that science is not certain, and that
is for sure. Science is never certain, but there are ways to
include probability assessments in scientific judgments, and
there are statistical tools that can be used in decision making
with uncertainly.
I have been--I am a mathematician, so I am aware of those
tools. So what do you say, Ms. Dudley, in terms of using that
approach because we can never have absolute certainty in
science?
Ms. Dudley. I think that is an excellent suggestion, and
the National Academies have suggested that regularly to improve
the quantitative uncertainty analysis for regulations that are
likely to have the biggest impacts. And the reason that is so
important is then you make more transparent what the
assumptions that are going into that risk assessment are.
So I think that is key.
Mr. McNerney. So we don't have to have absolute certainty.
We can't have absolute certainty.
Ms. Dudley. Oh, no, you can't.
Mr. McNerney. But we can make decisions in the absence of
absolute certainty.
Ms. Dudley. Absolutely. I don't think anyone suggests that
you have to wait for certainty. In fact, your point is related
to the science charade, which I did not mean to be
inflammatory. It is actually a phrase that Wendy Wagner coined
a decade or so ago in an excellent article. I have been doing
some research lately and find that all the incentives in the
regulatory system are to perpetuate that charade, and the
charade is that when we make the pretenses that something is
based solely on science, we are hiding the real decisions.
And what you are suggesting is a way to step back and make
that clear: here are our assumptions, and here is the range of
assumptions we could have used, and if we do this quantitative
uncertainty analysis, that makes transparent for everyone. It
is an excellent suggestion.
Mr. McNerney. Okay. Mr. Green.
Dr. Green. I think your point is very well taken. It is
also important for people to, I think, to understand. Science
is provisional and that science has a culture which is rather
different than the culture of policy, and that is science is
provisional in that everyone understands that a paper that they
put out one week can be overturned the next week.
Mr. McNerney. Uh-huh.
Dr. Green. And the consequence is simply that somebody goes
back to the lab. But once you start entraining the scientific
findings into a regulatory process, it is often hard to reverse
the train. And so as I was saying before, I think some feedback
mechanisms and evolutionary mechanisms that allow for the
provisionality of science to feed back and have faster impacts
on slowing the train or changing the course of direction would
be very important.
One last comment is I think the transparency issue is very
important. Proprietary models are a real problem when you have
an agency that is running propriety health models or having
proprietary data that can't be analyzed by--from outside. It is
very hard to assess whether or not the work itself really does
reflect science or reflects simply assumptions that are put
into models no one can see.
Mr. McNerney. Okay. Mr. Chairman, I yield back.
Chairman Harris. Thank you very much.
Yeah. We will have--we have a little more time left, so we
are going to have a second round of questions, but it is
limited to three minutes per Member, and I will have the first
questions of the second round.
Dr. Green, the Federal Advisory Committee Act, which
governs EPA's Science Advisory Board and CASAC, the Clean Air
Scientific Advisory Committee, requires that advisory peer
review panels be, ``fairly balanced in terms of the points of
view be represented.''
However, a recent hearing raised a number of issues related
to these panels. For example, five of the seven standing
members of CASAC have recently received EPA funds. They are
actually direct recipients of funds, and the current CASAC
Particulate Matter Review Panel includes nine scientists who
had previously recommended lowering the annual standards. So,
you know, maybe have a little bit of policy preference there.
Do you think the requirements for scientific, balanced
scientific advice is met by these EPA committees at this point
in time?
Dr. Green. As I have seen them, I am not--I guess the
answer I would say is probably not, but the question is how do
you best represent balanced points of view, and I think a lot
of the times the discussion comes down in the wrong framework.
That is it is industry views versus agency views or university
views versus private sector views, public sector versus private
sector views.
Without a recognition that there is expertise on both
sides, the person doing applied chemistry at Kodak or at a
chemical company has very detailed, specific information that
could inform policy process. The question is do we capture
those people who have direct field experience as much as we
capture the expertise of people with university experience or
agency experience or agency culture or leaning.
From that I have seen of review panels I rarely have seen
one as--you were mentioning the--the Ranking Member was
mentioning the lack of balance on the panel here. Imbalanced
panels seem to be the norm rather than balanced panels.
Chairman Harris. Thank you very much. Professor Dudley,
earlier this year the U.S. EPA's long-awaited study of
formaldehydes toxicity was panned by the National Academy of
Sciences panel that sharply disagreed with the agency's
conclusions and declared the effort in need of, ``substantial
revision.'' The panel stated, and I am quoting from their
statement. ``Overall the committee found that EPA's draft
assessment was not prepared in a logically-consistent fashion,
lacks clear links to an underlying conceptual framework, and
does not sufficiently document methods and criteria used to
identify evidence for selecting and evaluating studies.''
Now, NAS added that EPA's chemical assessments have
consistently displayed these problems in recent years. How
should the EPA modify the Integrated Risk Information System in
response to the criticisms that were raised by NAS?
Ms. Dudley. I think the NAS report itself gave some very
constructive suggestions, and it comes back to the transparency
that we have all been talking about, both you and your panel
today.
More transparency so that we understand why decisions are
made because risk assessments require a lot of those
assumptions, including which studies do you choose, which
models do you choose, what default assumptions do you use? If
we can make that more transparent and perhaps follow Dr.
Moghissi's, those steps to make sure that we really do
understand the range of assumptions, I think that would address
the Academy's concerns.
Chairman Harris. Thank you very much.
Mr. Miller.
Mr. Miller. Ms. Dudley, the IRIS procedures have changed at
least three times in the last decade. There was sort of an
early Bush Administration procedure, a late Bush Administration
procedure that I think you were the principle author of, and
then the Obama Administration has developed their own
procedures.
The criticisms of the formaldehyde decision or the
formaldehyde decision that was criticized by GAO, under which
set of procedures was that decision made?
Ms. Dudley. First let me say I was not the architect of the
procedures. It was EPA who changed the IRIS procedures. And
OIRA was not the architect of that.
I am not sure. I am sure it was over time. I don't know
that the new procedures will change that because the procedures
really were how you do the vetting, interagency and with the
public, and that certainly helps. I think bringing, engaging a
broader perspective will address some of the concerns, but I
won't use all your time.
Mr. Miller. Dr. Marchant, you discussed institutional
biases at EPA and said that it had sorted science and policies
and values into one big mess, but there are--there were panels,
review panels that--advisory panels that had been established
by statute, and I think maybe by EPA on their own, the
scientific, to review scientific research activities.
What role can those or do those advisory panels play, those
boards play? Are they functioning, and how can they or do they
separate science and policy decisions?
Dr. Marchant. I think they do help. They are sort of an
intermediate step to have sort of an independent scientific
check on what the agency is doing to give them advice. I do
think they are still somewhat beholden to the agency as opposed
to a completely separate and independent institute that is
basically made up of career scientists who work for that
institute rather than being appointed by an agency.
I also think that those committees should not be making
recommendations on policy. I don't think they should be telling
the EPA what level to set the standard. They should be telling
them what the science is and then it is the agency's job to set
the standard. The scientist shouldn't be making those policy
decisions. They aren't policy experts.
Mr. Miller. Okay. Dr. Green, same question to you.
Dr. Green. Well, I think Dr. Marchant's point is exactly
right, which is you do need review agencies. You need review
panels, but it is difficult not to have them be captured or
capture the agency that they are associated with if there is
some sort of benefit, whether it is a prestige benefit or an
influence benefit or a potential grant benefit or any kind of
interaction. It is hard to separate those things out.
It's not that it can't be done, but I think that the
important thing is that they should simply draw the line in
saying, here is what we read the science as. It is all
published, it is all public. Here is how we interpret it. Here
is what we think the science says is, and it is not our job to
say what it should be or what should be done, and they should
hand that--that should be clearly--a clearly political decision
by the administrative side of the agencies.
We did--but instead we have previous decisions that would
defend it as being the decision is dictated or driven by the
science. It is science based. It is science driven. The science
says we must X, and science can never tell you what to do. It
can only tell you what it is.
And so I guess my, one of my--my only suggestion would be
that we should ban the phrase, the science says we must, from
statutory language entirely, and we might get improvement that
way.
Chairman Harris. Thank you very much.
The gentleman from California, Mr. Rohrabacher.
Mr. Rohrabacher. Thank you very much, Mr. Chairman, and let
me just note, and again, this is a very--this is not a
scientific analysis of what has been said, it might be impacted
by my political opinions, but I would suggest that the Office
of Technology Assessment was not eliminated by Newt because it
was doing things that he didn't like. No. I was here when that
happened. We tried to balance the budget, and that was one of
the years that we were able to balance the budget by
eliminating what we thought were extraneous groups that were
not doing--the job that they were doing was not worth the money
that was being paid.
In the case of the Office of Technology Assessment, they
would often give us their assessment a year or two after we
requested it, and it was no longer necessary to hear their
opinion, but they weren't doing a good job, and at least that
is what those of us who voted to eliminate that part of our
budget in order to have a balanced budget.
I also don't believe that there was ever a groundswell of
public concern for fracking, that it might impact on the
groundwater. There was a groundswell among liberal politicians
who controlled the House at that time, again, another
scientific expertise by politicians, who wanted to prove that--
or who believe in like global warming is caused by CO
2

and that they would do anything they could to prevent more
availability of oil and gas because that would create
CO
2
, which created global warming. Again, a
political decision.
Let me ask my one question, which is at a recent hearing I
asked Dr. Paul Anastas, I guess you pronounce it. I am sorry if
I have mispronounced it. The Assistant Administrator for EPA's
Office of Research and Development, and the EPA Science
Advisor, I might add, about new regulations for perchlorate,
and this was--basically I asked him in the face of decades of
scientific work by--from the National Academies and other
reputable scientific institutions, saying that no such
regulation was needed, why were they moving forward, and his
answer simply, well, it implied that a scientific basis was not
required for EPA to create regulations.
I would like to hear from the panel just whether or not--we
don't have much time, but a yes or no whether you think that--
whether or not EPA should require a scientific basis to create
a new regulation.
Just a yes or no or whatever your quick thoughts are.
Dr. Moghissi. If they want to develop a regulation, which
is based on science, that would be absolutely necessary. How
else do you do? The gentleman over there, he is a physician.
How else do you go and treat someone with medicine if you don't
know what the medicine is?
So, therefore, the disease and medicine are related to each
other, and therefore, without having the scientific foundation,
the regulation is arbitrary.
Dr. Green. I would agree with that. I think you need to
have a scientific foundation.
That being said, I mean, there could--you could envision in
some cases where the science is so clear that something is
damaging that setting the level could be based on other factors
than that. You may not actually have to question the science,
but I agree. The key thing is if you are going to regulate, you
need a rationale for regulation. If it about environmental
protection that suggests you have measured something that needs
protecting, you determine what needs to be done in order to
protect it. All of those are scientific activities, and without
them it is hard to see how you have a rationale for your
actions as opposed to simply acting randomly. Why couldn't they
then just pass any regulation they want to on any subject if
there is no rationale and no linkage to their mission?
Mr. Rohrabacher. All right.
Dr. Marchant. I think personally that is a terrible idea to
base it not on science, but I am glad that they would explain
it. More honestly, if there isn't science to back it up, to be
explicit about that rather than trying to say that there is
science so now we can all evaluate it and make our own judgment
whether that is a good regulation or not, and I would think it
wouldn't be if there is no science to back it up.
Mr. Rohrabacher. Thank you, Mr. Chairman.
Chairman Harris. Thank you.
The gentleman from New York, Mr. Tonko.
Mr. Tonko. I am set.
Chairman Harris. Thank you. Okay. I want to thank the
witnesses for their valuable testimony and the Members for
their questions.
The Members of the Subcommittee may have additional
questions for the witnesses, and we ask you to respond to those
in writing as quickly as possible.
The record will remain open for two weeks for additional
comments from Members. The witnesses are excused. Without
objection, the hearing is recessed subject to call of the chair
to a date to be determined for a second day of testimony for
this hearing.
[Whereupon, at 3:40 p.m., the Subcommittee was adjourned.]

Appendix I

----------

Answers to Post-Hearing Questions

Responses by Ms. Susan Dudley,
Director, Regulatory Studies Center,
and Research Professor of Public Policy
& Public Administration,
The George Washington University

Questions submitted by Subcommittee Chairman Andy Harris

Q1.  We briefly discussed the potential for retrospective
``accountability research'' to serve as a feedback mechanism about past
regulations and their health and environmental outcomes. What steps
could be taken to ensure that these targeted reviews fully and usefully
evaluate past regulations to inform future decisions?

A1. Agencies face little incentive to conduct retrospective evaluations
of the accuracy of ex ante predictions of health or environmental
effects resulting from regulatory action. Unlike federal programs that
don't get reauthorized if they don't demonstrate success, regulations
tend to stay in place absent some new action. Congress could provide
incentives for agencies to examine ex post actuarial data of key
outcomes (such as children's IQ, mortality rates, etc.) through sunset
provisions that linked continued authorization to a demonstration of a
regulation's effectiveness. Perhaps a pilot project, where Congress
identified a particular regulation or target pollutant and health
effect for review, would help EPA develop a methodology for conducting
such reviews.

Q2.  The Bipartisan Policy Center's 2009 report, ``Improving the Use of
Science in Regulatory Policy'' was mentioned several times during the
hearing. This report made several suggestions that may be useful in
guiding this Subcommittee's efforts to reform regulatory science,
including:

``Studies used in the formulation of regulation should be
subject to data access requirements equivalent to those under the Data
Access Act.''

``The process of conducting literature reviews'' and ``the
process of naming advisory committees'' should be made more
transparent.

``Agencies should avoid turning repeatedly to the same
scientists for service on advisory committees.''

Executive branch agencies need to ``help clarify for both
officials and the general public which aspects of disputes are truly
about scientific results and which concern policy.''

``Policy makers should be wary of conclusions of risk that
are expressed as a single number.''

``Federal agencies need to experiment with ways to increase
the number of scientists who participate in peer review.''

``In presenting the conclusions of literature reviews,
agencies and their scientific advisory committees need to be as open
and precise as possible in discussing levels of risk and uncertainty.''

Do you agree with any or all of these recommendations? Do you have
any additional comments or advice in pursuing these goals?

A2. Yes, I agree with these BPC recommendations. Congress could support
these (particularly 4th, 5th and 7th bullets) by explicitly recognizing
in authorizing statutes that good policy decisions depend on a range of
information, and avoid delegating decisions to agencies on the pretense
that ``science'' alone can make the normative determination of what
policy should be. To quote further from the BPC report:

``The first impulse of those concerned with regulatory policy
should not be to claim `the science made me do it' or to dismiss or
discount scientific results, but rather to publicly discuss the
policies and values that legitimately affect how science gets applied
in decision making.'' (BPC 2009, 4)

``Distinguishing between science and policy is not always
easy or straightforward, and scientists may make choices based on
values in the course of their work. Nonetheless, policy debate would be
clarified and enhanced if a systematic effort were made to distinguish
between questions that can be resolved through scientific judgments and
those that involve judgments about values and other matters of policy
when regulatory issues comprise both. This transparency would both help
force values debates into the open and could limit spurious claims
about, and attacks on science.'' (BPC 2009, 15)

Legislators should also take care to limit the role of scientific
advisory panels to advising on science, and avoid embedding their
policy views in their scientific recommendations. I would also
highlight the following BPC recommendation:

``In general, scientific advisory panels should not be asked
to recommend specific regulatory policies.'' (BPC 2009, 5)

Q3.  A recent joint report from the EPA's Science Advisory Board and
Board of Scientific Councilors recommended that the Agency ``include
sustainability in its research vision'' in order to allow ``EPA to
adopt sustainability as a core principle to inform decisions and
actions.'' Is this emphasis on sustainability appropriate for EPA's
research and science activities?

A3. I am not familiar with this report or recommendation.

Q4.  Many of the regulatory activities that EPA is currently
undertaking are based upon statutes and priorities from several decades
ago. In your view, are we focusing our attention and scientific
resources on the most pressing environmental issues? Are there ways
that EPA could better prioritize?

A4. A concerted effort to focus resources on the most pressing
environmental issues would be a welcome change. In 1987, EPA ranked its
regulated activities according to the risks they posed to human health
and the environment. It found that the activities that commanded the
largest share of federal resources and public dollars were not the ones
that posed the greatest risk. However, the allocation of resources
tracked public perception of risks very well. (U.S. Environmental
Protection Agency. Unfinished Business: A Comparative Assessment of
Environmental Problems. February 1987) To my knowledge, EPA has not
repeated this exercise but it would likely be fruitful.

Q5.  Dr. Marchant recommended the Health Effects Institute or the
European Food Safety Agency as potential models for conducting
independent scientific assessments as an alternative to the current EPA
practices. In your experience, are there other governmental or non-
governmental organizations that demonstrate characteristics in
scientific assessment or R&D that could serve as a useful model for
science reform at EPA?

A5. I do not believe that an independent group of risk assessors,
insulated from challenge, would address the problems we see in risk
assessment in the U.S. While isolating risk assessors might be an
appropriate solution to a problem of ``politicized science,'' as the
BPC report concluded, ``some disputes over the `politicization' of
science actually arise over differences about policy choices that
science can inform, but not determine.'' EPA's Office of Research and
Development arguably fits the Marchant model, yet its IRIS process is
widely recognized to be broken, with long delays and the perception
that policy preferences are embedded in numbers that are presented as
purely risk-based assessments.

The peer-review process may offer a better model for reform, where
challenge and debate are encouraged, leading to more robust hypothesis
testing and more reliable theories.

Q6.  Many EPA science activities are housed within regulatory offices.
For example, EPA's Office of Air and Radiation (rather than the Office
of Research and Development) manages the National Fuel and Vehicle
Emissions Laboratory, as well as the National Air and Radiation
Environmental Laboratory. In your view, should science activities be
organizationally insulated from regulatory activities to ensure
objectivity and balance?

A6. The organizational location of the unit doing the analysis is less
important than requirements for transparency so that all analyses can
be examined from different perspectives and subjected to challenge.
Rather than insulating different groups from challenge, analyses should
be replicable, transparently distinguish scientific information from
assumptions and policy judgments, and be able to withstand legitimate
challenge. Further, the use to which the scientific assessments are put
influences the quality of the assessment. Assessments that are factors
in policy decisions that permit balancing of risks, costs, and benefits
(such as conducted under TSCA or FIFRA) are more likely to be
transparent and objective than those conducted for decisions for which
they will be the deciding factor (such as NAAQS).

Q7.  Some scientific information that is disseminated by federal
agencies is subject to specific data quality requirements. Are there
additional steps that you think could be taken to ensure that these
peer review and data quality guidelines are followed or expanded for
important scientific information at EPA?

A7. More conscientious adherence to existing information quality and
peer review requirements would improve both the information
disseminated and the policy decisions on which that information is
based. The most rigorous research I've seen on agency compliance with
information quality guidelines is that of Dr. Richard Belzer (a former
OIRA analyst). He has found that through FY2010 EPA's average response
times were 166 days for petitions and 316 days for appeals. This record
is worse than the government as a whole, which has average response
times of 148 days and 186 days, respectively. In its information
quality guidelines, EPA committed to respond to both petitions and
appeals within 90 days. (See his presentations in November and December
2010 here http://www.rbbelzer.com/presentations.html)

Checks and balances from other branches of government (legislative
and judicial) could provide needed incentives to follow these
guidelines. Agencies might be more responsive if responding were made a
nondiscretionary duty, or if there were penalties that came into force
automatically for failure to meet reasonable response deadlines. But
it's also possible that the quality of agency responses would decline
if responding by the deadline were all that mattered to avoid the
penalty. Thus, Dr. Belzer argues for incentives that encourage
timeliness and quality in agency responses, not one at the expense of
the other. He suggests compliance might improve if agencies could
correct errors without having to admit that they were wrong.

Q8.  Nearly all of EPA's recent Clean Air Act regulations have been
justified on the basis of two studies that rely on entirely on data
from the American Cancer Society and the so-called Harvard Six Cities
Study. Despite the fact that these data sets were developed with
government funds and provide the basic Agency justification for costly
regulations, they are not publicly-available so they can be analyzed by
other scientists. Do you support making this type of information
transparent? In your view, would making these underlying data sets
available to everyone improve the Agency's regulatory decisions?

A8. Yes, as the BPC report stated, ``Studies used in the formulation of
regulation should be subject to data access requirements equivalent to
those under the Data Access Act.'' Risk assessments depend on numerous
assumptions and choices, so making underlying data available allows
results to be replicated and tested under alternative assumptions. It
helps decision makers understand the sensitivity of predictions to
different assumptions, and improves the rigor of the analysis and the
quality of the regulatory decision.

Q9.  As you know, the Office of Management and Budget (OMB) defines
agency scientific assessments as ``highly influential'' if they ``could
have a clear and substantial impact on important public policies with a
potential effect of more than $500 million in any one year.''
Assessments that fall into this category are required to undergo
rigorous and transparent peer-review. However, in many instances EPA
has refused to designate even obvious assessments as highly
influential--such as its greenhouse gas endangerment finding that is
the basis for tens of billions in regulatory costs.

Q9 a.  In your experience as head of OIRA, how did you apply this test?
Do you think the EPA Endangerment Finding constitutes a highly
influential assessment, and if so how can Congress better ensure EPA
follows standing OMB requirements?

A9 a. The Information Quality Bulletin provides agencies some
discretion in defining ``highly influential,'' however EPA's IG
recently opined that the endangerment finding should have been
designated as such.

Q9 b.  At the Subcommittee's November 17th hearing, EPA Assistant
Administrator Paul Anastas said that the agency has not yet determined
whether its study on hydraulic fracturing would be designated as highly
influential. In your view is it advisable for EPA to determine whether
a study will be ``highly influential'' and thus subject to greater peer
review before it actually begins to collect and analyze data?

A9 b. Yes. As, OMB's Information Quality Bulletin for Peer Review
states with regard to planning for upcoming disseminations: ``The
agency shall provide its prediction regarding whether the dissemination
will be ``influential scientific information'' or a ``highly
influential scientific assessment,'' as the designation can influence
the type of peer review to be undertaken.''
Responses by Dr. Alan Moghissi,
President, Institute for Regulatory Science

Questions submitted by Subcommittee Chairman Andy Harris

I am greatly honored to have been invited to testify before the
Subcommittee on Energy and Environment of the House Committee on
Science, Space, and Technology. Your questions and my response to them
are as follows:

Q1.  The Bipartisan Policy Center's 2009 report, ``Improving the Use of
Science in Regulatory Policy'' was mentioned several times during the
hearing. This report made several suggestions that may be useful in
guiding this Subcommittee's efforts to reform regulatory science,
including:

``Studies used in the formulation of regulation should be
subject to data access requirements equivalent to those under the Data
Access Act.''

``The process of conducting literature reviews'' and ``the
process of naming advisory committees'' should be made more
transparent.

``Agencies should avoid turning repeatedly to the same
scientists for service on advisory committees.''

Executive branch agencies need to ``help clarify for both
officials and the general public which aspects of disputes are truly
about scientific results and which concern policy.''

``Policy makers should be wary of conclusions of risk that
are expressed as a single number.''

``Federal agencies need to experiment with ways to increase
the number of scientists who participate in peer review.''

``In presenting the conclusions of literature reviews,
agencies and their scientific advisory committees need to be as open
and precise as possible in discussing levels of risk and uncertainty.''

Do you agree with any or all of these recommendations? Do you have
any additional comments or advice in pursuing these goals?

A1. I am in fundamental agreement with the above items. Before I
respond to the question permit me to briefly address certain issues
that would simplify my response to this and other questions:

1. It may be recalled that in my testimony on November 30, 2011, I
provided a definition for regulatory science which is the generalized
version of definition used by various organizations. I also provided
five principles as the foundation of Metrics for Evaluation of
Regulatory Science Information (MERSI) and three pillars for scientific
information (SI) derived from the MERSI principles. Furthermore, my
testimony emphasized the need to identify assumptions, judgments,
application of default data, and other non-reproducible (NR) segments
in SI.

2. A large number of contested decisions of the EPA are traceable to
its history and how the regulatory process at the EPA evolved.
President Nixon established the EPA in December of 1970 by combining a
number of organizations from various federal agencies. Upon its
formation, the EPA faced a number of legally mandated deadlines and
during the early history of the EPA many laws were enacted or
reauthorized including Federal Insecticide, Fungicide, and Rodenticide
Act (FIFRA in 1972), Safe Drinking Water act (SDWA in 1974), Toxic
Substances Control Act (TSCA in 1976), Clean Water Act (CWA in 1977),
and Clean Air Act (CAA in 1977). In the overwhelming majority of cases,
the scientific information and supporting data were insufficient to
promulgate regulations based on acceptable science. During the Initial
Phase of the EPA's history that lasted about one decade, the
administrators had no other choice but to use what has become known as
Best Available Technical Information (BATI). Although in a few cases,
they were able to use Partially Reproducible SI, in the majority of
cases they were forced to rely upon SI at lower level of scientific
maturity notably judgment of the EPA staff and EPA consultants. In
order to be protective of heath and environmental effects of pollutants
they chose what they called the ``conservative'' approach and
overestimated, and often significantly overestimated the human health
end environmental effects of the pollutant. During this period, the
independent peer review process was virtually unknown.

3. The next decade of the EPA's history could be appropriately called
the Exploratory Phase. That phase started with the reappointment of
William Ruckelshaus by President Reagan and followed by his successor,
Lee Thomas. These administrators attempted to move the scientific
foundation of regulator decisions from the Initial Phase to a process
that would be scientifically more acceptable. However, during this
phase the process used during the Initial Phase continued and the BATI
process remained the predominant process at the EPA.

4. I and many other EPA employees had hoped that the Exploratory
Phase would quickly come to an end and a final phase would use
scientific methods and approaches commonly used in most scientific
disciplines. Unfortunately, despite an enormous level of funding;
objections by regulated communities; court cases; and reviews and
comments by organizations such as National Academies, Bipartisan Policy
Center, and Institute for Regulatory Science, EPA has yet to leave the
Exploratory Phase and often relies upon BATI that was common during its
Initial Phase.

In the following I will try to respond to the items identified in the
first question:

Question: ``Studies used in the formulation of regulation should be
subject to data access requirements equivalent to those under the Data
Access Act.''

Response: The Data Access Act requires that agencies provide
information to those who request it using the Freedom of Information
Act (FOIA). Experience shows repeated abuse of FOIA and thus a more
appropriate approach would be compliance with Transparency Principle of
MERSI. Congress should mandate that all scientific data with the
exception of those that would violate laws dealing privacy or national
security, should be placed on the Internet so that the entire
scientific community could have access to the information and use the
data for scientific assessments.

Question: ``Agencies should avoid turning repeatedly to the same
scientists for service on advisory committees.''

Response: As will be described in the response to the question on
peer review, it is imperative to ensure that information included in
NR/SI is not based on the philosophical, ideological, or other views of
an individual. Therefore, it is necessary to avoid seeking repeatedly
the services of the same individuals as members of the advisory
committees.

Question: Executive branch agencies need to ``help clarify for both
officials and the general public which aspects of disputes are truly
about scientific results and which concern policy.''

Response: There is a similarity between the views expressed by the
report of the Bipartisan Policy Center of 2009. It may be recalled that
the third pillar of MERSI is ``areas outside the purview of science.''
Mixing science with policy and other nonscientific issues is not only
undesirable but may have adverse consequences. As sated above, it is
imperative to separate science from its policy implications. Whereas
properly performed independent peer review can evaluate the validity of
scientific claims, and the reasonableness of selection of NR/SI
including potential alternatives, a scientific panel is not necessarily
qualified to judge the acceptability of chosen policies or identify
potential alternatives.

Question: ``Policy makers should be wary of conclusions of risk that
are expressed as a single number.''

Response: This question addresses one of the most important issues
that led to my recommendation of passing the Regulatory Science
Sunshine Act. During my tenure at the EPA I managed a risk research
program which led to the development of the methodology of ecological
risk assessment, a process currently used at the EPA but also globally
accepted. Risk assessment for human health and ecology consists of
several steps including: source assessment; transport and
transformation of pollutant leading to exposure assessment; exposure-
effect assessment also known as dose-response function; effect
assessment; and finally risk characterization. In most cases, the EPA
uses the steps following source assessment to regulate emission of
pollutants. In every step there are assumption, judgments and numerous
other areas that I called NR in the above description. In virtually
every step statistical methods can be and often are used. Instead of
statistically evaluating the combined uncertainties in various steps,
EPA often uses the upper 95th percentile in each step and then combines
the values and statistically evaluates the values. In the final step
the upper 95th percentile is reported. EPA has all the right to use the
upper 95th percentile provided the midpoint and lower 5th percentile
are also provided.

Question: ``Federal agencies need to experiment with ways to increase
the number of scientists who participate in peer review.''

Response: One of the fundamental principles governing peer review and
scientific assessment is to avoid using an individual repeatedly in
these activities. Increasingly, a rule of thumb has been established
requiring that an individual who is qualified to be a ``peer'' may not
be used more than three times .The consequence of violating this rule
is more significant that it may appear. It may be recalled that
scientific foundation of EPA's actions is at best Partially
Reproducible SI, and often lower level of scientific maturity going
down to SI based on Judgment. In all of these SI classes, there are
assumptions, judgments, application of default data and on occasion
societal objectives, identified described above as NR/SI. The repeated
use of an individual institutionalizes his/her selection of NR/SI and
societal objectives.

Question: ``On presenting the conclusions of literature reviews,
agencies and their scientific advisory committees need to be as open
and precise as possible in discussing levels of risk and uncertainty.''

Response: In the past and to some extent today, the EPA reviews the
existing literature and chooses one or a select number of information
as the foundation of the scientific decisions. It is necessary for the
EPA to include all information, identify NR/SI and justify the choices.

Q2.  A recent joint report from the EPA's Science Advisory Board and
Board of Scientific Councilors recommended that the Agency ``include
sustainability in its research vision'' in order to allow ``EPA to
adopt sustainability as a core principle to inform decisions and
actions.'' Is this emphasis on sustainability appropriate for EPA's
research and science activities?

A2. I remember fondly the establishment of the Science Advisory Board.
The task of the Board was to provide scientific advice to the EPA
managers and review their scientific activities. Although I am
unfamiliar with the Board of Scientific Councilors, I presume that
their mission is to provide scientific advice. Sustainability is a
societal goal much like many other societal goals such as energy
independency or global food supply that include environmental
considerations. The two scientific organizations would be well advised
to consider the statement by William Ruckelshaus who stated `` . . .
all scientists must make it clear when they are speaking as
scientists--ex cathedra--and when they are recommending policy they
believe should flow from scientific information.. What we need to hear
more of from scientists is science.'' Much like many other societal
goals sustainability is a highly desirable but should be mandated by
Congress and not by scientific groups.

Q3.  Many of the regulatory activities that EPA is currently
undertaking are based upon statues and priorities from several decades
ago. In your view, are we focusing our attention and scientific
resources on the most pressing environmental issues? Are there ways
that EPA could better prioritize?

A3. I believe that currently, the EPA is focusing its efforts including
significant resources to activities that have marginal human health and
environmental benefits with high-levels of expenditure. By exaggerating
the benefits and underestimating the costs EPA tries to justify its
decisions. Traditionally, the EPA has attempted to address chemical and
radiological agents and has left decisions on microbiological agents to
other agencies. EPA would be well advised to address the exceedingly
complex microbiological pollution.

Q4.  Dr. Marchant recommended the Health Effects Institute or the
European Food Safety Agency as potential models for conducting
independent scientific assessments as an alternative to the current EPA
practices. In your experience, are there other governmental or non-
governmental organizations that demonstrate characteristics in
scientific assessment or R&D that could serve as a useful model for
science reform at EPA?

A4. There is a distinction to be made between performing scientific
assessments and having the resulting activity independently peer
reviewed. EPA and its contractors are capable of preparing scientific
assessments. What is missing is a properly performed independent peer
review of the so prepared scientific assessment. The Institute for
Regulatory Science has performed over 300 peer reviews for government
agencies at federal, state, and local levels and for Congress. In most
cases, the oversight of these reviews was performed by a committee
established by the American Society of Mechanical Engineers in
cooperation with several other professions societies. The critical part
of thee reviews was the proper formulation of review criteria
(questions provided to the reviewers).The subject is too complex to be
addressed in this response and our upcoming text book on peer review
(as references in my testimony) provides details of the peer review
requirements.

Q5.  Many EPA science activities are housed within regulatory offices.
For example, EPA's Office of Air and Radiation (rather than the Office
of Research and Development) manages the National Fuel and Vehicle
Emissions Laboratory, as well as the National Air and Radiation
Environmental Laboratory. In your view, should science activities be
organizationally insulated from regulatory activities to ensure
objectivity and balance?

A5. As initially designed the sole objective of having scientists and
engineers assigned to program offices was to ensure scientific
competency within those offices so that scientific issues could be
addressed within those offices in promulgation or enforcing
regulations. In order for these Individuals to be informed on the
technical development, they were permitted to participate in technical
activities of their respective professions. If the above-mentioned
laboratories or any other laboratory in the EPA is predominantly
performing R&D, it should be assigned to the Office of Research and
Development.

Q6.  Some scientific information that is disseminated by federal
agencies is subject to specific data quality requirements. Are there
additional steps that you think could be taken to ensure that these
peer review and data quality guidelines are followed or expanded for
important scientific information at EPA?

A6. As stated several times both in my testimony and in response to
question in this document, the scientific foundation of EPA's decision
often include assumption, judgments, default data and occasionally
societal objectives. Consequently, the review criteria (questions
provided to the reviewers) should include the following:

Are the assumptions (defined as information that cannot be
reproduced by any individual with sufficient knowledge and equipment,
if required) justified?

How would the conclusions be different if the assumptions
chosen by the EPA would be replaced by other assumptions?

Are the judgments (as defined under assumptions) justified
and would the conclusions be different if the judgment chosen by the
EPA would be replaced by other?

Are the chosen defaults data justified and would the
conclusions be different if the default data chosen by the EPA would be
replaced by others?

Has the EPA provided justification for including non-
scientific criteria (often justified for being protective) in the
science instead of including it in the administrative and policy
decisions?

Q7.  Nearly all of EPA's recent Clean Air Act Regulations have been
justified on the basis of two studies that rely on entirely on data
from the American Cancer Society and the so-called Harvard Six Cities
Study. Despite the fact that these data sets were developed with
government funds and provide the basic Agency justification for costly
regulations, they are not publicly-available so that they can be
analyzed by other scientists. Do you support making this type of
information transparent? In your view, would making these underlying
data sets available to everyone improve the Agency's regulatory
decisions?

A7. In the interest of transparency, let me start be declaring that the
late Ben Ferris, one of the leaders of the Harvard Six City Study, was
a friend and I was briefly the project officer for that study. Both
studies can be classified as Correlation-Based SI and it is highly
likely that other investigators using the same data would come to
different conclusions than those reached by the respective authors. I
strongly recommend that the raw data from both the Harvard and American
Cancer Society studies be placed on the web. There is no justification
for not making the raw data available to other scientists.
Responses by Dr. Kenneth P. Green
Resident Scholar,
American Enterprise Institute

Questions submitted by Subcommittee Chairman Andy Harris

The views expressed in this testimony are those of the author alone and
do not necessarily represent those of the American Enterprise
Institute.

Q1.  The Bipartisan Policy Center's 2009 report, ``Improving the Use of
Science in Regulatory Policy'' was mentioned several times during the
hearing. This report made several suggestions that may be useful in
guiding this Subcommittee's efforts to reform regulatory science,
including:

``Studies used in the formulation of regulation should be
subject to data access requirements equivalent to those under the Data
Access Act.''

``The process of conducting literature reviews'' and ``the
process of naming advisory committees'' should be made more
transparent.

``Agencies should avoid turning repeatedly to the same
scientists for service on advisory committees.''

Executive branch agencies need to ``help clarify for both
officials and the general public which aspects of disputes are truly
about scientific results and which concern policy.''

``Policy makers should be wary of conclusions of risk that
are expressed as a single number.''

``Federal agencies need to experiment with ways to increase
the number of scientists who participate in peer review.''

``In presenting the conclusions of literature reviews,
agencies and their scientific advisory committees need to be as open
and precise as possible in discussing levels of risk and uncertainty.''

Do you agree with any or all of these recommendations? Do you have
any additional comments or advice in pursuing these goals?

A1. The suggestions of the Bipartisan Policy Center (BPC) referenced in
the Subcommittee's follow-up questions have considerable merit. More
transparency; more data-sharing; greater diversity of agency reviewers;
greater distinctions between scientific findings and value-driven
decisions; more accurate descriptions of proposed risks; and greater
explanations of uncertainty levels could only lead to better public
policy development.

I am not convinced that the BPC's recommendation to ``avoid turning
repeatedly to the same scientists for service on advisory committees''
is either necessary, nor particularly feasible. There are, after all, a
limited pool of scientists who will have particular expertise, time,
willingness, and capability of giving quality service on a review
committee. It seems reasonable that an agency might repeatedly turn to
a particular reviewer who has shown a willingness and ability to
participate in previous reviews. Should sufficient safeguards be in
place to guarantee balanced points of view, avoid conflicts of
interest, etc., agencies should, I think, have the discretion to use a
person as a ``regular'' reviewer.

Q2.  A recent joint report from the EPA's Science Advisory Board and
Board of Scientific Councilors recommended that the Agency ``include
sustainability in its research vision'' in order to allow ``EPA to
adopt sustainability as a core principle to inform decisions and
actions.'' Is this emphasis on sustainability appropriate for EPA's
research and scienceactivities?
A2. EPA's efforts to insert a ``sustainability'' agenda into their
mission is, I believe, politically driven and unwise. I most certainly
do not believe that the EPA should ``include sustainability in its
research vision.'' ``Sustainability'' is a highly subjective term in
both spatial and temporal domains. One can define actions as
sustainable in a region, or with regard to the entire planet. One can
define actions as sustainable for a year, a decade, a century, or for
eternity. Such a plastic term would grant EPA extremely wide latitude
in its ability to regulate activities that are far outside what I feel
is its only legitimate function, which is to protect human health and
property from damage via environmental contamination. Additionally,
arguments about ``sustainability,'' are often used to promote favored
technologies at the expense of disfavored technologies, and plays into
the hands of both rent-seekers and activist governments. Thus, by
declaring fossil fuels ``unsustainable,'' and wind or solar power
``sustainable,'' EPA could slant the playing field against fossil fuel
development (as they already do, to the limits of their abilities).

Q3.  Last year you wrote about one specific example of EPA's National
Center for Environmental Research providing $1.4 million dollars to
recruit people to ``dredge through EPA's databases in order to gin up
new things for the agency to worry about and possibly regulate.'' Can
you discuss the role of these epidemiological associations in
establishing major regulations, and whether EPA-funded research is
being overly protective?
A3. In any large set of data, one can search for, and usually find, any
number of correlations. In fact, in very large sets of data, such
correlations are virtually certain to exist. But correlations do not
equal causality, and it's highly likely that researchers dredging
through very large data sets will find statistically significant
correlations that are not causally related. As the saying goes, ice
cream sales correlate with heat-stroke incidence, but that's not
because ice cream causes heat stroke, it's because they both correlate
with hot weather.

As I wrote in the article you referenced,

``It is one thing for scientists to identify sick populations, and
to investigate what it is that might be making them sick. It is another
thing entirely to sift through large data bases in order to come up
with correlations that may have no causal relationship.

And, ever helpful, EPA gives some examples of what such data-
dredging exercises might look like:

For example, while air pollution associations with respiratory and
cardiovascular disease have been studied most extensively, evidence is
beginning to emerge of possible air pollution impacts on additional
health conditions including diabetes, neurological disorders, and
reproductive and developmental outcomes. Studies also might evaluate
factors that confer increased sensitivity to air pollution effects such
as compromised health status, genetic variants, social and neighborhood
conditions, higher exposure and others. In addition, some research
groups have developed innovative methods and models to characterize
exposure that might be applied to health effects analyses in other
cohorts to understand whether certain sources or atmospheric components
contribute to observed geographic heterogeneity in health-exposure
associations.

Further, EPA has specific outcomes in mind. This is not random data
dredging, which would be bad enough. This program seeks to fund
directional data dredging that looks only for relationships suggesting
that exposures to various air pollutants causes harm to human health.
In EPA's words:

EPA is interested in research to explain heterogeneity in health
responses to air pollutants. Heterogeneity might be explained by: 1)
Individual characteristics and other environmental/social conditions
that increase the likelihood of an adverse health outcome among a
subset of the population. [emphasis mine]

To pay for this innovative regulatory fishing expedition, EPA
proposes to give away $1.4 million dollars in portions up to $300,000,
for projects that could last up to three years.

Now, there's nothing wrong with trying to ensure that people's
health is protected from dangerous air pollutants (in fact, I'd argue
that it's a very legitimate function of government), but there is
something wrong with organizing taxpayer funded fishing expeditions to
probe for new regulatory potential by seeking out obscure relationships
in large databases. And those problems are intrinsic to data dredging,
an frequently abused form of data mining.

Data dredging, according to Wikipedia, is ``the inappropriate
(sometimes deliberately so) use of data mining to uncover misleading
relationships in data. These relationships may be valid within the test
set but have no statistical significance in the wider population.''
Wikipedia gives a particularly relevant example: ``Suppose that
observers note that a particular town appears to be a cancer cluster,
but lack a firm hypothesis of why this is so. However, they have access
to a large amount of demographic data about the town and surrounding
area, containing measurements for the area of hundreds or thousands of
different variables, mostly uncorrelated. Even if all these variables
are independent of the cancer incidence rate, it is highly likely that
at least one variable will be significantly correlated with the cancer
rate across the area.''

Or, as the Congressional Research Office explains (in the context
of fishing for terrorists in air-travel databases):

Although data mining can help reveal patterns and relationships, it
does not tell the user the value or significance of these patterns.
These types of determinations must be made by the user. Similarly, the
validity of the patterns discovered is dependent on how they compare to
``real world'' circumstances. For example, to assess the validity of a
data mining application designed to identify potential terrorist
suspects in a large pool of individuals, the user may test the model
using data that includes information about known terrorists. However,
while possibly re-affirming a particular profile, it does not
necessarily mean that the application will identify a suspect whose
behavior significantly deviates from the original model.

Another limitation of data mining is that while it can identify
connections between behaviors and/or variables, it does not necessarily
identify a causal relationship. For example, an application may
identify that a pattern of behavior, such as the propensity to purchase
airline tickets just shortly before the flight is scheduled to depart,
is related to characteristics such as income, level of education, and
Internet use. However, that does not necessarily indicate that the
ticket purchasing behavior is caused by one or more of these variables.
In fact, the individual's behavior could be affected by some additional
variable(s) such as occupation (the need to make trips on short
notice), family status (a sick relative needing care), or a hobby
(taking advantage of last minute discounts to visit new destinations).

In other words, with data dredging, it really is a situation of
``Seek and ye shall find.'' It is one thing for scientists to identify
sick populations, and to investigate what it is that might be making
them sick. It is another thing entirely to sift through large data
bases in order to come up with correlations that may have no causal
relationship, but that might, nonetheless, cause EPA to spend scarce
taxpayer money researching the potential linkage, or worse, to
endlessly dredge through databases in search of ever lower, ever more
obscure health impacts to justify expanded regulation and EPA intrusion
into the economy.

Q4.  Many of the regulatory activities that EPA is currently
undertaking are based upon statutes and priorities from several decades
ago. In your view, are we focusing our attention and scientific
resources on the most pressing environmental issues? Are there ways
that EPA could better prioritize?

A4. Partly because of regulations, and partly because of the normal
march of technology, which leads to greater efficiency and
environmental cleanliness, most indicators of environmental quality
have improved dramatically in the last 40 years. The lowest hanging
fruit of environmental protection have been plucked, the largest risks
and degradations mitigated. We now chase after ever smaller risk-
reductions, and the EPA seems to think that no pollution of any kind is
acceptable anywhere, for even transient moments where no persons are
present. A zero-risk and zero-contamination mindset has us spending
ever greater sums for ever smaller benefits. Contrary to EPA's self-
congratulatory analysis, economists widely recognize that regulation
imposes a drag on economic growth. It is never a good idea to waste
public funds, but it is unconscionable to do so under the kind of
economic conditions we face today. Policy analysts point out that
regulations also impose burdens on people and by restricting their
liberty, can deprive them of opportunity.

Thus, I think it is very important, as your question mentions, that
EPA's activities should focus on areas of greatest environmental risk--
and even better, focus on approaches to reducing those highest-risks
with as little economic destruction as possible.

Unfortunately, as I mentioned in my testimony, EPA's questionable use
of science--particularly risk assessment as it relates to particulate
matter and low-dose exposures to various airborne toxics--drives the
agency's prioritization and activities.

To quote from my testimony:

As is common in the Public Health community, EPA's science-culture
seems highly risk-averse, so much so that when confronted with a range
of possible risks, they tend to accept assumptions and design
analytical protocols and frameworks in ways that lead to ever-greater
estimations of health risk from ever-lower levels of pollution
exposure. This is sometimes referred to as being ``conservative,'' or
``precautionary.'' In a medical context, this can be beneficial, and
indeed, nobody wants an agency to blithely dismiss proclaimed risks to
the public health.

However, when such artificially elevated risk estimates are
translated into economic estimates of regulatory benefit and cost, the
product is increasingly costly regulations that do increasingly little
good, or worse, actually imposes costs greater than the benefits it
produces.

This is where things diverge from harmless (if excessive) ``risk-
aversion'' into poor public policy, and it is, I think, a serious
problem: having a sound understanding of the proposed benefits and
costs of regulation is a prerequisite for rational public policy
development.

Without rigorous benefit-cost estimates, it is impossible for an
agency to determine regulatory priorities. Thus, even where an agency's
proposals might do more harm than good, they cannot optimally bring
resources to bear to secure the biggest safety return-on-investment for
regulatory investments potentially wasting scarce public tax resources.
This applies between agencies as well. If agency A uses methodologies
that inflate the risk posed by the things they regulate, they may well
draw public resources away from agency B, which uses more
scientifically accurate risk-assessment methods.

Q5.  Dr. Marchant recommended the Health Effects Institute or the
European Food Safety Agency as potential models for conducting
independent scientific assessments as an alternative to the current EPA
practices. In your experience, are there other governmental or
nongovernmental organizations that demonstrate characteristics in
scientific assessment or R&D that could serve as a useful model for
science reform at EPA?
A5. I have not made a formal study of how agencies other than EPA
manage risk assessment, so I will yield to Dr. Marchant on this matter.
I believe that other agencies, such as OSHA take a more pragmatic
approach to risk assessment, but again, having not formally studied
their methdologies, I can not say if they'd do better with
environmental risk assessment than does the EPA.

Q6.  Many EPA science activities are housed within regulatory offices.
For example, EPA's Office of Air and Radiation (rather than the Office
of Research and Development),manages the National Fuel and Vehicle
Emissions Laboratory, as well as the National Air and Radiation
Environmental Laboratory. In your view, should science activities be
organizationally insulated from regulatory activities to ensure
objectivity and balance?

A6. As I believe I mentioned in my testimony, it seems obvious to me
that having too many related functions within one agency is a problem
at EPA. Separation of functions such as risk assessment; peer-review of
risk assessments; crafting of risk management plans; sponsoring of
scientific inquiry related to risks the agency itself has a motivation
to regulate; and cost-benefit analysis could only improve the quality
of our efforts to manage environmental risk. Just as we know that
monopolies lead to reduced competitiveness and lower-quality products
over time, the same is true for government agencies and entities.

Q7.  Some scientific information that is disseminated by federal
agencies is subject to specific data quality requirements. Are there
additional steps that you think could be taken to ensure that these
peer review and data quality guidelines are followed or expanded for
important scientific information at EPA?

A7. In 2009, I testified before the Senate Environment and Public Works
Committee on the question of scientific integrity and transparency.
This is what I told the Committee:

As more and more of our nation's public policy decisions involve
the use of complex scientific information, it becomes more and more
important that our policymaking institutions make use of such
information in a process that is free of bias, is open to outside
review and analysis, allows for the airing of divergent opinion, and is
deliberative enough to ensure that the decisions we make are the right
ones.

As recent experience has shown, this is not currently the case.
Policies intended to mitigate climate change and conventional pollution
with the use of corn-ethanol have backfired badly. Rather than reduce
greenhouse gas emissions, poorly-thought out ethanol mandates have
increased them. Rather than reduce conventional air pollution, corn-
ethanol has increased them, along with polluting surface and ground
water, contaminating fish stocks with pesticide and herbicide residues,
and expanding oceanic dead-zones caused by algae which bloom as they
are over-fed by fertilizer run-off from corn agriculture. Most of these
problems were raised by non-governmental analysts before the ethanol
mandates were passed, but the policymaking process proved opaque to
such cautionary voices.

Now, warnings are coming from non-governmental policy analysts and
scientists that we may see equally perverse impacts from other forms of
renewable energy that are being promoted at breakneck speed through the
spending of stimulus money, and pending legislation involving energy
and climate change. For example, new scientific reports are validating
concerns expressed by energy analysts that concentrated solar power
systems may have unsustainable water demand and will imperil fragile
desert ecosystems.

Warnings that wind turbines are not environmentally benign are
being validated as they are found to cause noise pollution, visual
blight, bird and bat kills, and potentially harm livestock. One recent
study has found that mass transit systems may well produce more
pollution than the automobiles and air travel they seek to displace.
Left and right, we are seeing failings of our government's policymaking
bodies to listen to cautionary voices in the development of public
policy dependent on the sound use of scientific information.

The President's memoranda on Transparency and Open Government and
on Scientific Integrity are a good start, but they can only be
considered a start in the process to ensure that scientific information
is used properly in the process of public policy formation.

On the positive side of the ledger, the memoranda correctly
identify certain important elements of a transparent process featuring
scientific integrity. The President is exactly correct when he says
that ``political officials should not suppress or alter scientific or
technological findings and conclusions.''

It is also reassuring to see the President order that ``To the
extent permitted by law, there should be transparency in the
preparation, identification, and use of scientific and technological
information in policymaking.''

Of particular importance, I think, is the President's declaration
that ``Government should be participatory.'' As the President observes,
``Public engagement enhances the Government's effectiveness and
improves the quality of its decisions. Knowledge is widely disbursed in
society, and public officials benefit from having access to that
dispersed knowledge.''

The President's call for Executive departments and agencies to
offer Americans greater opportunities to participate in policymaking
processes and to infuse the decision-making process with their
``collective expertise and information'' is spot on.

But all too often, I have seen an assumption that only scientists
working within government, or dependent on governmental grants have
worthwhile knowledge to inject into public policy decision-making.
There is, I believe, an inherent bias against scientists in the private
sector, even though those are often the people who, day by day, in
their laboratories, are producing the prescription drugs that save
millions, and who develop the technologies that empower billions.

The same is true with regard to the President's (and agency)
emphasis on the peer-reviewed literature. As we have discovered through
revelations about fraud in the scientific and medical literature, peer-
review is no guarantee of accuracy. And often, the keys to publication
are in the hands with those who have a vested interest in preserving
the theory that gained them the prestige and standing to be considered
as peer-reviewers. As a recent article, ironically published in the
peer-reviewed journal PLOS Medicine demonstrated, ``most claimed
research findings are wrong.''

The President, Congress, and regulatory agencies should explicitly
recognize that there is a legitimate role for non-governmental,
independent scientific participation in the public policy decision-
making process in terms of both personnel, and the injection of
scientific research conducted outside the peer-reviewed literature.

Many times, over my career, I have seen a lack of real opportunity
for consultation in the policymaking process. I have seen massive
scientific reports issued by state and federal governmental agencies
the day before Thanksgiving weekend, or just before the Christmas
season, with minimal time allowed for the review of thousand-page
scientific summary documents, and only trivial opportunities for
meaningful consultation. We may see that again in coming months, where
we've been promised the passage of landmark legislation on climate
change, just in time for the Independence Day holiday, and many
people's summer vacation.

Post-regulatory release of Regulatory Impact Assessments, as was
the case with the 1997 revisions to the National Ambient Air Quality
Standards, have sometimes made a mockery of the very idea of
consultative decision making.

Massive dockets in which thousands of review comments receive
little more than blithe dismissals have been common features of
governmental decision-making on important scientific issues I have
sought to analyze over the last 18 years.

Well-credentialed and experienced scientists have too often been
frozen out of consultative processes because they are viewed as tainted
by an industrial connection, or because they hold unorthodox views.

In conclusion, the President's memoranda on Transparency and Open
Government, and Scientific Integrity are a good step, but only a single
step in improving the way that our government makes use of scientific
information at all levels of the decision-making process.

As more and more issues require the use of such information, more
attention needs to be paid to reforming the processes by which
scientific information is gathered, validated, balanced, summarized,
and used to inform the decision-making process.

Finally, it must always be remembered that science may be able to
tell us ``what is,'' but it can never tell us ``what to do.'' Science
informs--it does not compel. Public policy formation involves the
balance of many factors, social, economic, ethics, equity, individual
rights, personal responsibility, and more.

Creating openness and transparency in the scientific elements of
the decision-making process is important, but that same level of
openness, transparency, and consultation should infuse every element of
the public policy development process.

Q8.  Nearly all of EPA's recent Clean Air Act regulations have been
justified on the basis of two studies that rely on entirely on data
from the American Cancer Society and the so-called Harvard Six Cities
Study. Despite the fact that these data sets were developed with
government funds and provide the basic Agency justification for costly
regulations, they are not publicly-available so they can be analyzed by
other scientists. Do you support making this type of information
transparent? In your view, would making these underlying data sets
available to everyone improve the Agency's regulatory decisions?

A8. While I understand the need to protect privileged information, and
the confidentiality of the doctor-patient relationship, I believe that
it is of utmost importance that the key data used to determine risk-
assessments be available for independent review: not simply by an
institution picked by EPA, or by any given agency, but by anyone who
wants to examine the data.

As we have seen with climate change data manipulation in the case of
the infamous hockey stick graph, and the revelation of a cliquish
mentality on the part of researchers that was clearly to the detriment
of our understanding of climate science, outside review is absolutely
vital if we are to have confidence in the quality of the data that is
being used to formulate far-reaching public policy initiatives.

There is no reason why suitably blinded data could not be made
available to allow others to review the validity of the ACS and Harvard
6-Cities studies which, as you point out, are overwhelmingly important
in how EPA develops air quality policy.
Responses by Dr. Gary Marchant,
Professor of Law and Executive Director
Center for Law, Science & Innovation,
Arizona State University

Questions submitted by Subcommittee Chairman Andy Harris

Q1.  The Bipartisan Policy Center's 2009 report, ``Improving the Use of
Science in Regulatory Policy'' was mentioned several times during the
hearing. This report made several suggestions that may be useful in
guiding this Subcommittee's efforts to reform regulatory science,
including:

``Studies used in the formulation of regulation should be
subject to data access requirements equivalent to those under the Data
Access Act.''

``The process of conducting literature reviews'' and ``the
process of naming advisory committees'' should be made more
transparent.

``Agencies should avoid turning repeatedly to the same
scientists for service on advisory committees.''

Executive branch agencies need to ``help clarify for both
officials and the general public which aspects of disputes are truly
about scientific results and which concern policy.''

``Policy makers should be wary of conclusions of risk that
are expressed as a single number.''

``Federal agencies need to experiment with ways to increase
the number of scientists who participate in peer review.''

``In presenting the conclusions of literature reviews,
agencies and their scientific advisory committees need to be as open
and precise as possible in discussing levels of risk and uncertainty.''

Do you agree with any or all of these recommendations? Do you have
any additional comments or advice in pursuing these goals?

A1. I agree with all these recommendations of the Bipartisan Policy
Center's report. I think the 4th recommendation listed on the
importance of separating science from policy is critical. If the two
are mixed together and confused, accountability and oversight, as well
as public participation, are undermined. Putting scientific
determinations in a separate institution from policy decisions, such as
the Institute for Scientific Assessments I have proposed, would achieve
this crucial separation.

Q2.  A recent joint report from the EPA's Science Advisory Board and
Board of Scientific Councilors recommended that the Agency ``include
sustainability in its research vision'' in order to allow ``EPA to
adopt sustainability as a core principle to inform decisions and
actions.'' Is this emphasis on sustainability appropriate for EPA's
research and scienceactivities?
A2. I have not read this report so cannot comment on it specifically. I
do believe sustainability, if defined and applied broadly, can provide
an appropriate framework for EPA's research program. It would broaden
EPA's focus from solely environmental impacts to consider also broader
economic and social values and impacts. It could help move EPA from the
adversarial, command and control philosophy that was developed in the
1970s to a more collaborative, cooperative paradigm that is more
appropriate to the more complex challenges facing us today.

Q3.  Many of the regulatory activities that EPA is currently
undertaking are based upon statutes and priorities from several decades
ago. In your view, are we focusing our attention and scientific
resources on the most pressing environmental issues? Are there ways
that EPA could better prioritize?

A3. The 1970s-era environmental statutes and regulations are increasing
obsolete, and tend to shackle EPA into rigid, media specific, end of
pipe controls that no longer represent the current priorities facing
the nation. EPA should have more flexibility to explore market,
cooperative/partnership, and other innovative approaches to address
remaining problems. For example, the EPA Project XL program was a win-
win for the environment and companies subject to artificially rigid and
narrow regulations. That program was terminated because it was not
consistent with the outdated 1970s-era statutes EPA continues to
regulate under.

Q4.  You proposed the establishment of an ``Institute for Scientific
Assessment'' to conduct R&D that is currently housed within EPA. Please
describe which particular science and R&D activities this Institute
could take over from the Agency. In particular, please assess the
feasibility of this organization overseeing and conducting: Integrated
Risk Information System assessments; integrated science assessments for
National Ambient Air Quality Standards; and determinations about
research priorities.

A4. The Institute for Scientific Assessments (ISA) as I have proposed
it would not oversee research programs, but would conduct scientific
assessments. The ISA would conduct assessments such as IRIS evaluations
and NAAQS integrated scientific assessments. The results of these
assessments would then be forwarded to EPA for its regulatory
decisions. As I have proposed it, the ISA would not provide
recommendations on research priorities, but it is conceivable that the
mission of the ISA could be expanded in that direction.

Q5.  Many EPA science activities are housed within regulatory offices.
For example, EPA's Office of Air and Radiation (rather than the Office
of Research and Development),manages the National Fuel and Vehicle
Emissions Laboratory, as well as the National Air and Radiation
Environmental Laboratory. In your view, should science activities be
organizationally insulated from regulatory activities to ensure
objectivity and balance?

A5. Yes, I believe scientific activities should be institutionally
separated from regulatory activities. Placing scientific assessments
within the institutional context of, and under the control of,
regulatory officials has the potential to consciously or subconsciously
influence and bias the nature and outcome of the scientific
assessments. This is inconsistent with good scientific practice, which
should be insulated from political, policy and personal influences as
much as practically possible.

Q6.  Some scientific information that is disseminated by federal
agencies is subject to specific data quality requirements. Are there
additional steps that you think could be taken to ensure that these
peer review and data quality guidelines are followed or expanded for
important scientific information at EPA?

A6. I have two suggestions. The first one would be to place the
activities subject to the peer review and data quality guidelines
within an institutional context that is familiar with and dedicated to
the principles of good scientific practice that are behind the
guidelines. I think an organization like the Institute of Scientific
Assessments that I have proposed, that is operated and managed from top
to bottom by scientists applying scientific methods and customs, would
be more likely to take seriously and adhere to the peer review and data
quality guidelines. My other suggestion is to make the guidelines
enforceable through judicial review. Unless the guidelines have teeth,
they are unlikely to be influential in an environment with so many
other factors influencing decision-making.

Q7.  1Nearly all of EPA's recent Clean Air Act regulations have been
justified on the basis of two studies that rely on entirely on data
from the American Cancer Society and the so-called Harvard Six Cities
Study. Despite the fact that these data sets were developed with
government funds and provide the basic Agency justification for costly
regulations; they are not publicly-available so they can be analyzed by
other scientists. Do you support making this type of information
transparent? In your view, would making these underlying data sets
available to everyone improve the Agency's regulatory decisions?

A7. I definitely think the data should be transparent and publicly
available. Transparency is a key requirement of science in order to
allow scientific findings to be replicated. As one recent review of
what makes good science stated: ``The essence of good science is
repeatability. Different scientists, in different places, at different
times, can repeat good science if they follow the same methods and
protocols.'' Dr. Samuel McNaughten, What is Good Science?, Natural
Resources & Envt. (ABA), Spring 1999, at 513. A recent special section
in the journal Science on the importance of data replication and
reproducibility states: ``Replication--the confirmation of results and
conclusions obtained independently in another--is considered the
scientific gold standard . . . The importance of replication and
reproducibility for scientists is unquestioned. Sometimes attempts to
replicate reveal scientific uncertainties. This is one of the main ways
that sciences progresses. Unfortunately, in rare instances (compared to
the body of scientific work), it can also indicate fraud.'' B.R. Jasney
et al., Again, and Again, and Again . . . , Science 234:1225 (Dec. 2,
2011) (citations deleted). If the underlying data are not made
available, they cannot be replicated, and thus the scientific validity
of the original study cannot be verified.

FOSTERING QUALITY SCIENCE AT EPA:
PERSPECTIVES ON COMMON SENSE REFORM--DAY II
(PART II)

----------

FRIDAY, FEBRUARY 3, 2012

House of Representatives,
Subcommittee on Energy and Environment,
Committee on Science, Space, and Technology,
Washington, DC.

The Subcommittee met, pursuant to call, at 9:52 a.m., in
Room 2318 of the Rayburn House Office Building, Hon. Andy
Harris [Chairman of the Subcommittee] presiding.

hearing charter

COMMITTEE ON SCIENCE, SPACE, AND TECHNOLOGY

SUBCOMMITTEE ON ENERGY AND ENVIRONMENT

U.S. HOUSE OF REPRESENTATIVES

Fostering Quality Science at EPA:

Perspectives on Common Sense Reform--Day II

friday, february 3, 2012
10:00 a.m.--12:00 p.m.
2318 rayburn house office building

Purpose

On Friday, February 3, 2012, the Subcommittee on Energy and
Environment of the Committee on Science, Space, and Technology will
hold a second day of testimony to provide external perspectives on the
need to reauthorize and reform science, research, and development
activities at the Environmental Protection Agency (EPA); explore the
intersection of Agency-supported science and its regulatory mission;
and receive focused recommendations to raise the level, quality,
usefulness, and objectivity of EPA science, including any necessary
changes to the Environmental Research, Development and Demonstration
Authorization Act.

Witnesses

Mr. Daniel Greenbaum, President and Chief Executive
Officer, Health Effects Institute

Dr. Deborah Swackhamer, Professor, Environmental Health
Sciences, University of Minnesota, and Chairwoman, EPA Science Advisory
Board

Mr. Michael Walls, Vice President, Regulatory and
Technical Affairs, American Chemistry Council

Dr. Richard Belzer, President, Regulatory Checkbook

Dr. Jerald Schnoor, Allen S. Henry Chair in Engineering,
Department of Civil and Environmental Engineering, University of Iowa

Dr. S. Stanley Young, Assistant Director for
Bioinformatics, National Institute of Statistical Sciences

Background

The Environmental Research, Development, and Demonstration
Authorization Act (ERDDA) authorizes research and scientific activities
at the Environmental Protection Agency (EPA). Originally enacted in
1976, Congress subsequently passed annual authorizations through fiscal
year 1981. In addition to establishing annual authorization levels,
these statutes also directed EPA policy in a variety of areas,including
establishing the Office of Research and Development (ORD), \1\
requiring a five-year environmental R&D plan, and creating EPA's
Science Advisory Board (SAB).
---------------------------------------------------------------------------
\1\ See Appendix 1 for EPA organizational structure.

Since 1981, there have been a number of bills introduced to
reauthorize ERDDA that were not ultimately enacted into law. \2\ As a
result, explicit authorization of EPA's environmental R&D ended at the
end of fiscal year 1981. This failure to comprehensively reauthorize
EPA research, development, and demonstration programs and activities
illustrates a broader trend among expired environmental statutes. The
Congressional Research Service notes this trend, stating, ``Although
Congress somewhat recently has renewed the authorization of
appropriations for certain EPA programs and activities through targeted
amendments to various statutes, a more comprehensive reauthorization of
many of the statutes that EPA administers has not been enacted for a
number of years.'' \3\
---------------------------------------------------------------------------
\2\ HR 3115 (1982), HR 2804 (1982), S. 1205 (1982), S. 2577 (1983),
HR 2899 (1984), S. 1292 (1984), HR 2319 (1985), S. 2702 (1985), S. 1144
(1986), HR 2355 (1987), HR 1523 (1987), HR 2153 (1989), HR 4873 (1990),
HR 2404 (1991), S. 1655 (1991), HR 1994 (1993), S. 1545 (1993), HR 2405
(1995), HR 1814 (1995), HR 3322 (1996), HR 1276 (1997), HR 1742 (1999),
HR 1743 (1999).
\3\ Congressional Research Service, ``Environmental Laws: Summaries
of Major Statutes Administered by the Environmental Protection
Agency,'' RL30798, August 11, 2011.
---------------------------------------------------------------------------
In addition to ERDDA, EPA also derives authority for R&D activities
through other major environmental statutes. For example, under the
Clean Air Act, the EPA Administrator must issue criteria that
``accurately reflect the latest scientific knowledge useful in
indicating the kind of extent of all identifiable effects on public
health or welfare which may be expected from the presence of such
pollutant in the ambient air.'' \4\ Through the Safe Drinking Water Act
(SDWA), EPA sets standards based on ``the best available, peer-reviewed
science and supporting studies conducted in accordance with sound and
objective scientific practices.'' \5\ Similarly, the Clean Water Act
(CWA) requires EPA to publish water quality information ``accurately
reflecting the latest scientific knowledge.'' \6\
---------------------------------------------------------------------------
\4\ 42 U.S.C. Sec. 7408(a)(2) (2000).
\5\ 42 U.S.C. Sec. 300g-1(b)(3)(A)(i).
\6\ 33 U.S.C. Sec. 1314(a)(1).
---------------------------------------------------------------------------
In many cases, these major regulatory statutes also authorize
specific R&D programs and activities. For example, the Clear Air Act
established a national research and development program for the
prevention and control of air pollution including establishing
technical advisory committees and research on air pollutant monitoring.
The SDWA authorized the Administrator of EPA to conduct research and
studies relating to the causes, diagnosis, treatment, control, and
prevention of physical or mental diseases resulting directly or
indirectly from contaminants in the water including improved methods to
identify and measure contaminants in drinking water and improved
methods to identify and measure the health effects of contaminants in
drinking water. The CWA directed the Administrator to establish
national programs for the prevention, reduction, and elimination of
pollution and as part of such programs to work in cooperation with
other State and federal agencies to coordinate and accelerate research,
investigation, experiments, demonstrations, and studies relating to the
causes, effects, extent, prevention, reduction, and elimination of
pollution in the navigable waters of the U.S.
The science enterprise at EPA is spread across program offices and
regions. ORD is organized into three national labs (comprised of 18
separate labs) and four national centers (which have 19 divisions). \7\
In addition to 18 labs within ORD, there are nine labs split among
several program offices and each of the 10 regions has its own lab. \8\
In FY 2010, the appropriations level for EPA Science and Technology
activities (S&T includes ORD and the other 19 labs) was $874.9 million.
The appropriations level for FY 2011 was $840.3 million. The FY 2012
House Committee-passed appropriations level is $777.6 million, and the
FY 2012 Senate Committee draft appropriations level is $809 million.
---------------------------------------------------------------------------
\7\ See Appendix 2.
\8\ See Appendix 3.
---------------------------------------------------------------------------
The fragmented nature of EPA R&D presents a challenge to program
management and coordination and has complicated efforts to evaluate the
effectiveness of these activities. Numerous studies conducted by the
EPA Office of Inspector General, the Government Accountability Office,
and others have cited significant concerns with the science activities
of the Agency and the difficulties in evaluating the usefulness of the
science to program needs. These studies have offered recommendations on
how to improve the science enterprise at EPA, but many of these
recommendations have not been implemented.

Chairman Harris. The Subcommittee on Energy and Environment
will come to order.
Good morning. Welcome to day two of the hearing entitled
``Fostering Quality Science at EPA: Perspectives on Common
Sense Reform.''
In front of you are packets containing the written
testimony, biographies and Truth in Testimony disclosures for
today's witness panel.
I want to welcome everyone, and we will have five minutes
for opening statements by myself and the ranking member. I want
to welcome everyone to the second day of our hearing on
fostering quality science at EPA. As this is a continuation of
the hearing held on November 30th of last year, I will be
brief.
Unfortunately, the Environmental Research, Development, and
Demonstration Authorization Act, or ERDDAA, which is the
statute authorizing R&D at EPA as well as the Science Advisory
Board, was last reauthorized for fiscal year 1981. I think we
can all agree that our fiscal, environmental, and economic
priorities have changed dramatically over the past 30 years,
and we should have statutes and a Congressional role in
environmental policy that reflects those changes. As we have
held nearly a dozen oversight hearings on specific EPA issues
during this Congress, we have seen patterns of behavior that
suggest the need for significant reforms.
At day one of this hearing, we received testimony from
several witnesses with decades of experience with the Agency:
Susan Dudley of George Washington University, who formerly
served as head of the White House Office of Information and
Regulatory Affairs; Alan Moghissi of the Institute for
Regulatory Science; Ken Green of the American Enterprise
Institute; and Gary Marchant of Arizona State University. They
provided specific recommendations on reforming scientific
activities at EPA, including the need to separate science and
policy; to quantify uncertainties; to ensure greater
transparency in the data, models, and assumptions used in
regulatory decisions; to prioritize environmental problems and
solutions; and to stop overly alarmist approaches to benefit-
cost analysis.
I want to thank the witnesses for appearing before the
Subcommittee, and I look forward to continuing this important
conversation with this panel of experts. That concludes my
opening statement.
[The prepared statement of Mr. Harris follows:]

Prepared Statement of Chairman Andy Harris

I want to welcome everyone to the second day of our hearing on
``Fostering Quality Science at EPA: Perspectives on Common Sense
Reform.''
As this is a continuation of the hearing held on November 30th of
last year, I will be brief.
Unfortunately, the Environmental Research, Development, and
Demonstration Authorization Act, or ERDDAA (ERDA), which is the statute
authorizing R&D at EPA as well as the Science Advisory Board, was last
reauthorized for fiscal year 1981. I think we can all agree that our
fiscal, environmental, and economic priorities have changed
dramatically over the last 30 years, and we should have statutes and a
Congressional role in environmental policy that reflects these changes.
As we have held nearly a dozen oversight hearings on specific EPA
issues during this Congress, we have seen patterns of behavior that
suggest the need for significant reforms.
At day one of this hearing, we received testimony from several
witnesses with decades of experience with the Agency: Susan Dudley of
George Washington University, who formerly served as head of the White
House Office of Information and Regulatory Affairs; Alan Moghissi of
the Institute for Regulatory Science; Ken Green of the American
Enterprise Institute; and Gary Marchant of Arizona State University.
They provided specific recommendations on reforming scientific
activities at EPA, including the need to separate science and policy;
to quantify uncertainties; to ensure greater transparency in the data,
models, and assumptions used in regulatory decisions; to prioritize
environmental problems and solutions; and to stop overly alarmist
approaches to benefit-cost analysis.
I want to thank the witnesses for appearing before the
Subcommittee, and I look forward to continuing this important
conversation with this panel of experts.

Chairman Harris. Mr. Miller.
Mr. Miller. Thank you, Chairman Harris.
Today the Subcommittee, as Chairman Harris said, meets
again for part two of the hearing we held at the end of
November on science at the EPA. The first two hearings in this
series were a disappointment, and a missed opportunity to build
a helpful record in preparation for the reauthorization of the
Environmental Research, Development, and Demonstration
Authorization Act. Mercifully, there is an acronym: ERDDAA.
However, today, I am pleased to see that we have some
panelists with the experience and knowledge required to address
in detail critical improvements that can make EPA's research
enterprise more effective, efficient, and transparent. At the
least, this is not just a panel of witnesses armed only with
talking points and flailing criticism meant to undermine or
dismantle the one agency charged with protecting our citizens
and the environment from unlawful pollution. Let us use their
time and ours wisely.
As I have said before, I approach this task hoping to work
with my Republican counterparts in pursuing reforms that will
lead to better research practices that help EPA accomplish its
mission. While we will not always agree on the best way to do
that, I am not interested in restructuring EPA to take the only
environmental cop off the beat. There are legitimate concerns
related to EPA's research infrastructure and processes, but
they are complex, and we have to approach the process in a
well-thought out and planned manner.
I have authored and co-authored many bills in my time here.
I understand the amount of research, stakeholder conversations,
and thought that must take place to write legislation as
important and ambitious as the reauthorization of ERDDAA.
EPA's scientific research is increasingly important as we
seek to understand and address more complex environmental
issues that continue to emerge and evolve. That was
demonstrated just 48 hours ago when this Subcommittee met to
consider EPA's role in examining groundwater research and the
start of the Pavillion Study process.
Scientific research knowledge and technical information are
fundamental to EPA's mission, and to inform its standard-
setting, regulatory, compliance, and enforcement functions.
That is why Congress created advisory bodies such as the Clean
Air Scientific Advisory Committee and the Science Advisory
Board that were created to provide independent advice on the
science that allows the Administrator to make regulatory
decisions. In addition to advice from an array of experts from
many fields, the scientific process also involves the use of
epidemiology and modeling to aid in hazard identification,
which is only the first stage of quantitative risk assessment.
But in the scientific process, epidemiology and modeling
investigations are not the only approach to research studies.
It is a multidisciplinary approach that includes real-time
monitoring, clinical and laboratory studies, model development,
measurement and exposure methods, characterization of sources,
and control technologies. Just like the process we need in
reauthorizing ERDDAA, the responsibility of the scientific
process and regulatory decision making takes a host of
perspectives, methods, and techniques.
In short, science should inform and support the decisions
we make, that Congress makes and the EPA makes, and most
important, we all have an ultimate responsibility to do
everything we can to make sure that everyone enjoys a decent
quality of life.
And Chairman Harris, I yield back.
[The prepared statement of Mr. Miller follows:]

Prepared Statement of Ranking Member Brad Miller

Thank you, Chairman Harris. Today the Subcommittee meets again for
part two of the hearing we held at the end of November on science at
the EPA. The first two hearings in this series were a disappointment
and a missed opportunity to build a helpful record in preparation for
the reauthorization of the Environmental Research, Development, and
Demonstration Authorization Act, or ERDDA.
However, today I am pleased to see that we have some panelists with
the experience and knowledge required to address in detail critical
improvements that can make EPA's research enterprise more effective,
efficient, and transparent. At the least, this is not just a panel of
witnesses armed only with talking points and flailing criticism meant
to undermine or dismantle the one agency charged with protecting our
citizens and the environment from unlawful pollution. Let's use their
time and ours wisely.
As I have stated before, I approach this task hoping to work with
my Republican counterparts in pursuing reforms that will lead to better
research practices that help EPA accomplish its mission. While we will
not always agree on the best way to do that, I am not interested in
restructuring EPA to take the only environmental cop off the beat.
There are legitimate concerns related to EPA's research
infrastructure and processes, but they are complex, and we have to
approach this process in a well-thought-out and planned manner. I have
authored and co-authored many bills in my time here. I understand the
amount of research, stakeholder conversations, and thought that must
take place to write legislation as important and ambitious as the
reauthorization of ERDDA.
EPA's scientific research is increasingly important as we seek to
understand and address more complex environmental issues that continue
to emerge and evolve. This was demonstrated just 48 hours ago when this
Subcommittee met to consider EPA's role in examining ground-water
research and the start of the Pavilion Study process.
Scientific research, knowledge, and technical information are
fundamental to EPA's mission, and inform its standard-setting,
regulatory, compliance, and enforcement functions. That is why Congress
created advisory bodies such as the Clean Air Scientific Advisory
Committee (CASAC) and the Science Advisory Board (SAB) that were
created to provide independent advice on the science which allows the
Administrator to make regulatory decisions. In addition to advice from
an array of experts from many fields, the scientific process also
involves the use of epidemiology and modeling to aid in hazard
identification, which is only the first stage of quantitative risk
assessment.
But in the scientific process that epidemiology and modeling
investigations are not the only approach to research studies. It is a
multidisciplinary approach including real-time monitoring, clinical and
laboratory studies, model development, measurement and exposure
methods, characterization of sources, and control technologies. Just
like the process we need in reauthorizing ERDDA, the responsibility of
the scientific process and regulatory decision making takes a host of
perspectives, methods, and techniques.
In short, science should inform and support the decisions we make.
And most important, we all have an ultimate responsibility to do
everything we can to ensure that EVERYONE continues to enjoy a decent
quality of life.
With that, Chairman Harris, I yield back.

Chairman Harris. Thank you very much.
At this time I would like to introduce our witness panel
and thank each of them for appearing before us today.
Our first witness is Mr. Daniel Greenbaum, President and
CEO of the Health Effects Institute. He has been a member of
the U.S. National Research Council, Board of Environmental
Studies and Toxicology, and Vice Chair of its Committee for Air
Quality Management. Mr. Greenbaum has over three decades of
governmental and non-governmental experience in environmental
health.
Our next witness is Dr. Deborah Swackhamer, a Professor of
Environmental Health Sciences at the University of Minnesota
and the Chairwoman of the EPA Science Advisory Board. She is
also a Governor appointee on the Minnesota Clean Water Council
and recently completed a one-year term as President of the
National Institute of Water Resources. She is also a member of
the Editorial Advisory Board for the Journal Environmental
Science and Technology and is Chair of the Editorial Advisory
Board of the Journal of Environmental Monitoring through the
end of last year.
Our third witness is Mr. Michael Walls, Vice President of
Regulatory and Technical Affairs for the American Chemistry
Council. He has experience in a wide range of domestic chemical
regulatory issues including the Toxic Substance Control Act,
Emergency Planning and Community Right to Know Act, and the
Resource Conservation and Recovery Act. His experience also
includes work on international chemical regulatory issues,
including the Europe Commission's Registration, Evaluation and
Authorization of Chemicals.
Our fourth witness is Dr. Richard Belzer, President of
Regulatory Checkbook. From 1988 to 1998, Dr. Belzer served as
Staff Economist in OMB's Office of Information and Regulatory
Affairs, where he reviewed major federal regulations and the
supporting analyses. He focused primarily on the assessment of
benefits and opportunity costs, both of which involve crucial
links to human health risk assessments.
Our fifth witness is Dr. Jerald Schnoor, Allen S. Henry
Chair in Engineering in the Department of Civil and
Environmental Engineering at the University of Iowa. Dr.
Schnoor chaired the Board of Scientific Counselors for the
Environmental Protection Agency, Office of Research and
Development, from 2000 to 2004. While serving as Editor in
Chief of Environmental Science and Technology, he guided the
leading journal in the world in both environmental engineering
and environmental science.
Our sixth and final witness is Dr. S. Stanley Young, the
Assistant Director for Bioinformatics at the National Institute
of Statistical Sciences. He is a fellow of the American
Statistical Association and the American Association for the
Advancement of Science. He has authored or co-authored over 50
papers including six Best Paper Awards and a highly cited book,
Resampling Based Multiple Testing.
Thank you all for appearing before the Subcommittee today.
As our witnesses should know, spoken testimony is limited to
five minutes each, after which the Members of the Committee
will have five minutes each to ask questions.
I now recognize our first witness, Mr. Daniel Greenbaum of
the Health Effects Institute.

STATEMENT OF MR. DANIEL GREENBAUM,

PRESIDENT AND CHIEF EXECUTIVE OFFICER,

HEALTH EFFECTS INSTITUTE

Mr. Greenbaum. Mr. Chairman and Members of the Committee, I
am pleased to appear before you today. I am Dan Greenbaum, as
you said, from the Health Effects Institute. We are a nonprofit
research institute with joint and balanced funding from U.S.
EPA and industry that for over 30 years has produced trusted
science to inform air quality decisions. I draw on HEI's and
other experiences to highlight five important principles for
producing credible science.
HEI was born out of controversy between EPA and industry
over whose science could be believed. We were established as an
independent, nonpartisan entity to produce health science that
could be agreed to by all parties, and we are designed with
several key elements to ensure impartiality: an independent,
high-level board of directors of distinguished science and
policy leaders who are not from sponsors; standing committees
of independent, respected experts; a research committee to
oversee all research; and a separate review committee to
conduct intensive peer review of all research and prepare a
commentary on the findings. The board also appoints special
expert committees to conduct targeted re-analyses of key
studies and systematic reviews of the literature.
All results from HEI are published and available for free,
and we work to actively provide access to all underlying data.
And importantly, HEI produces policy-relevant science, but we
do not take policy positions.
Now, HEI was not established to replace all science
produced for air quality and other environmental decisions but
HEI's design was designed to produce science of the highest
quality and credibility in often controversial circumstances.
Five key principles guide this work.
First, we engage scientists who are independent and
objective, scientists from a wide variety of arenas, not just
environment and health. It is essential that public and private
science organizations actively reach out to the widest possible
range of scientists with diverse perspectives and skills. Now,
scientist recruitment must also avoid real or readily perceived
conflicts of interest, and HEI, the National Academies, EPA and
others have procedures in place to identify these, but these
reviews of conflicts should not become a straitjacket that, for
example, disqualifies well-qualified scientists just because
they have been funded at times by industry or EPA or an
environmental organization. We need the best science, as long
as it is objective, from wherever it can come.
Second, science should be funded through vigorous, open
competition. HEI and a number of others including U.S. EPA's
Star Grant program, which has received exemplary reviews from
the National Research Council, use well-established techniques
for soliciting, reviewing, scoring and selecting projects.
Again, the broad-based recruitment of scientists to compete and
participate in these processes is essential to ensuring a level
playing field for the widest possible sets of institutes and
science perspectives.
Third, we need to apply the full range of multidisciplinary
skills, drawing on experts in emissions, exposure, toxicology
and epidemiology, but perhaps most important, we at HEI have
placed the field of statistics at the center of our work,
insisting on predesigned statistical analysis plans and
subjecting each study's results to detailed statistical review
to make sure that the best techniques were applied.
Fourth, all results must be subjected to intense peer
review and re-analysis if needed. Now, peer review has been a
cornerstone of science for many years, but with the profusion
of scientific journals in recent years, the quality of peer
review can vary substantially. This is further complicated by
the tendency of some journals to be more interested in
publishing studies that have found a positive effect, or so-
called publication bias. HEI's peer review process requires a
comprehensive report of all findings, not only positive
results, a broad-based standing expert peer review panel which
has had nothing to do with the study, the active engagement of
at least two statisticians in each review, and the ability to
request and gain access to all underlying data as part of that
review.
And finally, science should be conducted and reported with
full transparency. HEI seeks to produce its work with the
widest degree of disclosure of results and underlying data.
This is critical to ensuring that all positive and negative
results are reported and that the broader science community can
access and further analyze the results and data. We have even
placed entire databases for our studies on the Web for anybody
to go to at any time when that was possible.
Thank you for this opportunity to testify. I would be
pleased to answer any questions.
[The prepared statement of Mr. Greenbaum follows:]

Prepared Statement of Mr. Daniel Greenbaum,
President and Chief Executive Officer,
Health Effects Institute

Summary

The production of high-quality, credible science is of critical
importance to informing often-controversial policy decisions on
environment and health. For over 30 years, the Health Effects
Institute, an independent, not-for-profit research institute with joint
and balanced funding from U.S. EPA and industry, has produced trusted
science in a variety of forms to inform air quality decisions. This
testimony draws from that experience--and from the results of the
recent report of the Bipartisan Policy Center (Improving the Use of
Science in Regulatory Policy)--to highlight key principles of producing
credible science, including:

Engaging scientists who are independent and objective;

Funding science through vigorous open competition;

Applying the full range of multi-disciplinary skills;

Subjecting all results to intense peer review, and re-
analysis if needed; and

Conducting and reporting science with full transparency.

This testimony describes how each of these key principles
contributes to producing credible science; the critical elements
necessary for applying them successfully, and the degree to which
practice at US EPA and elsewhere in government includes these
approaches currently and/or could be enhanced.

Testimony

Mr. Chairman, and Members of the Committee, it is my pleasure to
appear before you at this important hearing, ``Fostering Quality
Science at EPA: Perspectives on Common Sense Reform--Day II.'' I am
Daniel S. Greenbaum, President of the Health Effects Institute (HEI),
an independent, not-for-profit research institute with joint and
balanced funding from U.S. EPA and industry that, for over 30 years,
has produced trusted science in a variety of forms to inform air
quality decisions. I also was pleased to serve recently on the
Committee of the Bipartisan Policy Center on Science and Policy, a
multi-party expert panel that made recommendations \1\ on improving the
development and use of science in policy. I draw on the rich experience
of HEI, and the recommendations of the Science and Policy Committee to
highlight several important principles for producing credible science
to inform environment and health decisions.
---------------------------------------------------------------------------
\1\ Bipartisan Policy Center. 2009. Improving the Use of Science in
Regulatory Policy. Washington, DC: Bipartisan Policy Center.

---------------------------------------------------------------------------
The Health Effects Institute

HEI was born out of controversy. During implementation of the Clean
Air Act rules for air quality and vehicle emissions in the 1970s, there
was substantial disagreement between manufacturers and the U.S. EPA
about the underlying health science driving decisions. HEI was
established with the support of U.S. EPA and industry as an
independent, non-partisan entity to produce health science that could
be agreed to by all parties--and could serve as the basis for better
decisions. HEI is designed with several key elements to ensure its
impartiality:

Joint and balanced core funding from US EPA and industry;

An independent, high-level Board of Directors of
distinguished science and policy leaders to guarantee the integrity of
the science, with members agreed to by the EPA Administrator and
industry but not containing any current sponsor employees;

Standing Committees of subject matter experts in
exposure, toxicology, epidemiology, statistics and other disciplines
who are not employees of sponsors and who may not have demonstrated ``a
lack of objectivity'' in their field:

Research Committee to design, conduct competitions for,
and oversee all research;

Review Committee to conduct intensive peer review of
all HEI-funded research, and prepare a Commentary on the scientific
findings and their implications for decisions.

Special Expert Committees appointed according to the same
principles to conduct targeted reanalyses of key studies and systematic
reviews of the literature in important areas.

Full transparency, with all results published and
available for free electronically, and active provision of access to
underlying data;

Importantly, HEI produces policy-relevant science, but
does not take policy positions.

With these elements in place, HEI has funded over 250 studies of a
wide range of air pollutants; reanalyses of a number of epidemiologic
studies central to decisions; and special reviews of the literature on
diesel exhaust, air toxics, traffic effects, and more. HEI's work has
been widely accepted as credible and comprehensive and is regularly
cited in decision making in the U.S. and worldwide.

Principles of Credible Science

HEI was not established to replace all science produced for air
quality policy decisions. Much science was then, and is today, produced
directly with funding from U.S. EPA, the National Institutes of Health,
and others. But HEI's design was developed to produce science of the
highest quality and credibility at the most critical and often
controversial junctures of science and decisions, and the key
principles that HEI has applied can inform the enhancing of credibility
of all science produced for informing decisions. These key principles
are:

Engaging scientists who are independent and objective:
Quality science for decisions requires the active involvement of a wide
range of talented individuals from diverse perspectives. Many
scientists are fully engaged in their research and teaching and
hesitant to become overly involved in often-controversial science/
policy settings. One result of this is that at times one can find a
range of scientists actively engaged in the work of organizations like
the National Academy of Sciences, but despite the best recruitment
efforts of entities such as the Science Advisory Board, unwilling to
engage in the scientific work of agencies like EPA. To further enhance
skills, HEI has sought to engage scientists from a wide variety of
arenas, not just environment and health; it is essential that public
and private science organizations actively reach out to the widest
possible range of scientists, seeking consciously to engage scientists
with diverse perspectives and skills.

For maximum credibility, scientist recruitment must also ensure
that scientists do not carry with them real or readily
perceived conflicts of interest, e.g., a direct financial
interest in the outcome of the scientific deliberation. The BPC
Science and Policy Report systematically reviews the many
detailed approaches that have been adopted by U.S. EPA, other
federal agencies, the NAS, and others for identifying both
biases and conflicts of interest, and recommends enhanced
approaches to this important task.

It is important, however, that such reviews of bias and conflicts
not act to unnecessarily place scientist selection in a ``strait
jacket'' that, for example, disqualifies well-qualified scientists
simply because they have been funded by industry or U.S. EPA, or have
done work or work currently for industry or an environmental
organization. Some of the best experts have received funds from a range
of sponsors, are capable of providing a balanced perspective on the
science, and should be included unless there is a real and current
conflict of interest.

Funding science through vigorous open competition: A
hallmark of the highest-quality science is to ensure that it is
selected and funded through the highest levels of peer-reviewed
competition. HEI and a number of other research programs, including
U.S. EPA's STAR grants program (which has received exemplary reviews
from the National Research Council) have used well-established
techniques for soliciting, reviewing, scoring, and selecting such
projects. At the same time, this is an area where the broad-based
recruitment of scientists to participate in these selection processes,
and the recusal of scientists from reviewing applications from their
own institutions, is essential to ensuring a ``level playing field''
for competitors from the widest possible set of institutions and
scientific perspectives.

Applying the full range of multi-disciplinary skills:
Since its inception, HEI has seen fully multi-disciplinary science as
the only way to answer complex questions facing decision makers in
environmental health. Thus, for example, a team studying the health
effects of certain emissions, or peer reviewing the results of such a
study, must include engineering and exposure measurement expertise. And
the best health studies will draw on a combination of toxicological and
epidemiological techniques to determine whether a certain exposure is
having an effect. Perhaps most important, HEI has placed the field of
biostatistics at the center of its work, insisting on pre-designed
statistical analysis plans for each major project, and subjecting each
study's results to intense statistical review to ensure that (a) the
best and most appropriate statistical techniques were applied and (b)
any positive results (i.e., those showing an ``effect'') are placed in
the context of the full range on positive and negative results before
interpreting the study's conclusions.

Subjecting all results to intense peer review, and re-
analysis if needed: Peer review has been a cornerstone of science for
generations and has served well, in general, to identify the strongest
contributions to the scientific literature on a wide variety of topics.
However, with the profusion of scientific journals in recent years, and
the diversification of peer review processes, the degree to which any
particular journal article is subjected to the highest level of peer
review can vary substantially. This is further complicated by the
tendency of journals to be more interested in publishing studies that
have found a positive ``effect,'' a ``publication bias'' which has now
been documented in a number of settings. \2\
---------------------------------------------------------------------------
\2\ Cf. Samet J.M., Zeger S.L., Dominici F., Curriero F., Coursac
I., Dockery D.W., Schwartz J., Zanobetti A. 2000. The National
Morbidity, Mortality, and Air Pollution Study, Part II: Morbidity and
Mortality from Air Pollution in the United States. Research Report 94.
Health Effects Institute, Cambridge, MA.

The HEI peer review process was designed to address these
shortcomings, especially for science at critical intersections
between science and decisions. That process includes several
key elements: (a) a comprehensive report of all findings, not
necessarily only the ``positive'' results; (b) a broad-based
standing panel of experts (the HEI Review Committee) which has
had nothing to do with the study and meets in person to review
each report and to prepare a detailed Commentary on the study
findings and their implications; (c) the active engagement of
at least two biostatisticians in each review; and (d) the
contractual ability to request and gain access to all
underlying data generated in the study and used in the
analysis. These and other steps result in a level of peer
review that is widely regarded as being as intense as, and in
some cases more intense than, the peer review at the best
---------------------------------------------------------------------------
scientific journals.

HEI has, at times, also been asked by Congress, U.S. EPA,
industry, and others to go beyond its intensive peer review of
its own studies to play two other intense review roles: the
reanalysis of key studies that are particularly central to
decisions (e.g., the HEI reanalysis of the Harvard Six Cities
and American Cancer Society studies), \3\ and the systematic
review of the complete scientific literature on emissions,
exposure, and health (e.g., recent reviews of the science on
the potential effects of exposure to air toxics and to traffic-
generated air pollution). \4\ In each of these cases HEI's
Board of Directors appoints multi-disciplinary expert panels
according to the same principles of independence to oversee
reanalysis and systematic literature reviews. And those efforts
are then in turn subjected to high levels of peer review by
experts who have not previously been involved.
---------------------------------------------------------------------------
\3\ Krewski D., Burnett R.T., Goldberg M.S., Hoover K., Siemiatycki
J., Jerrett M., Abrahamowicz M., White W.H. 2000. Reanalysis of the
Harvard Six Cities Study and the American Cancer Society Study of
Particulate Air Pollution and Mortality. A Special Report of the
Institute's Particle Epidemiology Reanalysis Project. Health Effects
Institute, Cambridge, MA.
\4\ Cf. HEI Panel on the Health Effects of Traffic-Related Air
Pollution. 2010. Traffic-Related Air Pollution: A Critical Review of
the Literature on Emissions, Exposure, and Health Effects. HEI Special
Report 17. Health Effects Institute, Boston, MA.

Conducting and reporting science with full transparency:
From its inception, HEI has sought to produce its work with the widest
degree of disclosure of results and underlying data. This is critical
to ensuring that all results--both positive and negative--are reported,
and that the broader science community can fully access, and further
analyze, the results and data. HEI's comprehensive reports present, for
free Web distribution, all methods and results, along with the
Commentary of the HEI Review Committee. And since the mid-1990s, HEI's
Board of Directors has had in place a Data Access Policy that has both
encouraged HEI investigators to make their data and analysis freely
available on the Web (for example, the data underlying HEI's National
Morbidity, Mortality and Air Pollution Study (NMMAPS)), \5\ and to
facilitate--wherever HEI investigators have full ownership of
underlying data--access for other investigators to the data.
---------------------------------------------------------------------------
\5\ www.ihapss.jhsph.edu.

Conclusions--Toward Credible Science for Environment and Health
---------------------------------------------------------------------------
Decisions

In conclusion, it is clear that science can and should play an
important role in providing the foundation for decisions on environment
and health, and that to do so, the science needs to be of the highest
quality and credibility. U.S. EPA and other agencies have established
procedures to produce and review science for decisions, and in many
cases those procedures work to enhance the quality and credibility of
the science. The HEI experience, founded out of a desire by both
industry and U.S. EPA for more readily trusted science, has illustrated
a number of key principles that can lead to even better science for
decisions in the years to come. Thank you for this opportunity to
testify. I would be pleased to answer any questions the Committee may
have.
Chairman Harris. Thank you very much.
I now recognize our second witness, Dr. Deborah Swackhamer
of the University of Minnesota and Chairwoman of the EPA
Science Advisory Board.

STATEMENT OF DR. DEBORAH SWACKHAMER, PROFESSOR,

ENVIRONMENTAL HEALTH SCIENCES,

UNIVERSITY OF MINNESOTA,

AND CHAIRWOMAN, EPA SCIENCE ADVISORY BOARD

Dr. Swackhammer. Good morning, Chairman Harris, Ranking
Member Miller and distinguished Committee Members. My name is
Deborah Swackhamer, and I hold the Denny Chair in Science
Technology and Public Policy at the Humphrey School of Public
Affairs at the University of Minnesota. I am trained as an
environmental chemist, and I am Professor of Environmental
Health Sciences in the School of Public Health and co-direct
the University's Water Resources Center.
I was appointed Chair of the SAB in 2008 by EPA
Administrator Stephen Johnson and reappointed for a second term
in 2010 by Administrator Lisa Jackson. While my perspectives
and opinions are my own, I am testifying today on behalf of the
SAB.
The SAB provides science advice to the EPA Administrator on
a wide range of scientific and technical issues. These issues
are complex, and they require a diversity of experience to
address. The SAB membership brings expert knowledge from the
natural and physical sciences, engineering, health sciences,
and social sciences including economics. Based on my years of
service on the board, I believe that the agency has a robust
process for identifying members with outstanding scientific
credentials who are committed to helping improve the quality of
agency science. The SAB and its committees and panels review
agency work products, undertake special studies when requested,
and perform self-initiated studies on topics that the Board
considers to be of critical importance.
Recent SAB advice that is directly relevant to this hearing
includes two reports we produced in 2009 and 2010 on strategic
directions for EPA research prepared for ORD to encourage
approaches and strategies needed to do their science most
effectively. These two reports have been instrumental in moving
ORD's research enterprise towards a more interdisciplinary
approach and one that can respond more nimbly and effectively
to the needs of the program offices and the regional offices.
The Administrator's One EPA and ORD Assistant Administrator
Anastas's ``The Path Forward'' strategies are consistent with
our previous advice. The board is in the process of finalizing
a report on how the agency can do a better job of integrating
science and problem formulation in its decision making.
The SAB is supportive of many changes that have taken place
in ORD in recent years. More could be done, more is being done,
but I believe and our reports have indicated that ORD is moving
in the right direction. We have advised strongly for an
integrated approach to EPA's scientific research, and the
agency has responded, as indicated by the realignment of
research programs from 13 independent programs to six
integrated programs. We have advised to include a greater
degree of social and decision science research, and the agency
is moving to fill this need. We have advised to develop the
capacity to respond to emerging issues and the new program
structure should move them in the right direction. We have
advised the agency to partner more nationally and
internationally and develop truly collaborative research
efforts in these times of limited and shrinking resources, and
they have been creative in doing so. Finally, we urged ORD to
support and creative incentives for their scientists to be more
innovative, and they have responded.
The SAB and presumably this Subcommittee share the goal and
commitment to assist EPA in producing and using high-quality
science to protect human health and the environment. The best
available science is essential to sound decision making but is
not the only aspect of sound policy decisions. What is best
available science? While hard to provide a simple one-size-
fits-all definition, generally, it is scientific results,
conclusions, and technical information that has been produced
using proven methods that has been peer reviewed where
hypotheses are tested with objective and unbiased approaches
and that has the support for its conclusions from other
independent studies. The role of the SAB is to examine the
scientific and technical knowledge that was synthesized within
the agency on a given issue and provide advice as to whether
this science was appropriate and adequate for its intended use.
Finally, the letter from Chairman Harris requested that I
comment on the capability of EPA to conduct and use the best
available science to fulfill its mission. The agency certainly
has the capability, given its excellent scientific enterprise.
It is sorely short of resources to provide the capacity needed
for all the science questions at the agency, and yet, there is
no other agency where such environmentally focused and directed
science is being done to fill the unique mission of protecting
the public's health and the environment on which they depend.
Investing in EPA science is a wise investment. That said,
this capability would be improved by continuing to address
scientific questions from an interdisciplinary approach, by
partnering more creatively with others, by involving
stakeholders in problem formulation, and integrating science
across the agency for the most effective decision making.
Thank you for the opportunity to speak with you today.
[The prepared statement of Dr. Swackhamer follows:]

Prepared Statement of Dr. Deborah Swackhamer, Professor,
Environmental Health Sciences, University of Minnesota,
and Chairwoman, EPA Science Advisory Board

My name is Deborah Swackhamer, and I hold the Charles M. Denny,
Jr., Chair in Science, Technology, and Public Policy in the Hubert H.
Humphrey School of Public Affairs at the University of Minnesota, and
co-direct the University's Water Resources Center. I am trained as an
environmental chemist and am also professor of Environmental Health
Sciences in the School of Public Health.
I was appointed chair of the SAB in 2008 by EPA Administrator
Stephen Johnson and reappointed for a second term in 2010 by EPA
Administrator Lisa Jackson. From 2006-2008, I served on the Board of
Scientific Counselors (BOSC) for EPA's Office of Research and
Development (ORD). While my views, perspectives, and opinions are my
own, I am testifying at this hearing on behalf of the SAB.

The Role of the SAB

The SAB provides science advice to the EPA Administrator on a wide
range of scientific and technical issues. These issues are complex and
require a diversity of expertise to address. The SAB membership brings
expert knowledge from the natural and physical sciences, engineering,
health sciences, and social sciences including economics. Based on my
years of service on the Board, I believe that the Agency has a robust
process for identifying members with outstanding scientific credentials
who are committed to helping improve the quality of Agency science. The
SAB and its committees and panels review Agency work products,
undertake special studies when requested, and perform self-initiated
studies on topics that the Board considers to be of critical
importance. The Board is in the process of finalizing a report on how
the Agency can do a better job of integrating science and problem
formulation in its decision making. \1\
---------------------------------------------------------------------------
\1\ Science Integration for Decision Making at the U.S.
Environmental Protection Agency (EPA) (draft January 5, 2012).
---------------------------------------------------------------------------
Recent SAB advice that is directly relevant to this hearing
includes the two reports we produced (2009, 2010) \2\ on Strategic
Directions for EPA Research, prepared for ORD to encourage approaches
and strategies needed to do their science most effectively. These two
reports have been instrumental in moving ORD's research enterprise
towards a more interdisciplinary approach, and one that can respond
more nimbly and effectively to the needs of the Program Offices and
Regional Offices. The Administrator's ``One EPA'' and ORD Assistant
Administrator Anastas' ``The Path Forward'' strategies are consistent
with our previous advice.1A\3\
---------------------------------------------------------------------------
\2\ EPA's Strategic Research Directions 2008: An Advisory by the
EPA Science Advisory Board. EPA-SAB-09-006.
\3\ Office of Research and Development Strategic Research
Directions and Integrated Transdisciplinary Research. EPA-SAB-10-010.
---------------------------------------------------------------------------
The SAB is supportive of many changes that have taken place in ORD
in recent years. We have advised strongly for an integrated approach to
EPA's scientific research, and the Agency has responded, as indicated
by its realignment of research programs from 13 individual programs to
six integrated programs. We have advised to include a greater degree of
social and decision science research, and the Agency is moving to fill
this need. The social sciences are a needed component to adequately
address issues such as sustainability, homeland security, risk
communication, valuation, and environmental stewardship and human
behavior. The Agency needs to develop a strategy for developing this
capability. We have advised to develop capacity to respond to emerging
issues, and the new program structure should move them in that
direction. We have advised the Agency to partner more nationally and
internationally and develop truly collaborative research efforts in
these times of limited and shrinking resources, and they have been
creative in doing so. Finally, we urged ORD to support and create
incentives for their scientists to be more innovative, and they have
created a highly successful internal program for Innovation Grants and
have modified their internal rewards system to encourage the best
scientific publications.
To summarize, we are supportive of these changes at ORD. More could
be done, more is being done, but I believe, and our reports have
indicated, that ORD is moving in the right direction.

Quality, Usefulness and Objectivity of EPA Science--the Role of SAB

The SAB, and presumably this Subcommittee, share the goal and
commitment to assist EPA in producing and using high-quality science to
protect human health and the environment. The best available science is
essential to sound decision making but is not the only aspect to sound
policy decisions. What is ``best available science''? While hard to
provide a simple one-size-fits-all definition, generally it is
scientific results, conclusions, and technical information that has
been produced using proven methods, that has been peer reviewed, where
hypotheses are tested with objective and unbiased approaches, and that
has support for its conclusions from other independent studies. EPA
cannot possibly do all of the science needed by the Program Offices and
Regional Offices. Some of this needed science is conducted within EPA,
and some science is used from outside research to verify, supplement,
and in general add to the collective body of knowledge used to inform a
given decision.
The role of the SAB is to examine the scientific and technical
knowledge that was synthesized within the Agency for a given issue, and
provide advice as to whether this science was appropriate and adequate
for its intended use. In SAB reviews of EPA science assessments, we
consider whether the data, reports, and other resources used were peer
reviewed and compared and contrasted appropriately. It is my
understanding that EPA has clear guidance regarding peer review of its
own scientific work, and for data quality and transparency. \4\ For
purposes of maximum transparency and quality assurance, we usually
advise the Agency not to include reports that have not been peer
reviewed, or journal manuscripts in preparation or draft form but not
yet published.
---------------------------------------------------------------------------
\4\ Guidelines for Ensuring and Maximizing the Quality,
Objectivity, Utility, and Integrity of Information Disseminated by the
Environmental Protection Agency. EPA/260R-02-008.
---------------------------------------------------------------------------
As a researcher who has received funding from EPA and many other
agencies, I have found that EPA has very high standards for data
quality and assurance.

Enhancing EPA Science

Finally, the letter from Chairman Harris requested that I comment
on the capability of EPA to conduct and use the best available science
to fulfill its mission. The Agency certainly has the capability given
its excellent scientific enterprise. It is sorely short of resources to
provide the capacity needed for all the science questions at the
Agency, and yet there is no other agency where such environmentally
focused and directed science is being done to fill the unique mission
of protecting the public's health and the environment on which they
depend. Investing in EPA science is a wise investment. That said, this
capability would be improved by continuing to address scientific
questions from an interdisciplinary approach, by partnering more
creatively with others, by involving stakeholders in problem
formulation, and integrating science across the Agency for the most
effective decision making.
Thank you for the opportunity to speak to you today.

Chairman Harris. Thank you very much.
I now recognize our third witness, Mr. Michael Walls of the
American Chemistry Council.

STATEMENT OF MR. MICHAEL WALLS,

VICE PRESIDENT, REGULATORY AND TECHNICAL AFFAIRS,

AMERICAN CHEMISTRY COUNCIL

Mr. Walls. Good morning, and thank you very much for the
opportunity to provide this testimony on behalf of the American
Chemistry Council.
Now, the business of chemistry is fundamentally the
business of science. The chemical industry practices high-
quality science to foster the discovery of new chemistries and
the development of new tools by which we can assess the
hazards, uses, and exposures of chemicals. We similarly expect
high-quality science and reliable assessment procedures to
underpin effective and efficient regulatory decisions by the
government.
Now, my testimony today boils down to a very simple
message: the process for bringing science to bear in regulatory
and policy decision making at EPA and at other federal agencies
is broken. The quality of the science has suffered as a result,
and the credibility and reliability of the decisions made on
the basis of that science is at stake. Now, Congress, the
agencies, the industry and the American public have a
significant interest in using the best science to ground those
decisions. The fact is that science and the government are
reasonably likely to lead the regulatory decisions, and those
decisions have practical implications for businesses, State,
and local governments and individuals.
I would just like to focus on several examples drawn from
EPA's IRIS program as well as some other government programs.
The IRIS draft assessment on n-Butanol relies on two studies
determined to be unreliable by the Organization for Economic
Cooperation and Development in a review that was sponsored by
yet another office within EPA. There is no indication that that
conflict is going to be resolved. The National Academy of
Sciences directed EPA to do nonlinear modeling in support of
its IRIS assessment of dioxin. Five years later, EPA published
yet another draft of the assessment that similarly failed to do
the nonlinear modeling that was requested. EPA Science Advisory
Board justly criticized the draft for that failure. The
National Toxicology Program, part of the Department of Health
and Human Services, issued its 12th report on carcinogens in
July 2011. The report makes many of the same errors in its
assessment of formaldehyde that the National Academy criticized
EPA for in its own review of formaldehyde. That 12th report
also viewed styrene and came to a sharply different conclusion
than a 2010 evaluation by another division within HHS.
Why do we need to get this right? Well, in the IRIS case,
it is particularly important because 80 percent of IRIS
assessments haven't been updated in more than 15 years. Ninety
percent are at least ten years old. Meanwhile, the science that
informs our understanding of chemicals and of exposures has
continued to advance by leaps and bounds. That new science
should surely inform our regulatory and policy decisions.
The Federal Government's processes for assessing risk lack
a consistent, coherent framework. That framework should bind
the agencies to an appropriate and transparent approach to
weigh the evidence, consider uncertainty, and keep up with
advances in the field. Peer review is a critical step to ensure
a high level of quality and reliability. Despite
recommendations from the NAS and from the SAB, little has been
done to ensure that peer review is consistent within and among
the federal agencies. In short, we need to modernize and
streamline these processes to meet both today's needs and our
future challenges.
My written testimony outlines some recommendations for
improving the quality and process of science in three areas.
Number one, establishing sound risk assessment procedures,
standards and criteria; two, enhancing peer review; and three,
leveraging the emerging science and technology to reach better
decisions.
The chemical industry looks forward to working with this
Subcommittee in its continuing effort to improve science and
risk assessment in the government. I very much appreciate the
invitation to join the discussion today and look forward to
your questions.
[The prepared statement of Mr. Walls follows:]

Prepared Statement of Mr. Michael Walls,
Vice President, Regulatory and Technical Affairs,
American Chemistry Council

Summary

The American Chemistry Council (ACC) \1\ very much appreciates this
opportunity to provide testimony on common-sense measures to foster
quality science at the Environmental Protection Agency (EPA) and
throughout the Federal Government.
---------------------------------------------------------------------------
\1\ The American Chemistry Council (ACC) represents the leading
companies engaged in the business of chemistry. ACC members apply the
science of chemistry to make innovative products and services that make
people's lives better, healthier, and safer. ACC is committed to
improved environmental, health, and safety performance through
Responsible Carer, common-sense advocacy designed to address major
public policy issues, and health and environmental research and product
testing. The business of chemistry is a $674 billion enterprise and a
key element of the Nation's economy. It is one of the Nation's largest
exporters, accounting for 10 cents out of every dollar in U.S. exports.
Chemistry companies are among the largest investors in research and
development. It is also one of the Nation's most heavily regulated
industries.
---------------------------------------------------------------------------
The business of chemistry is fundamentally the business of science.
This business of science is a critical component for manufacturing safe
products required to house, feed, and protect people in the United
States as well as provide for the tremendous quality of life
experienced by American citizens who enjoy many high-quality and safe
consumer goods that were unavailable just a few decades earlier. ACC
member companies rely on science to conduct the research necessary to
discover new chemistries and identify new applications of existing
chemistries. They also rely on science to develop new tools for
assessing the potential hazards, exposures, and risks of chemical
substances. As one of the Nation's most regulated industries, ACC
member companies similarly expect high-quality science--and reliable
assessment processes--to underpin effective and efficient regulatory
decisions by the Federal Government.
Unfortunately, processes for conducting and reviewing chemical
assessments at EPA and other government agencies are not always based
on the consistent use of the best available science. The lack of
scientific quality and reliability directly compromises societal access
to cost-effective and safe products that house, feed, and protect us
while making life more enjoyable at the same time. While there has been
much recent focus on EPA's Integrated Risk Information System (IRIS),
the problems identified by the National Academy of Sciences (NAS) in
the IRIS program are also evident in other government chemical
assessment programs.
EPA has acknowledged many of the deficiencies in the IRIS program
and is taking some welcome steps to address the concerns identified by
the NAS. EPA is also making an important effort to develop and evaluate
emerging technologies to improve chemical assessments, and ACC has been
pleased to support these efforts.
ACC's testimony today outlines a number of recommendations to
improve the quality and process of science at EPA and more broadly
through the Federal Government. The following areas should receive
particular attention:

Improving the quality of science through sound risk
assessment processes, standards and criteria.

Improving the quality of science through enhanced peer
review.

Enhancing the quality of science by leveraging emerging
science and technology.

I. Improving the Quality of Science Through Sound

Risk Assessment Processes, Standards, and Criteria

The Subcommittee's inquiry into the level, quality, usefulness, and
objectivity of science at the Environmental Protection Agency (EPA) is
timely. There are well-known deficiencies in EPA's Integrated Risk
Information System (IRIS)--deficiencies that Congress has directed the
National Academy of Sciences to review. But the problems that affect
the Agency's ability to assure that the science generated, reviewed,
and used is of the highest quality are not unique to EPA. \2\ ACC's
testimony today outlines a number of recommendations to improve the
quality and process of science at EPA and more broadly through the
Federal Government.
---------------------------------------------------------------------------
\2\ EPA's Integrated Risk Information System (IRIS) has been the
focus of much critical attention recently. As the Subcommittee is well
aware, the National Academy of Sciences (NAS) has expressed concern
over ``[t]he persistence of limitations of the IRIS assessment methods
and reports, particularly in light of the continued evolution of risk-
assessment methods and the growing societal and legislative pressure to
evaluate many more chemicals in an expedient manner.'' The NAS report
further cites a lack of clarity and transparency as a ``repeating
theme'' over the last decade, insufficient documentation on methods and
criteria for identifying evidence from relevant studies, and a lack of
information useful in assessing the weight of the evidence, among other
problems. These concerns are not limited to IRIS, or even EPA. For
example, the Report on Carcinogens (RoC) issued by National Toxicology
Program (NTP), housed in the Department of Health and Human Services
(HHS). The 12th RoC, released in July 2011, makes many of the same
methodological errors in its evaluation of formaldehyde as IRIS did in
its review, and the 12th RoC's review of styrene conflicts with a 2010
evaluation by another HHS entity. Similar concerns exist with EPA's
Clean Air Scientific Advisory Committee.
---------------------------------------------------------------------------
At the heart of the problem in the Federal Government's processes
for assessing risks to environment and human health is the lack of a
consistent, coherent, science-based framework that binds the agencies
to an appropriate and transparent approach for weighing evidence,
considering uncertainty, and keeping up with advances in the field. The
processes for considering scientific information and data and the
standards and criteria used in risk assessment need to be modernized
and streamlined to meet both today's needs and greater challenges of
the future.

A. Integrated Risk Information System (IRIS)

Despite continued evolution of the EPA IRIS process, specific
fundamental improvements to the program are necessary to ensure that
IRIS assessments developed by EPA are firmly based on up-to-date
scientific knowledge, meet the highest standards of scientific inquiry
and integrity, and are evaluated in accordance with acceptable
scientific approaches.
IRIS is used by EPA as the primary source of information regarding
the potential adverse human health effects of chemicals. IRIS is also a
leading source of health risk information for other federal, State, and
international regulatory bodies. Given the importance that IRIS
evaluations have for EPA program offices, other federal agencies, and
State governments, as well as their impacts on the private and public
sectors, it is clear that significant improvements are warranted and
long overdue.
Many of these necessary improvements were outlined in Chapter 7 of
the April 2011 NAS scientific peer review report on formaldehyde and
underscored during two recent Congressional oversight hearings on IRIS.
Despite general agreement with the need to make the changes recommended
by the NAS, EPA has yet to provide further details on how it will
implement the NAS IRIS improvements. The U.S. Government Accountability
Office (GAO) has called on EPA to develop a clear plan for fixing IRIS.
\3\
---------------------------------------------------------------------------
\3\ Government Accountability Office, ``Chemical Assessments:
Challenges Remain With EPA's Integrated Risk Information System
Program,'' GAO-12-42, Dec 9, 2011. Available at http://www.gao.gov/
assets/590/586620.pdf.
---------------------------------------------------------------------------
In an effort to move EPA in this direction, Congress recently
passed bipartisan legislation which directs EPA in FY 2012 to:

Incorporate, as appropriate, the recommendations of
Chapter 7 of the National Research Council's Review of the
Environmental Protection Agency's Draft IRIS Assessment of Formaldehyde
into the IRIS Process; and

Issue a progress report to House and Senate Committees on
Appropriations and relevant Congressional authorizing committees no
later than March 1, 2012, describing its implementation of the National
Research Council's Chapter 7 recommendations for ongoing and new
assessments.

This action by Congress rightfully underscores the widespread
agreement that more work is needed to improve IRIS so the program
delivers scientifically defensible assessments.
EPA does not need to go back to square one to improve IRIS and the
assessments already underway. But more than a cursory review and more
than simple improvements are needed. In particular, EPA should
determine whether all ongoing assessments--including those that the
Agency is revising to take into account peer review and public
comments--meet the NAS standards for reviewing studies, evaluating
weight of evidence, determining mode of action, establishing cause and
effect, and for selecting the dose-response method for quantifying
potential health risks. If an IRIS assessment falls short, it must be
upgraded.
ACC firmly believes that this process can be accomplished without
undue delay in making IRIS assessments final. All stakeholders have an
interest in IRIS assessments that rely on the best available scientific
information regarding hazard and exposure; employ consistent, objective
methods and models; utilize transparent evaluation procedures for data
quality, cause and effect; and that weigh the full body of scientific
evidence. If an ongoing IRIS assessment does not meet these criteria
(for example, if a draft IRIS assessment does not employ a robust
weight-of-the-evidence approach), the program must accept that more
time will be needed to get the assessment right. The credibility of the
IRIS program is not enhanced by assessments that fail to address the
basic criteria for quality and reliability.
Importantly, there is nothing in the current IRIS program that
provides an incentive for companies to develop new data and information
and to use new toxicological methods and tools to generate and gather
that data. Indeed, the industry has little confidence that new
informationand data can overcome the conservative default assumptions
employed in the program or the persistent problems identified in peer
review.
In ACC's view, two principal solutions can help meet the Federal
Government's need to enhance chemical risk assessment, and to restore
credibility in the results. First, federal agency standards for risk
assessment need to be updated. Ideally, the same set of updated
standards would apply across the Federal Government. There are a
variety of ways this might be accomplished. Second, the laws and rules
governing scientific peer reviews should be updated to make that vital
process more effective and transparent.

B. Improved Standards for Risk Assessment

Under existing authority, there is a clear role for the Office of
Management and Budget (OMB) in reviewing agency assessments and
coordinating a robust interagency review to promote uniformity in
process and results. It is clear that federal risk assessment
activities are not being coordinated, despite direction and guidance
provided by OMB bulletins and memoranda. \4\ Moreover, there is no
current governmentwide oversight to ensure coordination. As a
consequence, the lack of a coordinated approach to these various
assessment programs creates the potential for duplication and
inconsistent findings. Most troubling, each federal agency conducting
such assessments does so in a different way, using different processes
and standards.
---------------------------------------------------------------------------
\4\ OMB ``Final Information Quality Bulletin for Peer Review'' and
OMB's ``Updated Principles for Risk Analysis'' (http://
www.whitehouse.gov/sites/default/files/omb/memoranda/fy2005/m05-03.pdf;
http://www.whitehouse.gov/sites/default/files/omb/assets/
regulatory
-
matters
-
pdf/m07-24.pdf).
---------------------------------------------------------------------------
To address this lack of coordination and consistency, federal
agencies need to adopt updated state-of-the-art standards for human
health and environmental risk assessments. Ideally, agencies would all
follow a consistent set of standards. Agencies should be required to
explain how they followed these standards, including providing a clear
articulation of reasons for choices they made in the process. Agency
compliance with those requirements would be enhanced if it were subject
to regular oversight, including judicial review.
Federal standards for risk assessment should:

Include criteria for evaluating the validity of test
methods and the reliability and credibility of data.

Require an assessment of the weight of evidence regarding
hazard and exposure, based on criteria that should include elements
such as a systematic review of all relevant and reliable toxicological,
epidemiological, and mechanistic data, including negative results; a
preference for human data, where it is relevant and adequate; and
consideration of biologically plausible modes of action most relevant
to humans.

Require agencies to present the distribution of estimated
hazards or risks, including central tendency values.

Require agencies to characterize uncertainty and
variability quantitatively, where feasible, and to explain these and
other limitations of the analysis with sufficient clarity to be
understood by non-scientists.

Require full disclosure of:

Data, methods and models sufficient to allow
independent reanalysis by qualified experts;

Rationales for choosing key studies, methods and
models;

Assumptions, extrapolations and policy judgments;

Plausible alternatives and related impacts; and

Major risk conclusions and degree of confidence based
on uncertainties.

Outline a process of stakeholder engagement, including:

An interactive ``problem formulation'' at the outset of
each assessment to identify key issues and data needs;

Timing assessments to make maximum use of relevant
external research; and

Outreach regarding proposed charge questions for peer
review of the assessment.

Consider how the concept of proportionality can be
addressed in risk assessment standards, so that risk assessments are
more closely linked to the decision they are used to justify.

There are a number of options by which these standards can be
developed and appropriate oversight of Agency adherence to the
standards established. \5\ For example, if the Environmental Research,
Development, and Demonstration Authorization Act (ERDDA) is
reauthorized, Congress can direct EPA to develop and implement these
standards.
---------------------------------------------------------------------------
\5\ These proposals do not address who is responsible for
generating the data that is used in these assessments. ACC assumes that
companies will typically have that responsibility.
---------------------------------------------------------------------------
Congress could also consider a mandate that federal agencies
collaborate in an interagency committee that would be tasked with
developing risk assessment standards that all agencies would have to
follow. This might include standards outlining the basic assumptions
underlying risk assessment methodologies (such as concepts of threshold
versus linear modeling), the use of animal data, and weight of the
evidence approaches. The logic behind this approach is that it could
bring together the agencies charged with balancing competing risks and
benefits from protective interventions (e.g., the Food and Drug
Administration, the Centers for Disease Control) with those agencies
whose mandates are to reduce risks (e.g., EPA and the National
Toxicology Program). The critical point, of course, is to avoid the
development of lowest common denominator standards that simply preserve
the status quo.
Congress could also direct the practice of federal agency risk
assessment across the Federal Government by requiring the Office of
Management and Budget (OMB) and the Office of Science and Technology
Policy (OSTP) to develop standards broadly applicable across the
government. Both OMB and OSTP have career staff knowledgeable about
risk assessment and are interested in improving agency estimates of
risks. In 2006, OMB and OSTP issued a proposed bulletin providing
guidance to federal agencies regarding their conduct of health, safety,
and environmental assessments. \6\ Ultimately, OMB reinforced existing
guidance, and noted an expectation that agencies would follow the
principles. Unfortunately, agencies appear to routinely ignore these
principles. Upper- and lower-bound estimates are not provided, negative
studies are not discussed, and the uncertainties and limitations of the
assessment are not articulated. Congress should ensure that agencies
follow these basic principles.
---------------------------------------------------------------------------
\6\ See 71 Fed. Reg. 2600 (Jan. 17, 2006).

---------------------------------------------------------------------------
II. Improving the Quality of Science Through Enhanced Peer Review

Integrating scientific methods across EPA and the federal agencies
also requires enhancing the manner in which the broader scientific
community is engaged in the assessment process. In ACC's view, the
standards governing scientific peer reviews should be updated to make
this vital process more effective. Peer engagement and review are two
critical factors in the effort to ensure high-quality, reliable science
supports decision making. Although ACC focuses on EPA in this section,
the recommendations we provide should inform enhanced peer review
across the government.
Independent peer review is a critical element of EPA's scientific
policies and practices, and to date has received less attention than
other elements of IRIS. Peer review is defined by EPA as ``an in-depth
assessment of the assumptions, calculations, extrapolations, alternate
interpretations, methodology, acceptance criteria, and conclusions
pertaining to the specific major scientific and/or technical work
product and of the documentation that supports them.'' \7\ Peer review
plays a crucial role in development of the best scientific evaluation
and is integral to identifying information that would reduce
uncertainty in significant areas of the assessment. The process of peer
review should be structured to accomplish these objectives. There are
several areas to consider for enhancing EPA's peer review process:
---------------------------------------------------------------------------
\7\ U.S. Environmental Protection Agency, Peer Review Handbook 3rd
Edition, EPA/100/B-06/002, at 12. Available at http://www.epa.gov/
peerreview/pdfs/
peer
-
review
-
handbook
-
2006.pdf.

Peer review panels need to have sufficient time and
---------------------------------------------------------------------------
resources to fulfill their responsibilities.

Rather than base peer review charge questions solely on
the input provided by the lead agency office, the preparation of these
charge questions should reflect stakeholder input and be developed
using an iterative process. Development of the charge questions should
be initiated at the problem formulation step, and then issued as a
refined draft coinciding with the release of the draft IRIS assessment.
Public comments on the draft charge questions should be solicited.

Peer review charge questions should be written in order
to facilitate objective consideration of alternative plausible
scientific views rather than from the vantage point of giving deference
to the interpretation presented in the Agency assessment. This provides
peer reviewers greater opportunity to consider alternative scientific
views such as those offered by stakeholders.

As recommended in the Bipartisan Policy Center's report
``Improving the Use of Science in Regulatory Policy,'' EPA should
``explicitly differentiate between questions that involve scientific
judgments and questions that involve judgments about economics, ethics
and other matters of policy.'' \8\
---------------------------------------------------------------------------
\8\ The Center's report is available at http://
www.bipartisanpolicy.org/sites/default/files/
BPC%20Science%20Report%20fnl.pdf.

Peer review meetings should be structured to encourage
open scientific dialogue and thoughtful scientific deliberation.
Stakeholder input should not be limited to a few minutes at the
beginning of a meeting; greater effort should be made to structure the
meetings so that stakeholder input is provided and deliberated at
strategic times throughout the meeting. Moreover, peer reviewers should
not be dissuaded from embarking on open technical discussion/
---------------------------------------------------------------------------
scientific exchange with stakeholders.

In selecting peer review panel members, the foremost
consideration should be given to expertise. Qualified scientists from
industry should be given equal consideration for appointment based on
the subject matter, and in accordance with applicable conflict-of-
interest provisions. There is unanimity among the most authoritative
sources on this point, including the National Academies of Science and
the Society of Toxicology:

Appointments to scientific advisory bodies should be based
principally on the scientific credentials, demonstrated
accomplishments, and professional credibility of the nominee.
His/her source of employment and funding (past or present),
religious beliefs, political persuasion, sexual orientation,
gender, or race/ethnicity should not be used as (a)
determinant(s) of exclusion to such a scientific advisory body.
\9\
---------------------------------------------------------------------------
\9\ See Society of Toxicology, Appointment and Participation of
Scientists on Peer Review Panels and Scientific Advisory Boards,
available at http://www.toxicology.org/pm/AdvisoryBoard.asp.

The Office of Government Ethics (OGE) has issued detailed rules
under the Ethics in Government Act (EGA) and the federal criminal code
addressing conflict of interest, and impartiality, on the part of
government employees, including ``Special Government Employees''
serving part-time on peer review committees. Fairly interpreted, the
EGA and those rules strike a fair balance and allow persons employed by
industry or non-governmental organizations to serve as reviewers in
many cases. However, agencies have tended to interpret these rules in
ways that (i) restrict the participation of industry personnel and (ii)
are too accepting of persons who are not really independent of the
agency or the work being reviewed. Congress may wish to revisit the EGA
and the rules, and their role in promoting high-quality, reliable
science.
In ACC's view, EPA's Science Advisory Board (SAB) has adopted
generally sound processes and criteria for peer review of Agency
action. There is room for improvement, however. For example, the SAB
should ensure that the SAB peer reviewers fully understand their
independent roles as peer reviewers. At times, however, it appears that
peer reviewers are overly deferential to EPA, reluctant to be seen as
criticizing EPA staff. It also appears that EPA staff have an
unfettered ability to comment throughout the peer review meetings, and
their constant presence may have a chilling effect on frank and open
discussion among the peer reviewers. This practice contrasts sharply
with NAS peer reviews.
ACC is generally encouraged by EPA's recent announcement that it
will establish a standing SAB panel for IRIS assessments. Assuming that
that standing panel is truly independent, and the panel process
addresses the concerns such as the role of EPA staff and how review
comments are incorporated into completed IRIS assessments, this
approach could help promote a more reliable and consistent IRIS
process.
Responding to peer review and public comments is another area where
the Agency needs to make improvements in its practices. It is
imperative that the Agency provide a robust response in writing to
comments as part of the assessment revision process that follows the
publiccomment and peer review phases. Where the Agency elects not to
address a peer review finding or recommendation, or a significant
public comment, EPA should provide a written justification. This
practice should be made routine for all federal agencies.
The current practice of having the same office that develops the
assessment draft the charge questions, review public and peer review
comments, decide which recommendations and findings to act on and which
to ignore, and develop the final assessment is clearly not a best
practice. The inherent value of peer review--indeed the inherent value
of EPA's SAB--is to provide an objective, robust scientific review of
the agency's scientific work product. ACC believes there is value in
having an ``honest broker'' to oversee and ensure that the Agency
adequately revises assessments in a manner that addresses both public
comments and the findings and recommendations of independent scientific
peer review. At this time, upon receiving a SAB or NAS panel report,
EPA unilaterally decides what elements to accept or reject--a practice
that clearly has not worked, particularly given the NAS report on
formaldehyde. Reviewing bodies should have an opportunity to address
how the Agency intends to implement the recommendations.

III. Improving the Quality of Science by Leveraging Emerging Science
and Technology

One of ACC's key objectives is to ensure that federal risk
assessment policies and practices rely on 21st century knowledge of
toxicology, biological modes of action, and advanced mechanistic
technologies. There are dramatic changes underway in the science and
technology of assessing chemical risks. These changes promise a
revolution in the speed and accuracy with which chemical hazards,
exposures, and risks are evaluated and managed.
While EPA has made important investments in developing new, highly
reliable technologies that can speed chemical assessments, not all
offices within EPA appear disposed to adopt these technologies when
appropriate. Successful integration of emerging science and technology
into risk assessment will require a concerted and methodic approach to
evaluate the science and build consensus around their readiness.
The field of toxicology has grown more sophisticated as we have
learned more about the biochemical mechanisms of toxicity and the
differences between humans and test animals. New and exciting
technologies for evaluating chemicals are emerging. In some cases,
however, agencies are not well prepared to implement these new tools.
Many federal agencies still cling to a set of conservative default
assumptions little changed from the 1960s and '70s, and appear to be
reluctant to adopt new technologies.
In ACC's view, it is critical that the Federal Government and the
chemical industry be actively engaged in the transformation of chemical
safety sciences. ACC member companies have made a significant,
continuing investment in the ACC Long-range Research Initiative (LRI)
to inform and advance this objective. ACC currently commits some $5
million annually \10\ to the program, which is designed to help:
---------------------------------------------------------------------------
\10\ ACC estimates that as a whole, the business of chemistry spent
some $55 billion on research and development in 2010, the last year for
which complete data are available. Slightly over 40% of that amount was
spent on basic and applied research.

Drive development of innovative approaches to assess and
interpret health risks from low-dose exposures to chemicals and
---------------------------------------------------------------------------
exposures to mixtures.

Develop and apply new tools to interpret the explosion of
biomonitoring and high-throughput testing data regarding human health
risks.

Accelerate the shift away from traditional high-dose
animal toxicological testing by developing, validating, and promoting
broad acceptance of approaches with greater relevance for humans.

Translate emerging research outcomes for decisions about
the safety of our chemicals by partnering with thought leaders from
industry, government, academia, and public interest groups.

The LRI program's hallmark is the collaborative work to catalyze
technological innovations in chemical safety sciences with the Federal
Government, principally EPA and the National Institutes of Health.
Examples of current collaborations between industry and governmental
agencies include several ongoing projects between the Hamner Institute
for Health Sciences and the EPA's National Center for Computational
Toxicology (NCCT) and its National Center for Environmental Assessment
(NCEA).
Other collaborative projects funded by the LRI extend ongoing work
at the National Institute of Environmental Health Sciences (NIEHS). The
unprecedented collaborations that the LRI has fostered among industry,
governmental and regulatory agencies, and academia and demonstrates how
an industry-sponsored initiative can effectively partner with other
stakeholders to provide knowledge for science-informed decisions.
Among the collaborative research supported by the LRI program:

Efforts to deliver state-of-the-art exposure science to
advance the ExpoCastcomponent of EPA's ToxCastprogram.

Advance the interpretation of high-throughput data.

Accelerate the paradigm shift in chemical risk assessment
by incorporating ToxCastdata and toxicogenomics information into EPA's
NexGen Risk Assessment program.

Support validation of innovative biomarkers of cumulative
exposures.

Promote development of alternatives to animal testing.

The LRI program adheres to a stringent set of principles designed
to ensure that the collaborative research we fund meets the highest
standards for scientific excellence, transparency, and fairness.
The LRI program is focused not only on the new technologies for
toxicological testing that are revolutionizing risk-based decision
making, but is also helping to develop innovative biologically relevant
approaches to understanding exposure. These technologies present an
opportunity to develop a new paradigm for toxicity testing of
chemicals, facilitate understanding of chemical hazards, and improve
chemical safety evaluations. The current problem that they present is
the growing gap between the advancements in these new technologies and
the science to interpret and understand the emerging data.
In addition to providing state-of-the-art science and technology
for chemical safety and risk assessments, LRI promotes development of
tools that can be used by chemical companies for product innovation.
For example, the LRI currently manages one of the most comprehensive
portfolios of exposure projects that relates directly into efforts to
(a) predictively develop exposure information, and (b) make existing
exposure data widely available. Without these tools and data, there
would be an increased likelihood that the next generation of risk
assessments would be based entirely on hazard information or on overly
conservative exposure assumptions.
ACC has suggested to EPA that the transition to new integrative and
predictive molecular and computational techniques can be enhanced by
focusing on critical issues such as:

The need for an improved understanding of what short-
timescale in vitro assays can foretell about the likelihood of long-
timescale processes that lead to in vivo toxicity endpoints. \11\ For
example, specific response profiles in certain in vitro assays or
combinations of assays could provide insights into potential toxicity
endpoints, such as cancer, and may be useful in such decisions as
prioritizing chemicals for additional testing. Considerable work is
underway to enhance confidence in the use of these approaches and
better interpret the results.
---------------------------------------------------------------------------
\11\ Judson, R., et al., In Vitro Screening of Environmental
Chemicals for Targeted Testing Prioritization: The ToxCast Project,
Environmental Health Perspectives 118:485-492 (2010).

The value of increased collaboration and engagement
across the scientific community to interpret ToxCastdata for chemical
prioritization. Increased transparency of relevant data and algorithms
will allow EPA to leverage its intellectual resources and garner
stronger understanding of and support for its approaches. EPA's NexGen
Risk Assessment process already provides a similar mechanism to engage
---------------------------------------------------------------------------
experts and stakeholders in the emerging science.

Conclusion

Ensuring that EPA decision making is firmly based on the use of
high-quality science is critical to helping the Agency meet its
obligation to protect human health and the environment. This can be
achieved by common-sense reforms that will lead to more efficient and
effective regulatory decisions. ACC looks forward to working with
members of the Subcommittee to ensure that the science and processes
that support the important regulatory work of the Federal Government
meet the highest standards for quality and reliability.

Chairman Harris. Thank you very much.
I now recognize our fourth witness, Dr. Richard Belzer of
Regulatory Checkbook.

STATEMENT OF DR. RICHARD BELZER,

PRESIDENT, REGULATORY CHECKBOOK

Dr. Belzer. Chairman Harris, Ranking Member Miller, thank
you for the invitation to testify. My views are my own and
based on over 25 years of experience in this field.
Previous witnesses last November have testified that EPA's
science is not well. The symptoms include the politicization of
science, which occurs if agency policy officials change
scientific information to benefit their preferred policy
decisions; the scientization of policy, which occurs when
agency risk assessors make policy decisions behind a veil of
science; insufficient transparency reproducibility in agency
risk assessments, perhaps best exemplified by the National
Academy's recent report on formaldehyde; and dissatisfaction
with EPA peer review, perhaps best revealed when Congress seeks
peer review by the academy instead.
My analysis leads to a four-part diagnosis. First, the
politicization of science is not something only EPA policy
officials might do. EPA staff also politicize science, such as
when they choose a desired result and seek only the science
that supports it. Second, the scientization of policy is not
something only EPA risk assessors might do. EPA officials
scientize policy, such as when they say their policy decisions
merely follow the recommendations of the scientists. Third, EPA
risk assessments are not objective. This is not my opinion. An
agency staff report says ``EPA's policy is that risk assessment
should not knowingly underestimate or grossly overestimate
risks.'' Fourth, EPA peer review often does not serve the
purposes for which it presumably was intended. EPA guidelines
to the contrary, information quality is irrelevant to agency
peer review. EPA always controls the charge and often the
experts, who are often required to interpret science through
EPA's policy lenses. Amazingly, peer reviewers often are
charged with indirectly reviewing their own work. Fifth, EPA
advisory committees are especially susceptible to politicizing
science and scientizing policy. In April 2008, CASAC protested
then-Administrator Johnson's decision to set the primary
National Ambient Air Quality Standard for Ozone at .075 parts
per million. CASAC members had every right to disagree with
that decision on policy grounds, but they went off the rails,
saying that it was their ``consensus scientific opinion that
his decision violated the Clean Air Act.'' Science cannot
determine what is ``requisite'' to protect public health or
what constitutes an ``ample'' margin of safety. Those lie
beyond science.
I recommend several possible remedies for your
consideration. First, Congress could require the EPA risk
assessments, principal components, and key studies adhere to
information quality principles and standards. Risk assessment
should not be based on undisclosed data or models unless
perhaps national security is at stake. It also should be
objective. Deciding how much precaution should be accounted for
in regulatory decisions is not part of an analyst's job. It
belongs to the relevant agency official.
Second, Congress could revamp the EPA's peer review
practices to explicitly require them to invest in information
quality, to strictly limit peer reviews to science, and to
remove the agency's ability to substantially control outcomes
through procedural means.
Third, Congress could require advisory committees to
``establish and maintain a clear conceptual distinction between
assessment of risk and consideration of risk management
alternatives'' and ensure that their reports ``clearly
distinguish between the scientific basis and the policy basis
for the conclusions and recommendations.'' That advice isn't
mine. It was made by the National Academy committee that wrote
the 1983 Red Book. It makes perfect sense for advisory
committees. EPA officials making decisions should not have to
struggle to discern where an advisory committee's scientific
review ends and its policy advice begins.
These reforms would go a long way toward improving the
quality of the EPA science. None of them would politicize
science or scientize policy. Indeed, they would help prevent
both by making them stick out like sore thumbs.
Thank you again for the opportunity to testify. I am happy
to answer any questions when the time permits.
[The prepared statement of Mr. Belzer follows:]

Prepared Statement of Dr. Richard Belzer,
President, Regulatory Checkbook

Introduction

Chairman Harris, Ranking Member Miller, and Members of the
Subcommittee, thank you for inviting me to testify on ``Fostering
Quality Science at EPA: Perspectives on Common-Sense Reforms.'' I am
Dr. Richard B. Belzer, president of Regulatory Checkbook, a
nonpartisan, nonprofit organization whose mission includes the
promotion of quality improvements in science, economics, and
information quality. \1\
---------------------------------------------------------------------------
\1\ The views expressed here are my own and do not necessarily
represent those of Regulatory Checkbook.
---------------------------------------------------------------------------
I was elected Treasurer of the Society for Risk Analysis in 1998
and 2000, and earned its Outstanding Service Award in 2003. Previously
I was named a Fellow of the Cecil and Ida Green Center for the Study of
Science and Society. In 2009 and 2011, I was elected Secretary/
Treasurer of a new professional organization, the Society for Benefit-
Cost Analysis.
From 1988 through 1998, I was a career economist in OMB's Office of
Information and Regulatory Affairs, where I reviewed many risk
assessments that were integral parts of agencies' Regulatory Impact
Analyses, for it is impossible to estimate costs and benefits without
first estimating risks. My job was to examine agency analyses of the
risks, costs, and benefits of draft regulations, and present to OMB
officials and other Executive Office staff the most objective portrayal
possible. Typically, this could not be done based on the risk
assessments performed by the agencies. Agency risk assessments were
purposefully biased to make risk appear greater than it was and the
benefits of regulation appear greater than they were.
I have been president of Regulatory Checkbook since its founding in
2001. Regulatory Checkbook does not lobby or take public positions on
substantive legislation or rule making; there is no shortage of
organizations committed to doing that. Our sparsely populated niche is
to seek improvements in the quality of risk assessment and economic
analysis regardless of whether it tends to support or oppose specific
regulatory actions. For that reason, we are interested in how quality
is affected by various procedures, such as public comment, peer review,
information quality principles and standards, and Executive oversight.
No one has compensated Regulatory Checkbook or me for my testimony.
I am familiar with testimony previously provided to the
Subcommittee. I will try to build on that and not be redundant.

Symptoms of the Quality Deficit

The purpose of these hearings has been to identify ways to improve
the quality of science used by EPA in regulatory decision making. This,
of course, implies that the state of the science for science at the
Agency is not well. Numerous symptoms have been identified.

Politicization of Science or Scientization of Policy?

In March 2009, President Obama issued a Memorandum on Scientific
Integrity stating, among other things, ``Political officials should not
suppress or alter scientific or technological findings and
conclusions.'' \2\ The President also made a commitment to
transparency, saying, ``If scientific and technological information is
developed and used by the Federal Government, it should ordinarily be
made available to the public.'' It is my observation, based on over 20
years in risk assessment, that these principles are are universally
agreed to--in principle. Putting them into policy turns out to be more
difficult. It took 22 months for the White House Office of Science and
Technology Policy--an office whose director the President directly
supervises--to issue guidance implementing his memorandum. \3\
---------------------------------------------------------------------------
\2\ Barack Obama. ``Scientific Integrity.'' Federal Register, 2009,
74(46), 10671-10672.
\3\ John P. Holdren. ``Memorandum for the Heads of Executive
Departments and Agencies: Scientific Integrity,'' Office of Science and
Technoloy Policy, 2010.
---------------------------------------------------------------------------
Moreover, OSTP's guidance is crafted with considerable structural
and procedural ambiguity. \4\ It calls for ``policymakers [to] involve
science and technology experts where appropriate,'' without clearly
stating the circumstances where it wouldn't be. It directs agencies to
select candidates for scientific positions ``based primarily on their
scientific and technological knowledge, credentials, experience, and
integrity,'' thereby leaving wide open the option of giving substantial
weight to their political affiliation or policy views. \5\ It calls for
``independent peer review by qualified experts,'' but only ``where
feasible and appropriate.'' The guidance says ``political officials
should not suppress or alter scientific or technological findings,''
but it does not actually generally prohibit this practice. \6\ Only
agency public affairs officers are expressly forbidden from doing this.
\7\
---------------------------------------------------------------------------
\4\ OSTP's guidance is mostly hortatory, saying agencies ``should''
do various things 19 times but never saying ``shall'' or ``must.''
Eight times, these suggestions apply only if the agency judges them to
be ``appropriate.'' Four times, they apply only if ``practicable.''
\5\ President Obama's memorandum did not include this
qualification, stating: ``The selection of scientists and technology
professionals for positions in the executive branch should be based on
their scientific and technological knowledge, credentials, experience,
and integrity.''
\6\ The President's memorandum went further, saying ``Political
officials should not suppress or alter scientific or technological
findings and conclusions'' (emphasis added). The difference is surely
not accidental, but its significance is not transparent. Possibly it
shows that the White House has learned about the scientization of
policy.
\7\ Holdren (2010, p. 2). ``In no circumstance may public affairs
officers ask or direct Federal scientists to alter scientific
findings.''
---------------------------------------------------------------------------
The lesson from this is that it is much easier to announce a policy
that seems straightforward than to implement it. It turns out that the
intersection of policy and science is a lot more complicated than
newspaper reporters, activists, and even candidates for president might
think.
As the Subcommittee has heard, the 2009 report of the Bipartisan
Policy Center's Science Policy Project discreetly pointed in a
different direction--what is increasingly being called ``the
scientization of policy.'' \8\ The BPC's Science Policy Project
included former policy officials who, unsurprisingly, had a different
perspective on the policy/science divide. Former OIRA Administrator
Susan Dudley's testimony to the Subcommittee appears to be indicative
of this, presumably reflecting her own experience. \9\
---------------------------------------------------------------------------
\8\ Bipartisan Policy Center. ``Improving the Use of Science in
Regulatory Policy,'' Washington, D.C.: Bipartisan Policy Center, 2009,
p. 15. ``[S]ome disputes over the `politicization' of science actually
arise over differences about policy choices that science can inform,
but not determine.''
\9\ Susan E. Dudley. ``Written Testimony Before the U.S. House of
Representatives Committee on Science, Space, and Technology,
Subcommittee on Energy and the Environment, Hearing on `Fostering
Quality Science at EPA: Perspectives on Common Sense Reforms,' '' 2011.
---------------------------------------------------------------------------
It turns out that this is an old issue. In 1986, Harvard Kennedy
School professors Albert Nichols and Richard Zeckhauser published
papers claiming that cancer risk was systematically overstated at EPA.
\10\ They wrote that this was done by Agency risk assessors for the
purpose of influencing risk management decisions. \11\
---------------------------------------------------------------------------
\10\ Albert L. Nichols and Richard J. Zeckhauser. ``The Dangers of
Caution: Conservatism in Assessment and the Mismanagement of Risk,''
Smith, Advances in Applied Micro-Economics: Risk, Uncertainty, and the
Valuation of Benefits and Costs. Greenwich, Conn.: JAI Press, 1986a,
55-82. For a less technical version of this paper, see ----------.
``The Perils of Prudence: How Conservative Risk Assessments Distort
Regulation.'' Regulation, 1986b, 10(6), 13-24.
\11\ It is not clear, however, if this practice illustrates the
scientization of policy, or the politicization of science by Agency
staff rather than by Agency policy officials. It may have elements of
both.
---------------------------------------------------------------------------
In 1990, the Office of Management and Budget elaborated upon this
problem in its Regulatory Program of the United States Government:

Unfortunately, risk-assessment practices continue to rely on
conservative models and assumptions that effectively
intermingle important policy judgments within the scientific
assessment of risk. Policymakers must make decisions based on
risk assessments in which scientific findings cannot be readily
differentiated from embedded policy judgments. This policy
environment makes it difficult to discern serious hazards from
trivial ones, and distorts the ordering of the Government's
regulatory priorities. In some cases, the distortion of
priorities may actually increase health and safety risks. \12\
---------------------------------------------------------------------------
\12\ Office of Management and Budget. ``Current Regulatory Issues
in Risk Assessment and Risk Management,'' Regulatory Program of the
United States, April 1, 1990-March 31, 1991. Washington, DC: Office of
Management and Budget, 1990, 13-26. Full disclosure: I was the author
of OMB's white paper. It is out of print but available on my Web site
athttp://www.rbbelzer.com/uploads/7/1/7/4/7174353/
omb
-
1990
-
risk
-
assessment.pdf.

OMB noted with approval the recommendation made by the committee
---------------------------------------------------------------------------
that wrote the National Research Council's 1983 Red Book:

Regulatory agencies should take steps to establish and maintain
a clear conceptual distinction between assessment of risks and
the consideration of risk management alternatives; that is, the
scientific findings and policy judgments embodied in risk
assessments should be explicitly distinguished from the
political, economic, and technical considerations that
influence the design and choice of regulatory strategies. \13\
---------------------------------------------------------------------------
\13\ National Research Council. Risk Assessment in the Federal
Government: Managing the Process. Washington, D.C.: National Academies
Press, 1983, p. 151.

Like the authors of the Red Book, OMB thought that fidelity to the
Red Book recommendations was at least part of the solution. Though it
was published more than 20 years ago, the problem OMB highlighted is
the same thing that the BPC identified. \14\
---------------------------------------------------------------------------
\14\ Bipartisan Policy Center (2009, p. 13). ``Political decision
makers should never dictate what scientific studies should conclude,
and they should base policy on a thorough review of all relevant
research and the provisions of the relevant statutes. But some disputes
over the `politicization' of science actually arise over differences
about policy choices that science can inform, but not determine'' (p.
13).
---------------------------------------------------------------------------
While this is an old story, that does not mean it is outdated. In
2004, EPA published a staff report that explains its risk assessment
policies and practices with signal clarity. This report acknowledges
that EPA risk assessments are intentionally biased to overstate risk,
and that this is done for the purpose of scientizing policy:

[S]ince EPA is a health and environmental protective agency,
EPA's policy is that risk assessments should not knowingly
underestimate or grossly overestimate risks. \15\
---------------------------------------------------------------------------
\15\ U.S. Environmental Protection Agency Office of the Science
Advisor. ``An Examination of EPA Risk Assessment Principles and
Practices; Staff Paper, EPA/100/B-04/001,'' 2004, p. 13. This does not
necessarily mean that EPA always succeeds in overstating risk, or that
there are not circumstances in which EPA does not understate risks,
whether by accident or intent.

All risk assessments err because they are estimates. What the EPA
staff said is that they have a strong preference for erring on the side
of overestimating risk, just not ``grossly'' overestimating it. They
justify this preference based on the ``health and environmental
mission'' of the Agency. This preference for overestimating the
magnitude of risk is in addition to a preference for erring on the side
of promulgating regulations that err on the side of overprotection.
It is worth reflecting on what this would mean if other federal
agencies did the same thing:

Would it be reasonable for engineers at the Federal
Aviation Administration to intentionally overestimate the risk of air
travel, perhaps by assuming all aircraft were as risky as the riskiest
of them, and use those overestimates to motivate the FAA Administrator
to promulgate more stringent safety regulations for all aircraft?

Would it be reasonable for examiners in the Department of
the Treasury to knowingly overstate the risk that a major bank might
fail, in order to persuade the Secretary to take over that bank?

Would it be reasonable for analysts at the Central
Intelligence Agency to purposefully overstate the likelihood that the
Islamic Republic of Iran will succeed in developing an fielding a
nuclear weapon, thereby encouraging the President to launch a
preemptive military attack?

To ask these questions is to answer them. It is the obligation of
federal risk assessors, no matter where they work, to estimate risk as
objectively as possible. They should never misuse the tools of risk
assessment to manipulate decision makers into taking specific actions.
Remarkably, the EPA staff report denies that the discretion of Agency
policy officials is constrained or misdirected by their practice of
purposefully overestimating risk. \16\
---------------------------------------------------------------------------
\16\ U.S. Environmental Protection Agency Office of the Science
Advisor (2004, pp. 14-16).

---------------------------------------------------------------------------
Diagnosis

Whether science has been politicized or policy has been scientized
is a useful distinction, but it is not complete. For example, it is
assumed that science is politicized when policy officials invade the
space of the scientists; and conversely, policy is scientized when
agency scientists attempt to make policy decisions that Congress has
delegated to agency heads.
This model is incomplete because Agency policy officials and risk
assessors appear equally prone to do both. Sometimes, it is agency
policy officials who scientize policy, such as when they try to
attribute their policy choices to science. A policy official can avoid
a lot of controversy if he is perceived as ``merely following the
science.'' \17\
---------------------------------------------------------------------------
\17\ In previous testimony to this Subcommittee, EPA Administrator
Jackson's decision to revise the 2008 National Ambient Air Quality
Standard for ozone following the recommendations of the Clean Air
Scientific Advisory Committee was described by a former CASAC chairman
in similar but more strident terms. See Roger O. McClellan. ``Written
Testimony Before the U.S. House of Representatives, Committee on
Science, Space, and Technology, Subcommittee on Energy and the
Environment, Hearing on `Quality Science for Quality Air,' '' 2011.
---------------------------------------------------------------------------
Agency risk assessors may be willing or even pleased to go along,
for it increases their power and authority inside the agency, in its
battles with OMB, and for deflecting Congressional criticism. Thus,
Agency risk assessors may have no more interest than Agency policy
officials in revealing the extent to which officials have attributed
policy decisions to science. Similarly, Agency officials and risk
assessors alike may prefer not to make transparent the extent to which
risk assessors actually make policy decisions under the cover of
science.
Conflict arises, however, when Agency officials and risk assessors
do not agree on policy. In these situations, Agency policy officials
must first reclaim from Agency risk assessors the authority delegated
to them by Congress to make policy decisions. It is easy for risk
assessors to accuse their political bosses of politicizing science and
nearly impossible for policy officials to defend themselves when the
charge is false.
On the other hand, sometimes it is Agency risk assessors who
politicize science. This happens when risk assessors choose the best
available science that supports their preferred policy decision. Few
policy officials would ever be the wiser, because it requires from them
independent scientific expertise, substantial issue-specific knowledge,
and more time than they have available.
The desired principles can be clearly expressed, if not easily
implemented:

Agency policy officials should be limited to making
policy.

Agency risk assessors should be limited to assessing
risk.

Risk assessment should be performed as objectively as
possible and not be misused as a tool for achieving policy objectives
through the back door.

Policy officials should stay out of science. They should allow
science to inform their decisions but never allow it to control them,
never hide behind it, and never tell scientists what conclusions to
reach. They also should be persistent about asking risk assessors the
right questions and getting second opinions from external authorities.
This goal begins with the Red Book recommendation and goes much
further. Whereas the Red Book authors envisioned a smoothly interactive
and iterative relationship between risk assessors and risk managers,
with a ``clear conceptual distinction'' between science and policy
``established and maintained,'' 30 years of history has shown that this
model has either failed or cannot be implemented in a real-world
regulatory agency. \18\ &&
---------------------------------------------------------------------------
\18\ The author of this recommendation on behalf of the Red Book
committee believes that EPA officials misinterpreted and misapplied it.
See D. Warner North. ``Reflections on the Red/Mis-Read Book, 20 Years
After.'' Journal of Human and Ecological Risk Assessment , 2003, 9(5),
1145-1154. A somewhat different interpretation is that implementation
as envisioned by the Committee was not administratively or politically
feasible, an interpretation Professor Marchant appears to favor. See
Gary E. Marchant. ``Written Testimony Before the U.S. House of
Representatives Committee on Science, Space, and Technology,
Subcommittee on Energy and the Environment, Hearing on `Fostering
Quality Science at EPA: Perspectives on Common Sense Reform,' '' 2011,
p. 5. ``As the role of science becomes ever more important to EPA's
mission, and as the perception of EPA's science continues to be
skeptical across the political spectrum, it may be time to consider a
different model that institutionally separates the generation and
assessment of science from the application of that science in
regulatory decision making.'' Marchant does not credibly explain how an
external science production entity, such as his proposed Institute for
Scientific Assessments, staffed and managed by full-time federal
employees, would not succumb to the twin temptations of politicization
and scientization.

---------------------------------------------------------------------------
Information Quality Principles and Standards

In the following sections I focus on three areas in which EPA
science has specific, notable deficiencies. These are information
quality, peer review, and the confused role of federally chartered
advisory groups.
In 2002, OMB issued governmentwide guidelines \19\ to implement a
statutory directive to improve information quality. \20\ Like almost
every other covered agency, EPA issued its own agency-specific
guidelines before the October 1, 2002, deadline. \21\ These guidelines
commit EPA to adhere to certain standards of transparency,
reproducibility, integrity, objectivity, and utility, and to establish
administrative mechanisms whereby any person may seek and obtain the
correction of noncompliant information. Indeed, EPA expressed the view
that adhering to OMB's guidelines would not pose any challenge because
its existing policies and procedures already ensured and maximized
information quality. \22\
---------------------------------------------------------------------------
\19\ Office of Management and Budget. ``Guidelines for Ensuring and
Maximizing the Quality, Objectivity, Utility, and Integrity of
Information Disseminated by Federal Agencies; Notice; Republication.''
Federal Register, 2002, 67(36), 8452-8460.
\20\ ``Information Quality Act.'' 44 U.S.C. 3516 note. 2000.
\21\ U.S. Environmental Protection Agency. ``Guidelines for
Ensuring and Maximizing the Quality, Objectivity, Utility, and
Integrity of Information Disseminated by the Environmental Protection
Agency (EPA/260R-02-008),'' 2002.
\22\ U.S. Environmental Protection Agency (2002, pp. 10-14).
---------------------------------------------------------------------------
EPA's information quality guidelines say the Agency ``is dedicated
to the collection, generation, and dissemination of high quality
information'' and ``seeks to foster the continuous improvement of
existing information quality activities and programs.'' ``In
implementing these guidelines,'' EPA said ``ensuring the quality of
information is a key objective alongside other EPA objectives, such as
ensuring the success of Agency missions, observing budget and resource
priorities and restraints, and providing useful information to the
public.'' \23\ EPA also established well-defined administrative
procedures for managing requests for correction and administrative
appeals.
---------------------------------------------------------------------------
\23\ U.S. Environmental Protection Agency (2002, p. 10).
---------------------------------------------------------------------------
To be clear, information quality standards are expansive. They
apply to ``any communication or representation of knowledge such as
facts or data, in any medium or form''--but not to policy decisions.
Thus, they apply to risk assessment documents to the extent that they
contain ``representation[s] of knowledge such as facts or data.''
Because EPA officials claim that Agency risk assessment products are
scientific, \24\ there is no doubt that they are fully covered by
applicable information quality guidelines.
---------------------------------------------------------------------------
\24\ Paul Anastas. ``Written Testimony Before the U.S. House of
Representatives Committee on Science Space and Technology, Subcommittee
on Oversight, Hearing on `EPA's Integrated Risk Information System,' ''
2011, p. 1. ``IRIS assessments provide a scientific foundation for EPA
decisions to protect public health across EPA's programs and regions
under an array of environmental laws'' (emphasis added).
---------------------------------------------------------------------------
The Subcommittee should be aware that EPA has exempted press
releases and fact sheets from its information quality guidelines, which
it describes as ``[i]nformation of an ephemeral nature.'' Given that
press releases and fact sheets are often the only information Congress
and the press know about a complex risk issue, this exemption is
obviously problematic. Further, the Subcommittee should be aware that
EPA also exempts ``[i]nformation presented to Congress as part of the
legislative or oversight processes.'' \25\ EPA testimony may have many
desirable attributes, but adherence to information quality principles
and standards is not one of them.
---------------------------------------------------------------------------
\25\ U.S. Environmental Protection Agency (2002, pp. 16-17).
---------------------------------------------------------------------------
Many error correction requests submitted to EPA concern Agency risk
assessments or components thereof, which the petitioner claims contain
factual errors. Some requests are intended to seek full disclosure of
data and methods to enable third parties to test for error, which both
OMB's and EPA's information quality guidelines require. \26\
---------------------------------------------------------------------------
\26\ Some requests for correction are misguided attempts to change
regulatory decisions. However, these requests are easy for EPA to
dismiss on the ground that they concern matters that are exempt from
the information quality paradigm.
---------------------------------------------------------------------------
EPA committed to respond to requests for correction and appeals
within 90 days. EPA's actual performance, however, has not lived up to
these commitments. As of September 30, 2010, EPA's average response
time for a request for correction was no less than 166 days. EPA's
average response time for an appeal was no less than 316 days. \27\
These figures are biased downward, and thus understate EPA's dilatory
behavior, because they include requests and appeals that were still
open at the end of FY 2010. \28\
---------------------------------------------------------------------------
\27\ Richard B. Belzer. ``Risk Assessment and Information Quality:
An Empirical Study of Federal Agency Performance, 2010 Update,''
Society for Risk Analysis 2010 Annual Meeting, Salt Lake City, Ut.,
2010. Since this paper was presented, EPA has received four new
requests for correction.
\28\ Eleven of 44 requests for correction and one of 16 appeals
remained open at the end of FY 2010. The average response time, once
these open actions were resolved, could only be greater.
---------------------------------------------------------------------------
In short, EPA's well-written administrative procedures have in
practice failed to enable affected persons to ``seek and obtain'' the
correction of information that does not comply with applicable
information quality principles. Assuming it takes only 45 days to
review EPA's response to a request for correction and file an appeal,
it has taken on average more than 527 days for EPA's internal
administrative process to run its course.
The substantive merits of these requests for correction vary, but
it cannot be denied that many are highly meritorious. This can be seen
by reviewing specific requests or logically inferred by the length of
time EPA takes to respond. It should be easy for the Agency to quickly
refute requests for correction that lack any merit, especially those
which impermissibly seek to challenge Agency policy decisions.
Conversely, requests for correction that are highly meritorious could
be very hard to refute. If acknowledging error would undermine the
legal standing or political legitimacy of a major regulation or an
important EPA policy, no one should be surprised that the Agency takes
a long time to decide how to respond, or that its responses are
ambiguous, technically weak, misleading, or flatly wrong.
If an agency's response to a request for correction is incomplete,
misguided, or lacks merit, the only recourse is an appeal within the
agency. One cannot appeal to another Executive branch agency or seek
review by a federal court. For that reason, public enthusiasm is
limited even for submitting the most meritorious of error correction
requests. Governmentwide, the number of requests for correction filed
annually has declined by more than 75% since FY 2003. This is not
because federal agencies have suddenly stopped disseminating erroneous
information. It is because the agencies have responded to the
Information Quality Act as if it were a potentially lethal virus and
developed effective antibodies to prevent reinfection.

Peer Review

EPA is perhaps the federal agency that has committed the most to
peer review. It conducts numerous peer reviews every year and has
published a series of handbooks that guide Agency staff through the
process. \29\ Nevertheless, there appears to be widespread
dissatisfaction with the actual performance of EPA peer review. This is
self-evident given Congress' repeated decisions to supplement or even
bypass EPA peer review in favor of the National Academy of Sciences.
---------------------------------------------------------------------------
\29\ U.S. Environmental Protection Agency. ``Peer Review Handbook
(1st Ed.),'' Washington, D.C.: U.S. Environmental Protection Agency
Science Policy Council, 1988, ----------. ``Peer Review Handbook (2d
Ed.),'' Washington, D.C.: U.S. Environmental Protection Agency Science
Policy Council, 2000, ----------. ``Peer Review Handbook (3rd Ed.),''
Washington, D.C.: U.S. Environmental Protection Agency Science Policy
Council, 2006.
---------------------------------------------------------------------------
Several problems afflicting EPA's peer review program are discussed
below.

OMB's Bulletin on Peer Review Contains Obvious Errors

OMB issued governmentwide guidance on peer review in 2005. \30\
This guidance is generally very useful and helpful. For example, it
clearly states, ``Peer reviewers shall be charged with reviewing
scientific and technical matters, leaving policy determinations for the
agency.''
---------------------------------------------------------------------------
\30\ Office of Management and Budget. ``Final Information Quality
Bulletin for Peer Review.'' Federal Register, 2005, 70(10), 2664-2667.
---------------------------------------------------------------------------
But OMB's guidance is especially weak exactly where it should have
been strongest. Even though enhancing information quality was its
raison d'etre, the guidance includes no requirement that agencies
actually make information quality principles and standards an integral
part of scientific peer review. OMB waffles, saying ``[r]eviewers shall
be informed of applicable access, objectivity, reproducibility and
other quality standards under the Federal laws governing information
access and quality.'' \31\ In short, an EPA peer review complies with
OMB's guidance as long as peer reviewers are informed about information
quality, perhaps similar to one of the dozens of disclosure forms that
must be provided at settlement when purchasing a house. There is no
obligation for peer reviewers to do anything with this information.
---------------------------------------------------------------------------
\31\ Office of Management and Budget (2005, p. 2675). Emphasis
added.
---------------------------------------------------------------------------
OMB's guidance also includes a pair of extraordinarily large
loopholes. First, OMB allows agencies to infer that studies published
in peer-reviewed literature adhere to information quality principles
and standards, including the crucial standards of presentational and
substantive objectivity. This is bizarre. Adherence to these principles
plays no role in journal review. If they knew about them, some editors
of scholarly journals probably would consider information quality
principles and standards wholly irrelevant or contradictory to the
journal's mission. No matter; to OMB, peer review by a scholarly
journal means the information contained in it is presentationally and
substantively objective.
Second, OMB exempts reports of the National Academy of Sciences
from any scrutiny whatsoever. \32\ This is true even if there is no
evidence that the review took account of applicable information quality
principles and standards or there is incontrovertible evidence that the
review violated these principles and standards. \33\
---------------------------------------------------------------------------
\32\ Office of Management and Budget (2005, p. 2675). ``Principal
findings, conclusions and recommendations in official reports of the
National Academy of Sciences are generally presumed to have been
adequately peer reviewed.'' OMB may have tried to hedge this blanket
endorsement by limiting it to ``principal findings,'' but the
effectiveness of this hedge seems likely to be ephemeral.
\33\ An incontrovertible violation would occur in any instance
where the Academy gives policy advice. See the discussion surrounding
footnote 30.

---------------------------------------------------------------------------
Information Quality Is AWOL from EPA Peer Review

EPA's latest Peer Review Handbook mentions information quality
several places, but each reference is little more than boilerplate.
Here is the most substantive reference I can find:

The Agency recognizes peer review as a component of pre-
dissemination review that complements and enhances the
``objectivity'' and ``utility'' of EPA's information products.
The Agency recommends that offices conduct pre-dissemination
reviews of information to ensure that the information is of
appropriate quality before it is disseminated to the public.
Pre-dissemination review is especially important for
influential scientific information and highly influential
scientific assessments. \34\
---------------------------------------------------------------------------
\34\ U.S. Environmental Protection Agency (2006, p. 17).

Notice that pre-dissemination review, which applicable information
quality guidelines require agencies to perform, is reduced to a mere
recommendation. The Handbook does not even include OMB's requirement
that peer reviewers be ``informed'' about information quality
principles and practices, so it should surprise no one when they
aren't.
A reasonable inference is that EPA's Science Policy Council, the
author of the Peer Review Handbook, does not want information quality
to play a meaningful role in Agency peer review. Rather, the SPC hopes
that by conducting peer review EPA will be treated as if it had
complied with information quality principles and standards. This is
wholly unjustified. Peer reviews conducted fully in compliance with the
letter of the Handbook do not and cannot adhere to information quality
principles and standards because those principles and standards are
AWOL.
EPA's Science Advisory Board and the National Academy of Sciences
are not solutions to this problem, for their reviews are no more likely
to take information quality seriously. To take one obvious example,
many observers have strongly endorsed Chapter 7 of the Academy's review
of EPA's draft assessment of formaldehyde as a highly desirable step
forward for improving the quality of IRIS assessments. \35\ Perhaps it
is, but the Academy's formaldehyde report does not include adherence to
information quality principles and standards anywhere in its ``road
map.'' Indeed, the report never even mentions information quality,
which suggests that the formaldehyde committee was utterly unaware of
EPA's information quality guidelines. \36\
---------------------------------------------------------------------------
\35\ National Research Council. Review of the Environmental
Protection Agency's Draft IRIS Assessment of Formaldehyde. Washington,
D.C.: National Academies Press, 2011.
\36\ This does not mean the formaldehyde committee ignored
information quality in its review. Several places in the report one can
find discussions that indicate the committee wrestled with quality
issues. Similarly, the ``road map'' has numerous references to
``quality'' because it wanted EPA to focus on ``high-quality'' studies.
But the committee was bereft of a framework for defining quality
because it apparently knew nothing about EPA's Information Quality
Guidelines.
---------------------------------------------------------------------------
For this reason, the Chapter 7 ``road map'' might not be as helpful
as its advocates hope. Most disturbingly, any Congressional directive
to EPA insisting that it adhere to the ``road map'' is an implicit
invitation for the Agency to ignore information quality. Surely
Congress did not intend this to happen.

Noncompliance with the Peer Review Handbook

There are numerous anecdotes suggesting that EPA peer reviews do
not actually comply with the Peer Review Handbook. I am unaware of any
systematic research on this question that would permit a more
comprehensive inference. Clearly, such research could be valuable if it
were conducted rigorously and independently of EPA.
Obviously, if research showed that EPA's adherence the Peer Review
Handbook was as spotty as is the Agency's adherence to its information
quality guidelines, this might go a long way toward explaining why
there appears to be such widespread dissatisfaction with EPA peer
review. Research also could discover if noncompliance with the handbook
was random or causally associated with specific issues or regulatory
programs. \37\
---------------------------------------------------------------------------
\37\ It is an open question whether this question is researchable.
``Compliance'' with a complex guidance document is not a binary state.
The research task would involve a painstaking review of a
representative sample of peer reviews. The sample would have to be
large enough to have the statistical power to reject the null
hypothesis.

Excessive Agency Control
EPA's Peer Review Handbook makes clear that the Agency retains full
control over the peer review charge and de facto control over the
selection of peer reviewers. This is obviously true when a peer review
is conducted by a panel established by EPA under the Federal Advisory
Committee Act (FACA). But it is also true when the EPA conducts a
workshop or contracts with a private company to conduct peer review. In
these circumstances, EPA still controls the charge \38\ and has the
authority to veto the contractor's selection of peer reviewers. \39\
---------------------------------------------------------------------------
\38\ U.S. Environmental Protection Agency (2006, p. 59).
\39\ U.S. Environmental Protection Agency (2006, p. 61).

---------------------------------------------------------------------------
Nonscientific Content in EPA's Charge to Scientific Peer Reviewers

EPA peer review panels often are given a charge that includes
crucial nonscientific content for which scientists have no special
skills or insights. This occurs, for example, when a peer review panel
is constrained to look at scientific information through the Agency's
policy lenses. Common examples include the derivation of unit risk
factors for carcinogens and Reference Doses for noncarcinogens, both of
which have scientific content but are controlled by policy choices.
When a scientific peer review panel is asked to review a proposed unit
risk factor or Reference Dose, it is being asked to ratify the Agency's
policy choices.

Insufficient Expertise

By virtue of their size, peer review panels may appear to be
capable of reviewing all the relevant scientific questions posed by a
draft risk assessment. This may not be true, however, if the issues
presented are very broad and cross multiple disciplines. On a panel
containing the 15 best external scientists, there may be just a couple
who have crucial expertise related to a specific issue. If the number
of scientific issues is large, reviewers will be assigned to those
issues on which then have the most expertise. When it comes time to put
the review together, panel members will be inclined to jealously guard
the portion of the review they performed but defer completely to other
members with respect to the rest. Instead of a single peer review
performed by a panel of 15, the final report may be a half-dozen or
more separate reviews, each performed by a small number of scientists,
then repackaged as is it were a single document.

Excessive Expertise, of a Certain Form

It is becoming increasingly common to observe a peer review panel
consisting of experts who are the authors of the research on which EPA
has based its risk assessment. These experts are valuable and
important, for they alone can ensure that the Agency has interpreted
their work correctly. But they have no business serving on a peer
review panel whose job will be to review whether these studies were
performed correctly, whether they are the best available, whether they
are objective, etc.
This practice is disturbingly commonplace. The Clean Air Scientific
Advisory Committee (CASAC), which performs a peer review function under
Section 109(d)(2) of the Clean Air Act, is chaired by an author of
studies on which EPA bases risk assessments for mortality caused by
ambient air pollutants. \40\ Four of the seven current members of CASAC
have published research referenced in EPA's latest Integrated Science
Assessment for ozone, which CASAC is responsible for reviewing. A
scientist who formerly served on CASAC has testified before this
Subcommittee that he was also a contributing author of multiple ISAs.
\41\ It is simply impossible for CASAC to independently peer review EPA
risk assessment documents that rely on its members' own research. In
fact, it violates EPA's Peer Review Handbook, for it represents the
ultimate conflict of interest. \42\
---------------------------------------------------------------------------
\40\ M.L. Bell, F. Dominici and J.M. Samet. ``A meta-analysis of
time-series studies of ozone and mortality with comparison to the
national morbidity, mortality, and air pollution study.'' Epidemiology,
2005, 16(4), Michelle L. Bell, Aidan McDermott, Scott L. Zeger,
Jonathan M. Samet and Francesca Dominici. ``Ozone and Short-term
Mortality in 95 US Urban Communities, 1987-2000.'' JAMA, 2004, 292(19),
2372-2378.
\41\ George D. Thurston. ``Written Testimony Before the U.S. House
of Representatives, Committee on Science, Space, and Technology,
Subcommittee on Energy and the Environment, Hearing on `Quality Science
for Quality Air': RE: The Science of Air Pollution Health Effects and
The Role of CASAC in EPA Standard Setting,'' 2011, p. 2.
\42\ U.S. Environmental Protection Agency (2006, p. 37). ``Since it
would probably result in a perceived, if not real, conflict of
interest, the group that is generating the work product usually cannot
conduct or perform the peer review of its own work product.''

---------------------------------------------------------------------------
Conflicts of Interest

Most observers seem to agree that conflicts of interest ought to be
avoided if at all possible, and that peer review panels should manage
bias by ensuring that a ``balance of biases'' is obtained. This
principle is key to the National Academy's model, for example. \43\
---------------------------------------------------------------------------
\43\ The National Academies. ``Policy on Committee Composition and
Balance and Conflict of Interest,'' The National Academies, 2003.
---------------------------------------------------------------------------
I unapologetically take a different view. \44\ We are saddled with
conflict-of-interest policies that were written by lawyers in a way
that makes them easy for lawyers to implement. \45\ They treat
appearances the same as facts, and minor financial interests related to
for-profit employment more gravely than huge financial interests
related to dependence on government research grants. Conflict-of-
interest policies include measures to balance bias because scientific
peer review panels routinely do more than review science--they opine on
policy.
---------------------------------------------------------------------------
\44\ A more extensive discussion of the contrasts between scholarly
and governmental peer review can be found in a paper I wrote for a 2002
conference sponsored by the Society for Risk Analysis. See Richard B.
Belzer. ``Interests and Incentives in Government Peer Review,''
Conflict, Consensus, and Credibility: A Forum on Regulatory Peer
Review, Alexandria, VA, 2002. Available at http://www.rbbelzer.com/
presentations.html#2002.
\45\ Andrew Stark. Conflict of Interest in American Life.
Cambridge, Mass.: Harvard University Press, 2000.

---------------------------------------------------------------------------
Public Participation Is Limited and Public Comments Are Ignored

EPA's Peer Review Handbook purports to welcome public participation
in peer review, but it treats the public as a burden to be endured
rather than a source of insight. \46\ Similarly, the Handbook endorses
the practice of making public comments available to peer reviewers,
\47\ but it does nothing to encourage, never mind require, that peer
reviewers consider even the most significant scientific content of
public comments. Unsurprisingly, public comments are routinely ignored
in practice, and public participation is typically constrained to
presentations lasting a few minutes. \48\
---------------------------------------------------------------------------
\46\ U.S. Environmental Protection Agency (2006, p. 49). ``To
ensure that public participation does not unduly delay activities,
Offices should specify time limits for public participation throughout
the peer review process.''
\47\ U.S. Environmental Protection Agency (2006, p. 74
[distribution to peer reviewers is required for ``influential
scientific assessments'']). See also p. 49: ``When employing a public
comment process as part of the peer review, Offices should, whenever
practical, provide peer reviewers with access to public comments that
address significant scientific or technical issues.''
\48\ Robert F. Phalen. ``Written Testimony Before the U.S. House of
Representatives, Committee on Science, Space, and Technology,
Subcommittee on Energy and the Environment, Hearing on `Quality Science
for Quality Air': The CASAC-PM Committee--Setting Air Quality
Standards,'' 2011. ``The public comments were not weighed and discussed
by CASAC-PM in spite of the fact that most were well-reasoned and
relevant. If the agenda included time for discussion of public comments
and formal acceptance or rejection of their recommendations, the
process might be improved.''
---------------------------------------------------------------------------
This means peer reviews of draft EPA risk assessments tend to be
dialogues between the peer review panel and Agency staff, who might (or
might not) have written (part of) the document. Unless they happen to
be members of the peer review panel, primary researchers are rarely
present and would in any case be relegated to cameo presentations
during the limited time permitted for public comment. \49\
---------------------------------------------------------------------------
\49\ See, e.g., William C. Adams. ``Public Comment to CASAC Ozone
Review Panel Teleconference.'' Available at http://www.epa.gov/sab/pdf/
pub
-
comments
-
03-05-
07
-
dr
-
wm
-
adams
-
uc-
davis.pdf; accessed January 29, 2012.
---------------------------------------------------------------------------
In the section below on remedies, I describe an alternative to this
zoological style peer review in which public participation is taken
seriously, and primary researchers have the lead in presenting
scientific information but do not play a role in evaluating it. \50\
---------------------------------------------------------------------------
\50\ I use the term zoological to describe EPA peer reviews to
reflect the fact that the public's role is strictly observational. Even
tapping on the glass is prohibited.

---------------------------------------------------------------------------
Federally Chartered Advisory Committees

Even more than peer review panels, advisory committees are
susceptible to politicizing science and scientizing policy. To the
extent that they can locate a scientific rationale for the advice they
want to provide, it can only make their recommendations more
persuasive. Like Congress, the public often fondly hopes for scientific
answers to difficult policy questions. If a policy choice can be made
to appear scientific, it may have a much easier time gaining public
acceptance.
One of the most striking examples of scientization occurred in
2008, after EPA finalized its revision to the ozone National Ambient
Air Quality Standard. CASAC sent Administrator Stephen Johnson an
unsolicited letter strenuously disagreeing with his decision. By
itself, this might have been noteworthy but it should not have been
overly controversial. After all, advisory committees that are
independent of an agency's control must be free to offer whatever
policy advice they see fit, and Agency officials are never obligated to
accept policy recommendations from advisory committees.
But CASAC went much, much further. CASAC misrepresented its policy
advice as science:

It is the Committee's consensus scientific opinion that your
decision to set the primary ozone standard above this range
[0.060 to 0.070 ppm] fails to satisfy the explicit stipulations
of the Clean Air Act that you ensure an adequate margin
ofsafety for all individuals, including sensitive populations.
\51\
---------------------------------------------------------------------------
\51\ Rogene Henderson. ``April 7, 2008, Letter to Stephen L.
Johnson from CASAC on `Clean Air Scientific Advisory Committee
Recommendations Concerning the Final Rule for the National Ambient Air
Quality Standards for Ozone,' '' CASAC April 7, 2008, Letter on O
2

NAAQS. Washington, D.C.: U.S. Environmental Protection Agency Office of
the Science Advisory Board, 2008, p. 2. Emphasis added.

This is wrong in multiple ways, and it should have drawn widespread
opprobrium instead of acclaim. Science might be able to determine what
human health effects occur at defined ozone concentrations, though even
this ability becomes suspect as concentrations approach background. But
it is impossible for science to determine what concentration is
``requisite to protect the public health'' or determine what
constitutes ``an adequate margin of safety.'' ``Requisite'' and
``adequate'' are squishy policy terms; they cannot be defined
scientifically. But CASAC attempted to scientize air pollution policy--
to make it appear as if science is the rightful venue for determining
the meaning of ``requisite'' and ``adequate.'' Equally disturbing,
CASAC attempted to arrogate the authority to make these policy
decisions despite knowing full well that Congress delegated them to the
Administrator.
This incident exposed a serious defect in the Clean Air Act's
procedures, one that has lessons for advisory committees generally. By
asking CASAC to review the scientific record to ensure that it
``accurately reflects the latest scientific knowledge,'' \52\ but
simultaneously ask CASAC to give policy advice to the Administrator
concerning what the standard ought to be, Congress practically invited
CASAC to scientize policy. For CASAC members, it was their scientific
credentials and expertise that gave them power, which they willfully
abused. And because they did so, it is entirely reasonable to be
skeptical about the quality of CASAC's scientific review. Did CASAC
also politicize the science to make it support members' personal
opinions about air pollution policy? Has anyone conducted a rigorous
review to find out?
---------------------------------------------------------------------------
\52\ See, e.g., ``Clean Air Act.'' 44 U.S.C. 7401 et seq. 1970. See
Sec.  7409(d)(2)(B), referring back to Sec. 108(a)(2).

---------------------------------------------------------------------------
Some Possible Remedies

Several remedies can be envisioned that follow from my diagnosis.

Information Quality

The key problem noted above is that EPA does not adhere to its
information quality guidelines. It largely ignores its procedural and
substantive commitments. It does not respond in a timely manner to
requests for correction and appeals. When it does respond, it tends to
obfuscate. When it acknowledges errors, it does not correct them.
These deficiencies are no doubt caught up in program offices'
desire to defend their past or pending regulatory decisions. But that
cannot explain the Agency's unwillingness to adhere to information
quality principles and standards in its science program, which EPA
leadership claims is not regulatory. \53\
---------------------------------------------------------------------------
\53\ This principle is highlighted in previous testimony to the
Subcommittee without reference to applicable information quality
guidelines. See Anastas (2011, p. 1). ``IRIS assessments provide a
scientific foundation for EPA decisions to protect public health across
EPA's programs and regions under an array of environmental laws. While
not regulations, IRIS assessments are critical to many Agency
decisions. After becoming Administrator in early 2009, Administrator
Jackson reviewed the IRIS program and asked the Office of Research and
Development (ORD) in May 2009 to implement a new IRIS process that
would revitalize the program and make it more responsive to the needs
of the Agency. The aim of the new process was to ensure the highest
level of scientific quality, integrity, transparency, and timeliness.''
---------------------------------------------------------------------------
A reasonable inference is that EPA's research programs may be
infected by both scientization (the desire to make policy decisions
through science) and politicization (the abuse of science for policy
purposes). Requiring EPA research programs to fully adhere to
information quality principles and standards would go a long way toward
overcoming these problems if they exist. If they do not exist, then
full adherence to information quality principles and standards would
earn EPA the credibility it believes it is deserved, and once and for
all refute its many critics.
There are simple reforms that Congress could make that would
breathe life into the information quality paradigm, thereby achieving a
dramatic improvement in the quality of EPA science. In particular,
Congress could require one or more of the following:

Require Full Disclosure of All Data, Models and Methods for Any Study
Used as the Basis for a Risk Assessment or Component Thereof

There appears to be a broad consensus in favor of transparency and
reproducibility, the two procedural information quality standards.
Under applicable information quality guidelines, data, models, and
methods must be fully disclosed such that qualified third parties can
reproduce the agency's results and obtain essentially the same result.
If third parties are unable to even make such an attempt, then the
agency work product is per se insufficiently transparent and violates
applicable standards. If third parties can make the attempt but cannot
reproduce EPA's results, then the information should be presumed to
fail the objectivity test. In either case, the information involved
should not be disseminated, much less used for risk assessment. \54\
---------------------------------------------------------------------------
\54\ The scientific information classification scheme recommended
to the Subcommittee by Dr. Moghissi also has significant merit as a way
to identify where scientific knowledge is weakest so that investments
in research could be targeted to have the greatest value. See A. Alan
Moghissi. ``Written Testimony Before the U.S. House of Representatives,
Committee on Science, Space, and Technology, Subcommittee on Energy and
Environment, Hearing on `Fostering Quality Science at EPA: Perspectives
on Common-Sense Reform:' The Need for Regulatory Science Transparency
at the EPA,'' 2011.
---------------------------------------------------------------------------
Agencies avoid the full force of this transparency standard by
claiming, correctly, that published articles in scholarly journals do
not disclose enough information to meet the transparency and
reproducibility standards. Congress can best solve this problem by
altering incentives.
Contracting regulations already permit federal agencies to demand
that recipients of federal research funds submit their data upon
request. Unfortunately, agencies still have the discretion not to ask,
and they often do so precisely to avoid having to disclose the
information to the public as the Shelby Amendment otherwise requires.
\55\ Congress could relieve federal agencies of this conundrum by
requiring them to obtain research data if they want to use a federally
funded study as the basis for risk assessment. Requiring disclosure
imposes only trivial costs on the agencies and does not violate the
contractual terms of any federally funded researcher. No burden would
be imposed on anyone if the agency did not want to use a
federallyfunded study as the basis for risk assessment, and no
researcher would be compelled to accept federal research funds to
conduct a study likely to be useful in risk assessment.
---------------------------------------------------------------------------
\55\ Pub. L. 105-277, 112 Stat. 2681-495: ``That the Director of
OMB amends Section ----.36 of OMB Circular A-110 to require Federal
awarding agencies to ensure that all data produced under an award will
be made available to the public through the procedures established
under the Freedom of Information Act.'' OMB's implementation of this
provision was highly controversial among recipients of federal research
funds who considered the data they collected to be their private
intellectual property.
---------------------------------------------------------------------------
If an agency wants to rely on a study that was funded by another
party, whether that be a State, business, trade association, or
nongovernmental organization, nothing currently prevents the agency
from asking that this information be supplied, nor is there any general
legal barrier to the other party providing it. States, businesses,
trade associations, and nongovernmental organizations that want their
research to be used for public policy should happily volunteer to
provide it. Some do.
Moreover, an ever-increasing number of scholarly journals now
require disclosure as a condition for publication. Congress can
expedite this trend by prohibiting federal agencies from basing risk
assessments on studies published by journals that do not practice full
disclosure. Researchers who want their work to influence policy will
seek publication in journals that require disclosure.

Require That Any Study Used as the Basis for a Risk Assessment or
Component Thereof Adhere to Substantive Information Quality
Standards

Information quality standards, particularly the standards of
presentational and substantive objectivity, should not apply to all
scientific research. Exploratory, hypothesis-generating research often
has merit, but by its nature it often cannot comply. However,
hypothesis-testing research should always comply, particularly if it is
going to be used for risk assessment. By requiring crucial studies to
adhere to substantive information quality standards, much of the
controversy over study selection could be eliminated.
Notice that I would not require prior publication in a peer-
reviewed journal or give special weight to such studies. Journals
publish studies for many reasons, some of which are incompatible with
their use in risk assessment. Full disclosure is a much better
threshold requirement. Deference should be given to studies that, after
full disclosure, have been reproduced and not refuted.

Require That Agency Risk Assessments or Components Thereof Adhere to
Substantive Information Quality Standards

While it is crucial that key studies adhere to information quality
standards, it is not sufficient. Considerable analysis is performed
subsequent to the selection of key studies, so it is essential that
information quality standards also apply to risk assessments and other
derivative work products.
In practice, this would mean that cancer risk assessments
(including those containing unit risk values) and noncancer risk
assessments (including those containing Reference Doses or Reference
Concentrations) would have to adhere to the information quality
paradigm.
In the short run, this would be very difficult for EPA because, as
I noted above, it is the published policy and practice of the Agency
not to produce objective risk assessments. In the long run, however,
this requirement would unleash a torrent of new research into more
objective risk assessment methods. Currently, there is very little
``market demand'' for objective methods because EPA is essentially a
monopsonist in this ``market.' That is, EPA is the only buyer; as long
as EPA does not want objective risk assessment methods, the market will
not supply any.

Enforcement

If Congress were to require EPA research programs to adhere to
information quality principles and standards, it would have to devise a
way to enforce this requirement. We know that hortatory appeals and
executive certifications do not work. We also know that inviting judges
to ``do science'' cannot be much of an improvement, for they are just
as susceptible to the temptation to politicize science. Even if
judicial review never erred, it also would be an expensive remedy that
only a few could utilize.
One way to reduce the cost of judicial review is to narrowly tailor
it to take advantage of the courts' comparative advantage in
administrative procedure. Thus, courts might be authorized to render
opinions on agency adherence to published information quality
principles and practices, but they must be kept away from substantive
scientific disputes.

Peer Review

Several specific reforms of EPA peer review could be considered.

Explicitly Require Peer Reviews to Address Information Quality

The reforms recommended above in the section on information quality
would go a long way to solving this problem. They would make clear that
adherence to information quality principles and standards is not
optional for studies on which EPA intended to base a risk assessment,
or for risk assessments themselves.
As I noted above, EPA's Peer Review Handbook gives short shrift to
information quality. Congress could remedy this by explicitly requiring
peer reviews to include rigorous information quality review. This
should be done early in the process so that EPA does not commit itself
to basing risk assessments on noncompliant studies. EPA could be sure
early on that the studies on which it intends to rely are fully
compliant and will not be the subject of a spurious later controversy.
Information quality review also should be done later to ensure that
subsequent analyses performed by the Agency also comply. Waiting until
EPA has already published a draft risk assessment may be too late, for
by that time Agency risk assessors often have dug in their heels.
Considerable effort would be needed to train scientist-peer
reviewers in information quality principles and standards, or
alternatively, establish information quality as a distinct discipline
that must be represented on every peer review panel. I prefer training
scientist-peer reviewers so that they become better equipped to detect
information quality errors as a regular part of their own professional
discipline. This has external benefits insofar as it would introduce
concern for information quality into journal peer review, and thus into
scholarly research destined for journal publication.

Strictly Limit Scientific Peer Reviews to Science

It might seem superfluous to make such a requirement explicit, but
the record shows that it is needed. Peer reviewers have incentives to
scientize policy, and EPA staff have incentives to ask peer reviewers
to conduct their reviews in ways that at least implicitly ratify
embedded policy decisions. By strictly limiting scientific peer reviews
to science, it would be much easier to discern when any actor in the
peer-review process--EPA staff, peer reviewers, and public commenters
alike--has exceeded the charge.
At a practical level, this would mean removing so-called ``science
policy'' issues from peer review. This is highly desirable, for it is
within the domain of ``science policy'' that politicization and
scientization are most likely to occur. Also, removing ``science
policy'' would make peer review a much easier task for scientists to
perform. It would improve the scientific quality of the peer review
charge, for controversies over embedded policy choices within the
charge would go away.
If policy issues were removed from the scope of scientific peer
review, the importance of balancing bias among members of a peer review
panel would appreciably diminish. Instead of worrying about balancing
different policy views, greater attention could be devoted to ensuring
that peer review panels have diverse intellectual perspectives. When
there is a coincidence of intellectual interests among peer reviewers
or between the panel and the Agency, as the current regime encourages,
the result can be an echo chamber. \56\
---------------------------------------------------------------------------
\56\ The echo is deafeningly loud when peer reviewers also share
the same policy or ``science policy'' views as Agency staff--yet
another good reason for strictly limiting scientific peer review to
science.

Make the Selection of Reviewers and the Charge Independent of the
---------------------------------------------------------------------------
Agency

It's a well-known secret that the ability to select peer reviewers
and write the charge creates the opportunity to control the outcome.
For this reason, EPA should not control the charge and peer reviewers
should not be selected by EPA or its contractors. \57\ In its Peer
Review Handbook, EPA displays a high degree of skepticism about
external parties conducting peer reviews of their own work products.
\58\ It is therefore hardly unreasonable for others to be similarly
skeptical of peer reviews of EPA work products conducted by EPA. \59\ A
simple expedient might be to establish and maintain lists of qualified,
independent panel members for each discipline and select the requisite
number of members from each list by lottery.
---------------------------------------------------------------------------
\57\ It should be expected that contractors who want to maintain
their business relationships with EPA are cognizant of EPA's desires
with respect to panel selection.
\58\ See U.S. Environmental Protection Agency (2006, p. 72).
\59\ EPA appears to object even to peer reviews paid for by third
parties where there is ample evidence of independence or no evidence of
third-party control.
---------------------------------------------------------------------------
In 2006, Regulatory Checkbook organized and conducted a scientific
review that I believe follows another superior model that EPA could
adopt. We followed OMB's draft peer review guidelines, \60\ which were
much stronger than the final version. We strictly limited the review to
science--where possible, only primary scientific research was
considered--and excluded all manner of policy considerations, such as
the derivation of a unit risk factor. We focused on just four major
scientific questions, thus conserving resources to address only the
most important issues, with a separate peer review panel for each.
Rather than control information exchange, we delegated that
responsibility to universally respected, bona fide subject matter
experts. So long as it did not stray into policy, we encouraged open
discussion among all participants, including members of the public.
\61\ Finally, to avoid any interference by the sponsors, we established
a Planning Committee whose role was to select the issues to be
examined, select the subject matter experts and peer review panelists,
write the charge, and coordinate the submission of the final reports
for consideration by a scholarly journal subject to another round of
peer review. \62\
---------------------------------------------------------------------------
\60\ Office of Management and Budget. ``Proposed Bulletin on Peer
Review and Information Quality.'' Federal Register, 2003, 68, 54023-
54029.
\61\ We did not follow EPA's practice of limiting the participation
of independent experts to staged five-minute didactic presentations.
\62\ Richard B. Belzer, James S. Bus, Ercole L. Cavalier, Steven C.
Lewis, D. Warner North and Richard C. Pleus. ``The naphthalene state of
the science symposium: Objectives, organization, structure, and
charge.'' Regulatory Toxicology and Pharmacology, 2008, 51(2(1)), 1-5;
Kenneth T. Bogen, Janet M. Benson, Garold S. Yost, John B. Morris, Alan
R. Dahl, Harvey J. Clewell III, Kannan Krishnan and Curtis J.
Omiecinski. ``Naphthalene metabolism in relation to target tissue
anatomy, physiology, cytotoxicity and tumorigenic mechanism of
action.'' Regulatory Toxicology and Pharmacology, 2008, 51(2(1)), 27-
36; David Brusick. ``Critical assessment of the genetic toxicity of
naphthalene.'' Regulatory Toxicology and Pharmacology, 2008, 51(2(1)),
37-42; David Brusick, Mitchell S. Small, Ercole L. Cavalieri,
Dhrubajyoti Chakravarti, Xinxin Ding, David G. Longfellow, Jun
Nakamura, Eleanor C. Rogan and James A. Swenberg. ``Possible genotoxic
modes of action for naphthalene.'' Regulatory Toxicology and
Pharmacology, 2008, 51(2(1)), 43-50; Fumie Y. Griego, Kenneth T. Bogen,
Paul S. Price and Douglas L. Weed. ``Exposure, epidemiology and human
cancer incidence of naphthalene.'' Regulatory Toxicology and
Pharmacology, 2008, 51(2(1)), 22-26; D. Warner North, Kamal M. Abdo,
Janet M. Benson, Alan R. Dahl, John B. Morris, Roger Renni and
Hanspeter Witschi. ``A review of whole animal bioassays of the
carcinogenic potential of naphthalene.'' Regulatory Toxicology and
Pharmacology, 2008, 51(2(1)), 6-14; Paul S. Price and Michael A.
Jayjock. ``Available data on naphthalene exposures: Strengths and
limitations.'' Regulatory Toxicology and Pharmacology, 2008, 51(2(1)),
15-21.

---------------------------------------------------------------------------
Federally Chartered Advisory Committees

A key lesson for Congress from the CASAC experience is to refrain
from asking advisory committees to perform tasks that are inherently in
conflict, such as conducting scientific review and giving policy
advice.
Where this cannot be avoided, such as existing committees whose
charters it is impracticable to change, advisory committees should be
required to abide by relevant Red Book recommendations. They should
``establish and maintain a clear conceptual distinction between
assessment of risks and consideration of risk management
alternatives,'' and ensure that their reports ``clearly distinguish
between the scientific basis and the policy basis'' for their
conclusions and recommendations. This can be easily enforced, such as
by authorizing the EPA Administrator to ignore reports from advisory
committees that demonstrably do not comply. The threat of being ignored
is a powerful incentive.

What Agency Officials Can Do Without Congressional Action

I do not want to convey the impression that nothing can be done
unless Congress acts. This is clearly not true. Obviously, EPA
officials could, if they wanted to, insist that staff adhere to
applicable information quality principles and standards. EPA officials
could, if they wanted to, direct the Science Policy Council to amend
the Peer Review Handbook to explicitly include information quality
review. They could, if they wanted to, insist that Agency peer reviews
comply with the Peer Review Handbook.
EPA officials also could, if they wanted to, require Agency peer
reviews to be strictly limited to science. It would take hardly any
effort at all for EPA officials to modify the charters of Agency
advisory committees and specifically include within each a requirement
to abide by the Red Book.
In short, most of the reforms I have proposed actually require
Congress to do anything. The reason why the Subcommittee is conducting
oversight and considering legislation, however, is that EPA officials--
officials appointed by Democratic and Republican presidents alike--have
not made any of these reforms.

Final Remarks

My diagnosis of the problems afflicting EPA science is not novel;
indeed, I have specifically cited papers published in 1986 that make
many of the same points.
To the best of my knowledge, Congress has never politicized EPA
science by, for example, requiring it to estimate risk inaccurately or
in a misleading way. \63\ These are things EPA has done on its own,
often by misusing the tools of risk assessment (the estimation of what
risk is) to justify particular risk management decisions (the policy
determination of what risk ought to be). \64\
---------------------------------------------------------------------------
\63\ In its 2004 report explaining and defending its risk
assessment policies and practices, EPA staff say that Congress has, in
fact, directed EPA to use risk assessment methods that are
``protective'' (i.e., tend to overstate risk). See National Research
Council (1983, pp. 151, 153). However, the report does not provide a
single example of a statutory provision requiring EPA to estimate risk
in a biased manner. Every example given is either irrelevant to the
question or it conflates risk assessment with risk management. See
ibid., pp. 14-16.
\64\ U.S. Environmental Protection Agency Office of the Science
Advisor (2004,p. 14). ``Congress establishes legal requirements that
generally describe the level of protectiveness that EPA regulations
must achieve and, infrequently, Congress imposes specific risk
assessment requirements.'' ``EPA seeks to adequately protect public and
environmental health by ensuring that risk is not likely to be
underestimated'' (emphasis in original).
---------------------------------------------------------------------------
In this way, EPA risk assessors and other staff have scientized
policy and politicized science. They have scientized policy by claiming
that science can answer questions that science can inform but not
decide. They have politicized science by choosing not to estimate risk
accurately. By scientizing policy, Agency risk assessors and other
staff have taken away from Agency officials the authority and
responsibility, delegated by Congress, to make policy decisions. They
take away from policy officials alternatives that are well within the
range of plausible interpretations of their statutory directives. \65\
---------------------------------------------------------------------------
\65\ EPA staff deny this, but unconvincingly. ``[A]ny science
policy position or choice used in the risk assessment process does not
direct the risk assessment itself toward a specific risk management
decision, e.g., the use of a specific risk estimate,'' they write.
``Rather, the risk assessment informs the decision maker about the
potential risks and uncertainties around the risk estimate(s). These
characterized risks are then considered in light of the other factors
before a decision is made.'' (ibid., p. 13). Except that it misinforms
decision makers, making it harder for them to take account of ``other
factors.''
---------------------------------------------------------------------------
The remedies I have proposed should not be controversial if the
goal is to improve scientific quality while preserving the Agency's
legitimate discretion under the various laws Congress has directed it
to implement. They are grounded in the ideals of the National Academy's
1983 Red Book, yet recognize that the Red Book model has either failed
or cannot be implemented. Instead of ``establishing and maintaining a
clear conceptual distinction between assessment of risks and the
consideration of risk management alternatives,'' I believe it is time
to effect a full and complete separation. I believe this is essential
to restore science to its rightful place, freeing it from
politicization, while at the same time aggressively policing the
boundary between science and policy to ensure that policy making also
is free from scientization.
Some recommend removing risk assessment from EPA, believing that it
is simply not possible for science to be performed within ``the
political cauldron'' of EPA because its ``messy mix of politics,
policy, economics, law, interests, and values'' make it ``not a good
environment in which to develop and evaluate science.'' \66\ I
understand the sentiment but I am not ready to give up, nor is it clear
to me that giving up is a realistic option.
---------------------------------------------------------------------------
\66\ U.S. Environmental Protection Agency Office of the Science
Advisor (2004,p. 11). Professor Marchant advocates removing the
production and review of science from EPA's jurisdiction: ``it would be
best if the science was developed and evaluated separately, and in
particular in a separate institutional context, from the more political
decision-making process.''
---------------------------------------------------------------------------
Thank you again for the opportunity to testify today on this
important subject. I would be pleased to answer any question that
members of the Subcommittee might have.

References

1. ``Clean Air Act.'' 44 U.S.C. 7401 et seq. 1970.

2. ``Information Quality Act.'' 44 U.S.C. 3516 note. 2000.

3. Adams, William C. ``Public Comment to CASAC Ozone Review
PanelTeleconference.'' Available athttp://www.epa.gov/sab/pdf/
pub
-
comments
-
03-05-
07
-
dr
-
wm
-
adams
-
uc-
davis.pdf; accessed January 29, 2012.

4. American Association for the Advancement of Science. ``AAAS
Policy Brief: Access to Data.'' Available athttp://www.aaas.org/spp/
cstc/briefs/accesstodata/index.shtml;accessed January 27, 2012.

5. Anastas, Paul. ``Written Testimony Before the U.S. House of
Representatives Committee on Science Space and Technology, Subcommittee
on Oversight, Hearing on `EPA's Integrated Risk Information System,' ''
2011.

6. Bell, M.L.; F. Dominici and J.M. Samet. ``A meta-analysis of
time-series studies of ozone and mortality with comparison to the
national morbidity, mortality, and air pollution study.'' Epidemiology,
2005, 16(4).

7. Bell, Michelle L.; Aidan McDermott; Scott L. Zeger; Jonathan M.
Samet and Francesca Dominici. ``Ozone and Short-term Mortality in 95 US
Urban Communities, 1987-2000.'' JAMA, 2004, 292(19), 2372-2378.

8. Belzer, Richard B. ``Interests and Incentives in Government Peer
Review.'' Conflict, Consensus, and Credibility: A Forum on Regulatory
Peer Review, Alexandria, Va., 2002.

9. --------. ``Risk Assessment and Information Quality: An
Empirical Study of Federal Agency Performance, 2010 Update.'' Society
for Risk Analysis 2010 Annual Meeting, Salt Lake City, Ut., 2010.

10. Belzer, Richard B.; James S. Bus; Ercole L. Cavalier; Steven C.
Lewis; D. Warner North and Richard C. Pleus. ``The naphthalene state of
the science symposium: Objectives, organization, structure, and
charge.'' Regulatory Toxicology and Pharmacology, 2008, 51(2(1)), 1-5.

11. Bipartisan Policy Center. ``Improving the Use of Science in
Regulatory Policy,'' Washington, D.C.: Bipartisan Policy Center, 2009.

12. Bogen, Kenneth T.; Janet M. Benson; Garold S. Yost; John B.
Morris; Alan R. Dahl; Harvey J. Clewell III; Kannan Krishnan and Curtis
J. Omiecinski. ``Naphthalene metabolism in relation to target tissue
anatomy, physiology, cytotoxicity and tumorigenic mechanism of
action.'' Regulatory Toxicology and Pharmacology, 2008, 51(2(1)), 27-
36.

13. Brusick, David. ``Critical assessment of the genetic toxicity
of naphthalene.'' Regulatory Toxicology and Pharmacology, 2008,
51(2(1)), 37-42.

14. Brusick, David; Mitchell S. Small; Ercole L. Cavalieri;
Dhrubajyoti Chakravarti; Xinxin Ding; David G. Longfellow; Jun
Nakamura; Eleanor C. Rogan and James A. Swenberg. ``Possible genotoxic
modes of action for naphthalene.'' Regulatory Toxicology and
Pharmacology, 2008, 51(2(1)), 43-50.

15. Dudley, Susan E. ``Written Testimony Before the U.S. House of
Representatives Committee on Science, Space, and Technology,
Subcommittee on Energy and the Environment, Hearing on `Fostering
Quality Science at EPA: Perspectives on Common Sense Reforms,' '' 2011.

16. Griego, Fumie Y.; Kenneth T. Bogen; Paul S. Price and DouglasL.
Weed. ``Exposure, epidemiology and human cancer incidence of
naphthalene.'' Regulatory Toxicology and Pharmacology, 2008, 51(2(1)),
22-26.

17. Henderson, Rogene. ``April 7, 2008, Letter to Stephen L.
Johnson from CASAC on `Clean Air Scientific Advisory Committee
Recommendations Concerning the Final Rule for the National Ambient Air
Quality Standards for Ozone,' '' CASAC, April 7, 2008, Letter on
O
2
NAAQS. Washington, D.C.: U.S. Environmental Protection
Agency Office of the Science Advisory Board, 2008.

18. Holdren, John P. ``Memorandum for the Heads of Executive
Departments and Agencies: Scientific Integrity,'' Office of Science and
Technoloy Policy, 2010.

19. Marchant, Gary E. ``Written Testimony Before the U.S. House of
Representatives Committee on Science, Space, and Technology,
Subcommittee on Energy and the Environment, Hearing on `Fostering
Quality Science at EPA: Perspectives on Common Sense Reform,' '' 2011.

20. McClellan, Roger O. ``Written Testimony Before the U.S. House
of Representatives, Committee on Science, Space, and Technology,
Subcommittee on Energy and the Environment, Hearing on `Quality Science
for Quality Air,' '' 2011.

21. Moghissi, A. Alan. ``Written Testimony Before the U.S. House of
Representatives, Committee on Science, Space, and Technology,
Subcommittee on Energy and Environment, Hearing on `Fostering Quality
Science at EPA: Perspectives on Common Sense Reform:' The Need for
Regulatory Science Transparency at the EPA,'' 2011.

22. National Research Council. Review of the Environmental
Protection Agency's Draft IRIS Assessment of Formaldehyde. Washington,
D.C.: National Academies Press, 2011.

23. --------. Risk Assessment in the Federal Government: Managing
the Process. Washington, D.C.: National Academies Press, 1983.

24. Nichols, Albert L. and Richard J. Zeckhauser. ``The Dangers of
Caution: Conservatism in Assessment and the Mismanagement of Risk,'' V.
Kerry Smith, Advances in Applied Micro-Economics: Risk, Uncertainty,
and the Valuation of Benefits and Costs. Greenwich, Conn.: JAI Press,
1986a, 55-82.

25. --------. ``The Perils of Prudence: How Conservative Risk
Assessments Distort Regulation.'' Regulation, 1986b, 10(6), 13-24.

26. North, D. Warner. ``Reflections on the Red/Mis-Read Book, 20
Years After.'' Journal of Human and Ecological Risk Assessment, 2003,
9(5), 1145-1154.

27. North, D. Warner; Kamal M. Abdo; Janet M. Benson; Alan R. Dahl;
John B. Morris; Roger Renni and Hanspeter Witschi. ``A review of whole
animal bioassays of the carcinogenic potential of naphthalene.''
Regulatory Toxicology and Pharmacology, 2008, 51(2(1)), 6-14.

28. Obama, Barack. ``Scientific Integrity.'' Federal Register,
2009, 74(46), 10671-10672.

29. Office of Management and Budget. ``Current Regulatory Issues in
Risk Assessment and Risk Management,'' Regulatory Program of the United
States, April 1, 1990--March 31, 1991. Washington, DC: Office of
Management and Budget, 1990, 13-26.

30. --------. ``Final Information Quality Bulletin for Peer
Review.'' Federal Register, 2005, 70(10), 2664-2667.

31. --------. ``Guidelines for Ensuring and Maximizing the Quality,
Objectivity, Utility, and Integrity of Information Disseminated by
Federal Agencies; Notice; Republication.'' Federal Register, 2002,
67(36), 8452-8460.

32. --------. ``Proposed Bulletin on Peer Review and Information
Quality.'' Federal Register, 2003, 68, 54023-54029.

33. Phalen, Robert F. ``Written Testimony Before the U.S. House of
Representatives, Committee on Science, Space, and Technology,
Subcommittee on Energy and the Environment, Hearing on `Quality Science
for Quality Air': The CASAC-PM Committee--Setting Air Quality
Standards,'' 2011.

34. Price, Paul S. and Michael A. Jayjock. ``Available data on
naphthalene exposures: Strengths and limitations.'' Regulatory
Toxicology and Pharmacology, 2008, 51(2(1)), 15-21.

35. Stark, Andrew. Conflict of Interest in American Life.
Cambridge, Mass.: Harvard Universitry Press, 2000.

36. The National Academies. ``Policy on Committee Composition and
Balance and Conflict of Interest,'' The National Academies, 2003.

37. Thurston, George D. ``Written Testimony Before the U.S. House
of Representatives, Committee on Science, Space, and Technology,
Subcommittee on Energy and the Environment, Hearing on `Quality Science
for Quality Air': RE: The Science of Air Pollution Health Effects and
The Role of CASAC in EPA Standard Setting,'' 2011.

38. U.S. Environmental Protection Agency. ``Guidelines for Ensuring
and Maximizing the Quality, Objectivity, Utility, and Integrity of
Information Disseminated by the Environmental Protection Agency (EPA/
260R-02-008),'' 2002.

39. --------. ``Peer Review Handbook (1st Ed.),'' Washington, D.C.:
U.S. Environmental Protection Agency Science Policy Council, 1988.

40. --------. ``Peer Review Handbook (2d Ed.),'' Washington, D.C.:
U.S. Environmental Protection Agency Science Policy Council, 2000.

41. --------. ``Peer Review Handbook (3rd Ed.),'' Washington, D.C.:
U.S. Environmental Protection Agency Science Policy Council, 2006.

42. U.S. Environmental Protection Agency Office of the Science
Advisor. ``An Examination of EPA Risk Assessment Principles and
Practices; Staff Paper, EPA/100/B-04/001,'' 2004.

Chairman Harris. Thank you very much.
I now recognize our fifth witness, Dr. Jerald Schnoor of
the University of Iowa, Department of Civil and Environmental
Engineering.

STATEMENT OF DR. JERALD SCHNOOR,

ALLEN S. HENRY CHAIR IN ENGINEERING,

DEPARTMENT OF CIVIL AND ENVIRONMENTAL ENGINEERING,

UNIVERSITY OF IOWA

Dr. Schnoor. Good morning, Chairman Harris, Ranking Member
Miller, distinguished Committee Members. Thank you for the
chance to testify before the Subcommittee. I am Jerry Schnoor,
Professor of Civil and Environmental Engineering at the
University of Iowa. My views are my own today, and I have had
the pleasure of serving on a number of committees concerning
science at EPA, and I come to you with the shared interest in
fostering quality science.
But what constitutes quality science? EPA's mission is to
protect human health and the environment from detrimental
effects of pollution and other hazards. Their science should be
relative to the mission. It should be of high quality and high
priority, and it should be reviewed by qualified scientists and
engineers constantly. Such high-quality science enables
excellent policy decisions to be made by decision makers
including Congress, yourselves. In addition, EPA science should
help in identifying future and emerging environmental issues. I
can testify that the EPA and ORD offer world-class science in a
number of areas, including especially air quality modeling,
monitoring, and development of emission databases.
Improvements in air quality over the past 40 years are
remarkable and a testament to the good science at EPA. Please
see figure 1. In the top panel here, increasing population and
consumption as measured by gross domestic product, the vehicle
miles traveled in America, and energy consumption are drivers.
They serve to elevate the emissions in the United States. If
one wants to keep up with the ever-increasing pollution from
these drivers, it requires increasingly stringent regulations
just to maintain the status quo. For the most part, U.S.
greenhouse gas emissions--that is CO
2
emissions on
the slide--have mirrored the increasing U.S. population, which
continues to grow at about one percent per year in figure 1.
Notice all three lines in the middle are in lockstep.
But the surprising news from figure 1 is that in the bottom
panel, six aggregate air pollutants have been reduced by 41
percent over the past 18-year period. This illustrates a
tremendous success story, which constitutes lives saved, better
respiratory health for Americans, and billions of dollars in
medical costs avoided, not to mention clearer, purer air.
The United States achieved these results by virtue of
steadfast EPA adopting new rules and enforcing the Clean Air
Act and its amendments. The Clean Air Act is the most expensive
legislation to enforce in the entire U.S. Code, but it has a
30:1 benefit-to-cost ratio still. It has saved thousands of
lives and will result in the creation of 1.5 million new jobs
over the next five years for the ambient air quality standards
alone.
The Office of Research and Development provides a
significant portion of scientific research at EPA. In 2011,
ORD, as we have heard, realigned their programs from 13 to six,
shown on this slide. The realignment was in concert with peer
review provided over the past years by both the Science
Advisory Board and the Board of Scientific Counselors.
Motivation for this consolidation and realignment of programs
reflects an emphasis on integrated transdisciplinary research,
multipollutant exposures, and sustainability. These are not new
programs but rather they represent a new way of thinking within
ORD, and I believe considerable synergies may be realized in
combining research into the four programmatic areas shown on
the right-hand side of the slide and the two smaller programs
in Homeland Security and human health risk assessment, also on
the right.
As a member of EPA Science Advisory Board and several NRC
committees concerned with EPA research, I can assure you that
EPA is transparent and heavily peer reviewed already. The
entire scientific process from major reports to published
research journal articles, from their labs, centers, and
divisions to the proposed regulations, all are reviewed by SAB,
BOSC, CASAC and other entities. If anything, I would say the
scrutiny and accountability of EPA has increased in recent
years, based on my own experience serving on those committees.
Thank you very much for the chance to testify.
[The prepared statement of Dr. Schnoor follows:]

Prepared Statement of Dr. Jerald Schnoor,
Allen S. Henry Chair in Engineering,
Department of Civil and Environmental Engineering,
University of Iowa

Good morning, Chairman Harris, Ranking Member Miller, Distinguished
Committee Members, ladies and gentleman. Thank you for the chance to
testify before the Subcommittee. I am Jerald Schnoor, Professor of
Civil and Environmental Engineering at the University of Iowa and Co-
Director of the Center for Global and Regional Environmental Research.
I am also Editor-in-Chief of the American Chemical Society journal,
Environmental Science and Technology, a leading journal in
environmental science and engineering. I have had the good fortune to
teach and perform research in the environmental area for over 35 years.
During that time, I served as the Chair of the Board of Scientific
Counselors for EPA Office of Research and Development (ORD) from 2000-
2004, and more recently as a member of the Science Advisory Board (SAB)
to EPA. I also am a member of the National Academy of Engineering and,
as such, have served on a number of National Research Council
committees of the National Academies, including one which I am chairing
now on science for EPA's future. So I come to you with shared interest
in fostering quality science at EPA, and I have organized my testimony
in response to the questions posed to me in the invitation letter from
Chairman Harris dated January 25, 2012.
What constitutes quality science to support EPA's mission? EPA's
mission is to protect human health and the environment from detrimental
effects of pollution and other hazards. Thus, EPA's science should be
relevant to its mission; it should be of high quality and high
priority; and it should be reviewed by qualified scientists and
engineers. Such high-quality science enables excellent policy judgments
to be made by decision makers. In addition, EPA science should help to
identify future and emerging environmental issues.
One recent example which illustrates how quality science can help
to inform policy even in a time of crisis involved the Macondo oil
spill on April 20, 2010, and the subsequent release of almost 200
million gallons of oil and addition of two million gallons of
dispersant to the Gulf of Mexico. Shortly after the accident occurred,
EPA was asked about the toxicity of the dispersant that was chosen to
break up the oil plume. The toxicological data on dispersants at the
time were sparse, but EPA-ORD rapidly engaged in high-throughput
testing on eight commercial dispersants at the National Center for
Computational Toxicology in the EPA Lab at Research Triangle Park,
North Carolina. EPA scientists learned quickly that Corexit 9500, the
dispersant used, was comparable or relatively less toxic than other
alternative products. In fact, EPA scientists performed the research,
wrote and submitted a scientific journal article, and subsequently
published the peer-reviewed results on June 30, 2010, only 10 weeks
after the original explosion and release of oil (Judson et al., 2010)--
a remarkable accomplishment. Those events point to another
characteristic of quality science--it should be timely.
EPA should provide high-quality science to inform regulatory
decisions. As a research engineer and editor, I can testify that the
Office of Research and Development offers world-class science in a
number of areas including air quality monitoring, modeling, and
development of emissions databases. Improvements in air quality that
the U.S. has achieved over the past 40 years are a testament to the
good science at EPA. Let's consider air quality in recent decades in
the U.S. as a case study for sound science to improve human health and
the environment.
Increasing population and consumption are ``drivers'' serving to
elevate emissions both in the U.S. and globally. If one wants to ``keep
up'' with ever-increasing pollution from these drivers, it requires
increasingly stringent regulations just to maintain the status quo. For
the most part, U.S. greenhouse gas emissions (CO
2
-
equivalents) have mirrored the increasing population which continues to
grow at about one percent per year. Figure 1 shows the lock-step of
increasing CO
2
emissions, population, and energy consumption
in the U.S. since 1990. They track each other closely, and increasing
population and energy consumption result in greater CO
2

emissions. Note that CO
2
emissions have not increased nearly
as rapidly as the Gross Domestic Product (GDP), which indicates
improved efficiency in a changing economy. Also, the trend in the
transportation sector, responsible for approximately one-quarter of all
greenhouse gases (GHGs), shows that Americans drove many more miles
during this period. Vehicle miles traveled increased 36% from 1990-
2008, but the rate of release of greenhouse gas emissions due to
transportation has been much less, especially in recent years.
The surprising news from Figure 1 is that six aggregate air
pollutants have been reduced by 41% over the 18-year period. This
illustrates a tremendous success story which constitutes lives saved,
better respiratory health for millions, and billions of dollars in
medical costs avoided, not to mention cleaner/purer air. The U.S.
achieved these results by virtue of a steadfast EPA adopting new rules
and enforcing the Clean Air Act and its amendments. The Clean Air Act
is the most expensive legislation to enforce in the entire U.S. code,
but it has a highly positive benefit-to-cost ratio and has resulted in
lower morbidity and mortality due to lung and cardiovascular disease,
and the creation of many jobs by achieving and abiding by the new
standards (CERES, 2010). CERES, an organization that articulates the
views of major American corporations on their social responsibilities,
recently estimated that enforcement of the National Ambient Air Quality
Standards alone will result in the creation of 1.5 million jobs over
the next five years. The country needs clean energy and clean air as
well as high-paying jobs, and the former can augment the latter. In
March 2011, EPA issued The Benefits and Costs of the Clean Air Act from
1990-2020. According to this study, the direct benefits from the 1990
Clean Air Act Amendments are estimated to be almost $2 trillion for the
year 2020, exceeding costs by a factor of more than 30:1.

From Figure 2, one can see the large decline in specific emissions
of NO
2
(30 %), Volatile Organic Chemicals (VOC, 53%), carbon
monoxide (CO, 54%), sulfur dioxide (SO
2
, 55%), and
particulate matter less than 10 microns (PM
2
, 65%) since the
inception of EPA in 1970, and the implementation and enforcement of the
Clean Air Act and its Amendments (1967, 1976, 1990). Despite a doubling
of the U.S. GDP during this period (and large increases in vehicle
miles traveled, population, energy consumption, and CO
2

emissions), regulation of the transportation and industrial sectors has
allowed a decline in emissions of air pollutants. Note, however, that
the majority of emission reductions from 1970-2005 in Figure 2 occurred
prior to 1995 (with the exception of NO
2
), illustrating that
the rate of improvements have slowed.

Sometimes, there is no single entity or agency that is sufficiently
interested, capable, or funded to perform research necessary to protect
human health and the environment from pollution. Many times, it is
advantageous to form partnerships to combine expertise and resources. A
case in point is science to understand the emissions, fate, and effects
of fine particulate matter (PM
2
) in the 1990s. EPA partnered
with the National Institute of Environmental Health Sciences (NIEHS)
and the Electric Power Research Institute (EPRI) to fund this seminal
research. The famous Harvard Six Cities Study (Dockery et al., 1993)
found evidence that not only lung cancer mortality was elevated when
fine particles were prevalent in the air of U.S. cities, but
cardiopulmonary disease also increased. However, the etiology of the
disease, the cause of cardiopulmonary mortality, was unknown. How could
fine particles cause disease, let alone death by heart attack or
stroke? So it must have been with some trepidation that EPA began to
develop regulations in 1996 to regulate fine particulate matter less
than 2.5 microns in diameter (PM
2
) in order to protect the
public health.
Today scientists have a much better idea of how fine particles can
kill. In 2000, a reanalysis of the Harvard Six Cities Study was
reported by the Health Effects Institute (HEI) and, in 2004, research
was completed that validated the initial morbidity results (Krewski et
al., 2004). An extended follow-up study by Francine Laden and
colleagues was published in 2006 (Laden et al., 2006) and a summary of
the beneficial effects on life expectancy by Pope et al. (2009). Laden
was quoted in a Harvard School of Public Health Press Release at the
time:

``The follow-up study found that an average of three percent
fewer people died for every reduction of one microgram per
cubic meter in the average levels of PM
2
fine
particulate matter, defined as having a diameter of 2.5 microns
or less--narrower than the width of a human hair. This
decreased death rate is approximate to saving 75,000 people per
year in the U.S.''

That's an example of quality science performing well--hypotheses
are followed by hypothesis testing. Continual challenges in the peer-
reviewed literature are followed by subsequent publication and peer
review and iterated for further scrutiny of the results until the
conclusion emerges and new questions arise. Today EPA funds research at
the Rochester PM research Center and the Southern California Particle
Center on the health effects of even finer particles, ultrafine
particulate matter (UFP). EPA's (2011) Progress Report states,
``Ultrafine particulate matter (UFP) is easily transported throughout
the body even beyond the cardiopulmonary system. Tissue and cell
analysis shows evidence for the translocation of UFP to the liver,
kidneys and central nervous system. Surprisingly, there is potential
for UFP to cross into the circulatory and lymphoid systems, which could
allow the particles to reach sensitive sites, such as the heart, spleen
and bone marrow.''
How does EPA currently produce quality science? Science is
performed by the Office of Research and Development (ORD), by EPA
Agency Offices (e.g., Office of Water), through extramural grants and
contracts, and through small funding to the EPA Regional Offices and
states (NRC, 2000). Science to inform EPA regulations is developed
throughout the Agency, conveyed to the Administrator's Office, and
utilized accordingly. Of course, funding is provided through the
budgetary process and Congress, and oversight is performed by GAO, OMB,
and others. EPA employs a strategic planning process to utilize science
effectively. ORD seeks to maintain a balance between ``problem-driven''
research to address immediate policy and regulatory needs and ``core''
research in the basic environmental sciences, including research to
understand future and emerging issues. ORD recently implemented a
strategy to support innovation at the bench in ORD laboratories,
demonstrate the power of trans-disciplinary research, broaden their
network of problem solvers (crowd sourcing), and to showcase the
products of such research.
Partnerships are formed within EPA offices and across outside
agencies and institutions to perform both intramural and extramural
research. Peer review of major products and publications is the system
by which objective evaluation and criticism of the science occurs.
Increasingly, the National Research Council of the National Academies
has played an important role in peer review and advice to the Agency.
Considering the importance of air quality for the Agency and the
Nation, EPA contracted with NRC to produce a series of reports advising
the Agency on airborne particulate matter in the late 1990s and early
2000s. These were viewed as quite helpful at a critical juncture in
scientific research to inform rulemaking and policy (NRC, 1998; NRC,
1999). In addition, three FACA committees provide a wide range of
important scientific peer review and advice: the Science Advisory Board
(SAB), the Board of Scientific Counselors (BOSC), and the Clean Air
Scientific Advisory Committee (CASAC). The SAB reviews the President's
budget request and provides reviews on various reports which the Agency
produces. BOSC provides advice on management of ORD, its multi-year
program plans, and reviews of its various centers, laboratories and
divisions. Of course, CASAC reviews air pollution reports, rules, and
regulations.
The Office of Research and Development (ORD) provides a significant
portion of scientific research for the Agency. In 2011, EPA ORD
realigned their programs from 13 to six (Figure 3). The realignment was
in concert with advice provided in recent years by both the Science
Advisory Board (SAB) and the Board of Scientific Counselors (BOSC).
Thirteen major programs proved somewhat unwieldy, and the realignment
has received positive review from the SAB (SAB, 2011). Motivation for
this consolidation and realignment of programs reflects an emphasis on
integrated trans-disciplinary research, multi-pollutant exposures, and
sustainability. These are not new programs but represent a new way of
thinking within ORD. Considerable synergies may be realized in
combining research into the four programmatic areas: Air, Climate and
Energy; Safe and Sustainable Water Resources (water quality plus
drinking water); Sustainable and Healthy Communities; and Chemical
Safety for Sustainability; plus two smaller programs in Homeland
Security Research and Human Health Risk Assessment (Figure 3).
I believe ORD's realignment is wise, moving EPA research in a new
and effective direction. ORD is moving from a risk management paradigm,
which has guided and influenced research over the past two decades,
towards a sustainability paradigm. That effort will pay dividends. It
is consistent with a public health approach of ``preventing disease''
rather than a medical approach to ``treating disease'' after it occurs,
and it recognizes that environment and health are an interconnected
system. And it follows on early pioneering research which EPA did on
Pollution Prevention in the 1990s. Restructuring EPA's research
programs, however, is a significant challenge to an established Agency,
and ORD must effectively translate research results from these new
amalgamated programs into scientifically informed environmental policy.

What Improvements Are Needed for Future Science at EPA?

With a 41-year history, EPA finds itself in the second decade of
the new Millennia with different challenges and variable public support
for its mission to protect human health and the environment. EPA has
successfully controlled pollution and improved public health and
welfare since it was formed in 1970. Success has stemmed largely from
establishment and enforcement of its regulatory programs under the Safe
Drinking Water Act, the Clean Air Act, FIFRA, Superfund, TSCA, and
others. Those successes have been informed by good research, both
intramurally and extramurally, within the Agency and outside the Agency
by universities, colleges, and partnering agencies/institutions.
But EPA has been successful in reducing pollution mainly at the
local scale for single conventional pollutants where the legislative
mandate was strong. Now, our environmental problems are at larger scale
(regional to global) and involve aspects without solid legislative
authority (e.g., agricultural runoff, land use and climate change, and
choice of energy systems). Some factors driving these new challenges to
human health and the environment in the U.S. include the following:

Population growth and geographic shifts towards the
South, West, and the coasts;

Land use change (urban sprawl, coastal development,
agricultural practices);

Energy choices (biofuels, shale gas by hydraulic
fracturing, deep offshore oil, oil sands, coal bed methane,
concentrated solar power, wind energy);

Increased consumption and technological changes
(globalization of trade and invasive species, e-waste and complexity of
new electronic devices from 11 to 60 elements of the periodic table,
new plastics and flame retardants, endocrine disrupting chemicals);

Climate change (increased precipitation intensity,
changing precipitation patterns, increasing floods, droughts, forest
fires, tornadoes, hurricanes).

These factors have resulted in a new suite of emerging
environmental challenges for EPA:

Air quality deterioration due to warmer, moister climate;

Agricultural runoff and nutrient quality criteria from
climate change and land use choices;

Urban stormwater and by-pass exacerbated by sprawl and
storm severity;

Terrestrial ecosystem degradation (loss of species such
as birds, bees, butterflies, bats);

Coastal waters ecosystems degradation (harmful algal
blooms, red tides, and hypoxia).

EPA's science in the future will require a new and innovative
approach to investigating problems of broader scope where legislative
mandates are not strong. Land use change, energy choices, coastal
development, and climate change represent ``wicked'' problems of the
future for which quality science is needed to chart the path forward.
EPA must employ the most modern emerging technologies and tools to
address these problems. A nimbleness and adaptability will be required
to identify new environmental threats. Partnering and networking with
other agencies, other countries, and U.S. citizenry to fashion creative
innovative solutions to thorny problems must become the norm. Every
form of efficiency and innovation will be necessary. Certainly, a
science budget commensurate to these pressing problems and sufficient
to support policy decisions and regulatory actions will be needed to
protect human health and the environment in the future. This includes
better use of social, behavioral, and decision scientists who
understand how to develop alternative approaches for desired
environmental behaviors, rather than end-of-pipe command-and-control
regulations. Sometimes there is no alternative to direct control and
regulation, but EPA must think more creatively and seek market and
behavioral solutions when they present themselves.
Given the planned shift toward multi-pollutant cumulative risk
assessment and the backlog of ten thousand chemicals that need to be
assessed, there is a need to invest in modernizing the human risk
assessment approach to move beyond the one-pollutant-at-a-time
framework. ORD should develop a clear plan for how the outputs of the
Chemical Safety for Sustainability (CSS) program (e.g., Tox 21, NexGen)
will be used by the Human Health Risk Assessment program.The Safe and
Sustainable Water Resources SSWR program will need to increase their
focus on viewing water and wastewater holistically as an integral part
of the overall water cycle. Wastewater is not a ``waste,'' but rather a
resource from which we will recover water, nutrients, and energy for
reuse, and it will be used to make communities more socially,
economically, and environmentally sustainable. This is in concert with
EPA's changing role from not only a regulatory agency, but to one that
promotes sustainable and healthy communities.Lastly, EPA should assume
leadership in the social, behavioral, and decision sciences more
broadly as an explicit research enterprise and cross-cutting strategy.
Scientific research in these areas is inexpensive relative to the costs
involved in much of the physical and biological sciences. Relatively
modest investments in this cross-cutting domain could have large future
benefits to protect human health and the environment (SAB, 2011).

References

1. CERES (2011). New Jobs Cleaner Air: Employment Effects under
Planned Changes to the EPA's Air Pollution Rules, University of
Massachusetts, Political Economy Research Institute 9 James Heintz,
Heidi Garrett-Peltier, Ben Zippere), www.ceres.org/epajobsreport.

2. Dockery, D.W. et al. (1993). An association between air
pollution and mortality in six U.S. cities, The New England Journal of
Medicine 329 (24), 1753-1759.

Environmental Protection Agency (2011). Science and Research at the
U.S. Environmental Protection Agency--EPA Progress Report 2010, EPA/
600/R-011/067, Office of Research and Development, U.S. Environmental
Protection Agency, Washington, D.C., 79 pp.

Judson, RS, et al. (2010). Analysis of eight oil spill dispersants
using rapid, in vitro tests for endocrine and other biological
activity, Environ. Sci. Technol. 44, 5979-5985.

Krewski, D. et al. (2004). Validation of the Harvard Six Cities
Study of particulate air pollution and mortality, New England Journal
of Medicine 350 (2), 198-199.

Laden, F., Schwartz, J., Speizer, F.E., Dockery, D.W. (2006).
Reduction in fine particulate air pollution and mortality, Am J Respir
Crit Care Med 173, 667-672.

National Research Council (1998). Research Priorities for Airborne
Particulate Matter I. Immediate Priorities and a Long-Range Research
Portfolio, National Academy Press, National Academy of Sciences, 195
pp.

National Research Council (1999). Research Priorities for Airborne
Particulate Matter II. Evaluating Research Progress and Updating the
Portfolio, National Academy Press, National Academy of Sciences, 111
pp.

National Research Council (2000). Strengthening Science at the U.S.
Environmental Protection Agency--Research Management and Peer-Review
Practices, National Academy Press, National Academy of Sciences, 159
pp.

Pope, A., Ezzati, M., Dockery, D.W. (2009). Fine-particulate air
pollution and life expectancy in the United States, New England Journal
of Medicine 360, 376.

SAB Science Advisory Board (2011). Science Advisory Board Comments
on the President's Requested FY 2012 Research Budget, EPA-SAB-11-007,
U.S. Environmental Protection Agency, Washington, D.C., 30 pp.

Chairman Harris. Thank you very much.
And now our final witness, Dr. S. Stanley Young, the
Assistant Director for Bioinformatics at the National Institute
of Statistical Sciences.

STATEMENT OF DR. S. STANLEY YOUNG,

ASSISTANT DIRECTOR FOR BIOINFORMATICS,

NATIONAL INSTITUTE OF STATISTICAL SCIENCES

Dr. Young. Mr. Chairman, Mr. Harris and others, today I am
here to speak to making data sets used in papers supporting
regulation by the APA publicly available.
It is just good science to have data used in papers public.
A claim can be made. Is it plausible? If the data is not
available, then the claim is effectively ``trust me'' science.
You might think a claim is made in a peer reviewed journal.
Surely that makes it right. Peer review only says that the work
meets the standards of the discipline, and on the face of it,
the claims are plausible. Scientists doing peer review
essentially never ask for the data set. They look for obvious
things to correct, agree or not with the claims, agree or not
that the claims make some sense.
How often do claims prove false or dramatically less
pronounced in the original paper? Ioannidis in 2005 showed that
for medical observational studies, claims fail about 80 percent
of the time. I have kept an informal count of claims coming
from medical observational studies and then tested in
randomized clinical trials. Over 90 percent of the claims have
failed to replicate. Yes, 90 percent failure rate. I refer you
to a recent paper that covers these findings, Karr and Young,
2011.
There are a number of technical systems and reasons for the
high failure rate, which I will not deal with here. I will say
that the work of Congress and the work of regulatory agencies
often depend on valid science. With the best of intentions and
incorrect scientific claims, you can make spectacularly bad
decisions.
To give a historical medical example, two very large
observational studies made the claim that vitamin E will
protect against heart attacks. Several large, randomized
clinical trials did not support those claims. Hundreds of
millions of dollars were spent on the randomized clinical
trials.
My goal here is to suggest several things that can be done
to improve the situation. Any regulation that depends on
epidemiology studies, for example, formaldehyde, should make
data sets public. The ACS CPC II data set that is being relied
on for air pollution regulations should be public.
It makes sense to fund the data generation and the data
analysis separately. One group collects and stages the data and
posts it. Separate groups of scientists can be funded to
analyze the data. Other interested scientists can analyze the
data. Scientists can become vested in the claims they derive
from a data set. One group of scientists should not own a data
set.
Making efficient running of science is a good way forward.
Science is much more efficient if the scientists have access to
the data used to make claims. One scientist can make a claim
and another can say let's examine the data and see if the claim
is supported. Maybe there is a problem. For example, a Duke
University study that led to clinical trials was discovered to
have data-staging errors, just the handling of the data.
Perhaps the scientific analysis strategy is flawed. I
examined a data set where a claim was made that eating
breakfast cereal would make boy babies more likely. Examination
of the data set showed the claim was a result of a flawed
statistical analysis strategy. Evidence from medical
observational studies indicates that claims most often fail to
replicate. Environmental epidemiology studies are just as
subject to error.
On publication of a paper where research is used to--is
funded by the EPA, the data should be made public. When the EPA
proposes a regulation based on science, it should name the
papers it is depending on and should make the data sets used in
those papers publicly available. The agency should want to move
forward based on good science. Congress should want the EPA
regulations based on good science. The EPA would be more
efficient if the entire scientific process is utilized.
Congress would then depend not only on the EPA but on the
normal operating of science. Claims are more likely to be valid
and resulting policy sensible. Let normal science help in the
vetting process. Make the data sets available.
[The prepared statement of Dr. Young follows:]

Prepared Statement of Dr. S. Stanley Young,
Assistant Director for Bioinformatics,
National Institute of Statistical Sciences

I am Dr. S. Stanley Young.
I am the Assistant Director for Bioinformatics at the National
Institute of Statistical Sciences, NISS. NISS is a not-for-profit, non-
governmental statistics organization. NISS' mission is to identify,
catalyze, and foster high-impact, cross-disciplinary research involving
the statistical sciences. I am also the CEO of Omicsoft Corporation, a
company that designs software.
I graduated from North Carolina State University, BS, MES and a
Ph.D. in statistics and genetics.
I've worked in the pharmaceutical industry on all phases of pre-
clinical research, first at Eli Lilly and then at GlaxoSmithKline. I've
authored or co-authored over 60 papers and book chapters, including six
``best paper'' awards. I co-authored a highly cited book, Resampling-
Based Multiple Testing, which deals with false positives, among other
things. I have three issued patents. I conduct research in the area of
data mining.
I am a Fellow of the American Statistical Association and the
American Association for the Advancement of Science. I am an adjunct
professor of statistics at North Carolina State University, the
University of Waterloo, and the University of British Columbia.
Today I am here to speak to making data sets used in papers
supporting regulation by the EPA publicly available. It is just good
science to have data used in papers public. A claim may be made. Is it
plausible? If the data is not available, then the claim is effectively
``trust me'' science.
You might think the claim is made in a peer reviewed journal;
surely that makes it right. Peer review only says that the work meets
the standards of the discipline and that on the face of it, the claims
are plausible. Scientists doing peer review essentially never ask for
the data set; they look for obvious things to correct and agree or not
that the claims make some sense.
How often do claims prove false or dramatically less pronounced
than in the original paper? Ioannidis, 2005, showed that for medical
observational studies, claims fail about 80 percent of the time. I have
kept informal count of claims coming from medical observational studies
and then tested in randomized clinical trials. Over 90% of the claims
have failed to replicate. Yes, 90% failure rate. I refer you to a
recent paper covering these findings, Young and Karr (2011).
There are a number of technical and systems reasons for the high
failure rate, which I will not deal with here. I will say that the work
of Congress and the work of regulatory agencies often depends on valid
science. With the best of intentions and incorrect scientific claims,
you can make spectacularly bad decisions. To give a historical medical
example, two very large observational studies made the claim that
Vitamin E will protect against heart attacks.
Several very large randomized clinical trials did not support those
claims. Hundreds of millions of dollars were spent on the RCTs.
My goal here is to suggest several things that can be done to
improve the situation. Any regulation that depends on epidemiology
studies, e.g., formaldehyde, should make data public. The ACS CPS II
database that is being relied upon for air pollution regulations should
be public.
It makes sense to separately fund data generation and data analysis
separately. One group collects and stages the data and posts it.
Separate groups of scientists can be funded to analyze the data.
Interested scientists can analyze the data. Scientists can become
vested in the claims they derive from a data set. One group of
scientists should not ``own'' a data set.
Making efficient the running of science is a good way forward.
Science is much more efficient if scientists have access to the data
used to make claims. One scientist can make a claim and another can
say, let's examine the data and see if the claim is supported. Maybe
there is a problem. For example, a Duke University study that lead to
clinical trials was discovered to have data staging errors. Perhaps,
the statistical analysis strategy is flawed. I examined a data set
where a claim was made that eating breakfast cereal would make a boy
baby more likely. Examination of the data showed the claim was the
result of a flawed statistical analysis strategy. Evidence from medical
observational studies indicates that claims most often fail to
replicate. Environmental epidemiology studies are just as subject to
error.
On publication of a paper where research is funded by the EPA, the
data should be made public. When the EPA proposes a regulation based on
science, it should name the papers it is depending on, and it should
make data sets used in those papers publicly available. The agency
should want to move forward based on good science. Congress should want
the EPA regulations based on good science. The EPA would be more
efficient if the entire scientific process is utilized. Congress would
then depend not only on the EPA but the normal operating of science.
Claims are more likely to be valid and the resulting policy sensible.
Let normal science help in the vetting process. Make the data
available.

Chairman Harris. Thank you very much for your testimony,
and now we will begin the round of questions. I will recognize
myself for the first five minutes. And again, I want to thank
you all for taking the time to come here and advise the
Committee on such an important topic.
It is kind of interesting that sandwiched between the first
hearing and this hearing, we had the hearing Wednesday about
the Pavillion, Wyoming, study, which of course the ORD
participated in, and one of the things that we discovered at
the hearing was that in fact data was withheld until the night
before the hearing, certainly not an example of the
transparency I think some of you have called for.
Let me just ask, Dr. Swackhamer, the Health Effects
Institute has recently conducted retrospective accountability
research in specific instances to see if regulatory decisions
actually produce predicted health outcomes, and Doctor, you
understand that we get testimony such as, you know, gee, if we
just passed this rule or regulation, you will have 200,000 less
asthma cases and, you know, 600 million less cardiac deaths and
all the rest. My understanding is that EPA devotes a very small
portion of their R&D budget toward this kind of research, and
my interest is piqued because every single time we have had an
air pollution hearing, we have been promised that asthma
incidence would go down, and I am a physician. You know what
happened to asthma incidence in the last 30 years, that same
graph that shows that wonderful decline in air pollution over
the last 30 years? I suggest, Dr. Schnoor, that perhaps you
should graph the incidence of asthma. It has gone up over 30
years. What is the EPA doing in their R&D budget to look at
whether or not these health benefits that are claimed actually
come to pass in the magnitude that they are claimed? Because,
again, we have testimony that you have a 30:1 benefit ratio of
doing these. Well, my suggestion is, great, let us spend half a
billion dollars and we can solve our federal debt if it is a
30:1 ratio. That would be quite simple. As a scientist, I have
to believe that is an oversimplification and, I suspect, an
exaggeration. If we just look at asthma as an index case, could
you tell me whether that kind of backward-looking evaluation
would improve agency decision making?
Dr. Swackhamer. What I can tell you, Mr. Chairman, is that
I am not in charge of EPA's budget so I don't really know how
they are spending their budget in terms of these kinds of
studies.
Chairman Harris. Would you recommend the Science Advisory
Board, since the Science Advisory Board should recommend how
science is used and they use science--see, that is the thing,
and this is the crux of the matter. The policymakers, as has
been pointed out by the panel, point to science as a
justification and claimed scientific studies that claim
hundreds of thousands of less asthma cases, which appear not to
have occurred.
Dr. Swackhamer. Mr. Chairman, one of the things that we are
recommending is integrating science into decision making, and
what that means--that is kind of a fancy phrase, but what it
means is that there is a process that both the National Academy
has recommended, and now the Science Advisory Board in a draft
report is recommending, and part of that process--you know, you
look at a diagram--is to first formulate the problem, then do
the science necessary to address the problem, and then complete
the loop that you are talking about and looking at assessing
whether the fix was appropriate and making adjustments as you
go.
Chairman Harris. Well, thank you.
Dr. Swackhamer. So we are recommending to do exactly what
you are asking.
Chairman Harris. Dr. Belzer, you have criticized the EPA's
retrospective look at the overall cost of the Clean Air Act,
again, you know, this 30:1 benefit ratio. Is there a better way
to assess regulatory outcomes to maximize what are finite EPA
resources?
Dr. Belzer. Well, certainly, these estimates are done ex
ante. The estimates are done before the jury comes in. It
certainly would helpful to have retrospective analysis. I think
that is a very useful thing. I think as a general rule,
agencies don't like to do it broadly. I think the NHTSA may be
a good exception to that. They are a bunch of engineers. They
really like doing that sort of thing.
The larger problem with this set of rules is that it is EPA
that is charged by Congress with doing the retrospective review
of its own work and so I think----
Chairman Harris. I understand the implicit conflict of
interest when you are charging with looking back at whether or
not you have been effective.
Dr. Belzer. I certainly have always been effective.
Chairman Harris. I understand that.
Mr. Walls, last year the EPA announced numerous changes to
their IRIS process to respond to criticism from NAS and GAO
including the creation of a standing IRIS advisory panel. Is
the problem fixed?
Mr. Walls. Mr. Chairman, we think that the announcements
from EPA are a very good step in the right direction, but I
think we are in a situation where we really have to trust but
verify. We have to ascertain that these changes are in fact
addressing the problems that have been identified. I think
there are still some concerns, for example, of how this new SAB
committee that IRIS has established is going to work. I have
every confidence that Dr. Swackhamer and her colleagues are
committed to doing a great review of those assessments but I
question whether or not the process is really independent. I
think we have heard that EPA staff has kind of unfettered
access to the reviewers. You know, that contrasts sharply with
peer review done by the National Academy. So we are encouraged.
We will wait to see more.
Chairman Harris. Thank you very much.
I recognize the Ranking Member.
Mr. Miller. Thank you, Mr. Chairman.
Since there have been more than 30 years since ERDDAA was
reauthorized, or authorized, the scientific community has had
some time to think about it, and in preparing for reauthorizing
ERDDAA, there have been several suggestions that would improve
or suggestions for how to improve EPA research, to make it more
efficient, transparent, and even more credible. One that we
have heard repeatedly is there could be more integrated science
within the EPA, and the National Academy of Sciences has called
for a top science official. They say the lack of a top science
official is a formula for weak scientific performance in the
agency, and they suggest that Congress create a new position of
Deputy Administrator for Science and Technology with
responsibility for coordinating and overseeing agencywide
scientific policy, peer review quality assurance.
Dr. Swackhamer and everyone, what is your opinion, what is
SAB's opinion on the advantages or disadvantages of creating a
position like that? Would that make the head of ORD--creating a
deputy-level position make the head of ORD an obsolete
position? Or is it realistic to think that one person, one
position, would be able to handle the responsibility for the
large test of overseeing all of EPA's research so that we would
need both a deputy and the head of ORD?
Dr. Swackhamer. Mr. Chairman, Mr. Miller, the Science
Advisory Board has a panel right now that is drafting a report
on science integration at the agency, and one of the things
they have discussed is the need for scientific leadership
across the agency, not just ORD, which obviously has a science
leader, but to improve the leadership across the entire agency
linking the science enterprise both at the program offices and
the regional offices with the entire agency to integrate across
the whole agency. So we recognize the need for improved
integrated leadership and coordination across the agency. We
have not made a stand or made a statement or come to a
conclusion about how to implement that in terms of whether it
is a deputy or not.
Mr. Greenbaum. Just to reiterate the importance of this,
understanding that more than two-thirds of all scientists at
EPA do not work at ORD. They work in other parts of the
program, and one of the big challenges is that they are all
working at that place where they are both creating some science
but they are then involved in the interpretation of that
science. So making sure through some enhanced science
leadership, there is currently a chief science advisor, whether
that is the right mechanism or some other one, that there are
consistent procedures for transparency, for peer review and
various other things across the agency is an important factor.
Whether or not the full deputy is the right approach, as you
know, there are plusses and minuses to creating a new senior
position of that type.
Mr. Miller. There may be more opinion than there is time,
so could you state an opinion succinctly, Dr. Belzer?
Dr. Belzer. I just want to comment that this idea has come
up many times in the past. One of the things to keep in mind is
that for a Deputy Administrator for Science to be effective,
the deputy would have to have a very large staff and that staff
would have to be independent of all the program offices and
independent of ORD. So when you think about this as an idea,
think about what it takes to fully flesh it out so that it
actually has the capacity to be effective in an agency with,
what, 14,000 employees or something like that.
Mr. Miller. Dr. Schnoor, did you have an opinion?
Dr. Schnoor. Very quickly. I would agree with much of what
has been said. I am not positive that it has got to be a deputy
administrator level, but the need for coordination of science
throughout EPA, even down at the regional, I agree with
wholeheartedly, and that needs to be better coordinated.
Mr. Miller. Dr. Young?
Dr. Young. Just a quick comment. We can talk about top down
or we can talk about bottom up. Top down, you have a director.
Bottom up, if you make all the data sets available, good
decisions will start at the bottom and the top will take care
of itself.
Mr. Miller. Anyone else? Okay. I will yield back 25
seconds.
Chairman Harris. Thank you very much, and the gentleman
from California to my left is going to defer to the gentleman
from California on my right while he prepares his questions.
Anyway, I recognize Mr. McNerney from California for five
minutes.
Mr. McNerney. Thank you, Mr. Chairman. I thank my friend
from California for letting me go first.
I also want to thank the Chairman and the Majority Staff
for making what appears to be a good effort at sort of a
balanced approach to this. It is a complicated subject. The EPA
is a big organization, a lot of science going on, a lot of
money being spent, and we all want to make sure that it is done
right, that the money is effective, we don't make regulations
that cause more problems than they solve, and so I really
welcome the witnesses and the hearing.
My first question goes to Dr. Belzer. In your testimony,
you stated and made a point that the EPA should be free from
politicization. I think everybody would agree with that. There
should be some policing of the agency to make sure there is a
good boundary between science and policy. My question to you
is, what about industry? Should industry have the same
standards that draws a boundary between science and policy, or
should industry be able to just run roughshod over policy and
any decisions that are being made here in Washington?
Dr. Belzer. I don't see any reason why there would be any
difference with respect to science. The issue--I don't think
industry makes regulatory decisions. It is a little bit
different for government. It has certain responsibilities that
exceed those of all the interest groups that feed into it.
Transparency in science and effective peer review are probably
the very best tools available for dealing with problems like
scientization or politicization. I think that that is the best
that we can do and it should be applied to everyone. I like the
idea of having more and more competition, more and more people
playing in this and participating and doing research, and let
the best research win.
Mr. McNerney. Well, I think you said the right word, the
transparency. If we could make sure that industry is
transparent in their impact on policy, then I think we would be
a lot better off.
Mr. Greenbaum, thank you for your input this morning. In
your testimony, one of the things that was disturbing is that
you mentioned scientists are hesitant about getting involved in
the controversial policies with the EPA or involving EPA
reviewing. Could you give us some clue as to how we could
better that situation?
Mr. Greenbaum. Yeah, and I tried to make it very clear. I
know that the Science Advisory Board goes out of its way to try
and recruit a wide range of scientists, but if you do look at
the rosters of people who are willing, for example, to join
panels at the National Research Council and the group that is
at EPA, is not a complete overlap. There are people who are
hesitant to become involved because of the public scrutiny that
comes in, the criticism, sometimes unfair, that comes in, and
the time involved, and I think you need to reach out. It is
particularly important to reach out beyond the immediate
people, for example, who are only doing work in environment and
health. An example of that is statisticians. There are a number
of very good statisticians who have worked in the medical
arena. We recruit some of those. We are able to do that, and
sometimes because of who we are, we are able to get those
people into the academies, and I think the more you can do
that, the better off you will be because you get fresh
perspectives and new ideas. It is not a criticism. I do think
that the Science Advisory Board has tried to reach out, but
there are scientists who will hesitate to sort of put
themselves out of the frying pan and into the fire by going
right to work for----
Mr. McNerney. Do you think the peer review process is
working in terms of helping the EPA come to decisions?
Mr. Greenbaum. That is a broad statement, because peer
review applies to a lot of what the agency does, and I think it
varies across all of the various programs and others. I think
there are many cases certainly in the process by which the
science is peer reviewed, for example, in the clean air
decisions. I think that the science part of that goes extremely
well and is done as a model compared to, for example, the way
Europe sets similar standards or others. But in other areas, I
think there are more questions about exactly how that peer
review operates.
Mr. McNerney. Thank you.
Dr. Young, you made some pretty sweeping claims about the
peer review process. I have been involved in it, and you say
that most peer reviewers don't even ask for data. That is
pretty--that is a pretty blanket statement, and I again come to
the conclusion from your testimony that you don't think peer
review is sufficient. If that is the case, what do you think
would be sufficient? And do you follow those practices in your
own case? Do you follow what you think would be sufficient?
Dr. Young. I always make my data sets available unless they
are controlled by somebody else. I have made lots of data sets
available. I am very experienced with the peer review process.
I peer review for 10 or 15 different journals and I talk to a
wide range of scientists that are peer reviewers. I think my
statement is pretty accurate. The peer review of a journal
article, if a scientist is very conscientious, he may take a
day to look at a paper, he may take only a few hours. There is
no way that that person can look at the data. He is trusting
that the scientists on the other side did the work in a very
legitimate way.
Now, the other thing to say is, the 90 percent of the
papers that I have looked at where the things did not hold up,
those all came from peer reviewed journals. They came from
JAMA. They came from the New England Journal of Medicine. They
came from the best journals on the planet. Peer review does
just what I said. It is a quick look at the data. Obvious
things are fixed but the data is not looked at, and the
evidence is, it doesn't hold up, particularly in the case of
observational studies, particularly in the case of epidemiology
studies. Ninety percent of the time, the claims do not hold up,
and it is not just me. You guys are trusting that those claims
are good, and I am saying with a lot of----
Mr. McNerney. So what should be done to replace peer
reviews?
Dr. Young. Peer review replacements, I am going in
incremental steps. Make the data available. The scientific
process is that then other scientists can look at the data and
see if they reach the same conclusions. Don't rely on the peer
review system, don't rely on a few experts; rely on the entire
scientific process. And if you make the data set available,
that will come into play and eventually truth will come out.
Mr. McNerney. May I ask another question, Mr. Chairman?
Chairman Harris. We would like to get at least everybody in
before we break for votes and then decide. Do you have one
quick question?
Mr. McNerney. Well, Dr. Schnoor would like to----
Dr. Schnoor. May I just add something to what Dr. Young
said?
Chairman Harris. Sure, really quickly.
Dr. Schnoor. As a journal editor, our policy is, and most
journals, that if the data is asked for, we do give it, but I
agree with Dr. Young that often it is not asked for, for the
reasons that he has expressed.
But I would add one thing that I think is important to the
story, and that is that usually an important paper will get
eventually reproduced. Somebody will try to do that again, and
if it fails, then the literature will change. I tried to
represent that in my written testimony.
Chairman Harris. Thank you very much. I hope they allow
them to come in and try to verify the Pavillion findings.
I now recognize the gentleman from California, Mr.
Rohrabacher.
Mr. Rohrabacher. Thank you very much, Mr. Chairman, and let
me just note about the point that was just made, that I think
that we should take that very seriously, that all data should
be made available, not just conclusions that the people in
charge of a project have made about the data. When we see what
happened in the Climategate scandal, well, half of it is where
we have these scientists talking to each other about how they
are going to limit how much other people know about the data
they have collected. That is what got everybody angry, and I
know there is a group of people in the scientific community
that want to just ignore that atrocity, but it is an atrocity
when you hear a scientist talking about limiting knowledge,
limiting the availability of knowledge to other people. So now
on with my questions.
I am concerned about conflict of interest in the scientific
community, and especially in terms of the SAB and what we need
here, let me just ask, you can have a bias towards certain
businesses but you can have also biases towards certain
positions. In the academic community, we find these incredible
conflicts where some people won't even let someone be hired by
their department at a university if they disagree with them,
and so we have to consider that if someone is getting, for
example, EPA grants in order to prove something, that would
suggest that they have perhaps a bias. Let me ask Dr.
Swackhamer here on this, does SAB policy make a distinction
between the conflict of interest related to receiving federal
grants from the EPA, for example, for research and conflicts
with private industry? Shouldn't both of them be considered
prejudicial, let us say?
Dr. Swackhamer. Mr. Chairman, Mr. Rohrabacher, yes, the SAB
has a very rigorous process of looking at conflict of interest
prior to every activity, so it is not just an annual kind of
event. It is before every single activity we take on. Every
member who participates fills in a conflict of interest form
and must answer questions, not just related to financial
conflict of interest but in terms of impartiality, whether they
have made public statements on the topic, whether they have
grants related to that topic. So we actually look at the
issues, the very issues you have raised. We are actually very
sensitive to those issues.
Mr. Rohrabacher. So someone can receive EPA grants but--in
other areas but they cannot serve and exercise authority in
areas they have already received EPA grants?
Dr. Swackhamer. Well, as an example, what we do is, the SAB
does not look at individual EPA projects or individual grants.
We look at overall programming. So if an investigator gets an
EPA grant and also sits on the Science Advisory Board, if the
grant is unrelated to--that specific grant is unrelated to the
overall activity that we are reviewing, then that is not
considered a conflict. But as an example, I have a long history
of EPA funding, and we just recently reviewed the Great Lakes
Restoration Initiative study plan, and I recused myself on that
particular issue because the GLRI is such a broad program, I
felt that I did have a conflict.
Mr. Rohrabacher. Well, Mr. Walls described in his testimony
that sometimes peer reviewers are often overly deferential to
the EPA and the EPA staff. After all, especially if they are--
if the EPA is giving them a grant for something, but do you
think that insisting that EPA staff be present at such meetings
has a chilling effect? I will ask that to Mr. Walls.
Mr. Walls. Yes, Mr. Rohrabacher. We do believe that there
needs to be a higher degree of independence for the SAB in
conducting these peer reviews. I think there are some practices
within peer review in the agency and indeed across the
government that suggest some greater links between those who
are actually conducting these assessments and the peer
reviewers, so we need to have a greater degree of independence.
Mr. Rohrabacher. And Dr. Schnoor, is that the--okay. Good.
You served on the SAB Board of Science Counselors, but around
the same time you were very active in various issues. For
example, you wrote an article about hydraulic fracturing
entitled ``Regulate Baby, Regulate,'' and you also filmed a
YouTube video in which you said that all coal-powered electric
generation should be shut down. Do you think that someone who
is such an advocate as this, doesn't that represent a conflict
of interest with making--giving people advice, providing
scientific advice for the EPA?
Dr. Schnoor. Just one small correction. The issue on coal
was no new coal-fired power plants, not to shut down----
Mr. Rohrabacher. All right. Well, that is still quite an--
--
Dr. Schnoor. It is a strong statement.
Mr. Rohrabacher. It is still advocating----
Dr. Schnoor. It is a strong statement, and those are
opinion pieces, and they are labeled as opinion pieces as such,
and I do declare them in my activities on the SAB board. I do
declare them and sometimes recuse myself from an issue directly
involved----
Mr. Rohrabacher. Well, let us just note that when someone
works for an industry, yeah, we have to understand they have a
conflict of interest there, but if people, and especially in
the academic world, have made a specific advocacy, that becomes
part of their self-interest as well.
Dr. Schnoor. It is, and of course, it is out there for
everyone to see because it is freely available and published
and it is disclosed whenever those----
Mr. Rohrabacher. As long as the same standard is for
industry, that is fine.
Chairman Harris. Thank you very much.
The gentleman from New York, Mr. Tonko, is recognized for
five minutes.
Mr. Tonko. Thank you, Mr. Chair.
The Subcommittee attempts to explore the areas of
transparency, and in keeping in that vein, Dr. Belzer, your CV
indicates that you are an independent consultant. Can you
indicate for whom you consult?
Dr. Belzer. I am not prepared to reveal the identifies of
existing or past clients because they are covered by
confidentiality agreements that I am obligated to honor. I am
sorry. That is far as I could do on that.
Mr. Tonko. The agreements are confidential or your
relationship to them is confidential?
Dr. Belzer. I am not entirely sure----
Mr. Tonko. Well, confidential materials with which you are
consulting, to which you are consulting, or the groups
themselves, the clients themselves?
Dr. Belzer. I really don't know. I am not sure that I am
understanding it clearly enough, because it seems like a fine
distinction that is important to you but I don't quite follow
it. When I do things that are public or when I put my name on
something, a piece of work that I produced, then I disclose who
I did it for.
Mr. Tonko. And the Regulatory Checkbook of which you serve
as president is described as a nonprofit organization?
Dr. Belzer. It sure is.
Mr. Tonko. Who funds the Regulatory Checkbook?
Dr. Belzer. It is funded by a small number of unfortunately
too-small donations. We have done projects in the past and we
were able to engineer a large project. I bring an example
along. I have done a few things like that. But a large project
will take a lot of donors, and those are disclosed. I brought
one along. I would be happy to leave it for you. But the work
of the project is published in a scholarly journal, and it has
got, you know, complete disclosure of every organization that
funded the work. So I have done other work here. I have got
another thing recently published on the National Toxicology
Program, and that is identified who funded it. I have done work
for the government of Canada, and that is here as well and, you
know, you are welcome to have a copy of that, too.
Mr. Tonko. Dr. Swackhamer and Dr. Schnoor and Mr.
Greenbaum, you as a threesome seem to have the most experience
on this panel reviewing EPA's science, and each of you has
provided helpful suggestions to maintain or improve science at
EPA. At the same time, we do hear a lot of criticism of the
agency's science routinely. And I would like to present to
you--share with you a question and ask for a simple yes or no
answer. You can elaborate after your yes or no. With the
understanding that individual efforts may fall short of quality
goals and that things can always be improved upon, is the
science conducted, in your opinion, by the EPA generally of
poor quality?
Dr. Schnoor. I would say no, it is of good quality, but it
does vary from topic to topic, and that means that there is
always room for improvement.
Dr. Swackhamer. I believe that the answer to that is no, it
is not of poor quality. It is of good quality. At times it is
very high quality.
Mr. Tonko. Thank you.
Mr. Greenbaum?
Mr. Greenbaum. I would agree that the answer is no. I do
think that there are cases where it is of--it might almost
become poor quality, but I think also the agency has shown its
ability to learn from mistakes, for example, in the air quality
area it created an entire new database of the latest science on
air quality and health which it is using and which is available
to everybody who wants to use it to find the latest studies.
That is a place where it had been criticized in the past and it
is now doing it very well. In fact, it is a leader in the world
in that.
Mr. Tonko. Thank you, Mr. Chair. I will yield back.
Chairman Harris. We are not going to have to go to vote for
about 10 more minutes so we are going to take another five
minutes. We have agreed to divide five minutes per side. So let
me--I will start and then I will turn it over to Mr. Miller.
Dr. Schnoor, I am going to follow up a little bit about
what the Congressman from California here on my left asked
about, and that is the--when a scientist veers into personal
advocacy, writes an opinion piece called, you know, ``Regulate
Baby, Regulate,'' you have to look at--although it is an
opinion piece, I mean, I read through it. I thought it was
pretty interesting. Well, I thought it was interesting because
first of all, I think you were the editor of the journal when
you wrote the opinion piece, so that is not just kind of a Tom,
Dick and Harry writing an opinion piece, that is the editor of
the journal.
Now, I am going to use a phrase, because as a scientist,
you have to appreciate, and we brought this out at the hearing
two days ago, that a scientist uses words very specifically.
Like for instance, if you say ``likely'' that means then it
probably has, you know, more likely than not it occurred. If
you say it is the ``best supporting evidence,'' that means it
is probably not likely but it is probably the best among a wide
variety of alternatives. And by the way, these are terms that
were used in the Pavillion report. You say in your opinion
piece that for hydro fracturing causing--in addition to causing
tap water to burn, you used the word ``cause,'' a very specific
scientific word that means there is a cause and effect. You
cause it to burn. I looked through the entire literature
yesterday and I couldn't find scientific evidence that hydro
fracturing caused anybody's tap water to burn. I went back and
looked at that case in Colorado, and I am sure you reviewed
that before you wrote the word ``cause'' where in Colorado they
tested that water and found that that water that you mentioned
that comes in that Gasland film was in fact biogenic, not
thermogenic, that in fact there is overwhelming evidence that
it was not a result of gas coming from deeper sources but it
was a relative--you understand the science behind it. There is
large series--and yet you choose to use the word ``cause'' as a
scientist. Does that mean when you write an opinion piece, you
use different words than when you write a science piece? Fill
me in on this, because this blurring is a bone of contention on
our oversight at the EPA. When a scientist takes work and uses
words and then the press office uses slightly different words
and then they kind of blend these two and then you dig a little
bit, and oh, by the way, we don't want to share the data until
the night before the hearing so none of our experts have a
chance to look at it before they have a hearing. Call me
skeptical. Could you address your use of the word ``cause'' in
that article?
Dr. Schnoor. Thank you, Chairman Harris. Yes, I can. First
of all, the use of the word was in the context of the Gasland
film as having caused the----
Chairman Harris. Well, if you pardon me a second, I am
looking at the paragraph, and you said--and it is a different
paragraph. It says--it implies that hydro fracturing caused tap
water--and a home has exploded. Now, I won't even get to the
home exploding because I didn't even know about that.
Dr. Schnoor. It was in the context of referring to the
Gasland film, and also I would like to clarify that, you know,
in my job as--I did write that as Editor in Chief of
Environmental Science and Technology, one of the leading
journals in the world in environmental science and engineering,
and I wrote it--that is a part of my job actually.
Chairman Harris. Sure, and----
Dr. Schnoor. So in the----
Chairman Harris. I only have 1-1/2 minutes. Do you feel
that there is scientific evidence that would permit you to use
the word ``cause''?
Dr. Schnoor. To cause----
Chairman Harris. Yeah, that hydraulic fracturing----
Dr. Schnoor. In the context of the film----
Mr. Harris [continuing]. Caused----
Dr. Schnoor [continuing]. That is what I was talking about.
Chairman Harris. So you feel that at the time you wrote in
2010 that evidence indicated----
Dr. Schnoor. And regulate refers----
Mr. Harris [continuing]. Knowing----
Dr. Schnoor. If I could just finish answering the question,
``Regulate Baby, Regulate'' refers to a lack of regulation that
is laid out in the editorial on the oil and gas industry, which
caused the Macondo oil well spill, 200 million gallons to the
Gulf of Mexico, and has caused problems with pits, ponds and
lagoons left over from natural gas----
Chairman Harris. Sure. Well, as part of our written
questions, I am going to ask you to submit the proof of the use
of the word ``cause'' because I looked over the science. I am
convinced that the overwhelming evidence is that it didn't
cause it.
Does anyone on the panel disagree with Dr. Young's
recommendation that data used to justify regulations should be
made publicly available without any--I mean, that should be
taken for granted. Controversial data, make it publicly
available, and therefore do you think the EPA should have taken
well over two months or just about two months to release the
data associated with a highly controversial study that was a
draft report where it is the most important place to release
preliminary data, that you are asking people to suggest peer
reviewers. Does anybody disagree that they should be total data
transparency on an issue that important? Does that hand mean
you disagree?
Dr. Swackhamer. No, it doesn't, Mr. Chairman. I just wanted
to add to that.
Chairman Harris. Sure.
Dr. Swackhamer. I certainly believe that data should be
made available for peer review and that all data that goes into
making conclusions in a scientific study should be made
available, but it is important that the data be through a
quality review and that the data has been qualified assured
before it is released.
Chairman Harris. But it should have done that before you
wrote the initial draft report, right?
Dr. Swackhamer. Absolutely.
Chairman Harris. Thank you. Okay. I am talking about the
draft report. Thank you very much.
Mr. Miller, we have--they just called votes but we have
plenty of time for the five minutes or so.
Mr. Miller. Drs. Schnoor, Swackhamer and Mr. Greenbaum, Dr.
Young proposed funding data generation and data analysis
separately so one group would collect and stage the data and
post it and then a separate group of scientists with separate
funding would analyze the data. Do you agree with that
proposal?
Mr. Greenbaum. Actually, I would not agree with that,
partly because the design, the building of the database is a
fundamental scientific enterprise. It is not some rote process
by which somebody just goes out and collects data and then
makes it available so that I do think that--and we have a data
access policy, a very open data access policy since long before
the Shelby amendment. We have always assumed that the first
data collection is being done. We are funding it. People are
designing a study and then collecting the data to do it. Now,
having said that, once they have had the chance to go through
their data, make their data--analyze it, we have had a chance
to peer review that, we very strongly believe they should be
able to make that data publicly available and anybody should be
able to come in and get it, and that is what I referred to in
my testimony. We have actually put data from our studies up on
the Web. So I don't think it should be totally separate but I
do think there should be access to the underlying data
afterwards.
Mr. Miller. Okay. Succinctly, Dr. Swackhamer.
Dr. Swackhamer. I would agree very much with what you just
heard. Thank you.
Mr. Miller. Okay. Dr. Schnoor.
Dr. Schnoor. Again, the policy is that if you ask for the
data, you will get it from the journals such as ours, but I
would say that the general impression is that the person who
generated the data should be able to publish and work on it
first, so that it is a bit different than what Dr. Young is
proposing.
Mr. Miller. Dr. Young, I would be delighted to, but we just
don't have time.
I now yield the balance of my time to Mr. McNerney, my time
to Mr. McNerney.
Mr. McNerney. Well, thank you.
I think the peer process is kind of what we are talking
about here then. Apparently, from what we are hearing from the
panel this morning, most submitters do supply data with papers.
Is that your impression? I see some shaking yes and some
shaking no.
Dr. Schnoor. Actually in our journal, they do, and I think
Dr. Young agrees with that, but not every journal maybe has the
same policy.
Mr. McNerney. But what is coming out of this is that most
reviewers don't ask for the data. So, I mean, are we in a
position where we have to say if you want to review this, you
are going to have to look at the data? And I don't think that
is a viable option because aren't going to want to review
papers if you do that.
The other thing that kind of came out earlier was that
important papers are reproduced, which is actually a much
bigger step than just a peer review. If you can reproduce a
paper, you have done a lot more than just reviewing. So
requiring important papers to be reproduced, now, that is
another level of expense and delay and so on. Where can we go
that we don't have to take those kind of steps? Yes, Dr. Young.
Dr. Young. I refer you to a study that was done in the
1950s, type A personality and heart attacks. We all know it is
true, don't we? That study was replicated twice and both times
it failed. After the first replication, a learned group of
scientists got together and said the second study was wrong.
Well, when it was tried to be replicated a third time and it
was--it didn't replicate, it meant the first study itself was
wrong. So a false positive occurred in the first step, two more
steps, and it has taken 20 years and that is a legend in our
time right now. I will tell you, Congressman, you don't have to
lay back, you don't have to be cool. You can be a type A
personality and you are not going to get a heart attack.
Mr. McNerney. There aren't any type A personalities in
here. Don't worry about it.
Dr. Young. What I am saying is that if you release the data
as soon as possible, the scientific process can take over, and
we are talking about not just a correct answer but how fast you
get it. Type A personality took 20 years to overturn, and it is
still a legend, so we want it to be fast and we want----
Mr. McNerney. Let Mr. Greenbaum answer.
Mr. Greenbaum. Science is a messy business. There are
thousands and thousands of papers published every year, and
they can have a wide variety of results. They get peer
reviewed. I did note that the quality of peer review can vary
according to journals. There is a hierarchy, though, and as
papers become--first of all, as they get replicated, and I even
know of cases where EPA has funded explicit attempts,
independent attempts to replicate important results, they and
Congress and industry came to us to re-analyze some key
studies. As you get closer to key studies that are going to be
making a difference in a risk assessment or in a decision on an
ambient air quality standard, then you do need to get to the
next level of understanding what the underlying data is, what
the peer review is. I would agree with you, we cannot have
detailed re-analysis of every single paper out there or we
would have paralysis. On the other hand, when we get to the
really key studies, I think there is a higher standard, and
that is part of why HEI was set up, but we are not the only
ones. There are mechanisms for doing that.
Chairman Harris. Thank you very much. I thank the witnesses
for their valuable testimony and the Members for their
questions.
The Members of the Subcommittee may have additional
questions for the witnesses, and we will ask you to respond to
those in writing. The record will remain open for two weeks for
additional comments from Members.
The witnesses are excused with my thanks, and the hearing
is adjourned.
[Whereupon, at 11:12 a.m., the Subcommittee was adjourned.]
Appendix I

----------

Answers to Post-Hearing Questions

Answers to Post-Hearing Questions
Responses by Mr. Daniel Greenbaum,
President and Chief Executive Officer,
Health Effects Institute

Responses by Dr. Deborah L. Swackhamer,
Professor, Environmental Health Sciences,
University of Minnesota
and Chairwoman, EPA Science Advisory Board

Responses by Mr. Michael Walls,
Vice President, Regulatory and Technical Affairs,
American Chemistry Council

Responses by Dr. Richard Belzer,
President, Regulatory Checkbook

Responses by Dr. Jerald Schnoor,
Allen S. Henry Chair in Engineering,
Department of Civil and Environmental Engineering,
University of Iowa

Responses by Dr. S. Stanley Young,
Assistant Director for Bioinformatics,
National Institute of Statistical Sciences

Appendix II

----------

Additional Material for the Record

Reprint from American Journal of Entomology:
``Reproducible Epidemiologic Research''

``Deming, Data and Observational Studies,'':
Article by S. Stanley Young and Alan Karr



