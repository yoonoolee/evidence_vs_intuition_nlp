- DISINFORMATION NATION: SOCIAL MEDIA'S ROLE IN PROMOTING EXTREMISM AND MISINFORMATION

[House Hearing, 117 Congress]
[From the U.S. Government Publishing Office]

DISINFORMATION NATION: SOCIAL MEDIA'S ROLE IN PROMOTING EXTREMISM AND
MISINFORMATION

=======================================================================

VIRTUAL JOINT HEARING

BEFORE THE

SUBCOMMITTEE ON COMMUNICATIONS AND TECHNOLOGY

AND THE

SUBCOMMITTEE ON CONSUMER PROTECTION AND COMMERCE

OF THE

COMMITTEE ON ENERGY AND COMMERCE
HOUSE OF REPRESENTATIVES

ONE HUNDRED SEVENTEENTH CONGRESS

FIRST SESSION

----------

MARCH 25, 2021

----------

Serial No. 117-19

[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

Published for the use of the Committee on Energy and Commerce

govinfo.gov/committee/house-energy
energycommerce.house.gov

DISINFORMATION NATION: SOCIAL MEDIA'S ROLE IN PROMOTING EXTREMISM AND
MISINFORMATION

=======================================================================

VIRTUAL JOINT HEARING

BEFORE THE

SUBCOMMITTEE ON COMMUNICATIONS AND TECHNOLOGY

AND THE

SUBCOMMITTEE ON CONSUMER PROTECTION AND COMMERCE

OF THE

COMMITTEE ON ENERGY AND COMMERCE
HOUSE OF REPRESENTATIVES

ONE HUNDRED SEVENTEENTH CONGRESS

FIRST SESSION

__________

MARCH 25, 2021

__________

Serial No. 117-19

[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

Published for the use of the Committee on Energy and Commerce

govinfo.gov/committee/house-energy
energycommerce.house.gov
_________

U.S. GOVERNMENT PUBLISHING OFFICE

46-925 PDF               WASHINGTON : 2023

COMMITTEE ON ENERGY AND COMMERCE

FRANK PALLONE, Jr., New Jersey
Chairman
BOBBY L. RUSH, Illinois              CATHY McMORRIS RODGERS, Washington
ANNA G. ESHOO, California              Ranking Member
DIANA DeGETTE, Colorado              FRED UPTON, Michigan
MIKE DOYLE, Pennsylvania             MICHAEL C. BURGESS, Texas
JAN SCHAKOWSKY, Illinois             STEVE SCALISE, Louisiana
G. K. BUTTERFIELD, North Carolina    ROBERT E. LATTA, Ohio
DORIS O. MATSUI, California          BRETT GUTHRIE, Kentucky
KATHY CASTOR, Florida                DAVID B. McKINLEY, West Virginia
JOHN P. SARBANES, Maryland           ADAM KINZINGER, Illinois
JERRY McNERNEY, California           H. MORGAN GRIFFITH, Virginia
PETER WELCH, Vermont                 GUS M. BILIRAKIS, Florida
PAUL TONKO, New York                 BILL JOHNSON, Ohio
YVETTE D. CLARKE, New York           BILLY LONG, Missouri
KURT SCHRADER, Oregon                LARRY BUCSHON, Indiana
TONY CARDENAS, California            MARKWAYNE MULLIN, Oklahoma
RAUL RUIZ, California                RICHARD HUDSON, North Carolina
SCOTT H. PETERS, California          TIM WALBERG, Michigan
DEBBIE DINGELL, Michigan             EARL L. ``BUDDY'' CARTER, Georgia
MARC A. VEASEY, Texas                JEFF DUNCAN, South Carolina
ANN M. KUSTER, New Hampshire         GARY J. PALMER, Alabama
ROBIN L. KELLY, Illinois, Vice       NEAL P. DUNN, Florida
Chair                            JOHN R. CURTIS, Utah
NANETTE DIAZ BARRAGAN, California    DEBBBIE LESKO, Arizona
A. DONALD McEACHIN, Virginia         GREG PENCE, Indiana
LISA BLUNT ROCHESTER, Delaware       DAN CRENSHAW, Texas
DARREN SOTO, Florida                 JOHN JOYCE, Pennsylvania
TOM O'HALLERAN, Arizona              KELLY ARMSTRONG, North Dakota
KATHLEEN M. RICE, New York
ANGIE CRAIG, Minnesota
KIM SCHRIER, Washington
LORI TRAHAN, Massachusetts
LIZZIE FLETCHER, Texas
------

Professional Staff

JEFFREY C. CARROLL, Staff Director
TIFFANY GUARASCIO, Deputy Staff Director
NATE HODSON, Minority Staff Director
Subcommittee on Communications and Technology

MIKE DOYLE, Pennsylvania
Chairman
JERRY McNERNEY, California           ROBERT E. LATTA, Ohio
YVETTE D. CLARKE, New York             Ranking Member
MARC A. VEASEY, Texas                STEVE SCALISE, Louisiana
A. DONALD McEACHIN, Virginia         BRETT GUTHRIE, Kentucky
DARREN SOTO, Florida                 ADAM KINZINGER, Illinois
TOM O'HALLERAN, Arizona              GUS M. BILIRAKIS, Florida
KATHLEEN M. RICE, New York           BILL JOHNSON, Ohio
ANNA G. ESHOO, California            BILLY LONG, Missouri
G. K. BUTTERFIELD, North Carolina    RICHARD HUDSON, North Carolina
DORIS O. MATSUI, California, Vice    MARKWAYNE MULLIN, Oklahoma
Chair                            TIM WALBERG, Michigan
PETER WELCH, Vermont                 EARL L. ``BUDDY'' CARTER, Georgia
KURT SCHRADER, Oregon                JEFF DUNCAN, South Carolina
TONY CARDENAS, California            JOHN R. CURTIS, Utah
ROBIN L. KELLY, Illinois             CATHY McMORRIS RODGERS, Washington
ANGIE CRAIG, Minnesota                   (ex officio)
LIZZIE FLETCHER, Texas
FRANK PALLONE, Jr., New Jersey (ex
officio)
------

Subcommittee on Consumer Protection and Commerce

JAN SCHAKOWSKY, Illinois
Chair
BOBBY L. RUSH, Illinois              GUS M. BILIRAKIS, Florida
KATHY CASTOR, Florida                  Ranking Member
LORI TRAHAN, Massachusetts           FRED UPTON, Michigan
JERRY McNERNEY, California           ROBERT E. LATTA, Ohio
YVETTE D. CLARKE, New York           BRETT GUTHRIE, Kentucky
TONY CARDENAS, California, Vice      LARRY BUCSHON, Indiana
Chair                            NEAL P. DUNN, Florida
DEBBIE DINGELL, Michigan             GREG PENCE, Indiana
ROBIN L. KELLY, Illinois             DEBBIE LESKO, Arizona
DARREN SOTO, Florida                 KELLY ARMSTRONG, North Dakota
KATHLEEN M. RICE, New York           CATHY McMORRIS RODGERS, Washington
ANGIE CRAIG, Minnesota                   (ex officio)
LIZZIE FLETCHER, Texas
FRANK PALLONE, Jr., New Jersey (ex
officio)

C O N T E N T S

----------
Page
Hon. Mike Doyle, a Representative in Congress from the
Commonwealth of Pennsylvania, opening statement................     2
Prepared statement...........................................     4
Hon. Robert E. Latta, a Representative in Congress from the State
of Ohio, opening statement.....................................     5
Prepared statement...........................................     6
Hon. Jan Schakowsky, a Representative in Congress from the State
of Illinois, opening statement.................................     7
Prepared statement...........................................     8
Hon. Gus M. Bilirakis, a Representative in Congress from the
State of Florida, opening statement............................     9
Prepared statement...........................................    10
Hon. Frank Pallone, Jr., a Representative in Congress from the
State of New Jersey, opening statement.........................    11
Prepared statement...........................................    13
Hon. Cathy McMorris Rodgers, a Representative in Congress from
the State of Washington, opening statement.....................    14
Prepared statement...........................................    15
Hon. Anna G. Eshoo, a Representative in Congress from the State
of California, prepared statement..............................   129

Witnesses

Mark Zuckerberg, Founder, Chairman, and Chief Executive Officer,
Facebook.......................................................    17
Prepared statement...........................................    19
Answers to submitted questions \1\
Sundar Pichai, Chief Executive Officer, Alphabet.................    28
Prepared statement...........................................    30
Answers to submitted questions \1\
Jack Dorsey, Chief Executive Officer, Twitter....................    41
Prepared statement...........................................    43
Answers to submitted questions \1\

Submitted Material

Letter of March 25, 2021, from Asian Americans Advancing Justice
to Mr. Pallone, et al., submitted by Mr. Doyle.................   130
Letter of March 25, 2021, from Wade Henderson, Interim President
and Chief Executive Officer, and LaShawn Warren, Executive Vice
President for Government Affairs, Leadership Conference on
Civil and Human Rights, to Mr. Doyle, et al., submitted by Mr.
Doyle..........................................................   136
Letter of March 25, 2021, from Koustubh ``K.J.'' Bagchi, Senior
Policy Counsel, and Spandana Singh, Policy Analyst, Open
Technology Institute, and reports, ``Protecting the Vote How
Internet Platforms Are Addressing Election and Voter
Suppression-Related Misinformation and Disinformation,''
September 2020, and ``How Internet Platforms Are Combating
Disinformation and Misinformation in the Age of COVID-19,''
June 2020, to Mr. Doyle, et al., submitted by Mr. Doyle \2\

----------

\1\ The witnesses' answers to submitted questions for the record have
been retained in committee files and are available at https://
docs.house.gov/Committee/Calendar/ByEvent.aspx?EventID=111407.
\2\ The information has been retained in committee files and is
available at https://docs.house.gov/meetings/IF/IF16/20210325/111407/
HHRG-117-IF16-20210325-SD005.pdf.
Letter of March 3, 2021, from Donna N. Burns, President, NY Small
Farma Ltd., to Mr. Pallone, et al., and report, ``Creating
Opportunity and Justice with Regenerative Cannabis: A Challenge
to New York,'' December 2020, submitted by Mr. Doyle \3\
Statement of Alphabet Workers Union, March 25, 2021, submitted by
Mr. Doyle......................................................   143
Letters from David J. Johns, Executive Director, National Black
Justice Coalition, to Mr. Doyle, et al., submitted by Mr. Doyle   146
Letter of March 22, 2021, from Gurpatwant Singh Pannun, Legal
Advisor, Sikhs for Justice, to Mr. Pallone and Mrs. Rodgers,
submitted by Mr. Doyle.........................................   150
Letters of March 24, 2021, from William Tong, Attorney General of
Connecticut, to Mr. Pallone, et al., and to Jack Dorsey, Chief
Executive Officer, Twitter, Inc., and Mark Zuckerberg, Chairman
and Chief Executive Officer, Facebook, Inc., submitted by Mr.
Doyle..........................................................   152
Letter of March 24, 2021, from Arthur D. Sidney, Vice President
of Public Policy, Computer & Communications Industry
Association, to Mr. Doyle, et al., submitted by Mr. Latta......   160
Report, ``Facebook, From Election to Insurrection: How Facebook
Failed Voters and Nearly Set Democracy Aflame,'' AVAAZ,
submitted by Mr. Doyle \3\
Article of March 24, 2021, ``Why Section 230 Isn't Really a Good
Samaritan Provision,'' by Neil Fried, DigitalFrontiers
Advocacy, submitted by Mr. Latta...............................   163
Letter of March 25, 2021, from American Association of
Independent Music, et al., to Mr. Pallone, et al., submitted by
Mr. Doyle......................................................   168
Letter of March 25, 2021, from Disinfo Defense League to Mr.
Pallone, et al., submitted by Mr. Doyle........................   172
Letter of March 25, 2021, from Laurel Lehman, Policy Analyst,
Consumer Reports, et al., to Mr. Doyle, et al., submitted by
Mr. Latta......................................................   176
Report, ``The Disiniformation Dozen: Why Platforms Must Act on
Twelve Leading Online Anti-Vaxxers,'' Center for Countering
Digital Hate, submitted by Mr. Doyle \3\
Letter of March 25, 2021, from the Coalition for a Secure and
Transparent Internet to Mr. Doyle, et al., submitted by Mr.
Doyle..........................................................   184
Statement of the Sikh American Legal Defense and Education Fund,
by Kiran Kaur Gill, Executive Director, March 25, 2021,
submitted by Mr. Doyle.........................................   192
Letter of March 24, 2021, from Meenakshi Bewtra, et al., to Mr.
Pallone, et al., submitted by Mr. Doyle........................   204
Letter of January 21, 2021, from Ms. Eshoo, et al., to Sundar
Pichai, Chief Executive Officer, Google, LLC, and Susan
Wojcicki, Chief Executive Officer, YouTube, Inc., submitted by
Mr. Doyle......................................................   206
Letter of January 21, 2021, from Ms. Eshoo, et al., to Mark
Zuckerberg, Chairman and Chief Executive Officer, Facebook,
Inc., submitted by Mr. Doyle...................................   209
Letter of January 21, 2021, from Ms. Eshoo, et al., to Jack
Dorsey, Chief Executive Officer and Founder, Twitter, Inc.,
submitted by Mr. Doyle.........................................   212
Study, ``A longitudinal analysis of YouTube's promotion of
conspiracy videos,'' by Marc Faddoul, et al., March 6, 2020,
submitted by Mr. Latta.........................................   216
Letter of March 18, 2021, from John B. Hertig, President, Board
of Directors, Alliance for Safe Online Pharmacies Global, to
Mrs. Rodgers, submitted by Mr. Latta...........................   224
Statement of the Technology and Social Change Team, Harvard
Shorenstein Center, by Joan Donovan, et al., February 15, 2021,
submitted by Mr. Latta.........................................   231

----------

\3\ The information has been retained in committee files and is
available at https://docs.house.gov/Committee/Calendar/
ByEvent.aspx?EventID=111407.
Article of May 26, 2020, ``Facebook Executives Shut Down Efforts
to Make the Site Less Divisive,'' by Jeff Horwitz and Deepa
Seetharaman, Wall Street Journal, submitted by Mr. Kinzinger...   246
Article of March 17, 2021, ``FBI: Surge in Internet Crime Cost
Americans $4.2 Billion,'' by Masood Farivar, VOA News,
submitted by Mr. Latta.........................................   256
Report of the Global Research Project, National Center for
Missing & Exploited Children, ``A Global Landscape of Hotlines
Combating Child Sexual Abuse Material on the Internet and an
Assessment of Shared Challenges,'' submitted by Mr. Latta \3\
Article of June 11, 2020, ``Google Is Not Cracking Down on the
Most Dangerous Drug in America,'' by Dr. Hany Farid and Mathea
Falco, Newsweek, submitted by Mr. Latta........................   260
Article of March 11, 2021, ``How Facebook got addicted to
spreading misinformation,'' by Karen Hao, MIT Technology
Review, submitted by Mr. Latta \3\
Article of October 24 2017, ``Bill Gates and Steve Jobs Raised
Their Kids Tech-Free-And It Should've Been a Red Flag,'' by
Chris Weller, The Independent, submitted by Mr. Latta..........   267
Article of February 12, 2021, ``Inside the Making of Facebook's
Supreme Court,'' by Kate Klonick, The New Yorker, submitted by
Mr. Latta......................................................   271
Statement of the Coalition for a Safer Web, ``Proposal for a
Social Media Standards Board,'' submitted by Mr. Latta.........   282
Article of February 7, 2020, ``Tech Companies Detect a Surge in
Online Videos of Child Sexual Abuse,'' by Gabriel J.X. Dance
and Michael H. Keller, The New York Times, submitted by Mr.
Latta..........................................................   290
Article of October 5, 2020, ``Thank you for posting: Smoking's
lessons for regulating social media,'' by Joan Donovan, MIT
Technology Review, submitted by Mr. Latta......................   293
Article of January 2021, ``Who Is in Control? The Need to Rein in
Big Tech,'' by Allum Bokhari, Breitbart News, submitted by Mr.
Latta..........................................................   298
Article of December 2019, ``The Dark Psychology of Social
Networks,'' by Jonathan Haidt and Tobias Rose-Stockwell, The
Atlantic, submitted by Mr. Latta...............................   306
Article of June 23, 2020, ``Square, Jack Dorsey's Pay Service, Is
Withholding Money Merchants Say They Need,'' by Nathaniel
Popper, The New York Times, submitted by Mr. Latta.............   317
Letter of March 24, 2021, from Lauren Culbertson, Head of U.S.
Public Policy, Twitter, to Mrs. Rodgers, submitted by Mr. Latta   320
Letter of March 24, 2021, from Mark Isakowitz, Vice President,
Government Affairs and Public Policy, Google, to Mrs. Rodgers,
et al., submitted by Mr. Latta.................................   329
Letter of March 24, 2021, from Facebook, Inc., to Mrs. Rodgers,
submitted by Mr. Latta.........................................   339
Article of December 10, 2016, ``Twitter says no to law
enforcement protest policing tool,'' by T. Seppala,
engadget.com, submitted by Mr. Latta...........................   348
Letter of March 24, 2021, from Anti-Defamation League, et al., to
Mr. Pallone and Mrs. Rodgers, submitted by Mr. Cardenas........   350
Charts, youth suicide trends, submitted by Ms. Castor............   354
Report of the House Committee on Veterans' Affairs, ``Hijacking
Our Heroes: Exploiting Veterans Through Disinformation on
Social Media,'' submitted by Miss Rice \3\

----------

\3\ The information has been retained in committee files and is
available at https://docs.house.gov/Committee/Calendar/
ByEvent.aspx?EventID=111407.

DISINFORMATION NATION: SOCIAL MEDIA'S ROLE IN PROMOTING EXTREMISM AND
MISINFORMATION

----------

THURSDAY, MARCH 25, 2021

House of Representatives,
Subcommittee on Communications and Technology
joint with the
Subcommittee on Consumer Protection and Commerce,
Committee on Energy and Commerce,
Washington, DC.
The subcommittees met, pursuant to notice, at 12:01 p.m.,
via Cisco Webex online video conferencing, Hon. Michael F.
Doyle (chairman of the Subcommittee on Communications and
Technology) presiding.
Members present: Representatives Doyle, Schakowsky, Rush,
Eshoo, Butterfield, Matsui, Castor, McNerney, Welch, Clarke,
Schrader, Cardenas, Dingell, Veasey, Kelly, McEachin, Soto,
O'Halleran, Rice, Craig, Trahan, Pallone (ex officio), Latta
(Subcommittee on Communications and Technology ranking member),
Bilirakis (Subcommittee on Consumer Protection and Commerce
ranking member), Upton, Scalise, Guthrie, Kinzinger, Johnson,
Long, Bucshon, Mullin, Hudson, Walberg, Carter, Duncan, Dunn,
Curtis, Lesko, Pence, Armstrong, and Rodgers (ex officio).
Also present: Representatives Tonko, Blunt Rochester,
Schrier, Burgess, McKinley, Griffith, Crenshaw, and Joyce.
Staff present: AJ Brown, Counsel; Jeffrey C. Carroll, Staff
Director; Parul Desai, FCC Detailee; Jennifer Epperson,
Counsel; Lisa Goldman, Senior Counsel; Waverly Gordon, General
Counsel; Daniel Greene, Professional Staff Member; Tiffany
Guarascio, Deputy Staff Director; Perry Hamilton, Clerk; Alex
Hoehn-Saric, Chief Counsel, Communications and Consumer
Protection; Ed Kaczmarski, Policy Analyst; Zach Kahan, Deputy
Director, Outreach and Member Service; Jerry Leverich, Senior
Counsel; Dan Miller, Professional Staff Member; David Miller,
Counsel; Phil Murphy, Policy Coordinator; Joe Orlando, Policy
Analyst; Kaitlyn Peel, Digital Director; Tim Robinson, Chief
Counsel; Chloe Rodriguez, Clerk; Andrew Souvall, Director of
Communications, Outreach and Member Services; Sydney Terry,
Policy Coordinator; Anna Yu, Professional Staff Member; Michael
Cameron, Minority Policy Analyst, Consumer Protection and
Commerce, Energy, Environment; Nate Hodson, Minority Staff
Director; Peter Kielty, Minority General Counsel; Bijan
Koohmaraie, Minority Chief Counsel; Tim Kurth, Minority Chief
Counsel, Consumer Protection and Commerce; Kate O'Connor,
Minority Chief Counsel, Communications and Technology; and
Michael Taggart, Minority Policy Director.
Mr. Doyle. The Subcommittee on Communications and
Technology and Subcommittee on Consumer Protection and Commerce
will now come to order. Today we will be holding a joint
hearing entitled ``Disinformation Nation: Social Media's Role
in Promoting Extremism and Misinformation.''
Due to the COVID-19 public health emergency, today's
hearing is being held remotely. All Members and witnesses will
be participating via videoconferencing. As part of our hearing,
microphones will be set on mute for the purpose of eliminating
inadvertent background noise.
Members and witnesses, you will need to unmute your
microphones each time you wish to speak. Additionally, Members
will need to be visible on screen in order to be recognized.
Due to the anticipated length of this hearing, the
committee will take a 15-minute recess around 3 o'clock to
provide witnesses and Members a restroom break.
Finally, documents for the record can be sent to Ed
Kaczmarski and Joe Orlando at the email addresses we have
provided to your staff. All documents will be entered into the
record at the conclusion of the hearing.
The Chair will now recognize himself for 5 minutes.

OPENING STATEMENT OF HON. MIKE DOYLE, A REPRESENTATIVE IN
CONGRESS FROM THE COMMONWEALTH OF PENNSYLVANIA

Our Nation is drowning in disinformation driven by social
media. Platforms that were once used to share photos of kids
with grandparents are all too often havens of hate, harassment,
and division. The way I see it, there are two faces to each of
your platforms.
Facebook has Family and Friends Neighborhood, but it is
right next to the one where there is a White nationalist rally
every day. YouTube is a place where people share quirky videos,
but down the street antivaxxers, COVID deniers, QAnon
supporters, and Flat Earthers are sharing videos. Twitter
allows you to bring friends and celebrities into your home, but
also Holocaust deniers, terrorists, and worse.
Now, it would be one thing if every user chose where to go
organically, but almost everything is scripted on social media
platforms. Facebook recognizes antisocial tendencies in one
user and invites them to visit the White nationalists. YouTube
sees another user is interested in COVID-19 and autostarts an
antivax video. On Twitter, a user follows the trending
conversation never knowing it is driven by bots and coordinated
disinformation networks run by foreign agents.
Your platforms have changed how people across the planet
communicate, connect, learn, and stay informed. The power of
this technology is awesome and terrifying, and each of you has
failed to protect your users and the world from the worst
consequence of your creations.
This is the first time the three of you have appeared
before Congress since the deadly attack on the Capitol on
January 6th. That event was not just an attack on our democracy
and our electoral process, but an attack on every Member of
this committee and in the Congress.
Many of us were on the House floor and in the Capitol when
that attack occurred, and we were forced to stop our work of
certifying the election and retreat to safety, some of us
wearing gas masks and fearing for our lives. We fled as a mob
desecrated the Capitol, the House floor, and our democratic
process. People died that day, and hundreds were seriously
injured.
That attack, and the movement that motivated it, started
and was nourished on your platforms. Your platforms suggested
groups for people to join, videos they should view, and posts
they should like, driving this movement forward with terrifying
speed and efficiency.
FBI documents show that many of these individuals used your
platforms to plan, recruit, and execute this attack. According
to independent research, users on Facebook were exposed 1.1
billion times to misinformation related to the election last
year alone despite changes to your policies and claims that you
have removed election misinformation.
Our Nation is in the middle of a terrible pandemic. Nearly
550,000 Americans have lost their lives to this deadly disease,
more than any other country on the planet. And an independent
study found that on Facebook alone, that users across five
countries, including the United States, were exposed to COVID
disinformation an estimated 3.8 billion times, again despite
claims of fixes and reforms.
And now, as the Biden administration is working to
implement the American Rescue Plan and get vaccines in people's
arms, we are faced with waves of disinformation on social media
about the safety and efficacy of these shots. These vaccines
are the best chance we have to fight this virus, and the
content that your websites are still promoting, still
recommending, and still sharing is one of the biggest reasons
people are refusing the vaccine.
And things haven't changed. My staff found content on
YouTube telling people not to get vaccines, and was recommended
to similar videos. The same was true on Instagram, where it was
not only easy to find vaccine disinformation, but platforms
recommended similar post. The same thing happened on Facebook,
except they also had antivax groups to suggest as well. And
Twitter was no different. If you go to any of these
superspreader accounts that remain up despite the policies
meant to curb this antivax content, you will see this content.
Now, understand this. You can take this content down. You
can reduce division. You can fix this. But you choose not to.
We saw your platforms remove ISIS terrorist content. We saw you
tamp down on COVID misinformation at the beginning of the
pandemic. And we have seen disinformation drop when you have
promoted reliable news sources and removed serial
disinformation superspreaders from your platform. You have the
means.
But time after time, you are picking engagement and profit
over the health and safety of your users, our Nation, and our
democracy. These are serious issues, and to be honest, it seems
like you all just shrug off billion-dollar fines. Your
companies need to be held accountable. We need rules,
regulations, technical experts in government, and audit
authority of your technologies. Ours is the committee of
jurisdiction, and we will legislate to stop this. The stakes
are simply too high.
[The prepared statement of Mr. Doyle follows:]

Prepared Statement of Hon. Mike Doyle

Our Nation is drowning in disinformation driven by social
media. Platforms that were once used to share photos of kids
with grandparents are all too often havens of hate, harassment,
and division.
The way I see it, there are two faces to each of your
platforms. Facebook has the family and friends neighborhood but
it is right next to the one where there is a White nationalist
rally every day.
YouTube is a place where people share quirky videos, but
down the street, antivaxxers, COVID deniers, QAnon supporters,
and flat earthers are sharing videos. Twitter allows you to
bring friends and celebrities into your home, but also
Holocaust deniers, terrorists and worse.
Now, it would be one thing if every user chose where to go
organically, but almost everything is scripted on social media
platforms. Facebook recognizes antisocial tendencies in one
user and invites them to visit the White nationalists.
YouTube sees another user is interested in COVID-19 and
autostarts an antivax video. On Twitter a user following the
trending conversation, never knowing it is driven by bots and
coordinated disinformation networks run by foreign agents.
Your platforms have changed how people across the planet--
communicate, connect, learn, and stay informed.
The power of this technology is awesome and terrifying--and
each of you has failed to protect your users and the world from
the worst consequences of your creations.
This is the first time the three of you have appeared
before Congress since the deadly attack on the Capitol on
January 6th. That event was not just an attack on our Democracy
and our electoral process, but an attack on every member of
this committee and in the Congress.
Many of us were on the House floor and in the Capitol when
that attack occurred and we were forced to stop our work of
certifying the election--and retreat to safety--some of us
wearing gas masks and fearing for our lives.
We fled as a mob desecrated the Capitol, the House floor,
and our democratic process. People died that day, and hundreds
were seriously injured.
That attack and the movement that motivated it started and
was nourished on your platforms. Your platforms suggested
groups for people to join, videos they should view, and posts
they should like--driving this movement forward with terrifying
speed and efficiency.
FBI documents show that many of these individuals used your
platforms to plan, recruit, and execute this attack.
According to independent research, users on Facebook were
exposed 1.1 billion times to misinformation related to the
election last year alone--despite changes to your policies and
claims that you removed election misinformation.
Our Nation is in the middle of a terrible pandemic. Nearly
five hundred and fifty thousand Americans have lost their lives
to this deadly disease--more than any other country on the
planet. An independent study found that on Facebook alone,
users across five countries, including the United States, were
exposed to COVID disinformation an estimated 3.8 billion
times--again despite claims of fixes and reforms.
And now as the Biden administration is working to implement
the American Rescue Plan and get vaccines in people's arms, we
are faced with waves of disinformation on social media about
the safety and efficacy of these shots.
These vaccines are the best chance we have to fight this
virus, and the content that your websites are still promoting,
still recommending, and still sharing--is one of the biggest
reasons people are refusing the vaccine.
And things haven't changed--my staff found content on
YouTube telling people not to get vaccines and was recommended
similar videos.
The same was true on Instagram, where it was not only easy
to find vaccine disinformation--but the platform recommended
similar posts. The same thing happened on Facebook except they
also had antivax groups to suggest as well.
Twitter was no different, if you go to any of the super
spreader accounts that remain up despite policies meant to curb
antivax content, you'll see this content.
You can take down this content, you can reduce division,
you can fix this--but you choose not to.
We saw your platforms remove ISIS terrorist content; we saw
you tamp down on COVID misinformation at the beginning of the
pandemic; we have seen disinformation drop when you have
promoted reliable news sources and removed serial
disinformation super spreaders from your platforms.
You have the means, but time after time, you are picking
engagement and profit over the health and safety of your users,
our Nation, and our democracy.
These are serious issues, and to be honest--it seems like
you all just shrug off billion-dollar fines. Your companies
need to be held accountable--we need rules, regulations,
technical experts in government, and audit authority of your
technologies. Ours is the committee of jurisdiction, and we
will legislate to stop this. The stakes are simply too high.

Mr. Doyle. The Chair will now recognize Mr. Latta, ranking
member of the Subcommittee on Communications and Technology,
for 5 minutes for his opening statement.

OPENING STATEMENT OF HON. ROBERT E. LATTA, A REPRESENTATIVE IN
CONGRESS FROM THE STATE OF OHIO

Mr. Latta. Well, I thank the chairman for recognizing me.
And I want to thank our witnesses for being with us today, for
a conversation that is long overdue in the Energy and Commerce
Committee. I am deeply concerned by your decisions to operate
your companies in a vague and biased manner, with little to no
accountability while using Section 230 as a shield for your
actions and their real-world consequences.
Your companies have the power to silence the President of
the United States, shut off legitimate journalism in Australia,
shut down legitimate scientific debate on a variety of issues,
dictate which articles or websites are seen by Americans when
they search the internet. When these actions are taken, users
have little to no recourse to appeal the decision--if they are
aware of your actions. In most cases, we simply don't know.
What does this mean for everyday Americans? We are all
aware of Big Tech's ever-increasing censorship of deserving
voices and their commitment to serve the radical progressive
agenda by influencing a generation of children, who are moving,
shutting down, or canceling any news, books, and even now toys,
that aren't considered woke. This is fundamentally un-American.
At a recent hearing on disinformation and extremism online,
Professor Turley, one of the Nation's foremost experts on
constitutional law, testified about the ``Little Brother
Problem,'' a problem which private entities do for the
government which it cannot legally do for itself.
As of January of this year, Google has a greater than 92
market share in search. Facebook has over 2.7 billion monthly
users. And Twitter has 187 million daily users. Your companies
have enormous control over whose ideas are seen, read, or heard
around the world. This gives you great power. And if misused,
as we have seen in recent years, your actions have a ripple
effect throughout the world that result in American voices
being removed from the marketplace of ideas.
While the Little Brother Problem of censorship is
frightening enough, other serious harms are occurring on these
platforms that affect ordinary Americans. Young American
children and teenagers are addicted--actually addicted--to
their devices and social media. This problem has been
exacerbated by the pandemic and will only get worse if children
continue to be separated from their peers and cannot learn from
their teachers in a classroom.
Your platforms are purposely designed to keep our children
hooked to their screens. The use of social media has been
linked to increased rates of depression, mental illness,
cyberbullying, and suicide among America's youth. Illegal drugs
continue to be sold online despite your previous commitment to
solve these issues.
Mr. Chairman, I do ask unanimous consent to submit a letter
from the National Association of Boards of Pharmacy for the
record.
Mr. Doyle. Without objection, so ordered.
[The information appears at the conclusion of the hearing.]
Mr. Latta. Thank you very much.
Serious problems continue to persist, and I wonder how much
you are truly dedicating to combating these actions. What
actions are you taking to educate Americans about the dangers
of using your site, especially the dangers for kids?
As ranking member of the Subcommittee on Communications and
Technology, we have oversight of any change made to Section 230
of the Communications Decency Act. Section 230 provides you
with liability protection for content moderation decisions made
in good faith. Based on recent actions, however, it is clear
that in your definition of good faith, moderation includes
censoring viewpoints you disagree with and establishing a faux
independent appeals process that doesn't make its content
moderation decisions based on American principles of free
expression. I find that highly concerning.
I look forward to today's hearing as an important step in
reconsidering the extent to which Big Tech deserves to retain
the significant liability protection. And with that, Mr.
Chairman, I yield back the balance of my time.
[The prepared statement of Mr. Latta follows:]

Prepared Statement of Hon. Robert E. Latta

Good morning to our witnesses, and welcome to this long
overdue conversation with the Energy and Commerce Committee.
I am deeply concerned by your decisions to operate your
companies in a vague and biased manner, with little to no
accountability, while using Section 230 as a shield for your
actions and their real-world consequences.
Your companies have the power to silence the President of
the United States, shut off legitimate journalism in Australia,
shut down legitimate scientific debate on a variety of issues,
and dictate which articles or websites are seen by Americans
when they search the Internet. When these actions are taken,
users have little to no recourse to appeal the decision--if
they are aware of your actions. In most cases, we simply do not
know.
What does this mean for everyday Americans?
We are all well aware of Big Tech's ever increasing
censorship of conservative voices and their commitment to serve
the radical progressive agenda by influencing a generation of
children and removing, shutting down, or canceling any news,
books, and, now, even toys that aren't considered ``woke.''
This is fundamentally un-American.
At a recent hearing on disinformation and extremism online,
Professor Turley, one of the Nation's foremost experts on
constitutional law, testified about ``the little brother
problem''--a problem in which private entities do for the
Government what it cannot legally do for itself. As of January
of this year, Google has greater than 92% market share in
search, Facebook has over 2.7 billion monthly users, and
Twitter has over 187 million daily users.
Your companies have enormous control over whose ideas are
seen, read, or heard around the world. This gives you great
power--and if misused, as we have seen in the recent years,
your actions have ripple effects throughout the world that
result in American voices being removed from the marketplace of
ideas.
While the little brother problem of censorship is
frightening enough, other serious harms are occurring on these
platforms that affect ordinary Americans.
Young American children and teenagers are addicted,
actually addicted, to their devices and social media. This
problem has been exacerbated by the pandemic and will only get
worse if children continue to be separated from their peers and
cannot learn from their teachers in a classroom.
Your platforms are purposely designed to keep our children
hooked to their screens. The use of social media has been
linked to increased rates of depression, mental illness,
cyberbullying, and suicide among America's youth. Illegal drugs
continue to be sold online despite your previous commitments to
solve these issues [Mr. Chairman, I would like to submit a
letter from the National Association Boards of Pharmacy for the
record]. Serious problems continue to persist, and I wonder how
much you are truly dedicating to combating these actions.
What actions are you taking to educate Americans about the
dangers of using your site? Especially the dangers for our
kids?
As ranking member on the Subcommittee for Communications
and Technology, we have oversight over any change made to
Section 230 of the Communications Decency Act. Section 230
provides you with liability protection for content moderation
decisions made in ``good faith.'' Based on recent actions,
however, it is clear that your definition of ``good faith''
moderation includes censoring viewpoints you disagree with and
establishing a faux independent appeals process that does not
make its content moderation decisions based on American
principles of free expression. I find that highly concerning.
I look at today's hearing as an important step in
reconsidering the extent to which Big Tech deserves to retain
their significant liability protection.
I yield back.

Mr. Doyle. Thank you. The gentleman yields back.
The Chair now recognizes Chair Schakowsky, chair of the
Subcommittee on Consumer Protection and Commerce, for 5 minutes
for her opening statement.

OPENING STATEMENT OF HON. JAN SCHAKOWSKY, A REPRESENTATIVE IN
CONGRESS FROM THE STATE OF ILLINOIS

Ms. Schakowsky. Thank you. It is a pleasure to cochair this
meeting with you.
I want to welcome our witnesses and thank them for coming.
It is not an exaggeration to say that your companies have
fundamentally and permanently transformed our very culture and
our understanding of the world. Much of this is for good, but
it is also true that our country, our democracy, even our
understanding of what is truth has been harmed by the
proliferation and dissemination of misinformation and
extremism, all of which has deeply divided us.
What our witnesses today need to take away from this
hearing is that self-regulation has come to the end of its
road, and that this democracy, this democratic--the people that
you see before you, elected by the people, is preparing to move
forth with legislation and regulation.
The regulation that we seek should not attempt to limit
constitutionally protected freedom of speech, but it must hold
platforms accountable when they are used to incite violence and
hatred or, as in the case of the COVID pandemic, spread
misinformation that costs thousands of lives.
All three of the companies that are here today run
platforms that are hotbeds of misinformation and
disinformation. And despite all the promises and new policies
to match, disinformation was rampant in the 2020 election,
especially targeting vulnerable communities. For example,
Spanish language ads run by the Trump campaign falsely accused
President Biden of being endorsed by Venezuelan President
Maduro.
The spread of disinformation fed upon itself until it
arrived at the Capitol of the United States on January 6th,
which cost five lives. The lives lost in the insurgency were
not the first cases of these platforms' failure, nor even the
worst. In 2018, Facebook admitted a genocide of the Rohingya
people in Myanmar was planned and executed on Facebook.
2020 saw the rise of coronavirus disinformation on Facebook
platforms, including the playing of the--they called it ``The
Plandemic.'' This film got 1.8 million views and 150,000 shares
before it was removed. Disinformation like ``Plandemic'' made
people skeptical of the need for vaccines and almost certainly
cost--contributed to the horrible loss of life during the
pandemic. Disinformation also hops platforms to spread viruses.
Disinformation also hops from platform to platform. ``The
Plandemic'' actually was first on YouTube before it was on
Facebook and Instagram and Twitter.
Misinformation regarding the election dropped 73 percent
across social media platforms after Twitter permanently
suspended Trump as well as--and also the Capitol insurgency and
QAnon.
But the question really is: What took so long? The
witnesses here today have demonstrated time and time again that
they do not--that self-regulation has not worked. They must be
held accountable for allowing disinformation and misinformation
to spread. And that is why I will be introducing the Online
Consumer Protection Act, which I hope will earn bipartisan
support. And thank you. I will yield back.
[The prepared statement of Ms. Schakowsky follows:]

Prepared Statement of Hon. Jan Schakowsky

I want to welcome our witnesses and thank them for coming.
It is not an exaggeration to say that your companies have
fundamentally and permanently transformed our very culture: and
our understand of the world.
Much of this is for the good, but it is also true that our
country, our democracy, even our understanding of what is
truth, has been harmed by the proliferation of disinformation,
misinformation, and extremism, all of which has deeply divided
us.
What our witnesses need to take away from this hearing is
that self-regulation has come to the end of its road, and that
this democratically elected body is prepared to move forward
with legislation and regulation.
The regulation we seek should not attempt to limit
constitutionally protected free speech, but it must hold
platforms accountable when they are used to incite violence and
hatred--or as in the case of the Covid pandemic--spread
misinformation that costs thousands of lives.
All three companies here today run platforms that are
hotbeds of misinformation and disinformation.
Despite all the promises and new policies to match,
disinformation was rampant in the 2020 election--especially
targeting vulnerable communities.
For example, Spanish language ads run by the Trump campaign
falsely claimed President Biden was endorsed by Venezuelan
President Maduro. The spread of disinformation fed upon itself
until it came to a head in the historic assault on our Capitol
and our democracy on January 6th, which cost 5 lives.
The lives lost to the Insurrection were not the first
casualties of these platforms' failures, nor are they the
worst. In 2018, Facebook admitted a genocide of the Rohingya
people in Myanmar was planned and executed on Facebook.
2020 saw the rise of coronavirus disinformation on
Facebook's platforms including the propaganda film
``Plandemic.'' This film got 1.8 million views and 150,000
shares before it was removed by Facebook.
Disinformation like ``Plandemic'' made people skeptical of
the need for vaccines and almost certainly contributed to the
horrible loss of life during the pandemic.
Disinformation also hops platforms to spread virally across
the internet. ``Plandemic'' was first posted on YouTube before
taking off on Facebook, Instagram, and Twitter.
Misinformation regarding the election dropped by 73% across
social media platforms after Twitter permanently suspended
Trump as well as accounts tied to the Capitol Insurrection and
QAnon. The question is, what took so long?
The witnesses here today have demonstrated time and again
that promises to self-regulate don't work. They must be held
accountable for allowing disinformation and misinformation to
spread across their platforms, infect our public discourse, and
threaten our democracy.
That's why I'll be introducing the Online Consumer
Protection Act, which I hope will earn bipartisan support.
Thank you, and I yield back.

Mr. Doyle. The gentlelady yields back.
The Chair now recognizes Mr. Bilirakis, ranking member for
the Subcommittee on Consumer Protection and Commerce, for 5
minutes for his opening remarks.

OPENING STATEMENT OF HON. GUS M. BILIRAKIS, A REPRESENTATIVE IN
CONGRESS FROM THE STATE OF FLORIDA

Mr. Bilirakis. Thank you, Mr. Chairman. I appreciate it.
Thank you for participating in today's hearing, all the
witnesses and the Members.
I have been thinking about this hearing since our side
first requested this hearing last year. My time in college has
provided me enough knowledge about the history of the committee
to know what the Telecommunications Act was and, importantly,
what it wasn't. Components of that law have been struck down by
the courts, while other provisions are interpreted and applied
differently than first conceived. This is all a departure from
congressional intent.
Regardless of what one thinks of whether all of the
Communications Decency Act was the right approach, the same
members that voted for Section 230 voted for that entire bill.
The statute was meant to protect our society, specifically our
children.
To our witnesses today, here lies the problem for you: You
don't want the Federal Government telling you what parts of
your company you are allowed to operate. So imagine things from
our perspective when you pick and choose what parts of the law
you want to follow.
I really do admire your ingenuity. You have created
something truly remarkable, in my opinion. But with that power,
you must also be Good Samaritans, and you have an obligation to
be stewards of your platform. If your legal department doesn't
believe you are bound to the intent of the law, I would hope
your moral compasses will.
Many of my colleagues will raise legitimate concerns about
the attack on the Capitol from January, and other colleagues
can point to what occurred in our cities last summer. These
were all incidents where social media escalated tension,
incited chaos, and bred extremism through echo chambers and
algorithms.
As a new Republican leader, quite an honor, on the commerce
protection and commerce committee--so the Consumer Protection
and Commerce committee--I have been digging into how your
companies operate. That led me to run a survey of my district
following our Big Tech hearing announcement. The conclusion is
my constituents simply don't trust you anymore.
With thousands of responses, over 82 percent say they do
not trust Big Tech to be good stewards of their platforms or
consistently enforce their policies. That includes my
constituent who told me, ``We were providing information to
local families on teen suicide risks on Facebook Livestream. It
was blocked by Facebook.''
Another constituent said she has seen countless teens be
bullied online or simply not able to process a devastating
comparison game that they are forced to deal with on social
media. Others told me they stopped using your services
altogether out of fear and distrust. One even told me they quit
social media due to treatment from your companies over their
families' Christian views.
Each one of these represents a story of how your companies
have failed people. And you will be hearing from my colleagues
with more of these stories about how Big Tech has lost its way,
highlighting a much larger problem. People want to use your
services, but they suspect your coders are designing what they
think we should see and hear by keeping us online longer than
ever, and all with the purpose to polarize or monetize us,
disregarding any consequences for the assault on our inherent
freedoms which we hold so dearly.
So I don't want to hear about how changing your current law
is going to affect startups because I have heard directly from
them, accusing you of anticompetitive tactics. None of us want
to damage entrepreneurs. What I do want to hear is what you
will do to bring our country back from the fringes and stop the
poisonous practices that drive depression, isolation, and
suicide, and instead cooperate with law enforcement to protect
our citizens.
Our kids are being lost while you say you will try to do
better, as we have heard countless time already. We need true
transparency and real change. We need, again, not empty
promises from you, and we have heard that over and over again.
The fear you should have coming into this hearing today isn't
that you are going to get upbraided by a Member of Congress. It
is that our committee knows how to get things done when we come
together. We can do this with you or without you. And we will.
Thank you, Mr. Chairman. I yield back.
[The prepared statement of Mr. Bilirakis follows:]

Prepared Statement of Hon. Gus M. Bilirakis

Thank you for participating in today's hearing. I have been
thinking about this hearing since our side first requested it
last year.
My time in Congress has provided me enough knowledge about
the history of this committee to know what the
Telecommunications Act was and importantly what it wasn't.
Components of that law have been struck by the courts,
while other provisions are interpreted and applied differently
than first conceived. This is all a departure from
Congressional intent.
Regardless of what one thinks of whether all of the
Communications Decency Act was the right approach, the same
Members that voted for Section 230 voted for that entire bill--
the statute was meant to protect our society, specifically our
kids.
To our witnesses today, here lies the problem for you. You
don't want the Federal Government telling you what parts of
your company you're allowed to operate. Imagine things from our
perspective when you pick and choose what parts of the law you
want to follow.
I really do admire your ingenuity. You have created
something truly remarkable. But with that power you must also
be Good Samaritans, and you have an obligation to be stewards
of your platform. If your legal department doesn't believe you
are bound to the intent of the law, I would hope your souls and
consciences will.
Many of my colleagues will raise legitimate concerns about
the attack on the Capitol from January, and other colleagues
can point to what occurred in our cities last summer. These
were all incidents where social media escalated tension,
incited chaos, and bred extremism through echo chambers and
algorithms.
As the new Republican leader on the Consumer Protection and
Commerce subcommittee, I have been digging into how your
companies operate. That led me to run a survey of my district
following our Big Tech hearing announcement. The conclusion is
my constituents simply don't trust you anymore. With thousands
of responses, over 82% said they do not trust Big Tech to be
good stewards of their platforms or consistently enforce their
policies. That includes my constituent who told me ``We were
providing information to local families on teen suicide risks
on Facebook Livestream, and it was blocked by Facebook.''
Another constituent said she is seeing ``countless teens be
bullied online or simply not able to process the devastating
comparison game that they are forced to deal with on social
media.'' Others told me they stopped using your services all
together out of fear and distrust, one even told me they quit
social media due to treatment from your companies over their
family's Christian views. Each one of these represents a story
of how your companies have failed people, and you'll be hearing
from my colleagues with more of these stories about how Big
Tech has lost its way, highlighting a much larger problem.
People want to use your services, but they suspect your
coders are designing what they think we should see and hear, by
keeping us online longer than ever, and all with the purpose to
polarize and monetize us, disregarding any consequences for the
assault on our inherent freedoms.
So I don't want to hear about how changing current law is
going to hurt startups, because I've heard directly from them
accusing you of anticompetitive tactics. None of us want to
damage entrepreneurs.
What I do want to hear is what you will do to bring our
country back from the fringes and stop the poisonous practices
that drive depression, isolation, and suicide, and instead
cooperate with law enforcement to protect our citizens. Our
kids are being lost while you say you will ``try to do better''
as we've heard countless times already. We need true
transparency and real change, not empty promises.
The fear you should have coming into this hearing today
isn't that you're going to get yelled at by a Member of
Congress, it's that our committee knows how to get things done
when we come together. We can do this with you or without you.
And we will.
Thank you, I yield back.

Mr. Doyle. The gentleman yields back.
The Chair now recognizes Mr. Pallone, chairman of the full
committee, for 5 minutes for his opening statement.

OPENING STATEMENT OF HON. FRANK PALLONE, Jr., A REPRESENTATIVE
IN CONGRESS FROM THE STATE OF NEW JERSEY

Mr. Pallone. Thank you, Chairman Doyle and Schakowsky, for
this very important hearing. We are here today because the
spread of disinformation and extremism has been growing online,
particularly on social media, where there are little to no
guardrails in place to stop it.
And unfortunately this disinformation and extremism doesn't
just stay online. It has real-world, often dangerous, and even
violent consequences. And the time has come to hold online
platforms accountable for their part in the rise of
disinformation and extremism.
According to a survey conducted by Pew earlier this month,
30 percent of Americans are still hesitant or simply do not
want to take the COVID-19 vaccine. On January 6, our Nation's
Capitol was violently attacked. This month, Homeland Security
Secretary Mayorkas identified domestic violent extremism as the
``greatest threat'' to the United States. And crimes against
Asian Americans have risen by nearly 150 percent since the
beginning of the COVID-19 pandemic.
Five years ago, during the 2016 Presidential elections
Facebook, Google, and Twitter were warned about--but simply
ignored--their platforms' role in spreading disinformation. And
since then the warnings have continued, but the problem has
only gotten worse.
Only after public outrage and pressure did these companies
make inadequate attempts to appease critics and lawmakers. But
despite the public rebuke, Wall Street continued to reward the
companies' strategy to promote misinformation and
disinformation by driving their stock prices even higher.
And now, despite repeated promises to seriously tackle this
crisis, Facebook, Google, and Twitter instead routinely make
minor changes to their policies in response to the public
relations crisis of the day. And they will change some
underlying internal policy that may or may not be related to
the problem. But that is it. The underlying problem remains.
So Mr. Chairman, it is now painfully clear that neither the
market nor public pressure will force these social media
companies to take the aggressive action they need to take to
eliminate disinformation and extremism from their platforms.
And, therefore, it is time for Congress and this committee to
legislate and realign these companies' incentives.
Today our laws give these companies and their leaders a
blank check to do nothing. Rather than limit the spread of
disinformation, Facebook, Google, and Twitter have created
business models that exploit the human brain's preference for
divisive content to get Americans hooked on their platform at
the expense of the public interest.
It isn't just that social media companies are allowing
disinformation to spread--it is that, in many cases, they are
actively amplifying and spreading it themselves. And fines, to
the extent they are levied at all, have simply become the cost
of doing business.
The dirty truth is that they are relying on algorithms to
purposefully promote conspiratorial, divisive, or extremist
content so they can take more money in ad dollars. And this is
because the more outrageous and extremist the content, the more
engagement and views these companies get from their users. And
more views equal more money, Mr. Chairman. That is what it is
all about, more money.
It is crucial to understand that these companies aren't
just mere bystanders--they are playing an active role in the
meteoric rise of disinformation and extremism because they make
money on it. So when a company is actually promoting this
harmful content, I question whether existing liability
protections should apply.
Members on this committee have suggested legislative
solutions and introduced bills. The committee is going to
consider all these options so that we can finally align the
interests of these companies with the interests of the public
and hold the platforms and their CEOs accountable when they
stray.
That is why you are here today, Mr. Zuckerberg, Mr. Pichai,
and Mr. Dorsey. You have failed to meaningfully change after
your platforms played a role in fomenting insurrection, in
abetting the spread the virus, and trampling Americans civil
liberties.
And while it may be true that some bad actors will shout
``Fire!'' in a crowded theater, by promoting harmful content
your platforms are handing them a megaphone to be heard in
every theater across the country and the world. Your business
model itself has become the problem.
And the time for self-regulation is over. It is time we
legislate to hold you accountable. That is what we are going to
do. And I want to thank you, Mr. Chairman, Mr. Doyle, and Ms.
Schakowsky because I know that you are very serious about
moving forward on legislation, which we will do. I promise
everyone.
Thank you, and I yield back.
[The prepared statement of Mr. Pallone follows:]

Prepared Statement of Hon. Frank Pallone, Jr.

We are here today because the spread of disinformation and
extremism has been growing online, particularly on social
media, where there are little to no guardrails in place to stop
it. And unfortunately, this disinformation and extremism
doesn't just stay online. It has real world, often dangerous
and even violent consequences. The time has come to hold online
platforms accountable for their part in the rise of
disinformation and extremism.
According to a survey conducted by Pew earlier this month,
30 percent of Americans are still hesitant or simply do not
want to take the COVID-19 vaccine. On January 6, our Nation's
Capitol was violently attacked. This month, Homeland Security
Secretary Mayorkas identified domestic violent extremism as the
``greatest threat'' to the United States. And crimes against
Asian Americans have risen by nearly 150 percent since the
beginning of the COVID-19 pandemic.
Each of these controversies and crimes have been
accelerated and amplified on social media platforms through
misinformation campaigns, the spread of hate speech, and the
proliferation of conspiracy theories.
Five years ago, during the 2016 Presidential elections,
Facebook, Google, and Twitter were warned about--but simply
ignored--their platforms' role in spreading disinformation.
Since then, the warnings have continued, but the problem has
only gotten worse. Only after public outrage and pressure, did
these companies make inadequate attempts to appease critics and
lawmakers. But despite the public rebuke, Wall Street continued
to reward the companies' strategy to promote misinformation and
disinformation by driving their stock prices even higher.
And now, despite repeated promises to seriously tackle this
crisis, Facebook, Google, and Twitter instead routinely make
minor changes to their policies in response to the public
relations crisis of the day. They will change some underlying
internal policy that may or may not be related to the problem.
But that's it. The underlying problem remains.
It is now painfully clear that neither the market nor
public pressure will force these social media companies to take
the aggressive action they need to take to eliminate
disinformation and extremism from their platforms. And,
therefore, it is time for Congress and this committee to
legislate and realign these companies' incentives to
effectively deal with disinformation and extremism.
Today, our laws give these companies, and their leaders, a
blank check to do nothing. Rather than limit the spread of
disinformation, Facebook, Google, and Twitter have created
business models that exploit the human brain's preference for
divisive content to get Americans hooked on their platform, at
the expense of the public interest. It isn't just that social
media companies are allowing disinformation to spread--it's
that, in many cases, they are actively amplifying and spreading
it themselves. Fines, to the extent they are levied at all,
have simply become the cost of doing business.
The dirty truth is that they are relying on algorithms to
purposefully promote conspiratorial, divisive, or extremist
content so they can rake in the ad dollars. This is because the
more outrageous and extremist the content, the more engagement
and views these companies get from their users. More views
equal more money.
It's crucial to understand that these companies aren't just
mere bystanders--they are playing an active role in the
meteoric rise of disinformation and extremism.
So when a company is actually promoting this harmful
content, I question whether existing liability protections
should apply.
Members on this committee have suggested legislative
solutions and introduced bills. The committee is going to
consider all these options so that we can finally align the
interests of these companies with the interests of the public
and hold the platforms, and their CEOs, accountable when they
stray.
That is why you are here today, Mr. Zuckerberg, Mr. Pichai,
and Mr. Dorsey. You have failed to meaningfully change after
your platforms played a role in fomenting insurrection, in
abetting the spread of COVID-19, and trampling Americans civil
rights.
And while it may be true that some bad actors will shout
fire in a crowded theater, by promoting harmful content, your
platforms are handing them a megaphone to be heard in every
theater across the country and the world. Your business model
itself has become the problem.
The time for self-regulation is over. It is time we
legislate to hold you accountable. With that, I yield back.

Mr. Doyle. The gentleman yields back. The Chair now
recognizes Mrs. Rodgers, the ranking member of the full
committee, for 5 minutes for her opening statement.

OPENING STATEMENT OF HON. CATHY McMORRIS RODGERS, A
REPRESENTATIVE IN CONGRESS FROM THE STATE OF WASHINGTON

Ms. Rodgers. Thank you, Mr. Chairman.
Ten years ago, when I joined Big Tech platforms, I thought
they would be a force for good. I thought that they would help
us build relationships and promote transparency in Congress. I
can testify today I was wrong. That is not what has transpired.
You have broken my trust. Yes, because you failed to promote
the battle of ideas and free speech. Yes, because you censor
political viewpoints you disagree with. Those polarizing
actions matter for democracy.
But do you know what convinced me Big Tech is a destructive
force? It is how you have abused your power to manipulate and
harm our children. Your platforms are my biggest fear as a
parent. I am a mom of three school-aged kids, and my husband
and I are fighting the Big Tech battles in our household every
day.
It is a battle for their development, a battle for their
mental health, and ultimately a battle for their safety. I have
monitored your algorithms. I have monitored where your
algorithms lead them. It is frightening. And I know that I am
not alone.
After multiple teenage suicides in my community, I reached
out to our schools and we started asking questions: What is
going on with our kids? What is making them feel so alone, so
empty and in despair? And this is what I heard over and over
again from parents, pediatricians, school administrators, and
teachers: They are all raising the alarm about social media.
A day doesn't go by that I don't talk to friends and other
parents who tell me their 14-year-old is depressed, she used to
love soccer, now they can't get her to do anything, she never
gets off her device or leaves her room. I think about a mom who
told me she can't leave her daughter alone--ever--because she
harms herself. Or the family who is recovering after almost
losing their daughter to a predator she met online.
These stories are not unique to me or eastern Washington. I
recently heard of a young college student who has lost nine
friends to suicide. This is unimaginable. The science on social
media is becoming clear. Between 2011 and 2018, rates of
depression, self-harm, suicides, and suicide attempts exploded
among American teens.
During that time, rates of teen depression increased more
than 60 percent, with a larger increase among young girls.
Between 2009 and 2015, emergency room admissions for self-harm
among 10-to-14-year-olds tripled. And suicide substantially
increased.
One study found during that time teens who use their
devices for 5 or more hours a day were 66 percent more likely
to have at least 1 suicide-related outcome compared to those
who used theirs for just 1. Other studies found that teens who
spend more time online report lower psychological well-being
and more feelings of loneliness.
Remember, our kids, the users, are the product. You, Big
Tech, are not advocates for children. You exploit and profit
off of them. Big Tech needs to be exposed and completely
transparent for what you are doing to our children so parents
like me can make informed decisions. We also expect Big Tech to
do more to protect children, because you haven't done enough.
Big Tech has failed to be good stewards of your platforms.
I have two daughters and a son with a disability. Let me be
clear: I do not want you defining what is true for them. I do
not want their future manipulated by your algorithms. I do not
want their self-worth defined by the engagement tools you built
to attract their attention. I do not want them to be in danger
from what you have created. I do not want their emotions and
vulnerabilities taken advantage of so you can make more money
and have more power.
I am sure most of my colleagues on this committee who are
parents and grandparents feel the same way. Over 20 years ago,
before we knew what Big Tech would become, Congress gave you
liability protections. I want to know: Why do you think you
still deserve those protections today? What will it take for
your business model to stop harming children? I know I speak
for millions of moms when I say we need answers, and we will
not rest until we get them.
Thank you.
[The prepared statement of Mrs. Rodgers follows:]

Prepared Statement of Hon. Cathy McMorris Rodgers

Thank you, Mr. Chairman. 10 years ago--when I joined Big
Tech platforms--I thought they would be a force for good.
I thought they would help us build relationships and
promote transparency in Congress. I can testify today, I was
wrong. That is not what has transpired. You've broken my trust.
Yes, because you've failed to promote the battle of ideas and
free speech.
Yes, because you censor political viewpoints you disagree
with. Those polarizing actions matter for democracy. But, do
you know what has convinced me Big Tech is a destructive force?
It's how you've abused your power to manipulate and harm our
children.
Your platforms are my biggest fear as a parent. I'm a mom
of three schoolaged kids. My husband and I are fighting the Big
Tech battles in our household every day. It's a battle for
their development, A battle for their mental health and--
ultimately--a battle for their safety. I've monitored where
your algorithms lead them. It's frightening. I know I'm not
alone. After multiple teenage suicides in my community, I
reached out to our schools and we started asking questions.
What's going on with our kids? What's making them feel so
alone? So empty and in despair? This is what I hear over and
over again from parents...pediatricians...school
administrators...and teachers.
They all are raising the alarm about social media. A day
doesn't go by that I don't talk to friends and other parents
who tell me: Their 14-year-old is depressed. She used to love
soccer. Now, they can't get her to do anything. She never gets
off her device or leaves her room.
I think about a mom who told me she can't leave her
daughter alone EVER because she harms herself. Or the family
who is recovering from almost losing their daughter to a
predator she met online.
These stories are not unique to me or Eastern Washington. I
recently heard of a young college student who has lost 9
friends to suicide. This is unimaginable. The science on social
media is becoming clearer.
Between 2011 and 2018, rates of depression, self-harm,
suicides, and suicide attempts exploded among American teens.
During that time, rates of teen depression increased by more
than SIXTY percent, with the larger increase among young girls.
Between 2009 and 2015, emergency room admissions for self-
harm among 10 to 14-year-old girls tripled and suicides
substantially increased.
One study found that during that time, teens who used their
devices for 5 or more hours a day were 66 percent more likely
to have at least one suicide-related outcome compared to those
who used their device for just one. Other studies have found
that teens who spend more time online report lower
psychological well-being and more feelings of loneliness.
Remember our kids--the users--are the product. You--Big
Tech--are not advocates for children. You exploit and profit
off them.
Big Tech needs to be exposed and completely transparent for
what you are doing to our children so parents like me can make
informed decisions. We also expect Big Tech to do more to
protect children because you haven't done enough. Big Tech has
failed to be good stewards of your platforms. I have two
daughters and a son with a disability.
Let me be clear, I do not want you defining what is true
for them. I do not want their future manipulated by your
algorithms. I do not want their self-worth defined by the
engagement tools you've built to own their attention. I do not
want them to be in danger from what you've created. I do not
want their emotions and vulnerabilities taken advantage of so
you can make more money and have more power.
I'm sure most of my colleagues on this committee--who are
also parents and grandparents--feel the same way. Over 20 years
ago, before we knew what Big Tech would become, Congress gave
you liability protections.
I want to know why do you think you still deserve those
protections today? What will it take for your business model to
stop harming children? I know I speak for millions of moms when
I say we need these answers and we will not rest until we get
them.
Thank you.

Mr. Doyle. I thank the gentlelady. The gentlelady yields
back.
The Chair would now like to remind Members that, pursuant
to committee rules, all Members' written opening statements
shall be made a part of the record.
I would now like to introduce our witnesses for today's
hearing and thank them all for appearing today. First we have
Mark Zuckerberg, chairman and chief executive officer of
Facebook; Sundar Pichai, chief executive officer of Google; and
Jack Dorsey, chief executive officer of Twitter.
We want to thank all three of you for joining us today. We
look forward to your testimony. Each of you will have 5 minutes
to give your opening statements.
Mr. Zuckerberg, we will start with you. You are recognized
for 5 minutes.

STATEMENTS OF MARK ZUCKERBERG, FOUNDER, CHAIRMAN, AND CHIEF
EXECUTIVE OFFICER, FACEBOOK; SUNDAR PICHAI, CHIEF EXECUTIVE
OFFICER, ALPHABET; AND JACK DORSEY, CHIEF EXECUTIVE OFFICER,
TWITTER

STATEMENT OF MARK ZUCKERBERG

Mr. Zuckerberg. Chairs Pallone, Schakowsky, and Doyle,
ranking members Rodgers, Latta, and Bilirakis, and members of
the committee, I am glad that this committee is looking at all
the ways that misinformation and disinformation show up in our
country's discourse.
There are important challenges here for our society. We
have to decide how we want to handle speech that is legal but
harmful, and who should be responsible for what people say.
Misinformation is not a new problem. It was 200 years ago that
a congressman said that a lie would travel from Maine to
Georgia while truth was still getting on its boots. And
disinformation has often been spread through traditional media
too.
But the internet gives everyone the power to communicate,
and that certainly presents unique challenges. Now, people
often says things that aren't verifiably true but that speak to
their lived experiences. I think we have to be careful
restricting that. For example, if someone feels intimidated or
discriminated against while voting, I believe that they should
be able to share their experience even if the election overall
was fair.
I don't think anyone wants a world where you can only say
things that private companies judge to be true, where every
text message, email, video, and post has to be fact-checked
before you hit send. But at the same time, we also don't want
misinformation to spread that undermines confidence in
vaccines, stops people from voting, or causes other harms.
At Facebook, we do a lot to fight misinformation. We have
removed content that could lead to imminent real-world harm. We
have built an unprecedented third-party fact-checking program,
and if something is rated false, then we have warning labels
and significantly reduce its distribution. We invest a lot in
directing billions of people to authoritative information.
The system isn't perfect. But it is the best approach that
we have found to address misinformation in line with our
country's values. It is not possible to catch every piece of
harmful content without infringing on people's freedoms in a
way that I don't think that we would be comfortable with as a
society.
Our approach was tested in 2020 when we took extraordinary
steps during an extraordinary election. We removed voting
misinformation; banned hundreds of malicious and conspiracy
networks, including QAnon; labeled posts that prematurely or
wrongly declared victory; and directed people to official
results. We labeled over 180 million posts. We directed 140
million people to our official Voting Information Center. And
we helped 4\1/2\ million people register to vote.
We did our part to secure the integrity of the election.
And then, on January 6th, President Trump gave a speech
rejecting the results and calling on people to fight. The
attack on the Capitol was an outrage, and I want to express my
sympathy to all of the Members and Capitol workers who had to
live through this disgraceful moment in our history. And I want
to express my gratitude to the Capitol police, who were on the
front lines in defense of our democracy.
I believe that the former President should be responsible
for his words, and that the people who broke the law should be
responsible for their actions. So that leaves the question of
the broader information ecosystem. And I can't speak for
everyone else--the TV channels, radio stations, news outlets,
websites, and other apps--but I can tell you what we did.
Before January 6th, we worked with law enforcement to
identify and address threats. During and after the attack, we
provided extensive support in identifying the insurrectionists
and removed posts supporting violence. We didn't catch
everything, but we made our services inhospitable to those who
might do harm. And when we feared that he would incite further
violence, we suspended the former President's account.
Now, many people are concerns that platforms can ban
leaders. I am too. I don't think that private companies should
make so many decisions like this alone. We need an accountable
process, which is why we created an independent oversight board
that can overrule our decisions. And we need democratically
agreed rules for the internet.
The reality is, our country is deeply divided right now,
and that isn't something that tech companies alone can fix.
Now, we all have a part to play in helping to turn things
around, and I think that starts with taking a hard look at how
we got here.
Now, some people say that the problem is that social
networks are polarizing us. But that is not at all clear from
the evidence or research. Polarization was rising in America
long before social networks were even invented. And it is
falling or stable in many other countries where social networks
are popular. Others claim that algorithms feed us content that
makes us angry because it is good for business, but that is not
accurate either.
I believe that the division we see today is primarily the
result of a political and media environment that drives
Americans apart. And we need to reckon with that if we are
going to make progress. I know that technology can help bring
people together. We see it every day on our platforms.
Facebook is successful because people have a deep desire to
connect and share, not to stand apart and fight. And we believe
that connectivity and togetherness are more powerful ideals
than division and discord, and that technology can be part of
the solution to the challenges our society is facing. And we
are ready to work with you to move beyond hearings and get
started on real reform. Thank you.
[The prepared statement of Mr. Zuckerberg follows:]

[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

Mr. Doyle. Thank you, Mr. Zuckerberg.
Now Mr. Pichai. You are now recognized for 5 minutes.
Mr. Pichai, are you on mute?
Mr. Pichai. Sorry. I had my volume on.

STATEMENT OF SUNDAR PICHAI

Chairman Doyle, Ranking Member Latta, Chairwoman
Schakowsky, Ranking Member Bilirakis, full committee Chair
Pallone, and full committee Ranking Member McMorris Rodgers,
and members of the committee, thank you for the opportunity to
appear before you today.
To begin, I want to express my sympathies to those who have
lost loved ones to COVID or the recent gun violence in Boulder
and Atlanta. In difficult times, we are reminded of what
connects us as Americans: the hope that we can make things
better for our families and our communities. And we at Google
are committed to that work.
I joined Google because I believed the internet was the
best way to bring the benefits of technology to more people.
Over the past three decades, we have seen how it has inspired
the best in society by expanding knowledge, powering
businesses, and providing opportunities for discovery and
connection.
I am proud that anyone can turn to Google for help, whether
they are looking for vaccine information, learning new skills
on YouTube, or using digital tools to grow their businesses. In
2020 our products helped 2 million U.S. businesses and
publishers generate $426 billion in economic activity. We are
energized by the opportunity to help people at scale and
humbled by the responsibility that comes with it.
Thousands of people at Google are focused on everything
from cyber attacks to privacy to today's topic, misinformation.
Our mission is to organize the world's information and make it
universally accessible and useful. The goal to that is
providing trustworthy content and opportunities for free
expression while combating misinformation.
It is a big challenge without easy answers. Five hundred-
plus hours of video are uploaded to YouTube every minute. And
approximately 15 percent of Google searches each day are new to
us. Eighteen months ago, no one had heard of COVID-19. Sadly,
``coronavirus'' was the top trending search last year.
Staying ahead of new challenges to keep users safe is a top
priority. We saw the importance of that on January 6th, when a
mob stormed the U.S. Capitol. Google strongly condemns these
violent acts on our democracy and mourns the lives lost.
In response, we raised up authoritative sources across our
products. On YouTube, we removed livestreams and videos that
violated our Incitement to Violence policies and began issuing
strikes to those in violation of our Presidential Elections
policy. We removed apps from the Play Store for inciting
violence and stopped ads referencing the 2020 election or the
Capitol riots as part of our Sensitive Events policy.
We were able to act quickly because we were prepared ahead
of the 2020 elections. Our reminders of how to register and
vote were viewed over 2 billion times. YouTube's election
results information panels have been viewed more than 8 billion
times.
We also worked to keep campaigns safe from by cyber attacks
and protect platforms from abuse. After the December 8 safe
harbor deadline for States to certify elections, we removed
content from YouTube that alleged widespread fraud changed the
outcome of the election.
This past year, we have also focused on providing quality
information during the pandemic. Globally, we have committed
over $550 million in ad grants for COVID-related PSAs to
governments, health organizations, and nonprofits. On YouTube,
our COVID information panels have been viewed over 400 billion
times. We also removed 850,000 videos and blocked nearly 100
million COVID-related ads throughout 2020.
Across all of this work, we strive to have transparent
policies and enforce them without regard to politics or point
of view. Our ability to provide a range of information and
viewpoints while also being able to remove this information is
possible only because of legal frameworks like Section 230. It
is foundational to the open web, which has been a powerful
force for good for so many.
I look forward to sharing more about our approach today and
working together to create a path forward for the next three
decades. Thank you.
[The prepared statement of Mr. Pichai follows:]

[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

Mr. Doyle. Thank you, Mr. Pichai.
The Chair now recognizes Mr. Dorsey for 5 minutes.

STATEMENT OF JACK DORSEY

Mr. Dorsey. Thank you, members of the Energy and Commerce
Committee and its subcommittees for the opportunity to speak
with the American people about how Twitter may be used to
spread disinformation, and our solutions. My remarks will be
brief so we can move to your questions and discussion.
In our discussion today, some of you might bring up
specific tweets or examples, and I will probably have an answer
like, ``My team will follow up with you.'' I don't think that
is useful. I would rather us focus on principles and approaches
to address these problems. I will start with ours.
We believe in free expression. We believe in free debate
and conversation to find the truth. At the same time, we must
balance that with our desire for our service not to be used to
sow confusion, division, or destruction. This makes the freedom
to moderate content critical to us.
Our process to moderate content is designed to constantly
evolve. We observe what is happening on our service. We work to
understand the ramifications. And we use that understanding to
strengthen our operations. We push ourselves to improve, based
on the best information we have.
Much of what we are likely to discuss today are entirely
new situations the world has never experienced before and in
some unique cases involved elected officials. We believe the
best way to face a big, new challenge is through narrowing the
problem to have the greatest impact.
Disinformation is a broad concept, and we needed to focus
our approach on where we saw the greatest risk if we hope to
have any impact at all. So we chose to focus on disinformation
leading to offline harm, and three categories to start:
manipulated media, public health, and civic integrity.
Many of you will have strong opinions on how effective we
are in this work. Some of you will say we are doing too much
and removing free speech rights. Some of you will say we are
not doing enough and end up causing more harm. Both points of
view are reasonable and worth exploring.
If we woke up tomorrow and decided to stop moderating
content, we would end up with a service very few people or
advertisers would want to use. Ultimately, we are running a
business, and a business wants to grow the number of customers
it serves. Enforcing policy is a business decision. Different
businesses and services will have different policies, some more
liberal than others, and we believe it is critical this variety
continues to exist. Forcing every business to behave the same
reduces innovation and individual choice and diminishes free
marketplace ideals.
If instead we woke up tomorrow and decided to ask the
government to tell us what content to take down or leave up, we
may end up with a service that couldn't be used to question the
government. This is a reality in many countries today, and is
against the right of an individual. This would also have the
effect of putting enormous resource requirements on businesses
and services, which would further entrench only those who are
able to afford it. Smaller businesses would not be able to
compete, and all activity would be centralized into very few
businesses.
So how do we resolve these two viewpoints? One way is to
create shared protocols. Social media has proven itself
important enough to be worthy of an internet protocol, one that
a company like Twitter can contribute to and compete on
creating experiences people love to use. We started work on
such a protocol, which we call Blue Sky. It intends to act as a
decentralized, open-source social media protocol not owned by
any single company or organization. Any developer around the
world can help develop it, just as any company can access its
services.
But does an open protocol address the concerns raised here?
Greater transparency is the strongest benefit. Anyone around
the world can see everything that is happening in the
newsletter, including exactly how it works. One doesn't have to
trust a company. Just look at the source code.
Second, since the base protocol is shared, it will increase
innovation around business models, recommendation algorithms,
and moderation controls, which are in the hands of individuals
rather than private companies. This will allow people to
experiment in a market-based approach. Finally, it will allow
all of us to observe, acknowledge, and address any societal
issues that arise much faster. Having more eyes on the problems
will lead to more impactful solutions that can be built
directly into this protocol, making the network far more secure
and resilient.
A decentralized, open-source protocol for social media is
our vision and work for the long term. We continue the cycle
mentioned earlier of constantly improving our approach to
content moderation in the short term. I hope our discussion
today will focus on more enduring solutions.
One final note: We are a bunch of humans with a desire to
make the world around us better for everyone living today and
those that come after us. We make mistakes in prioritization
and in execution. We commit to being open about these and doing
our best to remedy what we control.
We appreciate the enormous privilege we have in building
technologies to host some of the world's most important
conversations, and we honor the desire to create better
outcomes or everyone who interacts with them.
Thanks for your time, and I look forward to the discussion.
[The prepared statement of Mr. Dorsey follows:]

[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

Mr. Doyle. Thank you, Mr. Dorsey.
Well, we have concluded witness opening statements. At this
time we will move to Member questions. I want to make sure that
Members are aware that our witnesses are being assisted by
counsel, and during questions our witnesses may briefly mute
themselves to seek advice of counsel, which is permitted.
Each Member will have 5 minutes to start asking questions
of our witnesses. I ask everyone to please adhere to that 5-
minute rule, as we have many people that want to ask questions.
I will start by recognizing myself for 5 minutes.
Mr. Duncan. Mr. Chairman, a point of order?
Mr. Doyle. The gentleman--who is speaking?
Mr. Duncan. This is Jeff Duncan. Point of order.
Mr. Doyle. Yes, sir?
Mr. Duncan. If the witnesses are advised by counsel and we
are not swearing them in, why would they need counsel?
Mr. Doyle. In previous hearings, we have always permitted
witnesses to have counsel. Sometimes you will see them at a
hearing just leaning back and talking to their counsel before a
question. But it is allowed under our rules, and I just wanted
to make Members aware that they may mute themselves while that
is going on.
Mr. Duncan. They should be sworn in, but I yield back.
Thank you.
Mr. Doyle. OK. Gentlemen, my time is short, and I ask that
you make your responses as brief and to the point as possible.
If I ask you a yes-or-no question, I am just looking for a yes
or no. So please respond appropriately.
I want to start by asking all three of you if your platform
bears some responsibility for disseminating disinformation
related to the election and the Stop the Steal movement that
led to the attack on the Capitol. Just a yes or no answer. Mr.
Zuckerberg?
Mr. Zuckerberg. Chairman, I think our responsibility is to
build systems that can help fight----
Mr. Doyle. Mr. Zuckerberg, I just want a yes or no answer.
OK? Yes or no: Do you bear some responsibility for what
happened?
Mr. Zuckerberg. Congressman, our responsibility is to make
sure that we build effective systems to help fight the spread
of----
Mr. Doyle. OK. The gentleman's preference is not to answer
the question.
Mr. Pichai, yes or no?
Mr. Pichai. We always feel a deep sense of responsibility.
But I think we worked hard. This election effort was one of our
most substantive efforts.
Mr. Doyle. Is that a yes or a no?
Mr. Pichai. Congressman, it is a complex question. We----
Mr. Doyle. OK. We will move on.
Mr. Dorsey?
Mr. Dorsey. Yes. But you also have to take into
consideration a broad ecosystem. It is not just about the
technology platforms that are used.
Mr. Doyle. Thank you. Thank you, and I agree with that.
Mr. Zuckerberg, independent analysis has shown that despite
all the things that Facebook did during the election, users
still interacted with election misinformation roughly 1.1
billion times over the last year. The initial Stop the Steal
group started on Facebook and gained over 350,000 followers in
less than a day, faster than almost any other in your
platform's history, and they were immediately calling for
violence.
In mid-December, you stopped promoting high-quality news
outlets for election content at a time when the disinformation
was as its height. And finally, the FBI has released numerous
documents showing that many of the insurrectionists used
Facebook to coordinate and plan the attack on January 6th.
So my question is: How is it possible for you not to at
least admit that Facebook played a central role or a leading
role in facilitating the recruitment, planning, and execution
of the attack on the Capitol?
Mr. Zuckerberg. Chairman, my point is that I think that the
responsibility here lies with the people who took the actions
to break the law and take--and do the insurrection.
And secondarily, also, the people who spread that content,
including the President but others as well, with repeated
rhetoric over time saying that the election was rigged and
encouraging people to organize. I think that those people bear
the primary responsibility as well. And that was the point that
I was making.
Mr. Doyle. I understand that. But your platforms
supercharged that. You took what--a thing and magnified it. In
12 hours you got 350,000 people in your site. You gin this up.
Your algorithms make it possible to supercharge these kinds of
opinions. I think we are here because of what these platforms
enabled, how your choices put our lives and our democracy at
risk. And many of us just find it just unacceptable.
I want to ask each of you another question: Do you think
vaccines that have been approved for COVID-19 work? Just yes or
no. Do you think the vaccines that have been approved work? Mr.
Zuckerberg?
Mr. Zuckerberg. Yes.
Mr. Doyle. Mr. Pichai?
Mr. Pichai. Yes. Absolutely.
Mr. Doyle. Mr. Dorsey?
Mr. Dorsey. Yes. But I don't think we are here to discuss
our own personal opinions.
Mr. Doyle. I just want to know if you think the vaccines
work. Yes?
Mr. Dorsey. Yes. However----
Mr. Doyle. Thank you. OK. So if you think the vaccines
work, why have your companies allowed accounts that repeatedly
offend your vaccine disinformation policies to remain up? I
mean, according to report, just 12 accounts on Facebook,
Twitter, and Instagram account for 65 percent of all the
vaccine disinformation on your platforms. You are exposing tens
of millions of users to this every day. I don't have the stats
on YouTube, but my understanding is it is similar.
So my question is: Why, in the midst of a global pandemic
that has killed over half a million Americans, that you haven't
taken these accounts down that are responsible for the
preponderance of vaccine disinformation on your platforms? Will
you all commit to taking these platforms down today? Mr.
Zuckerberg?
Mr. Zuckerberg. Congressman, yes, we do have a policy
against allowing vaccine disinformation----
Mr. Doyle. Oh, I know you have a policy, but will you take
the sites down today? You still have 12 people up on your site
doing this. Will you take them down?
Mr. Zuckerberg. Congressman, I would need to look at the--
and have our team look at the exact examples to make sure they
violate the policy----
Mr. Doyle. Look at them today and get back to us tomorrow
because those still exist. We found them as early as last
night.
Mr. Pichai, how about you?
Mr. Pichai. We have removed over 850,000 videos and we----
Mr. Doyle. But have you removed them all? Do you still have
people that are spreading disinformation on your platforms?
There are about 12 superspreaders.
Mr. Pichai. We have clear policies and we take down
content. Some of the content is allowed if it is people's
personal experiences. But we definitely----
Mr. Doyle. OK. Thank you. Mr. Dorsey? I see my time is
getting expired. Mr. Dorsey? Will you take these sites down?
You got about 12 superspreaders. Will you take them down?
Mr. Dorsey. Yes. We remove everything against our policy.
Mr. Doyle. Thank you.
I see my time is expired. I will now yield to the ranking
member, Mr. Latta, for his 5 minutes.
Mr. Latta. I thank my friend for yielding.
Amanda Todd was just 15 years old when she hung herself.
Amanda met a man online who took inappropriate screenshots of
Amanda and proceeded to follow her around the internet and
harass her for years. He found her classmates on Facebook and
he would send them the picture he took of her. To cope with the
anxiety, Amanda turned to drugs and alcohol. But it became too
much for her.
Mr. Zuckerberg, clearly Ms. Todd was underage, so the photo
that was shared to harass her was illegal. Do you believe that
Facebook bears any responsibility for the role it played in her
death? Yes or no?
Mr. Zuckerberg. Sorry, I was muted. Congressman, that is
a--it is an incredibly sad story. And I think that we certainly
have a responsibility to make sure that we are building systems
that can fight and remove this kind of harmful content. In the
case of child exploitation content, we have been building
systems for a long time that use AI, and we have thousands of
people working on being able to identify this content and
remove it, and I think our systems are generally pretty
effective at this. And I think it is our responsibility to make
sure that we keep improving them.
Mr. Latta. My time--my time is pretty short, but would you
say yes or no then?
Mr. Zuckerberg. Sorry. Can you repeat that?
Mr. Latta. Well, in the question, yes or no, then? Any
responsibility?
Mr. Zuckerberg. Congressman, I believe that the
responsibility of the platform----
Mr. Latta. OK. Well, let me move on because I have got--I
am very short on time.
Do you believe that Facebook should be held accountable for
any role in her death? Yes or no?
Mr. Zuckerberg. Congressman, the responsibility that I
think platforms should have----
Mr. Latta. OK.
Mr. Zuckerberg [continuing]. Is to build effective systems
to moderate this content.
Mr. Latta. I am going to have to move on. I am going to
have to take it that you are just not responding to the
question.
Unfortunately, stories like Amanda Todd's are only becoming
more common. While we all can talk about how your platforms can
be used for good or evil, the evil seems to persevere.
Mr. Zuckerberg, you stated that you support thoughtful
changes to Section 230 to ensure that tech companies are held
accountable for certain actions that happen on their platforms,
such as child exploitation. What specific changes do you
support in Section 230?
Mr. Zuckerberg. Thanks, Congressman. I would support two
specific changes, especially for large platforms--although I
want to call out that I think for smaller platforms I think we
need to be careful about any changes that we make that remove
their immunity, because that could hurt competition. So let me
just call on these for larger platforms.
I think, first, platforms should have to issue transparency
reports that state the prevalence of content across all
different categories of harmful content, everything from child
exploitation to terrorism to incitement of violence to
intellectual property violations to pornography, whatever the
different harms are, and----
Mr. Latta. Well, let me ask real quick now: Where are those
transparency reports you are being reported to, and how often
do you think that should be going out?
Mr. Zuckerberg. Oh, Congressman, as a model, Facebook has
been doing something to this effect for every quarter, where we
report on the prevalence of each category of harmful content
and how effective our systems are at identifying that content
and removing it in advance. And I think the company should be
held accountable for having effective systems to do that
broadly.
The second change that I would propose is creating
accountability for the large platforms to have effective
systems in place to moderate and remove clearly illegal
content, so things like sex trafficking or child exploitation
or terrorist content. And I think it would be reasonable to
condition immunity for the larger platforms on having a
generally effective system in place to moderate clearly illegal
types of content.
Mr. Latta. Let me interrupt real quick because I am running
really short on time. Because I know in your testimony you are
talking about that you would--you say that platforms should not
be held liable if a particular piece of content evades its
detection.
So again, that is one of the areas when you are talking
about the transparency and also the accountability I would like
to follow up on.
Let me ask you real quick, Mr. Pichai, yes or no: Do you
agree with Mr. Zuckerberg's changes to Section 230?
Mr. Pichai. There are definitely good proposals around
transparency and accountability, which I have seen in various
legislative proposals as well, which I think are important
principles and we would certainly welcome legislative
approaches in that area.
Mr. Latta. OK. Mr. Dorsey, do you agree with Mr.
Zuckerberg? Yes or no? On the changes on 230?
Mr. Dorsey. I think the ideas around transparency are good.
I think it is going to be very hard to determine what is a
large platform and a small platform, and it may incentivize the
wrong things.
Mr. Doyle. OK. The gentleman's time is expired.
Mr. Latta. Thank you very much. My time is expired, and I
yield back.
Mr. Doyle. The Chair now recognizes Chair Schakowsky, chair
of the Subcommittee on Consumer Protection and Commerce, for 5
minutes.
Ms. Schakowsky. Thank you so much.
Mr. Zuckerberg, immediately after the Capitol insurgency,
Sheryl Sandberg did an interview in which she insisted that the
siege was largely planned on smaller platforms, that--but the
court filings actually show something quite the opposite, that
the Proud Boys and Oath Keepers used Facebook to coordinate in
real time during the siege.
And so my question for you is: Will you admit today that
Facebook groups, in particular, played a role in fomenting the
extremism that we saw and that led to the Capitol siege?
Mr. Zuckerberg. Congresswoman, thanks for the question on
this. In the comment that Sheryl made, what I believe that we
were trying to say was--and what I stand behind--is what was
widely reported at the time, that after January 6th----
Ms. Schakowsky. No. But I am sorry to interrupt, as many of
my colleagues have had to do because we only have 5 minutes.
But would you say that--and would you admit that Facebook
played a role?
Mr. Zuckerberg. Congresswoman, I think certainly there was
content on our services, and from that perspective, I think
that there is further work that we need to do to make our
services and moderation more effective.
Ms. Schakowsky. I have heard that. OK. I am going to ask
Mr. Pichai a question.
Many companies have used Section 230 as a shield to escape
consumer protection laws. And I have a bill that would actually
not protect companies that do that. And so, Mr. Pichai, would
you agree that that that would be proper use, to not allow
liability protection for those who violate consumer protection
laws?
Mr. Pichai. Congresswoman, consumer protection laws are
very important areas, like we comply with COPPA and HIPAA. I
think the right approach is to have legislation in applicable
areas and have us----
Ms. Schakowsky. OK. I am going to have to interrupt again.
Is that a yes, that if a law has been broken, a consumer
protection law, that it would not--there would not be liability
protection under Section 230 for you?
Mr. Pichai. We rely on the liability protections to
actually take strong action in, particularly, new types of
content. When the Christchurch shooting happened, within a few
minutes our teams had to make decisions about the content to
take down. That certainty is what we rely on.
But I agree with you that we should have strong consumer
protection laws and be subject to it and have agencies like the
FTC have clear oversight over those laws and how we comply with
them.
Ms. Schakowsky. Let me just ask a real--thank you--a real
yes or no, quickly. Do you think that when you take money to
run advertisements that promote disinformation, that you are
exempt from liability? Yes or no? Yes or no?
Mr. Pichai. Section 230----
Ms. Schakowsky. Mr. Zuckerberg? Yes or no?
Mr. Zuckerberg. Congresswoman, I don't know the legal
answer to that. But we don't allow misinformation in our ads.
And any ad that has been fact-checked as false, we don't allow
it to run as an ad.
Ms. Schakowsky. OK. And Mr. Dorsey?
Mr. Dorsey. Again, I also would need to review the legal
precedent for it. But we would not allow that.
Ms. Schakowsky. OK. And Mr. Pichai?
Mr. Pichai. We are subject to FTC's deceptive ad practices,
so there are statutes which apply to us. We removed over 3
billion bad ads last year alone.
Ms. Schakowsky. OK. Let me ask one more question: Do you
think that Section 230 should be expanded to trade agreements
that are being made, as happened in the U.S. trade agreement
with Mexico and Canada? Yes or no? Mr. Zuckerberg.
Mr. Zuckerberg. Congresswoman, my primary goal would be to
help update Section 230 to reflect the kind of modern reality
in what we have learned over 25 years. But that said, I do
still think that Section 230 plays a foundational role in the
development of the internet and----
Ms. Schakowsky. I hear you. But I am talking now about
trade agreements. Mr. Pichai?
Mr. Pichai. Congresswoman, I think there is value in it.
But if there are evolution of Section 230, that should apply.
And so in a flexible way, being able to do that would be good,
I think.
Ms. Schakowsky. Mr. Dorsey?
Mr. Dorsey. I don't fully understand the ramifications of
what you are suggesting. So I would have to review any----
Ms. Schakowsky. I am saying to have a liability shield that
would be international and clarify it in trade agreements. And
I think it is a bad idea.
Mr. Doyle. The gentlelady's time has expired.
Ms. Schakowsky. Thank you. I yield back.
Mr. Doyle. The Chair now recognizes Mr. Bilirakis, ranking
member of the Subcommittee on Consumer Protection and Commerce,
for 5 minutes.
Mr. Bilirakis. Thank you, Mr. Chairman. I appreciate it.
Mr. Dorsey, you have heard briefly about what I am hearing
again my district. My opening remarks, you have heard them. The
other key part with these stories that we are hearing when we
conduct these surveys is how we empower law enforcement.
In a hearing last year, we received testimony that since
2016 Twitter has intentionally curtailed sharing threat data
with law enforcement fusion centers. Here is the question: You
are well aware that on Twitter and Periscope, that traffic has
increased from bad actors seeking to groom children for
molestation, lure females into sex trafficking, sell illegal
drugs, incite violence, and even threaten to murder police
officers.
Are you willing to reinstate this cooperation, retain
evidence, and provide law enforcement the tools to protect our
most vulnerable? Yes or no?
Mr. Dorsey. Well, first, child sexual exploitation has no
place on our platform, and I don't believe that is true. We
work with local law enforcement regularly.
Mr. Bilirakis. So you are saying that this is not true,
what I am telling you? Are you willing to reinstate--reinstate;
in other words, it is not going on now--reinstate this
cooperation with law enforcement to retain evidence and provide
law enforcement the tools to protect our most vulnerable?
Mr. Dorsey. We would love to work with you in more detail
on what you are seeing. But we work with law enforcement
regularly. We have a strong partnership.
Mr. Bilirakis. So you are saying that this is not true,
what I am telling you?
Mr. Dorsey. I don't believe so. But I would love to
understand the specifics.
Mr. Bilirakis. Will you commit to doing what I am telling
you you are not doing in the future, and work with me on this?
Mr. Dorsey. We will commit to continue doing what we are
doing.
Mr. Bilirakis. And what is that? You are saying that the--
so in other words----
Mr. Dorsey. Working with the local law enforcement.
Mr. Bilirakis. OK. Well, let me go on to the next question.
But I am going to follow up with this to make sure you are
doing this. I mean, our children's lives are in jeopardy here.
Mr. Zuckerberg, we have heard you acknowledge mistakes
about your products before. There are now media reports of an
Instagram for under-13 being launched. My goodness. Between
this and YouTube Kids, you and Mr. Pichai have obviously
identified a business case for targeting this age bracket with
content, and I find that very concerning, targeting this
particular age bracket, 13 and under.
Given these free services, how exactly would you be making
money, or are you trying to monetize our children, too, and get
them addicted early? And will you be allowing your own children
to use this site with the default settings? We are talking
about, again, the site that apparently is being launched for
children 13 and under, or under 13, actually. Can you please
answer that question for me?
Mr. Zuckerberg. Congressman, we are early in thinking
through how this service would work. There is clearly a large
number of people under the age of 13 who would want to use a
service like Instagram. We currently do not allow them to do
that. I think the offer----
Mr. Bilirakis. What would be beneficial to our children to
launch this kind of service?
Mr. Zuckerberg. Well, Congressman, I think helping people
stay connected with friends and learn about different content
online is broadly positive. There are clearly issues that need
to be thought through and worked out, including how parents can
control the experience of kids, especially kids under the age
of 13. And we haven't worked through all of that yet, so we
haven't kind of formally announced the plans. But I think that
something like this could be quite helpful for a lot of people.
Mr. Bilirakis. Excuse me. OK, I will reclaim my time.
Mr. Pichai, your company has had failures to rating content
for kids. What advice would you offer your challenge here?
Mr. Pichai. Congressman, we have invested a lot in a one-
of-a-kind product, YouTube Kids. The content there is--we work
with trusted content partners. Think Sesame Street as an
example of the type of channel you would find there, science
videos and cartoons. And we take great effort to make sure----
Mr. Bilirakis. I need to reclaim my time. I have one more--
one last question for Mr. Zuckerberg.
Do you have concerns with what has appeared on your
platform hosted by YouTube? And with regard to your children,
about--in general. Do you have concerns, yes or no?
Mr. Zuckerberg. Congressman, are you asking me about
YouTube?
Mr. Bilirakis. Yes. I am asking you about YouTube.
Mr. Zuckerberg. Congressman, I use YouTube to watch
educational videos with my children, and----
Mr. Bilirakis. Do you have concerns? First, for your
children and your family personally? Do you have concerns?
Mr. Zuckerberg. Well, Congressman, my children are 5 and 3
years old. So when I watch content on YouTube with them, I am
doing it and supervising them. So in that context, no, I
haven't particularly had concerns. But I think it is important
that if anyone is building a service for kids under the age of
13 to use by themselves, that there are appropriate parental
controls.
Mr. Doyle. The gentleman's time is expired.
Mr. Bilirakis. Thank you.
Mr. Doyle. I would ask all Members to try to stick to our
5-minute rule so that we can get out of here before midnight.
The Chair will now recognize Mr. Pallone, the full
committee chair, for 5 minutes.
Mr. Pallone. Thank you, Chairman Doyle. My questions are of
Mr. Zuckerberg and Mr. Pichai. But I just want to say, after
listening to the two of you's testimony, you definitely give
the impression that you don't think that you are actively in
any way promoting this misinformation and extremism. And I
totally disagree with that.
You are not passive bystanders. You are not nonprofits or
religious organizations that are trying to do a good job for
humanity. You are making money. And the point we are trying to
make today--or at least I am--is that when you spread
disinformation, misinformation, extremism, actively promoted
and amplified, you do it because you make more money.
And so I kind of deny the basic premise of what you said.
But let me get to the questions. Let me ask Mr. Zuckerberg.
According to a May 2020 Wall Street Journal report, a Facebook
researcher concluded that Facebook's own recommendation tools
were tied to a significant rise in membership in extremist
Facebook groups in Germany. I wrote to you last month
requesting this research and related documents. I trust you
will fully cooperate with the committee's inquiry and provide
all requested documents and information.
But my question is, and please yes or no: Were you aware of
this research showing that 64 percent of the members in the
extremist Facebook groups studied joined because of Facebook's
own recommendations to join these extremist groups in Germany?
Were you aware of that, yes or no?
Mr. Zuckerberg. Congressman, this is something that we
study because we want to make sure our products----
Mr. Pallone. But I am asking whether you were aware of it.
It is a simple question. Yes or no: Were you aware of it? That
is all I am asking. Were you aware of it?
Mr. Zuckerberg. Aware at what time? After we studied that--
--
Mr. Pallone. I just asked if you were aware of it, Mr.
Zuckerberg. Yes or no? If not, I am going to assume that the
answer is yes. OK?
Mr. Zuckerberg. Congressman, I have seen the study. It was
about a----
Mr. Pallone. All right. So your answer is yes.
Mr. Zuckerberg [continuing]. Contest leading up to the
German election. And we have since----
Mr. Pallone. I appreciate that. Let me go to the final
question, which relates to that. You said yes. OK.
The troubling research I mentioned demonstrates that
Facebook was not simply allowing disinformation and extremism
to spread, it actively amplified it and spread it. This is my
point. Nonetheless, Facebook didn't permanently stop
recommending political and civil groups to the United States
until after the January 6th insurrection, years after it was
made aware of this research.
The fact that Facebook's own recommendation system helped
populate extremist groups compels us to reevaluate platforms'
liabilities. Now, back to that Wall Street Journal article.
Facebook's chief product officer, Chris Cox, championed an
internal effort to address division on Facebook and proposed a
plan that would have reduced the spread of content by
hyperactive users on the far left and far right. The article
alleges, Mr. Zuckerberg, that you personally reviewed this
proposal and approved it, but only after its effectiveness was
decreased to 80 percent.
Is that true? Yes or no, please?
Mr. Zuckerberg. Congressman, we have made a lot of measures
that--to fight this content, including----
Mr. Pallone. Did you approve it after its effectiveness was
decreased to 80 percent? Yes or no?
Mr. Zuckerberg. Congressman, I can't speak to that specific
example. But we have put in place a lot of different measures,
and I think that they are effective, including----
Mr. Pallone. Did you review the proposal and approve it?
Mr. Zuckerberg. Congressman, we do a lot of work in this
area and I review a lot of proposals and we move forward on a
lot of steps.
Mr. Pallone. It is not a difficult question. I am just
asking if you reviewed this internal proposal and you approved
it. And you won't even answer that. It is so easy to answer
that question. It is very specific.
All right. You won't answer. Right? Yes or no?
Mr. Zuckerberg. Congressman, that is not what I said. I
said I did review that in addition to many other proposals and
things that we have taken action on.
Mr. Pallone. You whether or not----
Mr. Zuckerberg. Including shutting off recommendations for
civic and political groups.
Mr. Pallone. Did you approve it with the 80 percent
decrease in effectiveness?
Mr. Zuckerberg. Congressman, I don't remember that
specifically. But we have taken a number of different----
Mr. Pallone. OK. Let me----
Mr. Zuckerberg [continuing]. Steps on this.
Mr. Pallone. Let me go to Mr. Pichai. Mr. Pichai, according
to the New York Times, YouTube's recommendation algorithm is
responsible for more than 70 percent of the time users spend on
YouTube. In fact, a former design ethicist at Google was quoted
as saying, ``If I am YouTube and I want you to watch more, I am
always going to steer you towards Crazy Town.''
Mr. Pichai, is YouTube's recommendation algorithm designed
to encourage users to stay on the site? Yes or no? Is it
designed to encourage users to stay on the site? Yes or no?
Mr. Pichai. Content responsibilities are our number one
goal, so that trumps everything.
Mr. Pallone. I am only asking--very simple--whether
YouTube's recommendation algorithm is designed to encourage
users to stay on the site. Simple question. Yes or no.
Mr. Pichai. That is not the sole goal, Congressman. That
would definitely----
Mr. Pallone. So the answer is yes. OK. So the bottom line
is, simply put, your company's bottom line compels you to
amplify extremist and dangerous content. You are not
bystanders. And what happens online doesn't stay online. It has
real-world consequences. That is why Congress has to act,
because you are not bystanders. You are encouraging this stuff.
Thank you, Mr. Chairman.
Mr. Doyle. The gentleman's time is expired.
The Chair now recognizes Ms. Rodgers, the full committee
ranking member, for 5 minutes.
Ms. Rodgers. We tragically lost a number of young people to
suicide in my community. In a 3-year period from 2013 to 2016,
the suicide rate more than doubled in Spokane County. In the
last six months, one high school lost three teens. Right now
suicide is the second-leading cause of death in the entire
State of Washington for teens 15 to 19 years old.
As I mentioned, it has led to many painful conversations
trying to find some healing for broken families and
communities. And together we have been asking, what has left
our kids with a deep sense of brokenness? Why do children,
including kids we have lost in middle school, feel so empty at
such a young, vulnerable age?
Well, some studies are confirming what parents in my
community already know: Too much time on screens and social
media is leading to loneliness and despair. And it seems to be
an accepted truth in the tech industry because what we are
hearing today: Making money is more important.
Bill Gates put a cap on screen time for his daughter. Steve
Jobs once said in a quote, ``We limit how much technology our
kids use at home.'' Mr. Zuckerberg, you have also said that
your kids--or you don't want your kids sitting in front of
screens passively consuming content.
So Mr. Zuckerberg, yes or no: Do you agree too much time in
front of screens, passively consuming content, is harmful to
children's mental health?
Mr. Zuckerberg. Congresswoman, the research that I have
seen on this suggests that if people are using computers and
social----
Ms. Rodgers. Could you answer yes or no? I am sorry. Could
you use yes or no?
Mr. Zuckerberg. I don't think that the research is
conclusive on that. But I can summarize what I have learned, if
that is helpful.
Ms. Rodgers. I will follow up at a later time because I do
know that Facebook has acknowledged that passive consumption on
your platform is leading to people feeling worse. And you said
that going from video to video is not positive. Yet Facebook is
designed to keep people scrolling. Instagram is designed to get
users to go from video to video.
So I would like to ask you, if you said earlier that you
don't want kids sitting in front of the screens passively
consuming content, and your products are designed to increase
screen time, do you currently have any limitations on your own
kids' use of your products, or how do you think that will
change as they get older?
Mr. Zuckerberg. Sure, Congresswoman. My daughters are 5 and
3, and they don't use our products. Actually, that is not
exactly true. My eldest daughter, Max, I let her use Messenger
Kids sometimes to message her cousins. But overall, the
research that we have seen is that using social apps to connect
with other people can have positive mental health benefits and
well-being benefits by helping people feel more connected and
less lonely.
Passively consuming content doesn't have those positive
benefits to well-being but isn't necessarily negative. It just
isn't as positive as connecting. And the way we design our
algorithms is to encourage meaningful social interactions. So
it is a common misconception that our teams--our goals, or even
have goals, of trying to increase the amount of time that
people spend.
The News Feed team at Facebook and the Instagram team----
Ms. Rodgers. Thank you, Mr. Zuckerberg. I do have a couple
more questions.
So do you agree that your business model and the design of
your products is to get as many people on the platform as
possible and to keep them there for as long as possible? If you
could answer yes or no, that would be great.
Mr. Zuckerberg. Congresswoman, from a mission perspective,
we want to serve everyone. But our goal is not--we don't--I
don't give our News Feed team or our Instagram team goals
around increasing the amount of time that people spend. I
believe that if we build a useful product which----
Ms. Rodgers. OK. Thank you. Thank you. We all have limited
time. I think the business model suggests that it is true.
It was mentioned earlier that you are studying extremism. I
would like to ask, yes or no, of all of you, beginning with Mr.
Zuckerberg: Has Facebook conducted any internal research as to
the effect your products are having on the mental health of our
children?
Mr. Zuckerberg. Congressman, I know that this is something
that we try to study, and I am----
Ms. Rodgers. Can you say yes or no? I am sorry.
Mr. Zuckerberg. I believe the answer is yes.
Ms. Rodgers. OK. Mr. Dorsey, has Twitter?
Mr. Dorsey. I don't believe so, but we will follow up with
you.
Ms. Rodgers. OK. Mr. Pichai, has Google conducted any
research on the effect your products are having on the mental
health of children?
Mr. Pichai. We consult widely with expert third parties on
this area, including SAMHSA and other mental health
organizations, and invest a lot of time and effort in this
area.
Ms. Rodgers. OK. I would like to see that. It sounds like
you have studied extremism. Let's get focused on our children.
Mr. Doyle. The gentlelady's time is expired.
The Chair now recognizes Mr. Rush for 5 minutes.
Bobby, you need to unmute.
There you go.
Nope, you are still muted.
Mr. Rush. I want to thank you, Mr. Chairman. We all agree
that social media sites should not be tools for stoking racial
division or exacerbating racial injustice. However, there is a
broad finding of research that demonstrates the
disproportionate effects of disinformation and White supremacy
extremism on women and people of color, especially Black
people.
We have seen, and continue to see, that too often social
media sites put their earnings before equality. Simply stated,
your corporations carelessly put profits over people.
Misinformation, outlandish conspiracy theories, and incendiary
content targeting minorities remains firmly, and social media
companies, your companies, are profiting from hate and racism
on these platforms by harnessing data and generating
advertising revenue from such content.
There is only one comparison that remotely approaches the
avarice and moral discrepancy of your companies, and that is
the slavetocracy burden of our Nation's shameful and inhumane
and most difficult dark days in the past.
This is the very reason why I ask Mr. Dorsey, I remember
you at our 2018 hearing to commit to commissioning an
independent third-party civil rights audit of Twitter. This
response at the hearing was followed up with a joint letter
from Chairman Pallone and myself confirming that commitment.
It is 3 years later, and I am still waiting, Mr. Dorsey,
for the results of that audit. Where is that audit, Mr. Dorsey?
Mr. Dorsey. Thank you. We have taken another approach,
which is to work with civil rights orgs on a regular basis. We
have regular conversations with civil rights orgs multiple
times a year.
Mr. Rush. Mr. Dorsey, where is the audit that Members of
Congress, including the chairman of the committee--where is the
audit that we asked you and you agreed to forward?
Mr. Dorsey. We don't have it. We sought a different
approach with----
Mr. Rush. I don't have it either, and I thought that you
were being very, very disingenuous. As a matter of fact, I
thought that you had lied to the committee and you should be
condemned for that. And I can't wait until we come up with
legislation that will deal with you and your cohorts in a very,
very effective way. This was nothing but an empty promise that
you made.
You haven't taken this issue seriously, and Mr. Dorsey I as
a black man in America, my experiences are different from your
experiences. This audit is very, very important to me and to
those who are similarly situated just as I am. Facebook, to
their credit, has completed an audit. And there is no reason,
simply no reason under the sun, that corporation as large as
yours should not have completed that audit.
Mr. Dorsey, has Twitter evaluated the disparate impact from
COVID-19 misinformation on the African American community, and
simply has not even attempted to identify messages to combat
COVID-19 misinformation targeted at African Americans and
emphasized reliable, trustworthy medical information?
Mr. Dorsey. Yes on both. And we review with civil rights
orgs on a regular basis. That is the solution we chose.
Mr. Doyle. The gentleman's time is expired.
The Chair now recognizes Mr. Upton for 5 minutes.
Mr. Upton. Thank you, Mr. Chairman.
As I listen to this hearing, like it or not, it sounds like
everybody on both sides of the aisle is not very happy. I think
we all believe that there is a lot of responsibility that
should be shared for some of the issues that we have raised
today by the three of you. And I would just offer--or
speculate, I guess you could say--that we are going to see some
changes in Section 230.
The President, former President Trump, vetoed a pretty big
bill, the defense bill, earlier last year over this very issue
because he wanted the total repeal and he didn't get it. But I
know that the Senate now has got some legislation that is
pending that is looking at a couple reforms. And my sense is
that we may see something here in the near future as well.
I serve as one of only two House members on the Commission
on Combating Synthetic Opioid Trafficking. It is a multi-
Federal agency. It is cochaired by David Trone in the House and
Tom Cotton in the Senate. And there is a lot of concern that we
all have, not only as parents but as community leaders across
the country, on opioids and the inability to remove illegal
offers of opioids, steroids, even fake COVID-19 vaccines. Very
troubling, I think, as we see some of these platforms push such
content to a user in real search of it.
So I guess my first question is to you, Mr. Zuckerberg. The
sale of illegal drugs on your platform does violate your
policy, yet it does remain a problem on your platforms. Can you
explain the resources that you currently have devoted to
addressing the issue and whether or not you plan to develop
more? And this is an issue that I intend to raise with the
Commission as we look forward to this in the next number of
months.
Mr. Zuckerberg. Thanks, Congressman. I think this is an
important area and a good question. We have more than a
thousand engineers who work on our what we call integrity
systems that basically are AI systems that try to help find
content that violates our policies. You are right that that
content does violate our policies. And we also have more than
35,000 people who work in content review who basically are
either responding to flags that they get from the community or
checking things that our AI systems flag for them but are
unsure about.
And this is an area--and when we are talking about
reforming Section 230--where I think it would be reasonable to
expect that large platforms, especially, build effective
systems to be able to combat and fight this kind of clearly
illegal content. I think that there will be a lot of ongoing
debate about how to handle content which people find
distasteful or maybe harmful but is legal. But in this case,
when the content is illegal, I think it is pretty reasonable to
expect that large platforms build effective systems for
moderating this.
Mr. Upton. So we saw earlier this week--of course, we don't
know all the facts on this terrible shooting in Boulder,
Colorado. It appears, at least some of the initial reports,
that the alleged shooter was in fact bullied, and I think I saw
some press reports that some of it had happened online as well.
What process do you have that would allow parents or
families to be able to pursue antibullying efforts that might
be on your platforms?
Mr. Zuckerberg. Thanks, Congressman. I think bullying is a
really important case to consider for Section 230 because,
first of all, it is horrible, and we need to fight it, and we
have policies that are against it. But it also is often the
case that bullying content is not clearly illegal.
So when we talk about needing the ability under something
like Section 230 to be able to moderate content which is not
only clearly illegal content but broader, one of the primary
examples that we have in mind is making sure that we can stop
people from bullying children. And here we work with a number
of advocacy groups. We work with law enforcement to help fight
this. This is a huge effort and part of what we do, and I think
it is extremely important.
Mr. Upton. And other than taking the approach that you
don't want to see any changes to 230, what suggestions might
you have for us as we examine this issue?
Mr. Zuckerberg. Sorry, Congressman. I am not saying that I
don't think that there should be changes. I am saying that I
think 230 still broadly is important, so I wouldn't repeal the
whole thing.
But the three changes that I have basically suggested are--
one is around transparency, that large platforms should have to
report on a regular cadence, for each category of harmful
content, how much of that harmful content they are finding and
how effective their systems are at dealing with it.
The second thing I think that we should do is hold large
platforms to a standard where they should have effective
systems for handling clearly illegal content, like opioids or
child exploitation or things like that.
And the threshold thing that I think is an important
principle is that these policies really do need to apply more
to large platforms. And I think we need to find a way to exempt
small platforms, so that way--when I was getting started with
Facebook, if we had gotten hit with a lot of lawsuits around
content, it might have been prohibitive for me to get started.
And I think none of us here want to see the next set of
platforms from being stopped from kind of being able to get
started and grow.
Mr. Doyle. The gentleman's time is expired.
The Chair now recognizes Ms. Eshoo.
Ms. Eshoo. Am I unmuted? Thank you, Mr. Chairman. And good
morning--well, it is still--we are Californians, so it is good
morning for us.
I want to start by saying that content moderation, like
removing posts or banning accounts, is about treating symptoms.
And I think that we need to treat symptoms, but I also think
that we need to address two underlying diseases. The first is
that your products amplify extremism. The second is that your
business models of targeted ads enable misinformation to thrive
because you chase user engagement at great cost to our society.
So to Mr. Pichai, last month the Anti-Defamation League
found that YouTube amplifies extremism. Scores of journalists
and researchers agree. And here is what they say happens: A
user watching an extremist video is often recommended more such
videos, slowly radicalizing the user. YouTube is not doing
enough to address recommendations, and it is why Representative
Malinowski and myself introduced the Protecting Americans from
Dangerous Algorithms Act to narrowly amend Section 230 so
courts can examine the role of algorithmic amplification that
leads to violence.
And it is also why I, along with 40 of my House colleagues,
wrote to each of you about this issue. And Mr. Chairman, I ask
that those letters be placed into the record.
[The letters appear at the conclusion of the hearing.]
Ms. Eshoo. So my question to you, Mr. Pichai, is: Are you
willing to overhaul YouTube's core recommendation engine to
correct this issue? Yes or no?
Mr. Pichai. Congresswoman, we have overhauled our
recommendation systems, and I know you have engaged on these
issues before, pretty substantially in pretty much any area.
Ms. Eshoo. Now, Mr. Pichai, yes or no, because we still
have a huge problem. And I outlined what they--are you saying
that the Anti-Defamation League doesn't know what they are
talking about? All these journalists and researchers? There is
a lot more to address. And that is why I am asking you if you
are willing to overhaul YouTube's core recommendation engine to
correct this. It is serious. It is dangerous. What more can I
say about it? Yes or no?
Mr. Pichai. Congresswoman, if I may explain, we have----
Ms. Eshoo. No. I don't have time to explain. So we--let me
just say this to the witnesses. We don't do filibuster in the
House. That is something that is done in the Senate. So a
filibuster doesn't work with us.
To Mr. Zuckerberg, your algorithms use unseemly amounts of
data to keep users on your platform because that leads to more
ad revenue. Now, businesses are in business to make money. We
all understand that. But your model has a cost to society. The
most engaging posts are often those that induce fear, anxiety,
anger, and that includes deadly, deadly misinformation.
The Center for Countering Digital Hate found that the
Explore and Suggested Posts parts of Instagram are littered
with COVID misinformation, election disinformation, and QAnon
posts. So this is dangerous, and it is why Representative
Schakowsky and I are doing a bill that is going to ban this
business model of surveillance advertising.
So are you willing to redesign your products to eliminate
your focus on addicting users to your platforms at all costs?
Yes or no?
Mr. Zuckerberg. Congresswoman, as I said before, the teams
that design our algorithm----
Ms. Eshoo. Never mind. I think--let me just say this, and I
think it is irritating all of us, and that is that no one seems
to know the word ``yes'' or the word ``no.'' Which one is it?
If you don't want to answer, just say, ``I don't want to
answer.'' So yes or no?
Mr. Zuckerberg. Congresswoman, these are nuanced issues
and----
Ms. Eshoo. OK. So I am going to say that is a no.
To Mr. Dorsey, as chairwoman of the Health Subcommittee I
think that you need to eliminate all COVID misinformation--and
not label or reduce its spread, but remove it. I looked at a
tweet this morning. Robert Kennedy, Jr., links the death of
baseball legend Hank Aaron to the COVID vaccine even though
fact-checkers debunked the story. The tweet has 9,000 retweets.
Will you take this down, and why haven't you? And also, why
haven't you banned the 12 accounts that are spewing this deadly
COVID misinformation? This could cost lives.
Mr. Dorsey. No, we won't take it down because it didn't
violate our policy. So we have a clear policy in place----
Ms. Eshoo. What kind of policy is that? Is it a policy for
misinformation?
Mr. Dorsey. No.
Mr. Doyle. The gentlelady's time is expired.
The Chair recognizes Mr. Scalise. Is Mr. Scalise here?
Mr. Scalise. Thank you.
Mr. Doyle. Ah, there we go.
Mr. Scalise. Yes. Thank you, Mr. Chairman. I want to thank
you for having this hearing. I want to thank our three
witnesses for coming as well. Clearly, you are seeing a lot of
concern being expressed by Members on both sides, both
Republican and Democrat, about the way that your social media
platforms are run, and especially as it relates to the fairness
and equal treatment of people.
I know I have had a lot of concerns, shared it with some of
you individually over the last few years about whether it is
algorithms that seem to be designed sometimes to have an
antibias against conservatives. But look, we all agree that
whether it is illegal activity, bullying, those things ought
not to be permeated through social media.
There is a big difference between stopping bullying and
violent type of social media posts versus actual censorship of
political views that you disagree with. And I want to ask my
first question to Mr. Dorsey, because there have been a lot of
concerns expressed recently about that inequal treatment. And I
will just start with the New York Post article.
I think a lot of people have seen this. This article was
censored by Twitter when it was originally sent out. This is
the New York Post, which is a newspaper that goes back to 1801,
founded by Alexander Hamilton. And for weeks, this very
credibly sourced article, right before an election, about
Hunter Biden was banned by Twitter.
And then when you contrast that, you have this Washington
Post article that was designed to misportray a conversation
between President Trump and the Georgia secretary of state that
has since been--parts of this have been debunked. And yet this
article can still be tweeted out.
I want to ask Mr. Dorsey: First of all, do you recognize
that there is this real concern that there is an
anticonservative bias on Twitter's behalf? And would you
recognize that this has to stop if this has going to be--
Twitter is going to be viewed by both sides as a place where
everybody is going to get a fair treatment?
Mr. Dorsey. We made a total mistake with the New York Post.
We corrected that within 24 hours. It was not to do with the
content. It was to do with the hacked materials policy. We had
an incorrect interpretation. we don't write policy according to
any particular political leaning. If we find any of it, we root
it out.
Mr. Scalise. So we are regarding the Washington Post----
Mr. Dorsey. We will make mistakes. We will make mistakes,
and our goal is to correct them as quickly as possible. And in
that case, we did.
Mr. Scalise. And I appreciate you recognizing that was a
mistake. However, the New York Post's entire Twitter account
was blocked for about 2 weeks where they couldn't send anything
out, not just that article. And to censor--we have got a First
Amendment too. It just seems like to censor a newspaper that is
as highly respected as the New York Post--again, 1801, founded
by Alexander Hamilton--for their entire account to be blocked
for 2 weeks by a mistake seems like a really big mistake.
Was anyone held accountable in your censoring department
for that mistake?
Mr. Dorsey. Well, we don't have a censoring department. But
I agree. Like it----
Mr. Scalise. Well, who made the decision, then, to block
their account for two weeks?
Mr. Dorsey. We didn't block their accounts for 2 weeks. We
required them to delete the tweet, and then they could tweet it
again. They didn't take that action, so we corrected it for
them. That was----
Mr. Scalise. Even though the tweet was accurate. I mean,
are you now--look, you have seen the conversations on both
sides about Section 230, and there is going to be more
discussion about it. But you are acting as a publisher if you
are telling a newspaper that they have got to delete something
in order for them to be able to participate in your account.
I mean, don't you recognize that that--you are no longer
hosting a town square. You are acting as a publisher when you
do that.
Mr. Dorsey. It was literally just a process, sir. This was
not against them in any particular way. We require--if we
remove a violation, we require people to correct it. We changed
that based on their not wanting to delete that tweet, which I
completely agree with. I see it. But it is something we
learned. We learned to----
Mr. Scalise. OK. Well, let me go to the New York--now let
me go to the Washington Post article because this article can
still be tweeted. I don't know if it was ever taken down. It
contains false information. Even the Washington Post
acknowledges that it contains false information. Yet their
tweets today on your service that still mischaracterize it in a
way where even the Washington Post admitted it is wrong, yet
those mischaracterizations can still be retweeted.
Will you address that and start taking those down to
reflect what even the Washington Post themselves has admitted
is false information?
Mr. Dorsey. Our misleading information policies are focused
on manipulated media, public health, and civic integrity. That
is it. We don't have a general----
Mr. Scalise. I would hope that you would go and take that
down. And look. I know you said in your opening statement, Mr.
Dorsey, that Twitter is running a business, and you said, ``A
business wants to grow the customers it serves.'' Just
recognize if you become viewed and continue to become viewed as
an anticonservatively biased platform, there will be other
people that step up to compete and ultimately take millions of
people from Twitter. I would hope you recognize that.
And I would yield back the balance of my time.
Mr. Doyle. The gentleman's time is expired.
The Chair now recognizes Mr. Butterfield for 5 minutes.
Mr. Butterfield. Thank you, Mr. Chairman.
Mr. Zuckerberg, last year in response to the police killing
of George Floyd, you wrote a post on your Facebook page that
denounced racial bias. It proclaimed, ``Black Lives Matter.''
You also announced that the company would donate $10 million to
racial justice organizations.
And Mr. Dorsey, Twitter changed its official bio to a Black
Lives Matter tribute, and you pledged $3 million to an
antiracism organization started by Colin Kaepernick. And Mr.
Pichai, your company held a companywide moment of silence to
honor George Floyd, and you announced $12 million in grants to
racial justice organizations.
The CEO of Google subsidiary YouTube wrote in a blog post,
``We believe Black Lives Matter and we all need to do more to
dismantle systematic racism.'' YouTube also announced it would
start a $100 million fund for black creators.
Now, all of this sounds nice. But these pronouncements,
gentlemen, these pronouncements and money donations do not
address the way your companies' own products, Facebook,
Twitter, and YouTube, have been successfully weaponized by
racists and are being used to undermine social justice
movements, to suppress voting in communities of color, and
spread racist content and lies.
And so, gentlemen, in my view--in my view your companies
have contributed to the spread of race-based extremism and
voter suppression. As the New York Times noted last year, ``It
is as if the heads of McDonald's, Burger King, and Taco Bell
all got together to fight obesity by donating to a vegan food
co-op rather than lowering their calories.''
Gentlemen, you could have made meaningful changes within
your organizations to address the racial biases built into your
products and donated to these organizations. But instead, we
are left with platitudes and another round of passing the buck.
America is watching you today. This is a moment that begins
a transformation of the way you do business, and you must
understand that. Perhaps a lack of diversity within your
organizations has contributed to these failures. The
Congressional Black Caucus's Tech 2025 initiative has been
working for years to increase diversity and equity in tech
companies at all levels, and you know that because we have
visited with you in California.
We founded this initiative in 2015 with the hope that by
now the tech workforce would reflect the diversity of our
country. Here we are, 2021. I acknowledge that you have made
some modest advancements, but not enough. There must be
meaningful representation in your companies to design your
products and services in ways that work for all Americans.
And that requires public accountability. History has shown
that you have talked the talk but have failed to walk the walk.
It appears now that Congress will have to compel you--compel
you, perhaps with penalties--to make meaningful changes.
And I am going to try the yes-or-no answer, and hopefully I
will have better results than my colleagues.
Mr. Zuckerberg, I will start with you, and please be brief.
Yes or no: Would you oppose legislation that would require
technology companies to publicly report on workforce diversity
at all levels?
Mr. Zuckerberg. Congressman, I don't think so, but I need
to understand it in more detail.
Mr. Butterfield. Well, we will talk about that. And I hope
that, if we introduce this legislation, you will not oppose it.
What about you, Mr. Dorsey? Would you oppose a law that
made workforce diversity reporting a requirement?
Mr. Dorsey. No, I wouldn't oppose it. It does come with
some complications in that we don't always have all the
demographic data for our employees.
Mr. Butterfield. Well, thank you for that, and we talked
with you in your office some years ago and you made a
commitment to work with us, but we need more.
What about you, Mr. Pichai? Are you willing to support--
would you be willing to commit to--would you oppose a law that
made workforce diversity reporting a requirement? Would you
oppose it?
Mr. Pichai. Congressman, we were the first company to
publish transparency reports. We publish it annually. And so,
happy to share that with you and take any feedback. But we do
today provide, in the U.S., detailed demographic information on
our workforce, and we are committed to doing better.
Mr. Butterfield. Well, gentlemen, for the last 6 years, the
Congressional Black Caucus has said to you over and over again
we need greater diversity among your workforce from the top to
the bottom, and we need for you to publish the data so the
world can see it. That is the only way we are going to deal
with diversity and equity.
Thank you so very much, Mr. Chairman. I heard you at the
beginning of the committee gavel, and I yield back the 10
seconds that I have.
Mr. Doyle. The gentleman deserves commendation for doing
that, and I hope others follow his example.
The Chair now recognizes Mr. Guthrie for 5 minutes.
Mr. Guthrie. Thank you, Mr. Chair, and thanks to the
witnesses for being here.
And Big Tech decisions have real impact on people, and that
is why I ask my constituents, using your platforms, to share
their experiences on your platforms with me as their
representative. And I am here to advocate on their behalf. I
received 450 responses, and one major thing that I heard from
my constituents was the experience they have had with sites
taking down religious content, which is important because a lot
of religious organizations are now streaming their services due
to COVID.
I did have one instance where a constituent wrote to me--
and this is what she posted--``I am thankful God's grace is new
every morning.'' And then Facebook took it down, and then my
constituent said she got a notice from Facebook that it
violated their policies around hate.
And so I just want to discuss about this. I can ask you
yes-or-no questions, Mr. Zuckerberg, on that, but I just want
to talk about it a little bit. One is, it seems, I know that we
don't want extreme language on the internet. I am with you on
that. And you cannot watch everything. And so you use
algorithms to find that, so algorithms will flag things, some
that are clearly obvious and some that you would say probably
shouldn't have been flagged.
But it seems to me that it seems to be biased in that
direction. And so instead of just giving you a yes-or-no
question, I want to read that quote again. And I sort of know a
little bit about math, not a lot but a little bit, about within
that quote, what in there would get tripped up, with this quote
get tripped up and put into the flagged category?
And as it says, ``I am thankful God's grace is new every
morning.'' And so I guess the question is what word or thought
do you think would trip an algorithm for that quote, Mr.
Zuckerberg?
Mr. Zuckerberg. Congressman, it is not clear to me why that
post would be a problem. I would need to look into it in more
detail. Sometimes the systems look at patterns of posting, so
if someone is posting a lot, then maybe our system thinks it is
spam. But I would need to look into it in more detail.
Overall, the reality is that any system is going to make
mistakes. There is going to be content that we take down that
we should have left up, and there is going to be content that
we missed that we should have taken down that we didn't catch
or that the system has made a mistake on. And at scale,
unfortunately, those mistakes can be a large number even if it
is a very small percent.
But that is why, when we are talking about things like
Section 230 reform, I think it is reasonable to expect large
companies to have effective moderation systems but not
reasonable to expect that there are never any errors. But I
think that transparency can help hold the companies accountable
as to what accuracy and effectiveness they are achieving.
Mr. Guthrie. OK. Then, well, to your spam comment, I think
they did receive a notify it was for the hate policy. And I
understand there are going to be gray areas, whatever. But that
quote, I don't see where the gray area is as to how it could
get caught up in that.
Mr. Zuckerberg. I agree.
Mr. Guthrie. But I want to move on. Thanks for your answer
with that. I want to move on.
So Mr. Dorsey, I want to talk about the RFK, Jr. I didn't
see that quote, but you said that didn't violate your policy.
And just in the context of that, I know CDC just recently
updated its school guidance to make clear science says you can
be 3 feet away and still be safe in schools. The issue--things
are changing every day because we are learning more and more
about this virus.
So how did the RFK comment not violate your policy--RFK,
Jr.? And how did--we have an RFK III that we all--and JFK and
JPK III I guess we all like as a former colleague. But RFK,
Jr., and the policy towards that. And then how do you keep up
with what's changing so quickly, Mr. Dorsey?
Mr. Dorsey. We can follow up with you on the exact
reasoning. But we have to recognize that our policies evolve
constantly, and they have to evolve constantly. So, as has been
said earlier in this testimony, we observe what is happening as
a result of our policy. We have got to understand the
ramifications. And we improve it. And it is a constant cycle.
We are always looking to improve our policies and our
enforcement.
Mr. Guthrie. So Mr. Zuckerberg, Mr. Pichai, just on all
that continuously evolving information on COVID because we are
learning more and more about it, how do you keep up? We only
have about 30 seconds, so if you could--quick answers for each
of you, if you can. Mr. Pichai, maybe, since you haven't
answered a question.
Mr. Pichai. Yes. On COVID we have been really taking
guidance from CDC and other health experts, proactively
removing information. One thing we get to do in YouTube is to
recommend higher quality content. We have shown 400 billion
information panels on COVID alone last year, including a lot
from CDC and other health organizations.
Mr. Guthrie. OK. Thank you, and I will yield back 4
seconds, Mr. Chair.
Mr. Doyle. Thank you, Mr. Guthrie.
The Chair now recognizes Ms. Matsui for 5 minutes.
Ms. Matsui. Thank you very much, Mr. Chairman, for having
this hearing today.
Today we have another opportunity, hearing from the leaders
of Facebook, Twitter, and Google, in what has become a
concerning pattern. The members of this committee are here to
demand answers to questions about social media's role in
escalating misinformation, extremism, and violence.
Last week I testified at a House Judiciary Committee
hearing about the rise in discrimination and violence against
Asian Americans. Horrifically, that hearing came on the heels
of a violent attack in Atlanta that left eight people, six of
them Asian women, dead.
The issues we are discussing here are not abstract. They
have real-world consequences and implementations that are too
often measured in human lives. I am worried, as are many
watching this hearing, that the companies before us today are
not doing enough to prevent the spread of hate, especially when
it is targeted against minority communities. Clearly the
current approach is not working, and I think Congress must
revisit Section 230.
A recent study from the University of San Francisco
examined nearly 700,000 tweets in the week before and after
President Trump tweeted the phrase ``Chinese virus.'' The
results showed two alarming trends: There was a significantly
greater increase in hate speech the week after the President's
tweet, and that half of the tweets using the hashtag
#chinavirus showed an anti-Asian sentiment compared to just
one-fifth of the tweets using the hashtag #covid19.
This empirical evidence backs up what the World Health
Organization already knew in 2015, saying, ``Disease names
really do matter. We have seen certain disease names provoke a
backlash against members of particularly religious or ethnic
communities.'' Despite this, Facebook and Twitter are still
allowing hashtags like #chinavirus, #kungflu, and #wuhanvirus
to spread.
Mr. Zuckerberg and Mr. Dorsey, given the clear association
between this type of language and racism or violence, why do
you still allow these hashtags on your platforms? Anyone answer
that, or is that not answerable?
Mr. Dorsey. I think we were waiting for you to call on one
of us. We do have policies against hateful conduct, and that
includes the trends, so when we see associated with any hateful
conduct, we will take action on it. It is useful to remember
that a lot of these hashtags, though, do contain counterspeech,
and people on the other side of it do own them and show why
this is so terrible and why it needs to----
Ms. Matsui. Can I just take my time back? The fact of the
matter is I think you know how to develop algorithms to kind of
get rid of this and examine this further.
Mr. Zuckerberg, any comment here?
Mr. Zuckerberg. Thanks, Congresswoman. The rise in anti-
Asian hate is a really big issue and something that I do think
that we need to be proactive about. I agree with the comments
that Jack made on this. On Facebook, any of that context, if it
is combined with something that is clearly hateful, we will
take that down. It violates the hate speech policy.
But one of the nuances that Jack highlighted that we
certainly see as well in enforcing hate speech policy is that
we need to be clear about when someone is saying something
because they are using it in a hateful way versus when they are
denouncing it. And this is one of the things that has made it
more difficult to operationalize this at scale.
Ms. Matsui. Well, reclaiming my time, I think this gives us
an opportunity to really look at hate speech, what it really
means, particularly in this day and age when we have many
instances of these things happening. Hate speech on social
media can be baked in, and unfortunately this also is a trend
that maybe happened years and years ago, which it might have
just been a latent situation.
But with social media, it travels all around the world and
it hurts a lot of people. And my feeling, and I believe a lot
of other people's feeling, is that we really have to look at
how we define hate speech. And you all are very brilliant
people, and you hire brilliant people. I would think that there
is a way for you to examine this further and take it one step
lower to see if it is something that is legitimate or not.
And I really feel that this is a time, especially now when
we are examining platforms and what you can do and should do,
and as we are examining here in this committee and as we write
legislation, we really want to have the entire multitude of
what can and can't be done.
So with that, Mr. Chairman, I only have 11 seconds left,
and I yield back. Thank you.
Mr. Doyle. Thank you. The gentlelady yields back.
Let's see. The Chair now recognizes Mr. Kinzinger for 5
minutes.
Mr. Kinzinger. Thank you, Mr. Chairman, and thank you all
for being here. In all this conversation it is good to have, I
think we also have to recognize that we need to--we are lucky
to have all these companies located in the United States. When
we talked about the issues and concerns, for instance, with
TikTok, we can see that a lot of these companies could easily
leave here and go elsewhere and then we would have far less
oversight.
I think the crackdown on January 6 was correct. I think we
need to be careful to not use that as a way to deflect from
what led to January 6th, the pushing of this narrative of Stop
the Steal. I think there are folks that are concerned, though,
that we also need to make sure that those same levels of
protection exist when you talk about like Iran, for instance,
and what the leaders there tweet. But let me go into specific
questions.
Over the years we have obviously seen the rise of
disinformation. It is not new. I remember getting
disinformation in the 1990s. But we have seen it spread on
these platforms. So we live in a digital world where many
people get their news and entertainment from the internet, from
articles and posts that are often based off algorithms that can
cater to what people see and read.
So those constant News Feeds have simply reinforced
people's beliefs, or worse, that they can promote disgraceful
and utterly ridiculous conspiracy theories from groups like
QAnon. Extremism and violence have grown exponentially as a
result, and we know it is true specifically after January 6.
So Mr. Zuckerberg, let me ask you: According to Hany Farid
at Berkeley, numerous external studies and some of your own
internal studies have revealed that your algorithms are
actively promoting divisive, hateful, and conspiratorial
content because it engages users to spend more time.
Do you think those studies are wrong? And if not, what are
you guys doing to reverse course on that?
Mr. Zuckerberg. Sure. Thank you, Congressman. This is an
important set of topics.
In terms of groups, we stopped recommending all civic and
political groups even though I think a lot of the civic and
political groups are healthy, because we were seeing that that
was one vector that there might be polarization or extremism,
and groups might start off with one set of views but migrate to
another place. So we have removed that completely. And we did
it first as an exceptional measure during the election; and
since the election we have announced that we are going to
extend that policy indefinitely.
For the rest of the content in News Feed and on Instagram,
the main thing that I would say is I do think that there is
quite a bit of misperception about how our algorithms work and
what we optimize for. I have heard a lot of people say that we
are optimizing for keeping people on the service.
The way that we view this is that we are trying to help
people have meaningful social interactions. People come to
social networks to be able to connect with people. If we
deliver that value, then it will be natural that people use our
services more. But that is very different from setting up
algorithms in order to just kind of try to tweak and optimize
and get people to spend every last minute on our service, which
is not how we designed the company or the services.
Mr. Kinzinger. Thanks. I don't mean to interrupt you. I do
have another question.
Mr. Chairman, I want to ask unanimous consent to insert for
the record an article from the Wall Street Journal titled
``Facebook Executives Shut Down Efforts to Make the Site Less
Divisive.''
[The article appears at the conclusion of the hearing.]
Mr. Kinzinger. Let me move on to the next one. For years I
have called for increased consumer protection from companies on
fake accounts and bad actors who use them to exploit others.
This issue affected me personally. In 2015, a woman from India
spent all of her money on a flight to come see me because she
claimed to have developed a relationship with me over Facebook.
In 2019 I sent you, Mr. Zuckerberg, a letter highlighting
the issue, and your team provided a relatively inadequate
response. Since then, I have introduced two pieces of
legislation, Social Media Accountability and Account
Verification Act, and the Social Media Fraud Mitigation Act,
both of which aim to curb this activity.
So Mr. Zuckerberg, the last time you came before us, you
stated that Facebook has a responsibility to protect its users.
Do you feel that your company is living up to that? And
further, what have you done to remove those fake accounts?
Mr. Zuckerberg. Thanks. So fake accounts are one of the
bigger integrity issues that we face. I think in the first half
of--well, in the last half of last year, we took down more than
a billion fake accounts, just to give you a sense of the
volume, although most of those our systems are able to identify
within seconds or minutes of them signing up because the
accounts just don't behave in a way that a normal person would
in using the service.
But this is certainly one of the highest-priority issues we
have. We see a large prevalence of it. Our systems, I think, at
this point are pretty effective in fighting it, but they are
not perfect, and there are still a few percent that get
through. And it is a big issue and one we will continue working
on.
Mr. Kinzinger. Thank you. I would love to ask the rest--the
others a question, but I don't have time. So I yield back, Mr.
Chairman. Thank you for your attention.
Mr. Doyle. I thank the gentleman.
The Chair now recognizes Ms. Castor for 5 minutes.
Ms. Castor. Well, thank you, Mr. Chairman.
Gentlemen, since you were last here in front of the
committee, the illegal activities, the expanse of unwitting
Americans, the rampant misinformation on your platforms, have
gotten worse. Part of the reason for this toxic stew is that
you employ manipulative methods to keep people cemented to the
platform, often amplifying discord. And it boosts your bottom
line. You enjoy an outdated liability shield that incentivizes
you to look the other way or take half-measures while you make
billions at the expense of our kids, our health, the truth, and
now we have seen the very foundation of our democracy.
I have been working for over a year with advocates and
other members on an update to the children's protections
online. You all know the tracking and manipulation of children
under age 13 is against the law, but Facebook, Google, YouTube,
and other platforms have broken that law or have found ways
around it. Many have been sanctioned for knowingly and
illegally harvesting personal information of children and
profiting from it.
I have a question for each of you, just a qusick yes or no:
Did you all watch ``The Social Dilemma,'' where former
employees of yours or other Big Tech platforms say they do not
allow their kids on social media? Mr. Zuckerberg?
Mr. Zuckerberg. Congresswoman, I haven't seen it----
Ms. Castor. Yes or----
Mr. Zuckerberg [continuing]. But I am obviously familiar
with it.
Ms. Castor. OK. Mr. Pichai? Yes or no?
Mr. Pichai. Yes. I have seen the movie.
Ms. Castor. And----
Mr. Dorsey. No. No.
Ms. Castor. OK. Well, Mr. Zuckerberg, there is a good
reason that they have the former execs say that. Are you aware
of the 2019 Journal of the American Medical Association
pediatric study that the risk of depression for adolescents
rises with each daily hour spent on social media? And I am not
talking screen time. I am not talking about Facetime or sending
text messages to friends. But are you aware of that research?
Mr. Zuckerberg. Congresswoman, I am not aware of that
research.
Ms. Castor. All right. What about the 2019 HHS research
that suicide rates among kids aged 10 to 14 increased by 56
percent between 2007 and 2017 and tripled--tripled--for kids
between the age of 10 and 14? Yes or no?
Mr. Zuckerberg. Congresswoman, I am aware of the issue----
Ms. Castor. Yes. So yes. Certainly you are also aware of
the research that indicates a correlation between the rise in
hospital admissions for self-harm and the prevalence of social
media on phones and the apps on platforms that are designed to
be addictive and keep kids hooked. Yes?
[No response.]
Ms. Castor. Well, how about you, Mr. Pichai? Are you aware
of the JAMA pediatric September 2020 study where they tested
hundreds of apps used by children aged 5 and under, many of
which were in the Google Play Store's family section? The study
found 67 percent of the apps tested showed transmission of
identifying info to third parties in violation of the COPPA
law? Are you familiar?
Mr. Pichai. Extensively spent time on this area. We
introduced a curated set of apps for kids on the Play Store. We
give digital well-being tools so that people can take a break,
set time patterns, can set time limits for children. So the
concept of----
Ms. Castor. Let me ask you this, then, Mr. Pichai: How much
are you making in advertising revenue from children under the
age 13?
Mr. Pichai. Most of our products other than a specific
product designed for kids, YouTube--most of our products are
not eligible for children under the age of 13.
Ms. Castor. Yes. So you are not going to provide that.
Mr. Zuckerberg, how much advertising revenue does
Facebook--do you make from behavioral surveillance advertising
targeted towards kids under age 13?
Mr. Zuckerberg. Congresswoman, it should be none of it. We
don't allow children under the age of 13----
Ms. Castor. Are you----
Mr. Zuckerberg [continuing]. On the services that run
advertising.
Ms. Castor. Oh, are you saying that there are no kids on
Instagram under the age of 13 right now?
Mr. Zuckerberg. Congresswoman, children under the age of 13
are not allowed on Instagram. When we find out that they are
there----
Ms. Castor. No. That is not the answer. I think, of course,
every parent knows that there are kids under the age of 13 on
Instagram. And the problem is that you know it, and you know
that the brain and social development of our kids is still
evolving at a young age. There are reasons in the law that we
set that cutoff at 13. But now, because these platforms have
ignored it, they have profited off of it, we are going to
strengthen the law. And I encourage all of my colleagues to
join in this effort. I have heard a lot of bipartisan support
here today.
We also need to hold the corporate executives accountable
and give parents the tools that they need to take care and
protect their kids.
Thank you, Mr. Chairman. I yield back.
Mr. Doyle. The gentlelady's time is expired.
The Chair recognizes Mr. Johnson for 5 minutes.
Mr. Johnson. Thanks, Mr. Chairman.
Over a decade ago, Americans watched Facebook, Twitter, and
Google emerge from humble beginnings. We were curious to see
how these new, innovative companies would improve our lives.
The results are in, and they are deeply concerning.
We have seen a surge in cyberbullying, child porn, radical
extremism, human trafficking, suicides, and screen addiction,
all of which have been linked to the use of social media. Our
Nation's political discourse has never been uglier, and we
haven't been this divided since the Civil War.
Yet Big Tech marches on uninhibited. What is their newest
target? Children under the age of 13. News outlets this week
have reported that Facebook is planning to create an Instagram
app designed for children under the age of 13. We have talked
about it here already today. Elementary and middle school
students.
By allowing Big Tech to operate under Section 230 as is, we
will be allowing these companies to get our children hooked on
their destructive products for their own profit. Big Tech is
essentially handing children a lit cigarette and hoping they
stay addicted for life.
In 1994, Democratic Congressman Henry Waxman chaired a
hearing with the CEOs of our Nation's largest tobacco
companies. During his opening statement, he stated, and I
quote, ``Sadly, this deadly habit begins with our kids. In many
cases they become hooked quickly and develop a lifelong
addiction that is nearly impossible to break.''
So, Mr. Zuckerberg and Mr. Dorsey, you profit from your
company's hooking users to your platforms by capitalizing on
their time. So yes or no: Do you agree that you make money off
of creating an addiction to your platforms? Mr. Zuckerberg?
Mr. Zuckerberg. Congressman, no. I don't agree with that.
Mr. Johnson. OK. Thank you. Thank you.
Mr. Zuckerberg. What we do is----
Mr. Johnson. That is what I needed, a yes or a no, because
you do.
Mr. Dorsey?
Mr. Dorsey. No.
Mr. Johnson. OK. All right. Let me go on.
Chairman Waxman went on to say, and I quote, ``For decades,
the tobacco companies have been exempt from the standards of
responsibility and accountability that apply to all other
American corporations. Companies that sell aspirin, cars, and
soda are all held to strict standards when they cause harm, and
that we demand that when problems occur, corporations and their
senior executives be accountable to Congress and the public.
This hearing marks the beginning of a new relationship between
Congress and the tobacco companies.'' That is what Chairman
Waxman said in 1994.
So For all three of you, Mr. Zuckerberg, Mr. Dorsey, and
Mr. Pichai: Do you agree that the CEOs that--as the CEOs of
major tech companies, you should be held accountable to
Congress and the public? Mr. Zuckerberg?
Mr. Zuckerberg. Congressman, I think we are accountable to
Congress and to the public.
Mr. Johnson. Do you think you should be held accountable?
Mr. Zuckerberg. I am not sure I understand what you mean,
but I think so.
Mr. Johnson. It is an easy question. Should you be held
accountable----
Mr. Zuckerberg. Yes.
Mr. Johnson [continuing]. To Congress and the public for
the way you run your business?
Mr. Zuckerberg. Yes. And we are.
Mr. Johnson. OK. All right. Thank you.
Mr. Dorsey?
Mr. Dorsey. Yes. Accountable to the public.
Mr. Johnson. OK. Accountable--no. I said accountable to
Congress and the public. We represent the public. So you agree?
Mr. Dorsey. Yes.
Mr. Johnson. OK. Thank you. Mr. Pichai?
Mr. Pichai. Yes. I am here today because I am accountable
to Congress and members of the public.
Mr. Johnson. OK. Great. Well, gentlemen, let me tell you
this, and I think I have heard it mentioned by several of my
other colleagues. There is a lot of smugness among you. There
is this air of untouchableness in your responses to many of the
tough questions that you are being asked.
So let me tell you all this. All of these concerns that
Chairman Waxman stated in 1994 about Big Tobacco apply to my
concerns about Big Tech today, about your companies. It is now
public knowledge that former Facebook executives have admitted
that they use the tobacco industry's playbook for addictive
products. And while this is not your first hearing in front of
Congress, I can assure you that this hearing marks a new
relationship between all of us here today. There will be
accountability.
Mr. Chairman, I yield back.
Mr. Doyle. I thank the gentleman. He yields back.
The Chair now recognizes Mr. McNerney for 5 minutes.
Mr. McNerney. I want to thank the chair for organizing this
hearing, and I thank the participants. This is a lot of work on
your behalf and a long day for you. I appreciate that.
Are you all aware that your platforms are behemoths, and
that the Americans are demanding that we step in and rein in
your platforms both in terms of how you handle our data and how
platforms handle disinformation that causes real harm to
Americans and to the democracy itself?
I understand the tension you have between maximizing your
profits by engaging to your platforms on the one hand and by
the need to address disinformation and real harm it causes on
the other hand. Your unwillingness to unambiguously commit to
enforcing your own policies and removing the 12 most egregious
spreaders of vaccine disinformation from your platforms gets
right at what I am concerned about.
Disinformation is a strong driver for engagement, and
consequently you too often don't act even though we know you
have the resources to do that. There are real harms associated
with this. And my questions--I hope I don't appear to be rude--
but when I ask for a yes-or-no question, I will insist on a
yes-or-no answer.
Mr. Zuckerberg, yes or no: Do you acknowledge that there is
disinformation being spread on your platform?
Mr. Zuckerberg. Sorry, I was muted. Yes, there is, and we
take steps to fight it.
Mr. McNerney. Thank you. Yes or no: Do you agree that your
company has profited from the spread of disinformation?
Mr. Zuckerberg. Congressman, I don't agree with that.
People don't want to see disinformation on our services, and
when we do----
Mr. McNerney. So it is no, then.
Mr. Zuckerberg [continuing]. I think it hurts our long-
term----
Mr. McNerney. You said you don't agree with that. I
appreciate your forthrightness on that. But we all know this is
happening. Profits are being generated from COVID-19 and
vaccine disinformation, election disinformation, QAnon
conspiracy theories, just to name a few things. And it is
baffling that you have a negative answer to that question.
Approximately--well, let's move on to the next issue.
Mr. Zuckerberg, you talked a lot about relying on third-
party fact-checkers to combat the spread of disinformation, but
you tell us very little about the process. I wrote you a letter
nearly 2 years ago asking about it, and you failed to answer my
question.
I asked this question again when an executive from your
company testified last year, and she failed to answer. I would
like to get an answer today. On average, from the time content
is posted to Facebook's platform, how long does it take
Facebook to flag suspicious content to third-party fact-
checkers to review the content and for Facebook to take
remedial action after this review is completed? How long does
this entire process take? I am just looking for a quick number.
Mr. Zuckerberg. Congressman, it can vary. If an AI system
identifies something immediately, it can be within seconds. If
we have to wait for people to report it to us and have human
review, it can take hours or days. The fact-checkers take as
much time as they need to review things, but as soon as we get
an answer back from them, we should operationalize that and
attach a label if the content is rated false and----
Mr. McNerney. I am paying attention on what you are saying.
But what I do know is that this process isn't happening quickly
enough, and I am very concerned that you aren't motivated to
speed things up, because the most problematic content is what
gets the most views, and the longer the content stays up, the
more help--the more this helps maximize your bottom line and
the more harm that it can cause. It is clear that you are not
going to make these changes on your own.
This is a question for all of the participants, panelists:
Would you oppose legislation that prohibits placing ads next to
what you know to be or should know to be false or misleading
information, including ads that are placed in videos, promoted
content, and ads that are placed above, below, or on the site
of a piece of content?
Mr. Zuckerberg, would you answer with a yes or no first,
please?
Mr. Zuckerberg. Congressman, that is very nuanced. I think
the questions to determine whether something is misinformation
is a process that I think would need to be spelled out well in
a law like that.
Mr. McNerney. Well, OK. I appreciate that.
Mr. Dorsey?
Mr. Dorsey. Yes. I would oppose it until we see the actual
requirements and what the ramifications are. We need to
understand that.
Mr. McNerney. OK. And Mr. Pichai, would you oppose a
prohibition like this?
Mr. Pichai. The principle makes sense. In fact, advertisers
don't want anywhere or near to be content like that. And so we
already have incentives. You can imagine reputable advertisers,
like consumer products advertisers, do not want any ads to
appear next to information that could turn off their consumers.
So we have natural incentives to do the right thing here.
Mr. McNerney. You all say you want a safe and open platform
for everyone. You say it is not in your company's interest to
have this information on your platform. So you shouldn't oppose
efforts that would prevent harming the American people.
I yield back.
Mr. Doyle. The gentleman's time is expired. The gentleman
yields back.
The Chair now recognizes Mr. Long for 5 minutes.
Mr. Long. Thank you, Mr. Chairman.
Mr. Pichai, I am going to ask you a yes-or-no question, and
just tell me if you know the difference in these two words: yes
and no?
Mr. Pichai. Yes.
Mr. Long. Mr. Zuckerberg, same question for you. Do you
know the difference in yes and no?
Mr. Zuckerberg. Yes, Congressman.
Mr. Long. And Mr. Dorsey, same question for you. Do you
know the difference in two words, yes or no?
Mr. Dorsey. Yes.
Mr. Long. I am sorry?
Mr. Dorsey. Yes.
Mr. Long. Is that a yes? I didn't----
Mr. Dorsey. Yes. I know the difference.
Mr. Long. Thank you. I want a steak dinner there from one
of my colleagues. They didn't think I could get all three of
you to answer a yes-or-no question. I did it.
Mr. Zuckerberg, let me ask you: How do you ascertain if a
user is under 13 years old?
Mr. Zuckerberg. Congressman, on services like Facebook, we
have people put in a birthday when they register.
Mr. Long. That is handy. So a 13-year-old would never--I
mean, an 11-year-old would never put in the wrong birthday by 2
years and say they were 13? Is that kind of your policy?
Mr. Zuckerberg. Congressman, it is more nuanced than that.
But I think you are getting at a real point, which is that
people lie. And we have additional systems that try to
determine what someone's age might be, so if we detect that
someone might be under the age of 13, even if they lied, we
kick them off.
But this is part of the reason why we are exploring having
a service for Instagram that allows under-13s on, because we
worry that kids may find ways to try to lie and evade some of
our systems. But if we create a safe system that has
appropriate parent controls, then we might be able to get
people into using that instead. We are still early in figuring
this out, but that is a big part of the theory and what we are
hoping to do here.
Mr. Long. But currently they are now allowed to use
Instagram. Correct?
Mr. Zuckerberg. That is correct. Our policies do not allow
people under the age of 13 to use it.
Mr. Long. I am from Missouri, the Show Me State. And just
to say that no one under 13 can get on to me doesn't pass the
Missouri smell test of ``show me.'' So I was thinking with you,
Mr. Zuckerberg, you created the Facebook Oversight Board as a
way to help hold Facebook accountable. They are currently
looking at Facebook's decision to remove President Trump's
Facebook account.
If the oversight board determines that Facebook should have
left President Trump's account up, what will you do?
Mr. Zuckerberg. Congressman, we will respect the decision
of the oversight board, and if they tell us that former
President Trump's account should be reinstated, then we will
honor that.
Mr. Long. I don't know why people call Attorney General
Ashcroft ``Attorney General,'' but when they speak of President
Trump, they call him ``former President.'' But I guess I will
leave that for another day.
Sticking with you again, Mr. Zuckerberg, my understanding
is that the Facebook Oversight Board is comprised of members
from all over the world. As you are well aware, the United
States has the strictest protections on free speech than any
other country.
Since the decisions of the board are being made by a panel
rather than the U.S. court of law, how can you assure members
of this committee and the American people that the oversight
board will uphold free speech and make their decisions based on
American laws and principles?
Mr. Zuckerberg. Congressman, the members of the oversight
board were selected because of their views on free expression
and strong support of it. That is why we created the oversight
board, to help us defend these principles and to help us
balance the different aspects of human rights, including free
expression.
But each of the people on the oversight board was selected
because of a strong commitment to free expression, and I think
the decisions that the oversight board has made so far reflect
that.
Mr. Long. OK. Let me move on to Mr. Dorsey.
Mr. Dorsey, I know you are from the Show Me State also.
Have you been vaccinated against COVID-19?
Mr. Dorsey. Not yet.
Mr. Long. Mr. Pichai, have you been vaccinated against
COVID-19?
Mr. Pichai. Sorry. I missed the question, Congressman?
Mr. Long. I know. I bore a lot of people. Have you been
vaccinated against COVID-19?
Mr. Pichai. Congressman, I was very fortunate to have
received it last week.
Mr. Long. So you have one shot. You have another one to go?
Or is it just Johnson & Johnson, where you just need one?
Mr. Pichai. I still have one more shot to go.
Mr. Long. And Mr. Zuckerberg, same question: Have you been
vaccinated against COVID-19?
Mr. Zuckerberg. I have not yet, but hope to as soon as
possible.
Mr. Long. OK. It is not a personal preference not to get
vaccinated, they just haven't got to your age group?
Mr. Zuckerberg. That is correct.
Mr. Long. OK. Thank you. And I just cannot believe Robert
Kennedy, Jr., is out there with his antivax stuff and it is
allowed to stay up on Twitter.
With that, I yield back.
Mr. Doyle. The gentleman yields back.
Let's see who is next. I don't see a name. Can staff show
us who is next up?
Mr. Welch, you are recognized for 5 minutes.
Mr. Welch. Thank you, Mr. Chairman.
What we are hearing from both sides of the aisle are
enormous concerns about some of the consequences of the
development of social media--the algorithmic amplification of
disinformation, election interference, privacy issues, the
destruction of local news, and also some competition issues.
And I have listened carefully, and each of the executives has
said that your companies are attempting to face these issues.
But a concern I have is whether, when the public interest
is so affected by these decisions and by these developments,
ultimately should these decisions be made by private executives
who are accountable to shareholders, or should they be made by
elected representatives accountable to voters?
So I really have two questions that I would like each of
you, starting with Mr. Zuckerberg and then Mr. Pichai and then
Mr. Dorsey, to address.
First, do you agree that many of these decisions that are
about matters that so profoundly affect the public interest
should they be made exclusively by private actors like
yourselves who have responsibilities for these major
enterprises?
And secondly, as a way forward to help us resolve these
issues or work with them, will you support the creation by
Congress of a public agency, one like the Federal Trade
Commission or the Securities and Exchange Commission, one that
had staff that is expert in policy and technology, that has
rulemaking and enforcement authority to be an ongoing
representative of the public to address these emerging issues?
Mr. Zuckerberg?
Mr. Zuckerberg. Congressman, I agree with what you are
saying, and I have said a number of times that I think that
private companies should not be making so many decisions alone
that have to balance these complicated social and public
equities.
And I think that the solution that you are talking about
could be very effective and positive for helping out because
what we have seen in different countries around the world is
there are lots of different public equities at stake here--free
expression, safety, privacy, competition--and these things
trade off against each other. And I think a lot of these
questions, and the reason why people get upset with the
companies, I don't think it is necessarily because the
companies are negligent. I think it is because these are
complex tradeoffs between these different equities.
And if you----
Mr. Welch. Pardon my interruption, but I want to go to Mr.
Pichai. But thank you, Mr. Zuckerberg.
Mr. Pichai. Congressman, if your question is--I just want
to make sure. Are you asking about whether there should be
another agency? I defer to Congress on that. We are definitely
subject to a variety of statutes and oversight by agencies like
FTC. We have consent agreements with the FCC. And we engage
with these agencies regularly.
Mr. Welch. Do you believe that it should be up to the
public as opposed to private interests to be making decisions
about these public effects?
Mr. Pichai. We definitely think areas where there could be
clear legislation informed by the public--I think that
definitely is a better approach. I would say the nature of
content is so fast-changing and so dynamic, we spend a lot of
energy hiring experts, consult with third parties, and that
expertise is needed, I think, based on the----
Mr. Welch. Right. And that is the problem we have in
Congress, because an issue pops up and there is no way we can
keep up. But you all can barely keep up with it yourself.
Mr. Dorsey, your view on those two questions, please?
Mr. Dorsey. Yes. I don't think the decision should be made
by private companies or the government, which is why we are
suggesting a protocol approach to help the people make the
decisions themselves, have more control themselves.
Mr. Welch. So does that mean that the creation of an agency
that would be intended to address many of these tech issues
that are emerging is something you would oppose or----
Mr. Dorsey. I always have an open mind. I would want to see
the details of what that means and how it works in practice.
Mr. Welch. Well, of course. But the heart of it is creating
an entity that has to address these questions of algorithmic
transparency, of algorithmic amplification of hate speech, of
disinformation, of competition, and to have an agency that is
dedicated to that, much like the Securities and Exchange
Commission was designed to stop the rampant abuse on Wall
Street in the 1930s--a public sector entity that is doing this,
not just leaving it to private companies.
Mr. Dorsey. Yes. I do think----
Mr. Welch. Do you agree or not?
Mr. Dorsey. I do think there should be more regulation
around the primitives of AI. But we focus a lot of our
conversations right now on the outcomes of it. I don't think we
are looking enough at the primitives.
Mr. Welch. Thank you. I yield back.
Mr. Doyle. The gentleman yields back.
The Chair recognizes Mr. Bucshon for 5 minutes.
Mr. Bucshon. Thank you, Mr. Chairman. And first of all, I
want to thank the witnesses for being here today. It is going
to be a long day, and appreciate your testimony and your
answering questions.
I do think it is important to understand history--excuse
me--when you look at these situations and you know, when it
comes to the political side, when Thomas Jefferson wanted to
get out an anti-Adams message even though he was his own vice
president, had started his own newspaper because it was pretty
clear that the newspapers that were being published weren't
going to change their view because there was no competitive
reason to do that.
And I think we are looking at potentially a similar
situation here. Without competition, things don't change. I
mean, it would be interesting to know the conversations with
John D. Rockefeller in the early 1900s prior to the breakup of
Standard Oil in 1911, and then of course AT&T in 1982.
So I understand that these are businesses. They are
publicly held companies. I respect that. I understand that. I
am a capitalist. That said, these situations are a little
different, I think, because there is some social responsibility
here. And I appreciate your answers that your companies are
doing what you believe are necessary.
So I want to ask--I am going to take the antitrust area
here. And Mr. Pichai, what do you think--what is the situation
when you have Google, 92 percent of the searches are Google?
You basically can't get on the internet without some sort of
Google service. What do you think is going to happen? What do
you think we should do about that?
Mr. Pichai. Congressman, I mean, we definitely are engaged
with conversations as well as lawsuits in certain cases. We
understand there will be scrutiny here. We are a popular
general-purpose search engine, but we compete vigorously in
many of the markets we operate in. For example, the majority of
revenue comes from product services, and one in two product
services originate with Amazon today in the U.S.
So we definitely see a lot of competition by category.
There are many areas as a company we are an emerging player,
making phones. Or when we are trying to provide enterprise
software, we compete with or larger players as well. And if you
look at the last year and look at all the new entrants in the
market, new companies that have gone public and emerged
strongly, in tech shows, the market is vibrant and dynamic.
At Google, we have invested in many startups. Googlers have
started over--former Google employees have started over 2,000
companies in the past 15 years. And so I see a highly dynamic,
vibrant, competitive tech sector, and we are committed to doing
our part.
Mr. Bucshon. OK. Fair enough.
Mr. Zuckerberg, do you have some comments on that subject?
Mr. Zuckerberg. Congressman, I would echo Sundar's
comments. I think that this is a highly competitive market. I
mean, if this is a meeting about social media, not only do you
have the different companies that are here today that all offer
very big services that compete with each other, but you have
new entrants that are growing very quickly, like TikTok, which
is reaching a scale of hundreds of millions or billions of
people around the world and I think is growing faster than any
of our services of the companies that are up here today, and
certainly competitive with us. And that is just naming a few,
right? I mean, obviously there's Snapchat and a bunch of other
services as well.
So it is a very competitive marketplace.
Mr. Bucshon. And do you think--I will ask you this, Mr.
Zuckerberg. I think you have commented that some of the privacy
things that maybe the Europeans did would kind of solidify your
dominance as a company. So what should we do in the United
States on this? Because--it is a different subject, but
similar--to not do something that would stymie innovation and
competition, and further--in my view, further create a
monopolistic or at least a perceived monopolistic environment.
Mr. Zuckerberg. Well, Congressman, I do think that the U.S.
should have Federal privacy legislation because I think we need
a national standard. And I think having a standard that is
across the country that is as harmonized with standards in
other places would actually create clearer expectations of
industry and make it better for everyone.
But I think the point that you are making is a really
important one, which is, if we ask companies to lock down data,
then that to some degree can be at odds with asking them to
open up data to enable, whether it is academic research or
competition.
So I think that when we are writing this privacy regulation
we just should be aware of the interaction between our
principles on privacy and our principles on competition. And
that is why I think a more holistic view, like what Congressman
Welch was just proposing, I think is perhaps a good way to go
about this.
Mr. Bucshon. OK. Quickly, Mr. Dorsey, do you have any
comments on that?
Mr. Dorsey. One of the reasons we are suggesting more of a
protocol approach is to enable as many new entrants as
possible. We want to be a client on that.
Mr. Bucshon. OK. I want to----
Mr. Doyle. The gentleman's time is expired.
Mr. Bucshon. With that, I will yield back.
Mr. Doyle. The Chair recognizes Ms. Clarke for 5 minutes.
Ms. Clarke. Thank you, Mr. Chairman. I thank you, the
chairs, and the ranking members for today's hearing. I also
thank our witnesses for appearing.
In January, I called for public comment for the discussion
draft of my bill, the Civil Rights Modernization Act of 2021, a
narrowly focused proposal to protect historically marginalized
communities from the harms of targeted advertising practices.
These harms can and have infringed on the civil rights of
protected classes, and I am proud to formally introduce this
bill next week to diminish inequities in the digital world.
For time's sake, I ask our witnesses to please answer the
questions as succinctly as possible.
The first question goes to Mr. Zuckerberg. Facebook
currently provides their advertisers with insight on how to get
their ads in front of people who are most likely to find their
ads relevant by utilizing tools to use criteria like consumer's
personal interest, geography, to fine-tune thought targeting.
This has often used code that target or avoid specific
races or other protected classes of people. Let me add that I
am aware of the updates to your special ad audience. However,
why does Facebook continue to allow for discrimination in the
placement of advertisements that can violate civil rights laws?
Mr. Zuckerberg. Congresswoman, we have taken a number of
steps to eliminate ways that people can target different groups
based on racial affinity and different ways that they might
discriminate, because this is a very important area. And we
have active conversations going on with civil rights experts as
to the best ways to continue improving these systems, and we
will continue doing that.
Ms. Clarke. Mr. Dorsey, Twitter allows advertisers to use
demographic targeting to reach people based on location,
language, device, age, and gender. In July, your company made
changes to your ad targeting policies to advise advertisers to
``not wrongfully discriminate against legally protected
categories of users.''
What did Twitter mean by the phrase ``wrongfully
discriminate''? Are some kinds of discriminatory advertising
permitted on Twitter? If so, would you please explain?
Mr. Dorsey. No. None at all.
Ms. Clarke. I am sorry. I didn't get that answer.
Mr. Dorsey. No. None at all.
Ms. Clarke. OK. And so can you explain what you meant by
``won't wrongfully discriminate''?
Mr. Dorsey. We mean that you shouldn't use our ad systems
to discriminate.
Ms. Clarke. Oh, OK.
Mr. Pichai, Google has recently announced a new approach in
their targeting system called FLOC, or Federal Learning of
Cohorts--excuse me, Federated Learning of Cohorts--to allow an
ad targeting to groups of people with similar characteristics.
The new system will utilize machine learning to create these
``cohorts'' for the consumers' visits to websites.
Given the potentially biased and disparate impact of
machine learning algorithms, how has Google addressed the
potential discriminatory impact of this new FLOC system?
Mr. Pichai. Congresswoman, it is an important area. We
recently announced a joint collaboration with HUD to ban ads
that would target age, gender, family status, ZIP code, in
addition to race, which we have long disallowed. So we will
bring similar prohibitions, particularly when we are using
machine learning.
And by the FLOC--it is early, we haven't implemented it
yet. We will be publishing more technical proposals on it, and
they will be held to our AI principles, which prohibit
discrimination based on sensitive categories, including race.
And we will be happy to consult and explain our work there.
Ms. Clarke. I appreciate that.
Gentlemen, I just want you to be aware that the longer we
delay in this, the more that these systems that you have
created bake discrimination into these algorithms. I think that
it is critical that you get in there and that you do what is in
the best interest of the public of the United States of America
and undo a lot of the harm that has been created with the bias
that has been baked into your systems.
With that, Mr. Chairman, I yield back 23 seconds. And I
thank you for this opportunity.
Mr. Doyle. And I thank the gentlelady for that.
The Chair now recognizes Mr. Walberg for 5 minutes.
Mr. Walberg. Thank you, Mr. Chair. And thanks to the panel
for being here. What I have listened to so far today, I would
have to say that based upon what many of us in Congress say
about the best legislation, when both sides don't like it, it
is probably good. And you have certainly hit that today, I
think from both sides. You have been attacked for various
reasons.
But I have to say the platforms that you have developed are
amazing and they have huge potential. And they indeed have
enabled us to go directions--the information, the
communications, relationships--that can be very positive and
are amazing in what has been accomplished.
I think we get down to how that is controlled and who
controls it. Going back to our foundations as our country, it
was our second President, John Adams, who said that our
constitution was meant for a moral and religious people and is
wholly inadequate for any other.
I think we are seeing a lot of the problems that you are
frustrated with as a result of parents and families, churches,
schools, that aren't taking the primary responsibility. I get
that. So it comes down to the choice that is left for the
people is really between conscience and the constable.
We are either going to have a conscience that self-controls
and, as you have said, Mr. Zuckerberg--in fact, what you said,
I wouldn't mind my 3- and 5-year-old granddaughters coming to
your house. I am not asking for the invitation, but I think
they would be safe there relative to the online capabilities,
from what you have said. But that is conscience versus
constable.
But what I have heard today is that there will be some
constable, and I am not sure that we will have success in
moving forward. So I guess, Mr. Chairman, unfortunately we have
been here before. We have been here many times. A few years
ago, when Mr. Zuckerberg was here before this committee, I held
up a Facebook post by a State senator in Michigan whose post
was simply announcing his candidacy as a Republican for elected
office, and yet it was censored as shocking and disrespectful
or sensational in content.
Just a few months ago I posted my resolution that would add
teachers to the vaccine priority list on Twitter, and it was
labeled as ``sensitive content'' and encouraged to be changed.
Well, hiding behind Section 230, all of you have denied that
there is any bias or inequitable handling of content on your
platforms.
And yet Pew Research Center found that--and this is where I
have my problem--not so much with the platform or even the
extent of what is on the platform, but they found that 72
percent of the public thinks it is likely that social media
platforms actively censor political views that Big Tech
companies find objectionable.
Further, and I quote, ``By a 4-to-1 margin, respondents
were more likely to say Big Tech supports the views of liberals
over conservatives than vice versa.'' Probably equaled only by
higher education. That was my statement. And yet every time
this happens, you fall back on blaming glitches in the
algorithms.
It was former--Greg Coppola, a former Google insider, who
said, before he was suspended by Google, he said, ``Algorithms
don't write themselves. We write them to do what we want them
to do.'' That is my concern. Whether it is censoring pro-life
groups like Life Action or pro-Second Amendment groups like the
Well-Armed Women, your platforms continually shut down law-
abiding citizens in constitutional discussions and commerce
that don't align with Big Tech views and the worldview, and
this includes the First and Second Amendments that causes me to
be concerned that you don't share the same freedom and
constitutional concerns.
It is not often I find myself agreeing with Bernie Sanders,
but in an interview earlier this week, and I quote, he said,
``If you are asking me do I feel particularly comfortable that
the President of the United States should not express his views
on Twitter, I don't feel comfortable about that,'' he went on
to say, ``because yesterday was Donald Trump who is blamed, and
tomorrow it could be somebody else.''
Mr. Zuckerberg or Mr. Dorsey, do you believe the law should
allow you to be the arbiters of truth, as they have under
Section 230? Mr. Zuckerberg first.
Mr. Zuckerberg. Congressman, I think that it is good to
have a law that allows platforms to moderate content. But as I
have said today, I think that there--that we would benefit from
more transparency and accountability.
Mr. Walberg. Mr. Dorsey?
Mr. Dorsey. I don't think we should be the arbiters of
truth, and I don't think the government should be, either.
Mr. Walberg. Gentlemen, I agree.
Mr. Doyle. The gentleman's time is expired.
Mr. Walberg. I yield back.
Mr. Doyle. The Chair now recognizes Mr. Cardenas for 5
minutes.
Mr. Cardenas. Thank you very much, Mr. Chairman and ranking
members, for having this important hearing. I would like to
submit to the record a National Hispanic Media Coalition letter
against Spanish-language disinformation on social media. If we
could submit that for the record, I would appreciate that.
[The letter appears at the conclusion of the hearing.]
Mr. Cardenas. Also, my first question is to you, Mr.
Zuckerberg. In 2020, Facebook brought in approximately $86
billion revenue in 2020. Is that about right, give or take?
Mr. Zuckerberg. Congressman, I think that is about right.
Mr. Cardenas. OK. Thank you. Good. How much of that revenue
did Facebook invest in identifying misinformation,
disinformation, and that portion of your business?
Mr. Zuckerberg. Congressman, I don't know the exact answer.
But we invest billions of dollars in our integrity programs,
including having more than a thousand engineers working on this
and 35,000 people doing content review across the company.
Mr. Cardenas. OK. And how many people do have full-time
equivalents, in your company overall?
Mr. Zuckerberg. Congressman, I don't know the exact number,
but I think it is around 60,000.
Mr. Cardenas. OK. So you are saying over half of the people
in your company are doing the portion of content review, et
cetera, which is the main subject we seem to be talking about
today?
Mr. Zuckerberg. No, Congressman, because you asked about
full-time employees, and some of the content reviewers are
contractors.
Mr. Cardenas. Oh, OK. All right. Well, there seems to be a
disparity between the different languages that are used on your
platform in America. For example, there was a study published
in April, and over 100 items of misinformation on Facebook in
six different languages was found, and 70 percent of the
Spanish-language content analyzed had not been labeled by
Facebook as compared to 30 percent of the English-language
misinformation that had not been labeled. So there seems to be
a disparity there.
What kind of investment is Facebook making on the different
languages to make sure that we have more of an accuracy of
flagging those disinformation and misinformation?
Mr. Zuckerberg. Congressman, thanks. We have an
international fact-checking program where we work with fact-
checkers in more than 80 countries and a bunch of different
languages.
In the U.S. specifically, we have Spanish-speaking fact-
checkers as well as English-speaking fact-checkers. So that's
on the misinformation side. But also, when we create resources
with authoritative information, whether it is around COVID
information or election information, we translate those hubs so
that way they can be available in both English and Spanish. And
we make it so people can see the content in whatever language
they prefer.
Mr. Cardenas. Thank you. So basically you are saying it is
extensive?
Mr. Zuckerberg. Congressman, this is certainly something
that we invest a lot in. And it will be something that we
continue to invest more in.
Mr. Cardenas. OK. I like the last portion. I do believe,
and would love to see you invest more.
My 70-plus-year-old mother-in-law, who is primarily a
Spanish speaker, commented to me the other day that her friends
who communicate mainly in Spanish--and they do use the
internet, they use some of your platforms, gentlemen--that they
were worried about the vaccine and that somebody is going to
put a chip in their arm.
For God's sakes, I mean, that to me just was unbelievable
that they would comment on that. But they got most of that
information on the internet, on various platforms. Clearly,
Spanish language disinformation is an issue, and I would like
to make sure that we see all of your platforms address these
issues, not only in English but in all languages.
I think it is important for us to understand that a lot of
hate is being spewed on the internet, and a lot of it is coming
through many of your platforms. For example, there are 23
people dead in El Paso because somebody filled this person's
head with a lot of hateful nonsense, and he drove to
specifically kill Mexicans along the Texas-Mexican border.
Eight people are dead in Atlanta because anti-Asian hatred
and misinformation has been permitted to spread and allowed on
these platforms unchecked, pretty much unchecked. The spread of
hatred and incitement of violence on platforms is a deadly
problem in America, and we need to see that it stops.
Mr. Zuckerberg, do you believe that you have done enough to
combat these kinds of issues?
Mr. Zuckerberg. Congressman, I believe that our systems--
and that we have done more than basically any other company.
But I think that there is still a problem and there is still
more that needs to be done.
Mr. Cardenas. OK. That is good. You would like to do more.
Thank you.
I only have 15 seconds so I am going to ask this question
to all three of you: Do you think that each one of your
organizations should have an executive-level individual in
charge of this department reporting directly to the CEO? Do you
think you agree that that should be the case? Mr. Zuckerberg?
Mr. Zuckerberg. Congressman, we have an executive-level
person who is in charge of the integrity team that I talked
about. He is on my management team.
Mr. Cardenas. Reports directly to you?
Mr. Zuckerberg. Congressman, he does not. I only have a few
direct reports. A lot of people on the management team report
to them.
Mr. Cardenas. OK. Thank you. To the other two witnesses,
very quickly?
Mr. Pichai. Congressman, we have senior executives,
including someone who reports directly to me, who oversees
trust and safety across all of these areas.
Mr. Cardenas. Thank you. Mr. Dorsey?
Mr. Dorsey. We do. We do.
Mr. Cardenas. Thank you so much. I yield back the balance
of my time.
Mr. Doyle. The gentleman's time is expired.
The Chair now recognizes Mr. Carter for 5 minutes.
Mr. Carter. Thank you, Mr. Chairman. And thank all of you
for being here.
Mr. Zuckerberg, I would like to start with you. And I
wanted to ask you, you are aware, as all of us are, of the
disaster that we have at the Southern border [audio disruption]
indicate that human smugglers have been using social media,
including Facebook, WhatsApp, and Instagram, to coordinate
their operations in transporting illegal immigrants into the
United States--things like, what to say to authorities,
transportation tips, and other forms of information that are
being traded on your platform to evade authorities and
contribute to the crisis, this disaster at the border.
Mr. Zuckerberg, do you feel complicit in any way that your
platform is assisting in this disaster?
Mr. Zuckerberg. Congressman, first let me say that what is
happening at the border is----
Mr. Carter. I am not--we know what is happening at the
border. I am asking you specifically about your platform. Do
you feel complicit in what your platform is doing to assist in
this disaster?
Mr. Zuckerberg. Congressman, we have policies and we are
working to fight this content. We have policies against scams
in pages, groups, and events like the content that you are
talking about. We are also seeing the State Department use our
platform to share factual information with people about----
Mr. Carter. I am not talking about facts. I am talking
about--I am talking about coyotes who are using your platform
to spread this kind of information to assist in this illegal
activity that is resulting in horrible conditions for these
people who are trying to come across that border.
Mr. Zuckerberg. Congressman, that is against our policies,
and we are taking a lot of steps to stop it. And again, let me
just say that I think the situation at the border is really
serious and we are taking it very seriously.
Mr. Carter. Well, and I hope you will look into this, these
reports that your platform is being used by these traffickers.
This is something we need your help with. I hope you feel the
sense of responsibility, sir, to help us with this, because we
certainly need it.
Let me ask you something. You dedicated a lot of your
written testimony to election issues. And even today, during
this hearing, you have been very public in pushing back about
the election claims in November. Yet when Facebook has been
essentially silent on the attempted theft of the certified
election in Iowa of Representative Miller-Meeks. Why is that?
Why are you silent on that, yet you are not silent on other
elections?
Mr. Zuckerberg. Congressman, I think what we saw leading up
to January 6 was unprecedented in American history, where you
had a sitting President trying to undermine the peaceful
transfer of power----
Mr. Carter. You determined which one is important and which
one is not. This seat to these people who elected this duly
certified representative, this is the most important thing to
them as well.
Mr. Zuckerberg. Congressman, I think part of what made the
January 6th events extraordinary was not just that the election
was contested, but that you got folks like the President----
Mr. Carter. What--OK. Let me ask you this: What is it that
makes this particular issue irrelevant, that you are not even
covering it?
Mr. Zuckerberg. Congressman, I didn't say that it is
irrelevant. But on January 6th, we had insurrectionists storm
the Capitol, leading to the death of multiple people.
Mr. Carter. My time is--Mr. Zuckerberg, I am aware of that.
I was there. I understand what happened. But again, will you
commit to treating this as a serious election concern? What is
going on----
Mr. Zuckerberg. Congressman, we--I will commit to that. And
we apply our policies to all situations. And I think that this
is different from what happened on January 6th, but we apply
our policies equally in these cases.
Mr. Carter. Mr. Dorsey, you, too, have been very silent on
this issue on your platform. Will you commit to treating this
as a serious concern, the attempted theft of the certified seat
in Iowa?
Mr. Dorsey. Yes. We are looking for all opportunities to
minimize anything that takes away from integrity of elections.
Mr. Carter. OK. Mr. Dorsey, while I have got you, let me
ask you: You have started a new program. It is called the Bird
Watch, and it allows people to identify information in tweets
that they believe is misleading. And they write notes to
provide context in an effort to stop misleading information
from spreading.
Have you seen--we have seen mobs of Twitter users cancel
others. And even when the information they share is accurate,
why do you think Bird Watch is going to work, given the culture
that you created on your platform?
Mr. Dorsey. Well, it is an experiment. We wanted to
experiment with a more crowdsourced approach than us going
around and doing all this work.
Mr. Carter. Don't you think that is kind of a dangerous
experiment, when you are taking off true information?
Mr. Zuckerberg. No. It is an alternative. And I think----
Mr. Carter. An alternative.
Mr. Dorsey. I think we need to experiment as much as
possible to get to the right answers. I think it states----
Mr. Carter. OK. Well, that is fine as long as you are not
the one being experimented on, as long as you are not the one
that the information is going----
Mr. Doyle. The gentleman's time is expired.
The Chair announces that we are going to take a recess now
for 15 minutes. So the committee will stand in recess until
3:18, and then we will come back promptly. I call the committee
in recess.
[Recess.]
Mr. Doyle. OK. I will call the committee back to order and
ask all Members and witnesses to come back online.
[Pause]
Mr. Doyle. We will get started. The Chair recognizes Mrs.
Dingell for 5 minutes.
Mrs. Dingell. Thank you, Mr. Chairman. Thanks for having
this hearing, and to everyone for testifying today.
We can all agree that social media companies have a
responsibility to reduce and eliminate the impact of
disinformation on their platforms. Mr. Zuckerberg, in the fall
of 2020 you made numerous assurances to Congress that you had a
handle on militia and conspiracy networks. We know, however,
that Facebook private groups and the algorithms that recommend
them have assisted in radicalizing users and facilitated
terrorism, violence, and extremism against individuals,
including the Governor of my State of Michigan. Racial and
ethnic minorities, including Muslims and, recently, Asian
Americans, are facing growing racist hate online and violence
offline. Last year I sent you multiple letters about these
issues, so I know you are aware of them.
In October of 2020, Facebook temporarily decided to stop
recommending political or civic groups on its platforms, a
change it has now made permanent. But to be honest, despite
what you did in October, we had an insurrection that stormed
the Capitol on January 6.
I seriously question Facebook's commitment to actually
stopping extremism. In a recent investigative report, a former
Facebook AI researcher said he and his team conducted study
after study confirming the same basic idea: Models that
maximize engagement increase polarization. And you yourself
have said that the more likely content is to violate Facebook
community standards, the more engagement it generally receives.
Engagement is the key to Facebook's growth and success, and the
stock markets rewarded you for it even as you have been
criticized for promoting extremism and racist content,
including in a 2020 Facebook civil rights audit. The two seem
to go hand in hand. As Facebook was also the most cited social
media site in charging documents that the Justice Department
filed against the Capitol insurrectionists.
Mr. Zuckerberg, do you still maintain that the more likely
user content is to violate Facebook community standards, the
more engagement it will receive? Yes or no?
Mr. Zuckerberg. Congresswoman, thanks for raising this
because I think that there has been a bunch of inaccurate
things about this shared today.
Mrs. Dingell. OK.
Mr. Zuckerberg. There seems to be a belief--------
Mrs. Dingell. Yes or no?
Mr. Zuckerberg. Sorry. This is a nuanced topic. So if you
are OK with it, I would like to----
Mrs. Dingell. You have to keep it short. But I will give it
a second since I want to----
Mr. Zuckerberg. Sure. So----
Mrs. Dingell [continuing]. That is a victim of this hate.
Mr. Zuckerberg. People don't want to see misinformation or
divisive content on our services. People don't want to see
clickbait and things like that. While it may be true that
people might be more likely to click on it in the short term,
it is not good for our business or our product or our community
for this content to be there. It is not what people want, and
we run the company for the long term with a view towards 10 or
20 years from now.
And I think that we are highly aligned with our community
in trying to not show people the content that is not going to
be meaningful to them.
Mrs. Dingell. OK, Mr. Zuckerberg. I am going to--I only
have 2 minutes left. Do you still agree with the statement in
Facebook's most recent 10-K filing that the first risk related
to your product offerings is ``our ability to add and retain
users and maintain levels of user engagement with our
products''? Just a yes or no, please.
Mr. Zuckerberg. Congresswoman, I think that that is
generally right. I mean, for any product, the ability to
building something that people like and use is something that
is a risk if we can't do that.
Mrs. Dingell. OK. So do you still agree with the statement
of your CFO on a recent earnings call that the changes to group
recommendations so far wouldn't affect your engagement? Yes or
no?
Mr. Zuckerberg. Congresswoman, there are so many different
parts of the service that I think it is probably right----
Mrs. Dingell. Can I just----
Mr. Zuckerberg [continuing]. That not recommending
political or civic groups probably isn't going to meaningfully
decrease engagement. But we have taken a lot of HR steps,
including reducing viral videos by about 50 million hours of
watching a day, which have had a meaningful impact on
engagement. But we do that because it helps make the service
better and helps people like it more, which I think will be
better for both the community and our business over the long
term.
Mrs. Dingell. OK. Mr. Zuckerberg, I am sorry to have to do
this in 5 minutes. But given your promises in the fall, the
events that transpired on January 6, and your two incentives
that you yourself admit, I find it really difficult to take
some of these assurances you are trying to give us today
seriously.
I believe that regulators and independent researchers
should have access to Facebook and other large social media
platforms' recommendation algorithms, not just for groups but
for any relevant feature that can be exploited or exploit
private user data collected by the company to support
extremism. And I support legislation to do so.
Mr. Zuckerberg, given your inability to manage your
algorithms or your unwillingness to reduce controversial
content, are you opposed to a law enabling regulators to access
social media algorithms or other information technology that
result in the promotion of harmful disinformation and extremist
content?
Mr. Zuckerberg. Well, Congresswoman, while I don't
necessarily agree with your characterization, I do think that
giving more transparency into the systems is an important
thing. We have people working on figuring out how to do this.
One of the nuances here in complexity is that it is hard to
separate out the algorithms versus people's data which kind of
goes into that to make decisions, and the data is private. So
it is tough to make that public and transparent. But I do think
that this is an important area of study on how to audit and
make algorithms more transparent.
Mr. Doyle. OK. The gentlelady's time is expired.
The Chair recognizes Mr. Duncan for 5 minutes.
Mr. Duncan. Thank you, Mr. Chairman. Let me first say that
Democrats repeating disinformation about the motives of the
murder in Atlanta during a hearing on disinformation is irony
at its worst. The murderer admitted that he was a sex addict.
The problem was addiction, mental illness. While my thoughts
and prayers go out to the families who were impacted by this
hideous crime, it was not a hate crime, and to say so is
disinformation.
Mr. Dorsey, is it OK for a white male to tweet a picture of
a KKK Klansman hood to a black woman?
Mr. Dorsey. No. That would go against our hateful conduct
policy.
Mr. Duncan. Just this week, black conservative commentator
Candice Owens was sent a tweet from a white liberal depicting a
KKK hood. And your support center said that that racist
harassment of a conservative didn't violate your terms of
service. What do you have to say about that?
Mr. Dorsey. We removed that tweet.
Mr. Duncan. OK. Thank you for doing that. Also this week,
Syrian refugee Ahmad Al Aliwi Alissa, a Biden-supporting
Muslim, allegedly murdered 10 people at a grocery store in
Boulder, Colorado. Your support center told Newsweek that
referring to this gentleman as a white Christian terrorist
wasn't a violation of your misinformation policy. What do you
have to say about that?
Mr. Dorsey. I don't know that case, but we can follow up
with you on that.
Mr. Latta. Thank you. Your promises from the last hearing
that you will work on this or make it better rang completely
hollow sometimes, so I ask that you do.
You have censored and taken down accounts of conservatives,
Christian, and even pro-life groups. At the same time,
liberals, tyrants, and terrorists continue to have unfettered
access on Twitter. You were able to take down the account of a
sitting United States President while he was still President.
But you continue to allow State sponsors of terror to use
Twitter as a platform, including the Ayatollah Khoumeini, Javad
Zarif of Iran, or even Bashar al-Assad of Syria.
You act like judge and jury and continue to hide behind the
liability protections in Section 230 of the Communications
Decency Act, which Congress set up to foster a free and open
internet. You think you are above the law because, in a sense,
Congress gave you that power, but Congress gave you that
liability shield to one end: that was the protection of
innocent children. Catherine McMorris Rodgers knocked it out of
the park today, hammering the point where children are
vulnerable.
But let's look at the John Doe vs. Twitter case that is
ongoing right now. According to the National Center on Sexual
Exploitation, a teenage boy, a victim of child sex trafficking,
had images of his abuse posted on Twitter. One of those videos
went viral, and he became the target of bullying to the point
of being suicidal. He contacted you to alert you that his sex
abuse images were on your platform. You failed to take them
down. His mother contacted you to alert you, and again you
failed to take them down.
They called the police and they followed up with you with a
police report. Your support center told the family that, after
review, the illegal video was not a violation of your terms of
service. In the meantime, the illegal video accrued over
167,000 views.
It took a threat from a Homeland Security agent to get
Twitter to take down the video. Even then you took no action
against the accounts that were sharing it and continue to share
sexually explicit videos of minors in clear violation of the
law and in clear violation of your duties under Section 230 of
the Communications Decency Act, as they were passed.
So in the eyes of Twitter, it is better to be a pedophile
pornographer, a woke racist, or a state sponsor of terror than
it is to be a conservative, even a conservative President. You
have abused the Section 230 liability shield we gave you to
protect children and used it to silence conservatives instead.
As we have heard today, your abuses of your privilege are
far too numerous to be explained away and far too serious to
ignore. So it is time for your liability shield to be removed--
your immunity shield and the immunity shield of other woke
companies who choose to score political points with their
immunity shields rather than protect children.
My colleagues have been asking you if you deserve to
continue to receive immunity under Section 230. Let me answer
the question for you: No, you don't. You all think you do, but
you don't because you continue to do a disservice to that law
and its intent.
The United States Constitution has the First Amendment, and
that should be your guide. Protecting the speech of users of
your platform instead of trading them in like hostages and
forcing things through algorithms to lead them down a path.
The American people really are tired of you abusing your
rights, abandoning their values. So one of the Christian
leaders that you banned, Mr. Dorsey, had as her last post a
Scripture verse that you took down. And I want to leave it here
today, Psalm 34:14. ``Depart from evil and do good; seek peace
and pursue it.'' Rather than silence that wise advice, I
strongly suggest that you follow it.
Now, I have heard a lot of stuff on this hearing today
about 230 protections. I challenge my colleagues to really get
serious about doing something about this liability shield so
that we do have a fair and free internet and people aren't
censored.
With that, Mr. Chairman, I yield back.
Mr. Doyle. The gentleman's time is expired.
The Chair recognizes Ms. Kelly for 5 minutes.
Ms. Kelly. Thank you, Mr. Chair. Thank you to the witnesses
who are testifying today.
The business model for your platforms is quite simple: Keep
users engaged. The more time people spend on social media, the
more data harvested and targeted ads sold. To build that
engagement, social media platforms amplify content that gets
attention. That can be cat videos or vacation pictures, but too
often it means content that is incendiary, contains conspiracy
theories or violence.
Algorithms in your platforms can actively funnel users from
the mainstream to the fringe, subjecting users to more extreme
content, all to maintain user engagement. This is a fundamental
flaw in your business model that mere warning labels, temporary
suspension of some accounts, and even content moderation cannot
address. And your company's insatiable desire to maintain user
engagement will continue to give such content a safe haven if
doing so improves your bottom line.
I would like to ask my first question of all the witnesses.
Do each of you acknowledge that your company has profited off
harmful misinformation, conspiracy theories, and violent
content on your platform? Just say yes or no. Starting with Mr.
Dorsey, yes or no?
Mr. Dorsey. No. That is not our business.
Ms. Kelly. Mr. Zuckerberg?
Mr. Zuckerberg. No, Congresswoman. I don't think we profit
from it. I think it hurts our service.
Ms. Kelly. Mr. Pichai?
Mr. Pichai. Congresswoman, it is certainly not our intent,
and we definitely do not want such content. And we have clear
policies against it.
Ms. Kelly. Well, since you all said no, can you please
provide to me in writing how you manage to avoid collecting
revenue from ads either targeted by or served on such content?
So I will be expecting that.
There is a difference between a conversation in a living
room and one being pumped out to millions of followers, from
discouraging voting and COVID-19 misinformation to encouraging
hate crimes. The harms are real and disproportionate.
Do you acknowledge that such content is having especially
harmful effects on minorities and communities of color? Yes or
no again? I don't have a lot of time, so yes or no? Mr. Dorsey?
Mr. Dorsey. Yes.
Ms. Kelly. Mr. Pichai?
Mr. Pichai. Yes.
Ms. Kelly. Mr. Zuckerberg?
Mr. Zuckerberg. Yes. I think that's right.
Ms. Kelly. Thank you. If your financial incentive is that
human psychology leads to the creation of a system that
promotes emotionally charged content that is often harmful, do
you believe that you can address the--do you believe that you
will always need to play Whac-a-mole on different topics? Mr.
Zuckerberg?
Mr. Zuckerberg. Congressman, I do think that we can take
systematic actions that help to reduce a large amount of this.
But there will always be some content that gets through those
systems that we will have to react to.
Ms. Kelly. Mr. Dorsey?
Mr. Dorsey. That is not our incentive, but I agree with
Mark. Our model is to constantly integrate. We are going to
miss some things, and we will go too far in some cases.
Ms. Kelly. Mr. Pichai?
Mr. Pichai. I agree largely with what Mark and Jack said.
And we--a lot of channels, we remove thousands of misleading
election videos. There are many involving threats, and we are
very vigilant.
Ms. Kelly. OK. More transparency and research into the AI
models you use is needed. I understand that they are constantly
evolving and proprietary. However, those obstacles must not be
insurmountable. Would you agree to some type of test bed to
evaluate your procedures and technology for disparate impacts?
And would you welcome minimal standards set by the government?
I only have 44 seconds.
Mr. Dorsey. I will go. You are not calling us. But we--yes,
we are interested in opening all this up and going a step
further in having a protocol. I don't think that should be
government-driven, but it should be open and transparent that
the government can look at it and understand how it works.
Mr. Zuckerberg. I agree that this is an area where research
would be helpful. And I think some standards, especially
amongst the civil rights community, would be helpful guidance
for the companies.
Mr. Pichai. Congresswoman, we work with many third parties.
I just mentioned the HUD collaboration we had. Definitely would
be open to conversations about minimum standards. It is an
important area.
Ms. Kelly. Thank you. I yield back.
Mr. Doyle. The gentlelady's time is expired.
The Chair now recognizes Mr. Dunn for 5 minutes.
Mr. Dunn. Thank you very much, Mr. Chairman.
Many of the questions today deal with personal arms. But
there are long-term economic and security arms to our country I
would like us to keep in mind as well.
I represent Florida's 2nd Congressional District, which is
proud to host a large presence of the U.S. military, including
civilian support companies. One of these is Applied Research
Associates, which is doing great work with our military in the
field of artificial intelligence and machine learning.
I agree with our Nation's top national security experts on
the critical importance of the United States maintaining its
competitive edge in AI. And I share the concern of former
Google CEO Eric Schmidt, who warned just a few weeks ago of the
grave consequences should we lose that edge to China.
Leader Rodgers led a bipartisan bill enacted last year, the
American Compete Act, to lay out clear AI strategy. We all
recognize that China is not a good place to do business,
evidenced by the fact that all of your respective main products
and services are banned there. It is clear that the influence
of the Chinese Communist Party permeates the entire corporate
structure in China. Xi Jinping himself stated his goal of
integrating the party's leadership into all aspects of
corporate governance.
Let's be clear with each other. It is impossible to do
business in China without either directly or indirectly aiding
the Chinese Communist Party. It is also important to state for
the record that each of your business models involve collecting
data from individuals who use your product and then using that
data for some other purpose.
Mr. Pichai, I am deeply concerned with Google's pursuit of
and investment in artificial intelligence research in China,
widely reported over the last few years. First and foremost,
can you assure Americans that their personal data, regardless
of how you think you have de-identified it--data you collect
when they use Google and which is central to your algorithms--
is not used in your artificial intelligence collaboration with
the Chinese Government?
Mr. Pichai. Congressman, I want to correct any
misperceptions here. We do not have an AI research center in
China now. We had a limited presence working on open source
projects, primarily on open source projects and around K
through 12 education with a handful of employees. We don't have
that anymore. Compared to our peers, we don't offer our core
services in China, products like search, YouTube, Gmail, et
cetera.
Mr. Dunn. I am going to have to reclaim my time because it
is limited. But I want your team to follow up with me because I
am honestly somewhat skeptical. I think you had three centers
there in China. And I want to know more about what they are
doing and also what material they are using.
And I want to be clear. I am not just suggesting that
simply doing business in a country means that you endorse all
their policies. As a former businessman myself, I know the
politics all too often get in the way of what we are trying to
do. However, Google's own list of artificial intelligence
principles states that it will not collaborate on technologies
to gather or use information for surveillance, violating
international accepted norms or contravenes widely accepted
principles of international law and human rights.
We know that the Chinese Communist Party is using
artificial intelligence technology to spread misinformation and
suppress the prodemocracy movement in Hong Kong as well as
using that technology in its genocidal crimes against the
Uyghurs, including murdering them for their organ harvesting.
Once again, can you be sure that none of the work you are
doing in collaboration with the Chinese Government is not
aiding them in this ability?
Mr. Pichai. Congressman, happy to follow up and clarify the
limited work on AI we undertake. It is primarily around open
source projects. And very happy to engage and very specifically
follow up on what we do.
Mr. Dunn. Well, I think that is great. And I know I am
running out of time here, but I ask that we continue this
dialogue. And I think Google would be very well served by
promoting greater transparency in all of its actions regarding
artificial intelligence in China. Your customers have a right
to know about this.
In 2018, Diane Greene, former CEO of Google Cloud, noted,
``We believe the uses of our cloud and artificial intelligence
will prove to be overwhelmingly positive for the world. But we
also recognize we cannot control all downstream uses of our
technology.''
Well, a good place to start would be to end this dangerous
artificial intelligence research relationship with China. So
with that, Mr. Pichai, thank you. Thank you, all the members of
the witness panel.
And Mr. Chairman, I yield back.
Mr. Doyle. The gentleman yields back.
The Chair recognizes Mr. McEachin for 5 minutes.
Mr. McEachin. Thank you, Mr. Chairman. And to you and
Chairman Pallone and Chairwoman Schakowsky, thank you for
convening today's hearing and for our witnesses for joining us.
In July of last year, I led more than 30 of my colleagues,
including several on this committee, in a letter to your
companies asking what you were doing to halt the spread of
climate change disinformation on your platforms. As my
colleagues and I clearly expressed in our letter, climate
change is a real and urgent threat, and the spread of
disinformation on your platforms is underlining that fact.
For instance, the World Health Organization estimates that
climate change causes 150,000 deaths annually, a number that
will only increase in the coming years. All this begs a simple
question: Why do your platforms not treat climate change
disinformation with a sense of immediacy and alarm?
Mr. Zuckerberg, Facebook recently implemented the Climate
Change Information Center, which directs users to a landing
page with climate change facts from researchers and
organizations. Are you able to share data on how widespread a
problem climate change disinformation is on your platform and
how much the Climate Change Information Center has reduced it?
Mr. Zuckerberg. Sure. Thanks, Congressman. Our approach to
fighting misinformation--of which climate misinformation, I
think, is a big issue, so I agree with your point here. We take
a multipronged approach. One is to try to show people
authoritative information, which is what the Climate
Information Center does.
But then we also try to reduce the spread of misinformation
around the rest of the service through this independent third-
party fact-checking program that we have in which one of the
fact-checkers is specifically focused on science feedback and
climate feedback type of issues.
Overall, I would be happy to follow up and share more
details on what we have seen across those. But this is
certainly an area that I agree is extremely important and needs
multiple tactics to address.
Mr. McEachin. Well, thank you. And it is my understanding
that this climate center was modeled after your COVID-19
Information Center. However, different standards still apply
for both organic content and paid-for advertising for climate
change versus COVID-19.
Why does Facebook not apply the same standards of fact-
checking on climate change that it does on COVID-19 content?
Mr. Zuckerberg. Congressman, you are right that the Climate
Information Center was based off our work on the COVID
Information Center and Election Information Center. In terms of
how we treat misinformation overall, we divide the
misinformation into things that could cause imminent physical
harm--of which COVID misinformation that might lead someone to
get sick or hurt or vaccine misinformation falls in the
category of imminent physical harm--and we take down that
content.
Then other misinformation are things that are false but may
not lead to imminent physical harm. We label and reduce their
distribution but leave them up. So that is the broad approach
that we have, and that sort of explains some of the differences
between some of the different issues and how we approach them.
Mr. McEachin. Mr. Pichai--and I hope I am pronouncing that
correctly, sir--YouTube has employed contextualization tools
linking viewers to similar sources as Facebook's Climate
Center. That being said, you restricted but have not removed
some repeat offenders from your platform such as Prager
University, a nonaccredited university producing climate change
denial content.
Are you not concerned that by restricting those videos and
not removing repeat offenders, that people who are determined
to find those videos to validate their fears will indeed find
them and share them with others?
Mr. Pichai. Congressman, it is an incredibly important
area. In general, in these areas we rely on raising
authoritative information, both by showing information panels
as well as raising scientific content, academic content, and
journalistic content so our algorithms rank those types of
content higher for an area like climate change, similar to
election integrity and COVID.
And obviously it is an area where there is a range of
opinions people can express. We have clear policies, and if it
is violative, we remove. If it is not violative but if it is
not deemed to be of high quality, we don't recommend the
content. And that is how we approach it, and we are committed
to this area as a company.
We lead in sustainability. We have committed to operating
24/7 on a carbon-free basis by 2030. And it is an area where we
are investing significantly.
Mr. McEachin. Well, thank you. I have run out of time. Mr.
Dorsey, I apologize to you. Perhaps we will have an opportunity
to have a conversation.
Mr. Chairman, I give you my 2 seconds.
Mr. Doyle. I thank the gentleman. The gentleman yields
back.
The Chair now recognizes Mr. Curtis for 5 minutes.
Mr. Curtis. Thank you, Mr. Chairman. And thank you to our
witnesses.
My first comment is to point out that in her 2019
Presidential campaign, Senator Elizabeth Warren, Democrat,
called for the breaking up of your companies. Several weeks
ago, in a speech at CPAC, Senator Josh Hawley, Republican, also
said that Big Tech companies should be broken up. I don't think
I need to point out the irony of Josh Hawley validating
Elizabeth Warren at CPAC.
There seems to be a train wreck coming. Unfortunately, the
very few tools that we have in our tool bag are regulation and
breaking up. Mr. Zuckerberg, I read through your terms of
service, including the dense community standards document. In
your terms of service, you state that you cannot control and do
not take responsibility for content posted on your platform.
The community standards document, which is frequently cited
as why content is or is not censored, says you sometimes make
content moderation decisions based off what is considered best
for the public interest or public discourse.
I know in your testimony you said that companies need to
earn their liability protections. That is great. But that
doesn't address the concerns people understandably share about
your past or current views on what is or is not acceptable.
How do you claim you cannot take responsibility and
therefore should maintain your liability protections for
content posted on your site, but at the same time state that
your platform or monitored content based off what is in the
public's best interest? That appears to be two-sided.
Mr. Zuckerberg. Congressman, thanks. People use our
services to share and send messages billions of times a day.
And it would be impossible for us to scan or understand
everything that was going on, and I don't think that our
society would want us to take the steps that would be necessary
to monitor every single thing. I think that we would think that
that would infringe on our freedoms.
So broadly, I think it is impossible to ask companies to
take responsibility for every single piece of content that
someone posts, and that, I think, is the wisdom of 230. At the
same time, I do think that we should expect large platforms to
have effective systems for being able to handle, broadly
speaking, categories of content that are clearly illegal.
So we have talked today about child exploitation and
opioids and sex trafficking and things like that. And I think
it is reasonable to expect that companies have systems that are
broadly effective, even if they are not going to be exactly
perfect, and there are still going to be some pieces of content
that inevitably get through, just like no police department in
the city is able to eliminate all crime.
Mr. Curtis. I am going to jump in only because we are out
of time. I would love to spend more time on that with you.
Let me also ask you. Utah is known for Silicon Slopes, our
startup community. You have called for government regulation,
but some view this with skepticism because larger companies
tend to deal with regulation much better than small companies.
If you think back to your college days, the early startup
phase of Facebook, what challenges do you see for startups to
compete and what cautions should Congress consider as we look
at regulations that potentially could be a barrier for
companies that might be your future competition?
Mr. Zuckerberg. Thanks. I think that this is a really
important point whenever we are talking about regulation. And I
want to be clear that the recommendations that I am making for
Section 230 I would only have applied to larger platforms.
I think it is really critical that a small platform, the
next student in a dorm room or in a garage, needs to have a
relatively low--as low as possible regulatory burden in order
to be able to innovate and then get to the scale where they can
afford to put those kind of systems in place. So I think that
that is a really important point to make.
But I think that that goes for the content discussions that
we are having around 230. It probably also applies to the
privacy law that I hope that Congress will pass this year or
next year to create a Federal U.S. privacy standard. And I also
think that we should be exploring proactively requiring things
like data portability that would make it easier for people to
take data from one service to another.
Mr. Curtis. I want to thank you. I have got just a few
seconds left. And Mr. Pichai, this is a little bit off topic so
I am simply going to ask this question and submit it for the
record and not ask for a response.
Almost a decade ago your company started Google Fiber. You
introduced Kid Speed and free internet to all the residents of
my home city, Provo, Utah. Sadly, it seems like your efforts to
do this across the country were slowed down or even stopped by
excessive government regulations. I would love you to share off
the record--and I will submit it for the record--why government
is making it so hard to expand internet across the country.
Thank you, Mr. Chairman, and I yield my time.
Mr. Doyle. The gentleman yields back.
The Chair recognizes Mr. Soto for 5 minutes.
Mr. Soto. Thank you, Mr. Chairman.
When television, radio, traditional newspapers, political
blogs, and even private citizens spread lies, they can be sued
and held liable for damages or FCC fines. But pursuant to 230,
you all can't be sued. You have immunity. But it ain't 1996
anymore, is it? Meanwhile, lies are spreading like wildfire
through platforms. Americans are getting hurt or killed. And
the reason is your algorithms.
I want you to all know I was held captive in the gallery
during the Capitol insurrection. I was surrounded by domestic
terrorists that killed a Capitol police officer, ransacked the
Capitol, and almost disrupted a Presidential election. And many
of these domestic terrorists plotted on your platforms. I think
we all understand by now this violence is real. And so this is
why we are here today, in the committee of jurisdiction, with
power to protect our fellow Americans.
Mr. Zuckerberg had mentioned effective moderation systems.
So now we know you have systems that can prevent many of these
harms. Thank you for your statements supporting accountability
today, and even for championing support of accountability now.
So the question is: What specific changes to Section 230 do
you support to ensure more accountability? Mr. Zuckerberg just
mentioned categories of content that are clearly illegal, U.S.
privacy standards, and data portability as three standards we
should be looking at.
Mr. Pichai, should we be creating these standards and then
holding platforms accountable if they violate them under 230?
Mr. Pichai. Congressman, first of all, there are many ways
and there are many laws today which do hold us liable. FTC has
oversight, we have a consent decree with the FCC, COPPA, HIPAA,
et cetera, and for example areas where there are privacy laws,
and we have called for Federal privacy legislation, but in
Europe, the GDPR. In California, we have privacy State
legislation. We are both accountable as well as we are subject
to private plaintiff action against these statutes.
Mr. Soto. So Mr. Pichai, you agree with these categories
that were just outlined by Mr. Zuckerberg. Is that correct?
Mr. Pichai. I definitely think what Mark is talking about
around lines of transparency and accountability are good
proposals to think through. There are various legislative
proposals, among those----
Mr. Soto. Excuse me. My time is--Mr. Dorsey, do you think
we should be establishing categories of content that are
clearly illegal, U.S. privacy standards, and data portability,
as well as penalties for violation of those standards?
Mr. Dorsey. I believe, as we look upon 230 and evolutions
of it, inputting upon it, I think we need more transparency
around content moderation practices, not just policies. I think
we need more robust appeals processes. And I think the real
issue is algorithms and giving people more choice around
algorithms, more transparency around algorithms. So if there is
any one I would pick, it would be that one. It is a tough one,
but it is the most impactful.
Mr. Soto. Thank you, Mr. Dorsey.
Mr. Zuckerberg, political misinformation spread rampantly,
unfortunately, in Spanish in Florida's Hispanic community on
Facebook in the 2020 Presidential election even with the
political ad ban. How do you think this happens? Mr.
Zuckerberg?
Mr. Zuckerberg. Congressman, it is--I do still think that
there is too much misinformation across all of these media that
we have talked about today. How did it happen? I mean, it is--I
think we have talked to a lot today about algorithms. I
actually think a lot of this stuff happens in what we refer to
as deterministic products like messaging, right? Someone sends
a text message to someone else. There is no algorithm there
determining whether that gets delivered. People can just send
that to someone else.
A lot of this stuff, I think, unfortunately was amplified
on TV and in traditional news as well. There was certainly some
of this content on Facebook, and it is our responsibility to
make sure that we are building effective systems that can
reduce the spread of that. I think a lot of those systems
performed well during this election cycle. But it is an
iterative process, and there are always going to be new things
that we will need to do to keep up with the different threats
that we face.
Mr. Soto. Mr. Zuckerberg, will you commit to boosting
Spanish-language moderators and systems on Facebook, especially
during election season, to help prevent this from happening
again in Spanish language?
Mr. Zuckerberg. Congressman, this is already something that
we focus on. We already beefed up and added more capacity to
Spanish language fact-checking and Spanish language
authoritative information resources. And that is certainly
something that we hope to build on in the future. So the answer
to your question is yes.
Mr. Doyle. The gentleman's time is expired.
The Chair now recognizes Mrs. Lesko for 5 minutes.
Mrs. Lesko. Thank you, Mr. Chair, and thank you to the
witnesses.
I represent constituents in the great State of Arizona, and
most of my constituents just want to be treated fairly,
equitably, impartially, and they want to make sure that their
private information stays private.
Mr. Pichai, does Wikipedia influence Google's search
results?
Mr. Pichai. We do index, and Wikipedia is in our index. And
for certain queries, if an answer from Wikipedia rises to the
top of our ranking, yes, we do rely on it.
Mrs. Lesko. Thank you.
Mr. Dorsey, did you personally decide to ban President
Trump from your platform?
Mr. Dorsey. We have a process that we go through to get
there, and that came after a warning.
Mrs. Lesko. And did you make the final decision?
Mr. Dorsey. Ultimately, I have final responsibility.
Mrs. Lesko. Thank you.
And Mr. Pichai, in July 2018 the Wall Street Journal
reported that Google let hundreds of outside developers scan
the inboxes of millions of Gmail users. Mr. Pichai, do Google
employees review and analyze Gmail users' content?
Mr. Pichai. Congresswoman, we take privacy very seriously.
We don't use the data from Gmail for advertising, and our
employees generally do not access it, only in narrow cases,
either to troubleshoot with the right consent and permissions.
There are prohibitions with enough checks and balances.
Mrs. Lesko. So I think what you are saying is occasionally
your Google employees do review and analyze.
I have another question regarding that. Does Google share
Gmail users' emails or analysis of your emails with third
parties?
Mr. Pichai. We do not sell any data. I think what you are
referring to is users could give API access to third-party
developers--for example, there are applications which could
give travel-related information. So this is a user choice, and
it is an API on top of the platforms. We have done numerous
steps to make sure users have to go through multiple steps
before they would give consent to a third party.
Mrs. Lesko. And so I have looked through your Google
Privacy Statements and User Content, and I still have concerns
about that. I am very concerned. I have Gmail accounts, just
like millions of people, and I don't know if you are looking at
them. I don't know who is looking at them. I don't know who is
sharing them. I don't know what you are doing with them.
Mr. Pichai. If I----
Mrs. Lesko. You make me concerned. Mr.--I only have----
Mr. Pichai. If I could clarify one thing I said there?
Mrs. Lesko. Yes.
Mr. Pichai. Only if a user asks us to troubleshoot an
account, with that user's permission. But we do not look into
users' email contents, and we do not share the contents with
anyone else without the user's asking us to do so.
Mrs. Lesko. However, the Wall Street Journal had this
article saying that hundreds of developers were reviewing the
email contents. So I have to move on to another question
because I only have a short time.
Mr. Dorsey, Twitter denied the Center for Immigration
Studies the ability to promote four tweets that contained the
phrases ``illegal alien'' and ``criminal alien,'' even though
those are the correct legal terms. Mr. Dorsey, if there is a
warning posted related to a border threat, how will Twitter
algorithms react to the use of the word ``illegal'' versus
``undocumented''?
Mr. Dorsey. Well, it isn't about our algorithms. It is
interpretation against our policy and if there are violations.
But we can follow up with you on how we handle situations like
that.
Mrs. Lesko. Well, this is the legal term, is ``illegal
alien.'' That is in law, in legal terms. I don't understand why
you would not allow that. That is the legal, factual term. And
with that, I am going to ask another question.
Mr. Zuckerberg, this has been brought up before. Do you
believe that your platform harms children?
Mr. Zuckerberg. Congresswoman, I don't believe so. This is
something that we study and we care a lot about. Designing
products that improve people's well-being is very important to
us. And what our products do is help people stay connected to
people they care about, which I think is one of the most
fundamental and important human things that we do, whether that
is for teens or for people who are older than that.
And again, our policies on the main apps that we offer
generally prohibit people under the age of 13 from using the
services.
Mr. Doyle. The gentlelady's time is expired.
The Chair now recognizes Mr. O'Halloran for 5 minutes.
Mr. O'Halloran. Thank you, Mr. Chairman. I am enlightened.
Thank you to the panel today.
I am enlightened by what I have heard today: three of the
most knowledgeable business people in the word, with beautiful
profit centers, business models, a sense of the future
direction that your companies want to go in, standards that are
in many cases reliable but others not very much so, and a very
big concern by the Congress of the United States on the
direction you want to go in versus what is good for our Nation
in total.
Mr. Zuckerberg, last October Facebook announced it removed
a network of 202 accounts, 54 pages, and 76 Instagram accounts
for violating your coordinated inappropriate behavior policy. A
really forged network was based in [audio disruption] Arizona
and ran its disinformation operation from 2018 to 2020 by
creating fake accounts and commenting on other people's content
about the 2018 midterm election, the 2020 Presidential
election, COVID-19, and criticism and praise of creation of
certain political parties and Presidential candidates. Sadly,
Facebook only acted after a Washington Post investigation
reported its findings.
While your testimony states since 2017 Facebook has removed
over 100 networks of accounts for engaging in coordinated,
inauthenticated behavior, where did Facebook fail by not
finding this network over the course of a number of years? Mr.
Zuckerberg,
Mr. Zuckerberg. Well, Congressman, we have a team of--I
think it is more than 300 people who work on counterterrorism
at this point, and basically trying to work with law
enforcement and across the industry to basically find these
networks of fake accounts and authentic accounts that are
trying to spread behavior.
And I think we have gotten a lot more effective at this. I
can't say that we catch every single one, but certainly I think
we have gotten a lot more effective, including just this week
we announced that we took down a network of Chinese hackers
that were targeting Uyghur activists outside of China.
So we have gotten more sophisticated at this. Sometimes
when we start finding a lead, we need to wait to kind of see
the full extent of the network so we can take down the whole
network. So that is a tradeoff that sometimes we are able to
discuss with law enforcement and other times not, in terms of
how we do enforcement. But overall, I think this effort has
gotten a lot more sophisticated over the last 4 years.
Mr. O'Halloran. So you are happy with the amount of
personnel that you have working on these issues?
Mr. Zuckerberg. Congressman, I think we have one of the
leading teams in this area. We went from more than----
Mr. O'Halloran. Are you happy with--the question was: Are
you happy with the amount of people you have working, the
capacity that you have to take care of these issues?
Mr. Zuckerberg. Congressman, I think that the team is well-
staffed and well-funded. We spend billions of dollars a year on
these kind of content and integrity and security issues across
the company. So I think that that is appropriate to meet the
charge. And there are always things that we are going to want
to do to improve the tactics of how we find this, and a lot of
that over the last several years has been increasing the work
that we do with law enforcement and the intelligence
community----
Mr. O'Halloran. I am going to move on to another question,
Mr. Zuckerberg. Thank you very much. I do want to say that,
again, you are a bright, intelligent CEO. You know in advance
what you want. Your algorithms are created by your company and
the other companies. You have control over those algorithms.
And so the idea that you have to work maybe in this
direction, Mr. Zuckerberg, Facebook's most recent community
standards enforcement report states that 2.5 million pieces of
content related to suicide and self-injury were removed in the
fourth quarter of 200 due to increased reviewer capacity.
You can do this if you want to do all this stuff. Very
briefly explain what policies Facebook put in place to reviewer
capacity, not just on that issue but across the--how much over
time has this occurred that you continue to increase reviewer
capacity?
Mr. Zuckerberg. Sure, Congressman. The biggest thing that
we have done is automated a lot of this by building AI tools to
identify some of this. So now, for example, more than 98
percent of the hate speech that we take down is done by an AI
and not by a person. I think it is 98 or 99 percent of the
terrorist content that we take down is identified by an AI and
not a person. And you mentioned the suicide content as well,
which I think a high 90s percent is identified by AI rather
than----
Mr. O'Halloran. Mr. Zuckerberg, I am over my time. I want
to thank the chair, and I also want to state very briefly that
you have a lot of work to do, you and your other cohorts on
this panel. Thank you.
Mr. Doyle. The gentleman's time is expired.
The Chair recognizes Mr. Pence for 5 minutes.
Mr. Pence. Thank you, Chairs Doyle and Schakowsky and
Ranking Members Latta and Bilirakis, for holding this joint
subcommittee meeting hearing. And thank you to the witnesses
for appearing before us today.
The extent to which your platforms engulf our lives is
reminiscent to the all-encompassing entities we have seen over
the past century. In the early 1900s, Standard Oil had a
monopoly on over 90 percent of our country's refining business.
By the 1970s, if you used a telephone it was going to be Ma
Bell's system.
In each instance, you could choose not to use either
product. But participation in society demanded that you use
both. In a similar sense, it is difficult if not impossible to
participate in society today without coming across your
platforms and using them. We could choose not to use them, but
like oil and telecommunications, it is considered essential,
and so many other people do use it.
Even the government has become an equal contributor. Each
Member of Congress and every Senator is all but required to use
your platforms to communicate with their constituents while we
are in Washington, DC. I know you understand that your
platforms have a responsibility to act in good faith for
Hoosiers and all Americans.
Unfortunately, regularly my Facebook and Twitter accounts,
like many of my peers and other people I know, are littered
with hateful, nasty arguments between constituents that stand
in complete opposition to the ideas of civil discourse that
your platforms claim to uphold and that you have referenced
today.
I am sure you are aware that official government accounts
have restrictions that significantly limit our ability to
maintain a platform that is a productive resource of
information to the public. They have essentially become a micro
town hall without a moderator on social media.
I agree with all your testimonies that a trust deficit has
been growing over the past several years. And as some of you
have suggested, we need to do something about it now. The way
in which you manage your platforms in an inconsistent manner,
however, has deepened this distrust and devolved the public
conversation.
My constituents in southeast Indiana have told me they are
increasingly mistrustful of your platforms, given how you
selectively enforce your policies. There are just a few
examples of how this has occurred. Members of the Chinese
Communist Party have verified Twitter accounts to regularly
peddle false and misleading claims surrounding the human rights
violations we know are occurring in northern China.
Twitter gives the Supreme Leader of Iran a megaphone to
proclaim derogatory statements endorsing violence against the
U.S. and Western culture. Twitter accounts associated with the
Supreme Leader have called Israel a ``cancerous tumor'' and
called for the eradication of the Zionist regime. This happens
as he also bans the service for his own people to restrict
their free expression.
Mr. Dorsey, clearly you need to do more to address content
that violates your policies. I have two questions for you. Why
is the Chinese Communist Party allowed to continue the use of
your platform after pushing propaganda to cover up human rights
abuses against Muslims in Northern China? And two, why does the
Supreme Leader of Iran still half a platform to make threats
against Israel and America?
Mr. Dorsey. So first and foremost, we do label those
Chinese accounts so that people have context as to where they
are coming from. That is on every single tweet, so people
understand the source. We think that is important.
We are reviewing our world leaders policy. We are actually
taking public comment review right now. So we are enabling
anyone to give us feedback on how----
Mr. Pence. If I may interrupt you quickly, Mr. Dorsey. On
that very point, Iran has been supporting Hezbollah, and it is
not just saber-rattling, as you have made the statement, or
your company has made the statement. They have done serious
damage to whole countries and people, and as I served in the
military, they killed hundreds of Marines many years ago. So I
don't know what you have to study about this.
Mr. Chairman, I yield back.
Mr. Doyle. The gentleman yields back.
The Chair recognizes Miss Rice for 5 minutes.
Miss Rice. Thank you, Mr. Chairman.
Mr. Dorsey, what is winning, Yes or No, on your Twitter
account poll?
Mr. Dorsey. Yes.
Miss Rice. Hmm. Your multitasking skills are quite
impressive.
In December of 2020, the House Committee on Veterans'
Affairs released a report entitled, ``Hijacking Our Heroes:
Exploiting Veterans Through Disinformation on Social Media.'' I
ask unanimous consent, Mr. Chairman, that this report be
submitted for the record.
Mr. Doyle. So ordered.\1\
---------------------------------------------------------------------------
\1\ The report has been retained in committee files and is
available at https://docs.house.gov/meetings/IF/IF16/20210325/111407/
HHRG-117-IF16-20210325-SD028.pdf.
---------------------------------------------------------------------------
Miss Rice. Thank you. I bring up the report today because
it is very--deeply disturbing, the investment of our veterans
and military service members in the violence that took place on
January 6. It is estimated that 1 in 5 people charged in
connection with the attack have served or are currently serving
in the U.S. military.
It should come as no surprise to those testifying today
that for years nefarious actors have learned how to harness the
algorithms on all of your platforms to introduce content to
veterans and military service members that they did not
actively seek out for themselves. Veterans and military service
members are particularly targeted by malicious actors online in
order to misappropriate their voices, authority, and
credibility for the dissemination of political propaganda.
We have to do better for those who have served our country.
Mr. Zuckerberg, do you believe that veterans hold a special
status in our communities and have military training, making
them prime targets for domestic terrorists and our adversaries
seeking to foment insurrection?
Mr. Zuckerberg. Congresswoman, I certainly believe that
veterans hold a special place in our society. I haven't seen
much research----
Miss Rice. Did you see on the National Mall and at the
Capitol there were rioters who arrived in combat gear who were
armed with tactical equipment? Did you see those images, yes or
no?
Mr. Zuckerberg. Yes.
Miss Rice. OK. Have you personally talked to the Iraq and
Afghanistan Veterans of America, IAVA, about disinformation
campaigns targeting veterans?
Mr. Zuckerberg. No, Congresswoman, I have not personally,
although our team certainly is in contact with a number of
these groups as we set up our policies.
Miss Rice. Have you talked to the Vietnam Veterans of
America about disinformation campaigns targeting veterans?
Mr. Zuckerberg. Congresswoman, I can get back to you on
whether our team has consulted with them specifically. But
broadly, what our teams----
Miss Rice. Please do. Do you believe that veterans and
military service members are just like other Americans in that
they are susceptible to the impulses in human psychology that
Facebook exploits to drive engagement? Do you believe that they
are susceptible in that way? Yes or no?
Mr. Zuckerberg. Congresswoman, there is a lot in your
characterization there that I disagree with.
Miss Rice. No, no. It is a question of do you think they
are susceptible to that kind of information coming at them? Yes
or no?
Mr. Zuckerberg. Congresswoman, I believe that----
Miss Rice. OK. So given your answers, I am not convinced
that you have the appropriate resources devoted to the problem
of mitigating the real-world effects of content that is
designed to mislead and radicalize your users, especially those
who are veterans and military service members.
Would you support legislation that would require you to
create an Office of Veterans' Affairs that reports to the CEO
and works with outside veterans service organizations to ensure
our enemies don't gain ground trying to radicalize our brave
men and women who serve in our military? Would you support that
legislation?
Mr. Zuckerberg. Congresswoman, I think the details matter a
lot. So I would be happy to follow up with you or have our team
follow up with your team to discuss this. But in general, I do
think that----
Miss Rice. We will take you up on that, Mr. Zuckerberg. It
is just a broad stroke: Do you believe that you could find your
way to support legislation that would have as its goal the
protection of our military active duty and veterans? In
principle?
Mr. Zuckerberg. I think in principle, I think something
like that could certainly make sense.
Miss Rice. So I wrote to you, Mr. Zuckerberg, last month
requesting information about Facebook's efforts to curb
disinformation campaigns that specifically targeted American
service members and victims. I am just curious if you know how
many public groups with the word ``veteran'' or public pages
with the word ``veteran'' did you remove from your platform
after January 6th in association with misinformation about the
2020 election or the attack on the Capitol?
Mr. Zuckerberg. Congresswoman, I don't know the answer off
the top of my head, but I would be happy to get back to you
with that.
Miss Rice. Thank you. We believe that you should be
tracking that information. Your platform was in fact a crime
scene after January 6, and we need that information and data to
understand how the attack happened.
I want to thank all three of you for coming here today and
spending so much time with us. I yield back, Mr. Chairman.
Thank you.
Mr. Doyle. The gentlelady yields back.
The Chair recognizes Mr. Armstrong for 5 minutes.
Is Mr. Armstrong here? You need to unmute, Kelly.
Mr. Armstrong. All right. Sorry about that. Can you hear
me?
Mr. Doyle. Yes. We can hear you.
Mr. Armstrong. All right. Thank you.
No other industry receives such bipartisan scrutiny--
disinformation, content moderation, deplatforming, antitrust,
privacy, and the list continues to grow. We discuss these
things too often in isolation, but they are all related, and it
starts with the fact that your users aren't your customers.
They are the product. More specifically, the data that you
collect from your users is the product.
You are incentivized to collect and monetize user data for
behavior advertising. This results in the collection of even
more user data. And data is unique as a business asset. It
doesn't deplete. Data is perpetual and reinforcing. Data begets
more data. Massive data collection expands your market share,
which harms competition.
That is why censorship is so concerning to all of us. Your
platforms have a stranglehold on the flow of modern
communication, and I think we absolutely have to resist the
urge of content moderation and censorship. In 1927, Justice
Brandeis wrote: ``The remedy to apply is more speech, not
enforced silence.'' I think that statement still holds true
today.
Yet your platforms don't simply silence certain speech.
Your algorithms are designed to reinforce existing
predispositions because you profit by keeping users locked into
what they already enjoy. This leads to information siloes,
misinformation, extremism on both sides, and even more data
collection, which repeats the cycle.
Mr. Pichai, you testified before the House Judiciary
Committee last year, and at that hearing I raised several
examples of Google's consolidation of the ad tech stack. Your
answers large reiterated the privacy justifications, which I
understand and support. However, my question was whether
Google's consolidation of both the buy and sell sides of
digital advertising would further harm competition.
Since then I have reviewed Google's privacy sandbox and the
FLoC proposal, which is an alternative group identifier to
replace third-party cookies. Again, I understand and I
appreciate the privacy justification. But--and this is my
question: How will these actions not further entrench Google's
digital advertising market share and harm competition?
Mr. Pichai. Congressman, as you rightfully point out,
privacy is really important, and we are trying to get that
correct. Users are giving clear feedback in terms of the
direction they would like to take. Advertising allows us to
provide services to many people who wouldn't otherwise be able
to use services, and we are trying to provide relevant ads,
protecting their privacy. And that is what FLoC is working on.
We will----
Mr. Armstrong. I am going to move on because I understand
the privacy. I understand the privacy. And I understand the
rationale of eliminating individual-level tracking in favor of
cohorts and the potential privacy benefits of user data in CRO
method device level.
But this is still eliminating competitors' access to user
data at a time when you already control 60 percent of the
browser market. I have real concerns that FLoC will incentivize
more first-party data collection, which will not actually
benefit user privacy. Instead of spreading it amongst a lot of
different companies, it will just all be with you. And so I
guess my point is Congress needs to conduct careful oversight
as the privacy sandbox and FLoC are introduced. And we need to
ensure that the user privacy increases and that competition is
not stifled further.
But I do have one question, and it is important. I am going
to ask all three of you. When we are conducting competition
analysis in the tech industry, should nonprice factors like
privacy be considered? And I will start with you, Mr. Pichai.
Mr. Pichai. I think so. I think privacy is very important,
and we have called for comprehensive Federal privacy
legislation. And to clarify, Google doesn't get any access to
FLoC data. It is protected. And then we will publish more
papers on it.
Mr. Armstrong. All right. And I understand completely. But
you are forcing--I mean, you are forcing advertisers into the
ad stack. I mean, that is--I don't discount it increases
privacy. That is not--I think this is a real problem because I
think they are in conflict with each other.
But Mr. Dorsey, do you think when we are conducting
competition analysis in the tech industry, nonprice factors
should be considered?
Mr. Dorsey. Not sure exactly what you mean, but open to
further discussion on it.
Mr. Armstrong. All right. How about you, Mr. Zuckerberg?
Mr. Zuckerberg. Yes, Congressman. My understanding is that
the law already includes the quality of products in addition to
price.
Mr. Armstrong. And I will just say I appreciate you talking
about the difference between big platforms and small platforms
because I think in our history of trying to regulate big
companies, Congress has already done a really good job at
harming the smaller companies worse.
And with my last 6 seconds because this isn't the
appropriate hearing, but I am going to ask: Please all do a
better job of making sure artists get paid for their work on
your platforms. And with that, I yield back.
Mr. Doyle. The gentleman yields back.
The Chair recognizes Mr. Veasey for 5 minutes.
Mr. Veasey. Thank you, Mr. Chairman.
It has often been said that lies travel faster than truth,
and we have seen that play out with devastating consequences on
social media platforms today. This concerns me greatly, not
just as a father or a lawmaker but as someone ready to see the
past divisions that have dominated our country for the past
several years, and really decades, really.
But it is hard to see how this can change when the CEOs of
the largest social media platforms repeatedly say they will fix
their ways, only to keep spreading harmful lies and
misinformation. I want to give you an example.
Last August here in the Dallas/Fort Worth area, the North
Texas Poison Control Center felt the need to warn people
against ingesting bleach or other disinfecting products as a
cure to prevent COVID-19. Despite efforts of your companies to
take down such harmful mis- or disinformation calls to the
North Texas Poison Control Center about disinfectant, ingestion
rates were much higher than usual and statewide calls about
bleach products were up over 70 percent compared to the year
before. The North Texas Poison Center pointed this out largely
to misinformation online as the cause for these increases.
And as we know, in the lead-up to the last elections Black
communities were specifically targeted for disinformation
campaigns designed to suppress the vote, especially in
battleground States. And right now there are sites up that are
discouraging Black people from getting the COVID-19
vaccination. I know a lady that was put in Facebook jail for 30
days because all she did was repost one of the faulty posts
saying Black folks aren't falling for this business, and she
was put in Facebook jail for 30 days.
Now, even if these posts were eventually taken down or
otherwise labeled as false, again, lies travel a lot faster
than truths. Your companies have been largely flat-footed when
it comes to getting out ahead of these issues, and it is time
for something to change.
That is why I am exploring legislation that would establish
an independent organization of researchers and computer
scientists who could help by identifying and warn about
misinformation trends before they become viral. This early-
warning system would help social media sites, the public, and
law enforcement so that when dangerous conspiracies or
disinformation is spreading, they can be on alert and hopefully
slow its effect.
Mr. Zuckerberg, would you support legislation that would
alert all Facebook or Instagram users of harmful disinformation
and conspiracy theories spreading across your platforms?
Mr. Zuckerberg. Congressman, I think we need to look into
that in more detail to understand the nuances. But in general,
I agree that it is our responsibility to build systems that can
help slow the spread of this kind of misinformation. And that
is why we have taken all the steps that I have outlined today,
from building in an unprecedented independent fact-checking
program to taking down content that could cause imminent
physical harm to the work in the COVID Information Center and
the Voting Information Center and the Climate Information
Center to promote authoritative information across our
services. So I certainly think that there is a lot to do here.
Mr. Armstrong. Mr. Dorsey, would you support legislation
for an early-warning system across Twitter?
Mr. Dorsey. I would be open to reviewing the details. I
just don't think it will be effective. And it will be very much
Whac-a-mole. I think that the more important thing is to, as I
said in my opening remarks, get much more of an open standard
and protocol that everyone can have access to and review.
Mr. Armstrong. And Mr. Pichai? For Google and YouTube and
that? I have a 14-year-old at home that watches YouTube. What
about you for those platforms?
Mr. Pichai. Already today in many of these areas, we show,
proactively, information panels. So for example on COVID, we
have showed a lot of information from CDC and other experts,
and we had views of over 400 billion. And so conceptually,
showing proactive information, including information panes, I
think makes sense to me.
Mr. Armstrong. OK. Well, thank you. I appreciate the time,
Mr. Chairman. I am worried. I think that we need to act quickly
and that we are running out of time and that we need these
companies to take affirmative action on addressing some of
these issues.
I yield back my time. Thank you.
Mr. Doyle. I thank the gentleman. The gentleman yields
back.
The Chair now yields 5 minutes to Ms. Craig.
Ms. Craig. Thank you so much, Mr. Chair.
Mr. Zuckerberg, thank you so much for joining us today. As
cochair of the LGBTQ Equality Caucus in the U.S. Congress, I
would like to ask you a few questions about an incident that
occurred several weeks ago now. And I would appreciate a simple
yes-or-no answer. Most of these have absolutely no room for
nuance. These aren't trick questions. I would just like to
clarify a few facts.
So on February 25th, Facebook took down a video hosted by
my colleague Representative Marie Newman in which she places
the transgender flag outside her office. Is that correct, to
your knowledge? Yes or no?
Mr. Zuckerberg. Congresswoman, I am not aware of this.
Ms. Craig. You are not aware of this?
Mr. Zuckerberg. No.
Ms. Craig. Well, the answer is yes. Facebook took her video
down. According to Representative Newman, the reason Facebook
gave for taking down the video was that it violated Facebook's
community standards on hate speech and inferiority. Does that
seem right to you, that if someone put up a trans flag and took
a video of it and posted it on your platform, that it should be
put down?
Mr. Zuckerberg. Congresswoman, no. That doesn't seem right
to me. But I would need to understand the specifics of the case
in more details.
Ms. Craig. Yes. Thank you. The answer is no, it is
absolutely not right.
Meanwhile, across the hall, Representative Marjorie Taylor
Greene from Georgia posted a video to Facebook. Her video
showed her putting up a transphobic sign so that Representative
Newman, the mother of a trans child, could ``look at it every
time she opens her door.'' Facebook allowed Representative
Greene's video to remain online. Is that right? Yes or no?
Mr. Zuckerberg. Congresswoman, I am not aware of the
specifics. But as I have said a number of times today, we do
make mistakes, unfortunately, in our content moderation, and we
hope to fix them as quickly as possible----
Ms. Craig. Reclaiming my time, reclaiming my time. The
answer was yes, Representative Greene's video was allowed to
remain online. Representative Newman reached out to Facebook,
and a few hours later her video was restored with a perfunctory
apology. But Representative Greene's video was never taken
down. I am not even going to ask you if I am getting that
right, as I was, because you obviously don't know.
Are you aware that Facebook has repeatedly flagged the
transgender flag as hate speech and that trans-positive content
ends up being taken down while transphobic content, like
Representative Greene's video, is not taken down and is often
shared widely? Yes or no?
Mr. Zuckerberg. Congresswoman, I am now aware of that
specifically, but this is an instance of a broader challenge in
identifying hate speech, which is that there is often a very
nuanced difference between someone saying something that is
racist versus saying something to denounce something that
someone else said that was racist.
And we need to build systems that handle this content in
more than 150 languages around the world, and we need to do it
quickly. And, unfortunately, there are some mistakes in trying
to do this quickly and effectively.
Ms. Craig. Mr. Zuckerberg, I am going to give you your
nuance this one time.
As it exists today, do you think your company is going to
get these content moderation decisions right on the first try
eventually?
Mr. Zuckerberg. Congresswoman, if what you are asking is
are we ever going to be perfect, the answer is no. I think that
there will always be some mistakes, but I think we will get
increasingly accurate over time. So for example, a few years
back, we identified----
Ms. Craig. Mr. Zuckerberg, I only have a couple of minutes,
or 1 minute left, so I am going to continue here.
As has been mentioned repeatedly throughout today, we just
don't have faith that your companies have the proper incentives
to proactively contemplate and address basic human rights. With
that in mind, would you support legislation requiring social
media companies to have an Office of Civil Rights reporting to
the CEO, and that would mean you would have to reconsider your
corporate structure, including the civil rights and human
rights of the trans community?
Mr. Zuckerberg. Congresswoman, we took the unprecedented
step of hiring a VP of civil rights, and I think we are one of
the only companies that has done something similar to what you
are saying.
Ms. Craig. Well, I hope that you do better, then, because
this example I am giving you was completely unacceptable. This
panel has done something truly rare in Washington these days:
It has united Democrats and Republicans. Your industry cannot
be trusted to regulate itself.
And with that, I yield back.
Mr. Doyle. The gentlelady yields back.
The Chair now recognizes Mrs. Trahan for 5 minutes.
Mrs. Trahan. Thank you, Mr. Chairman.
I would like to turn the focus back to our children. My
husband and I have five. Our oldest is 27, our youngest is 6,
and over the years I have noticed how technology has been
increasingly designed to capture their attention. The more time
my first-grader spends scrolling through an app, the less time
she is playing outside or enjoying face-to-face interactions
with us.
Google and Facebook are not only doing a poor job of
keeping our children under 13 off of YouTube and Instagram, as
my colleagues have already mentioned today, but you are
actively onboarding our children onto your ecosystems with apps
like YouTube Kids, Facebook Messenger Kids, and now we are
hearing Instagram for Kids. These applications introduce our
children to social media far too early and include manipulative
design features intended to keep them hooked.
Mr. Pichai, when a child finishes a video on YouTube or
YouTube Kids, does the next video automatically play by
default? And I think this one is a yes or no.
Mr. Pichai. Sorry, I was muted. Congresswoman, I have
children, too. I worry about the time they spend online, and I
agree with you it is an important issue.
Mrs. Trahan. Yes.
Mr. Pichai. We design YouTube----
Mrs. Trahan. The autoplay function by default? That is a
yes----
Mr. Pichai. On the main app, it is there, and for each
video there is an easy on/off toggle. Users have preference to
select----
Mrs. Trahan. But the default setting is yes. When a user
who is predicted to be a teen is watching a YouTube video, are
the number of likes displayed by default? Yes or no, please?
Mr. Pichai. On all videos, I think we do have--across all
videos we have.
Mrs. Trahan. Right. And Mr. Zuckerberg, will the recently
reported Instagram app for kids have endless scroll enabled?
Yes or no?
Mr. Zuckerberg. Sorry. Congresswoman, we are not done
finalizing what the app is going to be. I think we are still
pretty early in designing this. But I just want to say that----
Mrs. Trahan. Are you not sure or are you not sharing
features or--and look, another feature of concern is the filter
that adds an unnatural but perfect glow for my 10-year-old to
apply to her face. Is that feature going to be part of
Instagram for Kids?
Mr. Zuckerberg. Congresswoman, I don't know. I haven't
discussed this with the team yet.
Mrs. Trahan. Well, look, please expect my office and many
others to follow up, given what we know about Instagram's
impact on teen mental health. We are all very concerned about
our younger children.
And I just want to speak mother to father for a moment,
fathers, because leading experts all acknowledge that social
media sites pose risks to young people--inappropriate content,
oversharing of personal information, cyberbullying, deceptive
advertising--the list goes on. And those risks are exacerbated
with more time children spend in these apps.
Mr. Pichai, you mentioned that you have children, and I
have also read you limit their screen time. What do you say
when one of your children doesn't want to put their phone down?
Mr. Pichai. Congresswoman, the struggle is the same,
particularly through COVID. It has been hard to moderate it.
And I do take advantage of the parental controls and the
digital well-being tools. We can limit the time on their apps.
And so we have prohibitions in place.
Mrs. Trahan. I don't mean to cut you off, Mr. Pichai. But
the last thing overworked parents need right now--especially
right now--are more complex to-dos, which is what parental
controls are. They need childcentric design by default.
Mr. Zuckerberg, I understand your children are younger. But
when they start using social media, what will you say when they
are craving their tablet over spending time face to face with
you or with friends?
Mrs. Trahan. Well, Congresswoman, we haven't gotten to that
point yet. But we are designing all of these tools--we designed
Messenger Kids that the parents are in control. I think we have
proven that that can be a good and safe experience. And I think
that was one of the things that made us think that we should
consider doing this for Instagram as well, by having it so that
we have a parent-controlled experience and, as you say,
childcentric experience for people under the age of 13----
Mrs. Trahan. I am going--I am going to reclaim my time,
only because. Connecting with others is one thing. Adding
filters, no breaks for kids to take, and manipulating the
design of these apps for our children is another. Look, this
committee is ready to legislate to protect our children from
your ambition.
What we are having a hard time reconciling is that, while
you are publicly calling for regulation--which, by the way,
comes off as incredibly decent and noble--you are plotting your
next frontier of growth, which deviously targets our young
children and which you all take great strides, with infinitely
more resources, in protecting your own children.
This playbook is familiar. As some of my colleagues have
pointed out, it is the same tactic we saw from alcohol
companies and Big Tobacco: Start 'em young and bank on them
never leaving, or at least never being able to. But these are
our children, and their health and well-being deserve to take
priority over your profits.
Mr. Doyle. The gentlelady's time is expired.
The Chair now recognizes Mrs. Fletcher for 5 minutes.
Mrs. Fletcher. Thank you, Chairman Doyle. And thanks to you
and Chairwoman Schakowsky and Ranking Members Latta and
Bilirakis for holding this hearing today. I agree with my
colleagues. There is a broad consensus on a range of issues,
and I appreciate the discussion.
As we have discussed extensively today, one of the big
challenges of this rise of dangerous disinformation is that it
denies us a basic set of shared facts to enable an informed
debate like what we are having here today. And it is absolutely
vital that we take charge and that we address this.
What we have seen is that countries whose interests are not
aligned with ours, extremist organizations and others, have
used online social media platforms to engage and to amplify
extremist content and disinformation, from the COVID-19
pandemic to the January 6 insurrection, both of which we have
talked about extensively.
We have seen that the real-world cost of this unchecked
spread of disinformation is in lies. And like my colleagues, I
worry that the structure of many social media companies,
including those we have before us today, prioritize engagement,
including engagement with provocative or extremist content,
over responsible corporate citizenship.
So one of my greatest concerns regarding how extremist
content and disinformation is allowed to spread on your
platform is the lack of data transparency when it comes to
independent analysis. Now, everyone has claimed they have an
internal system, that it is about the systems, that you need
good systems to remove and delete disinformation and extremist
content.
But we have no way to verify how effective those systems
are. And that is a huge part of the challenge before us. I
think we all would agree that we need data and information to
make good policy and to write good legislation which will be
coming out of this committee.
So that brings me to a followup on my colleague Miss Rice's
questions about data. As she mentioned, and it is my
understanding that all three of your platforms chose to remove
content that was posted regarding the Capitol insurrection on
January 6. And I think we can all understand some of the
reasons for that. But as a result, it is unavailable to
researchers and to Congress.
So my question for each of you is: Will you commit to
sharing the removed content with Congress to inform our
information of the events of January 6 and also the issues
before us today about how to respond to extremist and dangerous
content online?
And I will start with Mr. Zuckerberg.
Mr. Zuckerberg. Thanks, Congresswoman. When we take down
content that might be connected to a crime, I think we do, as a
standard practice, try to maintain that so that we can share it
with law enforcement if necessary. And I am sure our team can
follow up to discuss that with you as well.
Mrs. Fletcher. Sure. I appreciate that. And I understand
that you have a legal obligation to cooperate with authorities
and law enforcement in these cases. And I think that what I am
talking about is also sharing it with us in Congress, and I
appreciate your response there.
Mr. Dorsey?
Mr. Dorsey. We would like to do this, actually. We have
been thinking about a program for researchers to get access to
actions that we had to take. But all of this is subject to
local laws, of course.
Mrs. Fletcher. Well, and that may be something that we can
help craft here. So I think that it is consistently something
we have heard from researchers as well. It is a real area of
challenge in not having the data. So I appreciate that.
And Mr. Pichai? Do you also agree?
Mr. Pichai. Congresswoman--sorry, I was muted--we are
working with law enforcement, and happy to connect with your
office. And we cooperate as allowed by law while balancing the
privacy of the people involved.
Mrs. Fletcher. Well, thank you. So I appreciate all of your
willingness to work with us and to assist Congress in
addressing this attack on our Capitol and our country.
Another idea that I would like to touch base with you on in
the time I have left, just over a minute, is the difference we
see in how your platforms handle foreign extremist content
versus domestic content. By all accounts, your platforms do a
better job of combating posts and information from foreign
terrorist organizations, or FTOs, like ISIS or al-Qaeda and
others, where the posts are automatically removed, depending on
keywords and phrases, et cetera.
The FTOs are designated by the State Department. There are
rigorous criteria to identify groups that wish to cause harm to
Americans. Currently there is no legal mechanism or definition
for doing the same for domestic terror and hate groups.
Would a FSederal standard for defining a domestic terror
organization similar to FTOs help your platforms better track
and remove harmful content from your sites? Mr. Zuckerberg?
Mr. Zuckerberg. Congresswoman, I am not sure. I think
domestically we do classify a number of white supremacist
organizations and militias and conspiracy networks like QAnon
as the same level of problematic as some of these other
organizations that are able to take decisive action.
I think where this ends up being more complicated is where
the content is----
Mrs. Fletcher. I hate to cut off, but I am going to run out
of time. So your answer was, ``I am not sure.'' Could I just
get a quick yes or no from Mr. Dorsey and Mr. Pichai?
Mr. Doyle. Yes, but very quickly because your time is
expired. Very quickly.
Mr. Dorsey. We need to evaluate it. We need to understand
what that means.
Mrs. Fletcher. Mr. Pichai?
Mr. Pichai. We as domestic agencies focus on that, I think
we are happy to work and cooperate there.
Mr. Doyle. OK. The gentlelady's time is expired.
Mrs. Fletcher. Well, thank you very much, Mr. Chairman. I
yield back.
Mr. Doyle. It is my understanding we have--let's see--eight
Members who were requesting to waive on for the hearing. I
believe we have given all members of the subcommittees their
opportunity to speak. So we will now start to recognize the
Members waiving on. And first on the list here I see Mr.
Burgess.
Doc Burgess, are you with us?
Mr. Burgess. Yes. Sorry. I couldn't find my cursor.
Mr. Doyle. OK. You are recognized for 5 minutes.
Mr. Burgess. Thank you, Mr. Chairman. And thanks to our
witnesses for spending so much time with us. This is clearly a
very important issue to every member of this committee
regardless of which political party they identify with.
I guess, Mr. Zuckerberg, let me just ask you a question
because it strikes me, listening to your answers to both our
colleague Jeff Duncan and our colleague Angie Craig--both
coming at the issue from different directions--but the concern
is that there was the exercise of editorial authority over the
postings that were made on your website. Is that a fair
assessment?
Mr. Zuckerberg. Congressman, I am not sure what you mean.
But I think content moderation and enforcing standards, I don't
think that that is the same kind of editorial judgment that,
for example, a newspaper makes when writing a post.
Mr. Burgess. Yes. But maybe it is, because Mr. Duncan
eloquently pointed out there was restriction of conservative
speech. And our colleague, Angie Craig, eloquently pointed out
how there was restriction of trans-affirming speech. So that
strikes me that we are getting awfully close to the line of
exercising editorial discretion.
And forgive me for thinking that way, but if that is--and I
am sure I am not alone in this--it does call into question,
then, the immunity provided under Section 230. Maybe it is not
a problem with the law itself, Section 230. Maybe the problem
is that the mission has changed in your organization and other
organizations.
Mr. Zuckerberg. Congressman, I am not sure what you mean.
But we have clear standards against things like terrorist
content, child exploitation, incitement of violence,
intellectual property violations, pornography--things that I
would imagine that you agree with. And we can enforce----
Mr. Burgess. All spelled out in the plain language of
Section 230. But again, you are putting restrictions on
conservative speech. Mr. Duncan eloquently pointed out how that
is occurring. Angie Craig eloquently pointed out how you are
putting restrictions on trans-affirming speech. None of those
fall into any of the other categories that you are describing.
Because to the casual observer, it appears that you are
exercising editorial authority, and as such maybe you should be
regulated as a publisher as opposed to simply someone who is
carrying--who is indifferent to the content that they are
carrying.
Mr. Zuckerberg. Congressman, I think one of the virtues of
Section 230 is it allows companies to moderate things like
bullying that are not always clearly illegal content but that I
think you and I would probably agree are harmful and bad.
So I think it is important that companies have the ability
to go beyond what is legally required. I do not think that that
makes these internet platforms the same thing as a news
publisher who is literally writing the content themselves. I do
think we have more responsibility than maybe a telephone
network, where----
Mr. Burgess. Let me interrupt you in the interest of time
because I want to pose the same question to Mr. Dorsey.
Mr. Dorsey, every Presidential tweet that I read following
the election had an editorial disclaimer appended to it by you.
How does that not make you someone who is exercising editorial
discretion on the content that you are carrying?
Mr. Dorsey. Our goal with our labels was simply to provide
connection to other data and provide context.
Mr. Burgess. Yes. But you don't do that routinely with
other tweets. It seemed to be a singular assignment that
someone had taken on, to look at whatever the President is
publishing. ``We are going to put our own spin on that.'' And
again, that strikes me as an editorial exercise.
And the only reason I bring this up and we are going to
have these discussions, I recognize that smaller companies just
starting out, the protection of Section 230 may be invaluable
to them. But you all are no longer just starting out. You are
established. You are mature companies. You exercise enormous
control over the thought processes of not just an entire
country but literally the entire world. You are exercising
editorial discretion. I do think we need to revisit Section 230
in the terms of, have you now become actual publishers as
opposed to simply carriers of information?
Thank you, Mr. Chairman. I will yield back.
Mr. Doyle. The gentleman yields back.
The Chair recognizes Mr. Tonko for 5 minutes.
Mr. Tonko. Thank you, Mr. Chair. Thank you for allowing me
to waive on.
Gentlemen, thank you for being with us today. While there
are many issues I would like to raise with you, my most
pressing unresolved questions revolve around what I saw and
experienced on January 6, when I had to dive for cover in the
House gallery as violent insurrectionists attempted to break
down the doors and take the chamber.
The rioters who breached the Capitol building were
propelled by at least one bully that the election had been
stolen from former President Donald Trump. They reached this
false and dangerous conclusion, yet somehow in massive numbers.
Their assault was not disorganized or isolated, and it was not
coincidence.
So Mr. Zuckerberg, you and your colleagues have downplayed
the role Facebook played in helping the rioters mobilize on
January 6. In light of growing evidence that suggests
otherwise, including the fact that Facebook was the most cited
social media in charging documents the Department of Justice
filed against insurrectionists, do you still deny that your
platform was used as a significant megaphone for the lies that
fueled the insurrection?
Mr. Zuckerberg. Congressman, to be clear, I think part of
the reason why our services are very cited in the charging docs
is because we worked closely with law enforcement to help
identify the people who were there. So I don't view that that
collaboration with law enforcement should be seen as a negative
reflection on our services.
And as I have said a number of times to today, there was
content on our services from some of these folks. I think that
that was problematic. But by and large, I also think that by
putting in place policies banning QAnon, banning militias,
banning other conspiracy networks, we generally made our
services inhospitable to a lot of these folks. And that had the
unfortunate consequence of having those folks not use Facebook
and use other places as well.
So there is certainly more for us to do. But I stand behind
the work that we have done with law enforcement on this and the
systems that we have in place.
Mr. Tonko. Thank you.
Mr. Pichai, can you affirmatively state that YouTube did
not recommend videos with Stop the Steal content, white
supremacy content, and other hate and conspiracy content that
was seen by rioters at the Capitol?
Mr. Pichai. Congressman, we had clear policies and we were
vigorously enforcing this area. Just leading up to the
election, we had removed hundreds of thousands of videos, and
we had terminated 8,000 channels. And on the day of the riot,
we were successfully able to take down inappropriate
livestreams. We gave precedence to journalistic organizations
covering the event. And that is the content we raised up on
YouTube that day. And since then we have been cooperating with
law enforcement as well.
Mr. Tonko. So you're indicating that you did not recommend
videos with Stop the Steal?
Mr. Pichai. We were rigorously enforcing. We had clear
policies around content that undermined election integrity.
Once the States certified the election on December 8th, we
introduced a Sensitive Events policy and we did take down
videos which were violative. And so we have been monitoring it
very closely.
Mr. Tonko. Thank you.
And Mr. Dorsey, are you confident that the conspiracy
theorists or other purveyors of electoral misinformation and
Stop the Steal on Twitter were not recommending to others?
Mr. Dorsey. I can't say that I was confident, but I know we
did work really hard to make sure that if we saw any
amplification that went against the terms of service, which
this would, we took an action immediately. We didn't have any
up-front indication that this would happen, so we had to react
to it quite quickly.
Mr. Tonko. All right. Thank you. And who and what content
your platforms recommend have real-world consequences, and the
riot caused five deaths and shook our democratic foundations.
And I believe that your platforms are responsible for the
content you promote, and look forward to working with my
colleagues to determine how to hold you accountable.
Mr. Pichai, Google and YouTube often slip under the radar
as a source of disinformation. But in the last election, bad
actors used ads on Google Search to scam people looking for
voting information, and YouTube failed to remove videos that
spread misinformation about the 2020 vote results.
So Mr. Pichai, when journalists pointed out in November
that election misinformation was rampant on Google's YouTube,
the company said it was allowing discussions of election
processes and results. A month later YouTube said it would
remove new content alleging widespread voter fraud in the 2020
election. Why did YouTube wait a month to take action on
election misinformation?
Mr. Pichai. If I could clarify here, we were taking down
videos leading up to the election. There is obviously a month
from the date of election till there are due processes, co-
challenges, and we waited till this--we consulted with CISPA
and Association of Secretaries of State. And on December 8,
when the States certified the election, we started enforcing
newer policies on December 9th.
To be very clear, we were showing information from the
Associated Press, and we were proactively showing information
high up in our search results to give relevant information
throughout this election cycle.
Mr. Doyle. The gentleman's time is expired.
Mr. Tonko. Thank you. Mr. Chair, I yield back.
The Chair recognizes Mr. McKinley for 5 minutes.
Mr. McKinley. Thank you, Mr. Chairman, and this panel. You
all have to be exhausted after being grilled all day long like
this.
So my questions are to Mr. Zuckerberg.
When you came before our committee in 2018, you
acknowledged that Facebook had used what you just said, ``clear
standards,'' preventing the sale of illegal drugs on your site.
But you were shown examples of active posts that traffickers
were still using that platform unlawfully to sell prescription
opioids. You did apologize and confirm that ``social media
companies need to do a better job of policing these posts.''
Now, 3 years later it appears a shell game is emerging.
Facebook seems to have cleaned up its act, but you are now
allowing Instagram, one of your subsidiaries, to become the new
vehicle. Even though Instagram has the same policies against
the sale of illegal substances, you are still allowing bad
actors to push pills on your site.
It didn't take long for our staff to find numerous
examples. For example, here is oxycodone that is being sold on
your site. Here is Ritalin that is being sold on your site.
Here is Xanax and Adderall that is being sold on your site. So
these posts have--they are not new. They have been active since
last fall.
If we can find posts this easily, shame on you for not
finding them for yourself. Apparently you are not taking the
warnings of Congress seriously. After drug manufacturers dumped
millions of pills in our community, killing thousands, ravaging
families, and destroying livelihoods, Congress responded by
passing laws to hold them liable.
If a retail store is selling cigarettes to underage kids,
that store is held liable. So why shouldn't you be held liable
as well? Do you think you are above the law? You are knowingly
allowing this poison to be sold on your platform into our
communities, to our children, to our vulnerable adults.
Look. I have read Scott Galloway's book ``The Four.'' I
encourage all the members on this committee to read his book.
It is a perfect depiction of the arrogance of Big Tech
companies like Facebook, Google, Apple, and Amazon. He develops
a very compelling argument as to why Big Tech companies should
be broken into smaller companies, much like that occurred to
AT&T in 1984.
Maybe it is time for Congress to have an adult conversation
about this loss of liability protection and the need to reform
our antitrust laws. I don't think Congress wants to tell you
how to run your company, but maybe it should.
So Mr. Zuckerberg, let me close with this one question:
Don't you think you would find a way to stop these illegal
sales on your platforms if you were held personally liable?
Mr. Zuckerberg. I keep on getting muted.
Congressman, we don't want any of this content on our
platforms, and I agree with you that this is a huge issue. We
have devoted a lot of resources and have built systems that are
largely quite effective at finding and removing the content.
But I just think that what we all need to understand is that at
the scale that these communities operate, where people are
sharing millions or, in messages, billions of things a day, it
is inevitable that we will not find everything, just like a
police force in a city will not stop every single crime.
Mr. McKinley. I agree.
Mr. Zuckerberg. So I think that we should----
Mr. McKinley. But I ask you the question very directly,
Mark. Should you not be held liable when people are dying
because your people are allowing these sales to take place? We
did it with manufacturers. We do it to the stores. Why aren't
we doing it to the salesman that allows this to take place?
Mr. Zuckerberg. Well, Congressman, I don't think we are
allowing this to take place. We are building systems that take
the vast majority of this content off our systems. And what I
am saying----
Mr. McKinley. We have been dealing with this for 3 years,
Mark. Three years this has been going on. And you said you were
going to take care of it last time, but all you do is switch
from Facebook over to Instagram. They are still doing it now.
And you are saying ``We need to do more.''
Well, how many more families are going to die? How many
more children are going to be addicted while you still study
the problem? I think you need to be held liable.
Mr. Zuckerberg. Congressman, we are not sitting and
studying the problem. We are building effective systems that
work across both Facebook and Instagram. But what I am saying
is that I don't think that we can expect that any platform will
find every instance of harmful content. I think we should hold
the platforms to be responsible for building generally
effective systems at moderating these kinds of content.
Mr. Doyle. The gentleman's time is expired.
Mr. McKinley. I am not going to get an answer, Mike. Thank
you.
Mr. Doyle. The gentleman yields back. The Chair recognizes
Ms. Blunt Rochester for 5 minutes.
Ms. Blunt Rochester. Thank you, Mr. Chairman, for allowing
me to waive onto this important hearing. And thank you to the
witnesses.
I want to focus on two areas: first, a consumer protection
and safety issue, and second, more broadly, manipulation and
privacy of our data.
On consumer protection and safety, earlier this year two
infants from two different families ended up in the intensive
care unit in Wilmington, Delaware, after being fed homemade
baby formula based on instructional videos viewed on YouTube.
One infant suffered from cardiac arrest that resulted in brain
damage.
For years, the American Academy of Pediatrics has warned
parents against homemade baby formulas because it puts infants
at risk of serious illness and even death. And since at least
2018, the FDA has recommended against the use of homemade
formula. Even as recent as 29 days ago, the FDA issued an
advisory against homemade formula.
In February, my office informed your team, Mr. Pichai, and
as a followup I have sent a letter requesting information and
action on this issue in the hopes of a response by April 1st.
Mr. Pichai, this is just a yes-or-no question: Can I count on a
response to my letter by the deadline of April 1st?
Mr. Pichai. Congresswoman, definitely yes. Heartbreaking to
hear the stories. We have clear policies. Thanks for your
highlighting this. I think the videos have been taken down, and
we are happy to follow up and update the team.
Ms. Blunt Rochester. We checked today. For years, these
videos have clearly violated your own stated policy of banning
the videos that endanger the, as you say, ``physical well-being
of minors.'' And so I am pleased to hear that we will be
hearing back from you.
And while we are considering Section 230, what is clear
from this hearing is that we should all be concerned by all of
your abilities to adequately--and just as importantly,
rapidly--moderate content. In some of these cases, we are
talking life and death.
Second, as many of my colleagues have noted, your companies
profit when users fall down the rabbit hole of disinformation.
The spread of disinformation is an issue all of us grapple with
from all across the political specimen. Disinformation often
finds its way to the people most susceptible to it because the
profiles that you create through massive data collection
suggest what they will be receptive to.
I introduced the DETOUR Act to address common tactics that
are used to get such personal data as possible. And these
tactics are often called ``dark patterns,'' and they are
intentionally deceptive user interfaces that trick people into
handing over their data.
For the people at home, many of you may know this as when
you go on an app, it doesn't allow you to have a No option, or
it will insinuate that you need to do something else, install
another program like Facebook Messenger app to get on Facebook.
You all collect and use this information. Mr. Pichai, yes
or no: Would you oppose legislation that banned the use of
intentionally manipulative design techniques that trick users
into giving up their personal information?
Mr. Pichai. We definitely are happy to have oversight on
these areas and explain what to do.
Ms. Blunt Rochester. Thank you. I have to go to Mr. Dorsey.
Mr. Dorsey, yes or no?
Mr. Dorsey. Open to it.
Ms. Blunt Rochester. Mr. Zuckerberg?
Mr. Zuckerberg. Congresswoman, I think the----
Ms. Blunt Rochester. Yes or no, please.
Mr. Zuckerberg [continuing]. Principle makes sense, and the
details matter.
Ms. Blunt Rochester. OK. Mr. Zuckerberg, your company
recently conducted this massive ad campaign on how far the
internet has come in the last 25 years. Great ad. You end it
with a statement: ``We support updated internet regulations to
address today's challenges.'' Unfortunately, the proposal that
you direct your viewers to fails to address dark patterns, user
manipulation, or deceptive design choices.
Mr. Zuckerberg, will you commit now to include deceptive
design choices as part of your platform for better internet
regulations?
Mr. Zuckerberg. Congresswoman, I will think about it. My
initial response is that I feel there are other areas that I
think might be more urgently in need.
Ms. Blunt Rochester. That might be your--if you say this is
a desire of yours to address the issues that we face today,
dark patterns goes back to 2010, this whole issue of deceptive
practices. And I hope that you will look into it.
I will say--Mrs. Trahan and others have mentioned--she
mentioned our children. Others have mentioned seniors,
veterans, people of color, even our very democracy, is at stake
here. We must act and assure you--we will assure you we will
act.
Thank you so much, and Mr. Chairman, I yield back 6
seconds.
Mr. Doyle. I thank the gentlelady. The gentlelady yields
back.
And now the Chair recognizes Mr. Griffith for 5 minutes.
Mr. Griffith. Thank you very much, Mr. Chair.
According to new data from the National Center for Missing
and Exploited Children, Siler Pythian found the vast majority
of child exploitation reports from Big Tech sites. Facebook had
the most, 20.3 million. Google was second with 546,000-plus.
Twitter had 65,000-plus. Put in perspective, MindGeek, the
Canada-based parent company of major portion websites, had
13,229. Facebook claims 90 percent of the flagged incidents
were duplicates. All right. Let's accept that. That still
leaves over 2 million incidents--2 million incidents.
Mr. Zuckerberg, yes or no, does Facebook have a problem
with child exploitation on its platform?
Mr. Zuckerberg. Congressman, this is an area that we work
on a lot. But the recent why those numbers are so high is
because we are so proactive about trying to find this and send
it to NCMEC and others who are doing good work in this area. We
send content and flags over to them quite liberally, whenever
we think that we might see that something is at issue.
And that is, I think, what the public should want us to do,
not criticize us for sending over a large number of flags but
should encourage the companies to do it.
Mr. Griffith. So you are admitting that you all have a
problem, and this is one way you are trying to work on it.
Mr. Pichai, yes or no: Do you agree with Mr. Zuckerberg
that you all have a problem? Are you there?
Mr. Pichai. Congressman, sorry, I was muted. This is an
area which we invest very heavily. We have been praised by
several authorities. We work proactively----
Mr. Griffith. So the answer is yes.
Mr. Dorsey, yes or no: Do you agree?
Mr. Dorsey. If we see any problems, we try to resolve them
as quickly as possible.
Mr. Griffith. But you do have problems, and that is why you
are trying to resolve them. I get that. The problem is, when
you are talking about millions of incidents, and we take 90
percent of them as duplicates from the Facebook data, that is
millions of incidents that are happening where our children are
being exploited with child pornography on you all's sites. We
have got to do better.
I think you all need, for everything that we have talked
about today, an independent industrywide review team like the
electronic industry did with the Underwriters Laboratory nearly
150 years ago. I told you all that when you were here before.
Nobody has done anything. I don't think it needs to be within
your company. I think it needs to be outside.
And on that vein, I would say to Google, special permission
was given to Moonshot CVE to target ads against extremist
keywords. Moonshot then directed thousands of individuals who
searched for violent content to videos and posts of a convicted
felon who espouses anti-law-enforcement, anti-Semitic, and
anarchist viewpoints.
Mr. Pichai, are you aware of this problem?
Mr. Pichai. Congressman, I am not aware of the specific
issue. Last year we blocked over 3.1 billion bad ads, 6,000 ads
per minute. And so we enforce vigorously. But I am happy to
look into this specific issue and follow up back with you.
Mr. Griffith. Well, here is what happened. You partnered
with an outside group that didn't do their job. What are your
standards when you partner with an outside group? What are your
standards, and what are your philosophy? Because they sent
people who were already looking for violence to a convicted
felon with anarchist and anti-Semitic views.
Mr. Pichai. There is no place for hate speech, and I am
disappointed to hear of this. We will definitely look into it
and follow up back with you.
Mr. Griffith. Well, and I appreciate that. I recognize
that. But I have the same concerns that Mr. McKinley had. And
you weren't here last time, but we heard these same kinds of
things about how ``we are going to work on it'' and how ``we
are going to get these problems resolved.'' And I forget when
that hearing was, but a year or so ago.
And yet we continue to have the same problems, where
political candidates' information is being taken down because
for some reason it is flagged, where conservatives and people
on the left are being hit and taken down. And I agree with many
of the sentiments on both side of the aisle that, if you all
aren't doing anything and it appears that you are not moving
fast enough, we have no choice in Congress but to take action.
I don't want to. I would rather see you all do it, like the
electric industry did with Underwriters Laboratory. But nobody
is doing that. Nobody is coming up with a group that both sides
of the aisle and the American families can feel comfortable
with. And so we are going to have to take action, and it is
probably going to be this year.
I yield back.
Mr. Doyle. The gentleman yields back.
The Chair recognizes Ms. Schrier for 5 minutes.
Ms. Schrier. Thank you, Mr. Chair.
I am a pediatrician, and I have spent my life calming
patients who are nervous about vaccines because of online
misinformation. In fact, that is why I introduced a Vaccines
Act when I was a new Member of Congress. Did you know that
there are doctors who, after spending their entire day on the
front line fighting this virus, come home at night and spend
their scarce free time and family time fighting misinformation
about vaccines online? And this misinformation, of course,
comes primarily from Facebook and Twitter.
So the question is: Why do they do that? Well, they do it
because of things like this that happened after I introduced
the Vaccines Act. Here are some overt threats:
``Keep shoving this vaccine monitor down people's throats
and expect riots.''
``Be careful. You will answer for this tyranny one day.''
``She needs to just disappear. Can we vote her out of
office? I am enraged over these poison pushers.''
``We have weapons and are trained to fight off possible
forced vaccinations. I will die protecting my family.''
And then there is just the misinformation.
``It says 'safe and effective' many times, yet no vaccine
has been studied in a double-blind study.'' False.
``Who is going to take this vaccine? I heard rumors that it
changes a person's DNA.'' False.
``You do not give''--excuse my language--``You do not give
a shit about the health and welfare of our children. This
horrid vaccine has already killed 600 people. You are
deplorable.'' And of course that again is false.
So while the overt threats are unsettling, particularly
after January 6, I think about this whole ecosystem, your
ecosystem, that directs a hostile sliver of society, en masse,
to my official Facebook page. And these are not my
constituents. In fact, most came from two specific groups that
directed their members to my page.
Mr. Zuckerberg, I have some questions for you. I know you
understand these issues are important, and sometimes
misinformation can be very hard to spot. Would you agree?
Mr. Zuckerberg. Congresswoman, I agree with both of those.
This is important, and the enforcement processes can be
difficult.
Ms. Schrier. Thank you. And I heard your answer earlier to
Representative Upton's question, that there are 35,000 people
doing content review of posts that have been flagged by users
and AI. Can you tell me what ``content review'' means and how
many of those 35,000 are dedicated to topics regarding health?
Mr. Zuckerberg. Congresswoman, yes. What the people are
doing overall is, you know, content gets flagged, either by the
AI systems or by another person in the community. And if the AI
can't by itself determine that something either violates or
doesn't, then it gets flagged for human review and human
judgment. And the 35,000 people go through all those different
queues, focused on all the different types of harms that we
have discussed today.
I don't have the number off the top of my head about how
many of them are focused on vaccine misinformation. But, as you
know, we have a policy that doesn't allow vaccine
misinformation, and we work with the WHO and CDC to take down
false claims around COVID, and the vaccines around that, that
could cause harm.
Ms. Schrier. That is where it really gets tricky, because
you have to have experts and healthcare professionals who
really understand. Are your people trained in healthcare to
really even be able to discern what is real, what is fake, and
what to take down?
Mr. Zuckerberg. Congresswoman, the people who set the
policies either are experts in these areas or engage in a
consultative process where they talk to a lot of these
different folks. In this case, we largely defer to the CDC and
WHO on which claims they think are going to be harmful. And
then we try to break that down into kind of very simple
protocols that the 35,000 people can follow and that we can
build into AI systems to go find as much of that content
proactively as possible without requiring all those people to
be medical experts.
Ms. Schrier. So with my short time remaining I would love
to jump to that part about the CDC because I want to turn my
attention to the COVID resource center that you describe as a
central part of your efforts to fight misinformation directed
over 2 billion people to the COVID-19 Information Center.
But on the information page, almost all of the content
links to additional Facebook pages. It looks to me like an
extension of Facebook's walled garden that just keeps users on
the site instead of leading directly to authoritative, trusted
sources like the CDC.
So knowing that your platform is a large source of
misinformation, did you consider just referring people directly
to sites like the CDC rather than keeping them within your
platform?
Mr. Zuckerberg. Congresswoman, I think we have considered
both, and I think we have done both in different cases. The
team is very focused on building this in the way that is going
to be most effective at getting people to actually see the
content, and I believe that they have concluded that showing
content from people within a person's community that they are
going to trust on the service is one of the most effective
things that we can do.
Mr. Doyle. The gentlelady's time is expired.
Ms. Schrier. Thank you. I yield back.
Mr. Doyle. The Chair now recognizes Mr. Crenshaw for 5
minutes.
Mr. Crenshaw. Thank you, Mr. Chairman. Thank you all for
being here. It has been a long one.
I have been on some social media longer than anyone in
Congress, I think. I was one of the first schools to have
Facebook back in 2004. And it seemed to me that the goal of
social media was simply to connect people.
Now, the reason we are here today is because, over time,
the role of social media has expanded in an extraordinary way.
Your power to sway opinions and control narratives is far
greater than the U.S. Government's power ever has been.
So I noticed a trend today. There is a growing desire from
many of my colleagues to make you the arbiters of truth. See,
they know you have this power and they want to direct that
power for their own political gain. Mr. Zuckerberg, since
Facebook was my first love, I am going to direct questions at
you. And this isn't a trick question, I promise.
Do you believe in the spirit of the First Amendment--free
speech, robust debate, basically liberal values?
Mr. Zuckerberg. Yes, absolutely.
Mr. Crenshaw. See, my colleagues can't infringe on the
First Amendment. The American people in their speech are
protected from government, as they should be. My colleagues,
this administration, they can't silence people they disagree
with no matter how much they want to.
But I do think they want to. Just in this hearing, I have
heard Democrats complain about misinformation, by which they
clearly mean political speech they disagree with. They have
complained today that Prager University content is still up. I
have heard them accuse conservative veterans of being tinfoil-
hat-wearing extremists, and that opinions on climate change
that they disagree with should be taken down.
This is quite different from the Republican complaint that
illegal content needs to be addressed. There is a growing
number of people in this country that don't believe in the
liberal values of free speech and free debate. I promise you,
the death of the First Amendment will come when the culture no
longer believes in it. But that happens and it becomes OK to
jail or investigate citizens for speech, like has happened in
Canada and throughout Europe. Their culture turned against free
speech.
You all sitting here today as witnesses are part of the
culture. You can stand up for the spirit of open debate and
free speech, or you can be the enemy of it. Your stance is
important because it is clear that many want to weaponize your
platforms to get you to do their bidding for them.
Mr. Zuckerberg, do you think it is your place to be the
judge of what is true when it comes to political opinions?
Mr. Zuckerberg. Congressman, no. I don't believe that we
should be the arbiter of truth.
Mr. Crenshaw. Thank you. And look. I promise you this: As
long as you resist these increasing calls from politicians to
do their political bidding for them, I will have your back.
When you don't, you become an enemy of liberty and longstanding
American tradition.
You might all agree in principle with what I just said. Mr.
Zuckerberg, you clearly do, and I appreciate it. I have a
feeling the others would answer it as well, I just don't have
time to ask everybody. But the fact remains that community
standards on social media platforms are perceived to be applied
unequally and with blatant bias.
Mr. Dorsey, in just one example, I saw a video from Project
Veritas that was taken down because they confronted a Facebook
executive on his front lawn. But here is the thing: I can show
you a video of CNN doing the exact same thing to an old woman
who was a Trump supporter in her front yard. I have looked at
both videos. It is an apples to apples comparison. CNN remains
up, Project Veritas was taken down.
I will give you a chance to respond to that. I have a
feeling you are going to tell me you have to look into it.
Mr. Dorsey. I don't have an understanding of the case, but
I would imagine, if we were to take a video like that down, it
would be due to a doxxing concern, private address.
Mr. Crenshaw. The address was blurred out. Look, you don't
have it and you don't have the case in front of you. I get
that. The point is that there are countless examples like this.
I just found that one today. But there are countless examples
like this.
So even if we agree in principle on everything I just went
over, you guys have lost trust. And you have lost trust because
this bias is seeping through. And we need more transparency. We
need a better appeals process, more equitable application of
your community guidelines, because we have to root out
political bias in these platforms.
I think--and I have talked with a lot of you offline or at
least your staff, and I think there is some agreement there.
And I haven't heard, in this hearing, anybody ask you what
you're doing to achieve these goals. So I will allow you to do
that now. Maybe, Mr. Zuckerberg, we will start with you.
Mr. Zuckerberg. Sorry. To achieve which goals?
Mr. Dorsey. More transparency, more feeling that--better
appeals process for content taken down, more equitable
application of community guidelines.
Mr. Zuckerberg. So for transparency, we issue quarterly
community standards enforcement reports on what prevalence of
harmful content of each category--from terrorism to incitement
of violence to child exploitation, all the things that we have
talked about--how much of it there is and how effective we are
at finding that, and states around that.
For appeals, the biggest thing that we have done is set up
this independent oversight board, which is staffed with people
who all have a strong commitment to free expression, for whom
people in our community can ultimately appeal to them and that
group will make a binding decision, including overturning
several of the things that we have taken down and telling us
that we have to put them back up, and then we respect that.
Mr. Doyle. The gentleman's time is expired.
The Chair now recognizes----
Mr. Crenshaw. I yield back seconds.
Mr. Doyle [continuing]. Last but not least, my fellow
Pennsylvanian, Mr. Joyce. You are recognized for 5 minutes.
Mr. Joyce. Thank you for yielding. And thank you, Mr.
Chairman and the ranking members, for convening this hearing. I
thank you all. It has been a long day.
But this is an incredibly important day. We have heard
consistently during this hearing about alarming accounts of
content policing, censorship, and even permanent deplatforming
of individuals. I have also been concerned about the lack of
transparency and consistency in Facebook's application, of
Facebook's own standards.
As you mentioned, I am a representative from Pennsylvania,
and in my district Facebook shut down the personal pages of
Walt Tuchalski and Charlotte Shaffer as well as the Adams
County Republican Committee Facebook page that they
administered in historic Gettysburg, Pennsylvania. And this all
occurred without warning.
Since the pages were taken down in December, these
Pennsylvanians haven't received an acceptable answer from
Facebook about why they were banned, nor have they been given
the opportunity to appeal this decision.
Mr. Zuckerberg, could you please explain how something like
this could happen?
Mr. Zuckerberg. Congressman, I am not familiar with those
specific details. But in general, I agree that building out a
better appeals process and better and more transparent
communication to people about why specific decisions were made
is one of the most important things that we need to do next.
And that is one of the big things on our roadmap for this year
and next year, and I hope we can dramatically improve those
experiences.
Mr. Joyce. Mr. Zuckerberg, may I get from you a commitment
that a more concise and transparent appeals process will be
developed?
Mr. Zuckerberg. Congressman, yes. We are working on more
transparent communication to people and more of an appeals
process as part of our product now, like I just said.
Mr. Joyce. And will you commit to getting my constituents
answers as to why they were banned?
Mr. Zuckerberg. Congressman, I can certainly have my team
follow up with them and make sure that we can do that.
Mr. Joyce. Thank you for that.
I am also concerned by potential partisan bias in
Facebook's enforcement of its content policies. Shutting down
the Adams County Republican Committee Facebook page strikes me
as an infringement on speech, and that is normally protected in
the public domain.
Mr. Zuckerberg, does Facebook maintain data on how many
Democrat and Republican county committee pages that you have
banned from your platform?
Mr. Zuckerberg. No, Congressman, we don't. We don't
generally keep any data on whether the people who use our
platform are Democrats or Republicans. So it is hard for us----
Mr. Joyce. Then let me--time is running short here, and it
is a long day. But Mr. Zuckerberg, you say you have not
maintained that data. Would you consider gathering such data to
verify that there is no political bias in your enforcement
algorithms?
Mr. Zuckerberg. Congressman, I am not sure that that is a
great idea. I don't know that most people would want us to
collect data on whether they are a Democrat or a Republican and
have that be a part of our overall system.
Mr. Joyce. I think there is a huge disparity, as I
represent Pennsylvania. And I think that that data would be
appreciated if shared with us in a fair manner.
My next question is to Mr. Dorsey. Does Twitter maintain
data on the political affiliations of accounts that you block?
Mr. Dorsey. No.
Mr. Joyce. Have you determined that any political bias is
necessary for your enforcement?
Mr. Dorsey. I'm not sure what you mean, but no.
Mr. Joyce. I think that these discussions today are so
important. I think that you all recognize that the platforms
that you represent have developed an incredible ability for
Americans to connect and contact. But this free speech that we
hold so dear to us must be maintained.
Again, I thank the chairman, I thank the ranking member for
bringing us together and allowing us to present what I feel are
sincere concerns to you. Thank you, Mr. Chairman, and I yield.
Mr. Doyle. I thank the gentleman. The gentleman yields
back.
Everyone who wanted to ask a question has asked one. And I
want to thank all of you for your patience today. I request
unanimous consent to enter the following records, testimony,
and other information into the record:
A letter from Asian Americans Advancing Justice.
A letter from the Leadership Conference on Civil and Human
Rights.
A letter from New America's Open Technology Institute.
A letter from New York Small Farma, Limited.
A statement from the Alphabet Workers Union.
Letters from National Black Justice Coalition.
A letter from Sikhs for Justice.
A letter from State AGs.
A letter from the Computer and Communications Industry
Association.
A letter from AVAAZ.
Opening statement from Anna Eshoo.
A blog from Neil Fried of DigitalFrontiers Advocacy.
A letter from the music community.
A letter from the Disinfo Defense League.
A letter from Consumer Reports.
A report from the Center for Countering Digital Hate called
``The Disinformation Dozen.''
A letter from the Coalition for a Secure and Transparent
Internet.
A letter from the Sikh American Legal Defense and Education
Fund.
A letter from gun violence survivors, Faces of Tech Harm
Congress.
Letter to YouTube from Rep. Eshoo.
Letter to Facebook from Rep. Eshoo.
Letter to Twitter from Rep. Eshoo.
A longitudinal analysis of YouTube's promotion of
conspiracy videos.
A letter from the Alliance for Safe Online Pharmacies.
A CCIA statement.
A comment by Donovan, et al., from the Technology and
Social Change team.
A Wall Street Journal article titled ``Facebook Executives
Shut Down Efforts to Make Site Less Divisive.''
A Voice of America article titled ``FBI: Surge in Internet
Crime Cost Americans $4.2 Billion.''
A Global Research Project report.
An opinion article titled ``Google Is Not Cracking down on
the Most Dangerous Drug in America.''
An MIT Technology Review article titled ``How Facebook Got
Addicted to Spreading Misinformation.''
An article from the Independent.
An article from the New Yorker.
A letter from the Coalition for a Safer Web.
A New York Times article titled ``Tech Companies Detect a
Surge in Online Videos of Child Sex Abuse.''
An MIT Review article titled ``Thank You for Posting:
Smokers Lessons for Regulating Smug Social Media.''
An article from Imprimis.
An article from The Atlantic.
A New York Times article titled ``Square, Jack Dorsey's Pay
Service, Is Withholding Money Merchants Say They Need.''
A response letter from Twitter to Rep. Rodgers.
A response letter from Google to Rep. Rodgers.
A response letter from Facebook to Rep. Rodgers.
An article from Engadget.
A letter regarding Spanish language misinformation.
Data from the Centers for Disease Control: ``The National
Survey on Drug Use and Health.''
And Mercado, Holland, Leemis, Stone, and Wang regarding
teen mental health.
A report from the House Committee on Veterans' Affairs.
Without objection, so ordered.
[The information appears at the conclusion of the
hearing.\1\]
---------------------------------------------------------------------------
\1\ The Open Technology Institute, New York Small Farma, and AVAAZ
letters with accompanying reports, the MIT Technology Review article,
and the Center for Countering Digital Hate, Global Research Project,
and House Committee on Veterans' Affairs reports are saved in committee
files and are available at https://docs.house.gov/Committee/Calendar/
ByEvent.aspx?EventID=111407.
---------------------------------------------------------------------------
Mr. Doyle. I want to thank our witnesses today for
appearing. We appreciate it. We appreciate your patience while
you answered these questions from all Members. I hope you can
take away from this hearing how serious we are on both side of
the aisle to see many of these issues that trouble Americans
addressed. But thank you for being here today.
I want to remind all Members that, pursuant to Committee
Rules, they have 10 business days to submit additional
questions for the record to be answered by the witnesses who
have appeared. And I would ask each witness to respond promptly
to any questions that you may receive.
At this time, this hearing is adjourned.
Ms. Schakowsky. Mr. Chairman?
Mr. Doyle. Yes?
Ms. Schakowsky. Jan Schakowsky here.
Mr. Doyle. Yes. You are recognized.
Ms. Schakowsky. Thank you. As chair of the Consumer
Protection and Commerce Subcommittee, I just want to say that I
was glad to be really a cochair of this. I think you did a
great job, Mike, in making this happen. It is 5 and a half
hours. I want to thank the witnesses for doing your best to
answer the questions, or at least being willing to be here to
hear all the questions. You can see there is a lot of concern.
We want to work with you and we want to work with each
other in order to move ahead. As I said at the very beginning,
if you take one thing away from this hearing today, is that
these democratically elected Members are ready to act, are
ready to legislate, are ready to regulate in your arena. And we
are hoping that we can work with you as well.
So thank you, Mike, and I yield back.
Mr. Doyle. Thank you, Jan. This hearing is adjourned.
[Whereupon, at 5:33 p.m., the subcommittees were
adjourned.]

Prepared Statement of Hon. Anna G. Eshoo

Chairs Doyle and Schakowsky, thank you for holding this
critically important hearing.
As I've said before, misinformation is killing Americans
and damaging our democracy. Social media companies--Facebook,
YouTube, and Twitter--are a major cause of misinformation
proliferating across society.
We'll hear a lot today about content moderation issues. I
have no knowledge of what my colleagues will ask today, but
we've all seen this movie before. I've asked, as have my
Democratic colleagues, why companies won't remove posts and
accounts that spread misinformation. My colleagues on the other
side of the aisle have asked the opposite question about why
certain posts and accounts are being taken down. Though I
haven't found evidence for any alleged anticonservative bias, I
hear their point and doubt I or this hearing will change minds
on this issue. These are indeed important questions and issues,
but these issues are the symptoms. It's time we start
addressing the disease.
To truly address misinformation, we have to address root
problems.
First, we must use Section 230 strategically. I was a
conferee for the Telecommunications Act of 1996 which included
the now famous Section 230. I have a reverence for the core
idea of the statute--online user speech must be protected.
However, we could not have conceived of the role internet
platforms would play in amplifying, recommending, and sorting
content using complex and opaque, AI-driven algorithms. Too
often, platforms are the ones amplifying illegal or harmful
speech, including speech that leads to offline violence.
This is why Rep. Malinowski and I reintroduced our
legislation, the Protecting Americans from Dangerous Algorithms
Act, which narrowly amends Section 230 to remove liability
immunity for a platform if its algorithm is used to amplify or
recommend content directly relevant to a case involving
interference with civil rights (42 U.S.C. 1985); neglect to
prevent interference with civil rights (42 U.S.C. 1986); and in
cases involving acts of international terrorism (18 U.S.C.
2333). 42 U.S.C. 1985 and 1986 are Reconstruction-era statutes
originally designed to reach Ku Klux Klan conspirators. Sadly,
they are being invoked in lawsuits against insurrectionists and
perpetrators of the January 6th attacks.
This bill is not a panacea for all online harms--no bill
is--and I believe it can pair well with some other narrow
Section 230 reforms that are being suggested. We should use a
scalpel, not a sledgehammer, in reforming this critically
important law.
Second, we must ban surveillance advertising. We've begun
to work in silos where privacy is one problem, advertising is
another, and misinformation is a third. I think this is the
wrong way to see things. All of these problems, and others, are
interconnected. We have to work on all of them and more.
Surveillance advertising is the root of the tree where the
poisonous fruit of misinformation thrives. It incents platforms
to maximize engagement by collecting unseemly amounts of data
to target ads and amplify content that induces anger, anxiety,
and fear. It's why algorithmic amplification thrives unchecked.
That's why, Rep. Schakowsky and I will introduce a bill in
the coming weeks to ban surveillance advertising altogether.
Misinformation is a deadly problem, and we must address it at
its roots. When a business model is fundamentally harmful, it
shouldn't continue.
Finally, traditional content moderation must be improved.
Platform companies have made important efforts to combat COVID-
19 misinformation but the outcomes show that more must be done.
According to a Walgreens executive, about 60% of employees and
20% of residents at long-term care facilities declined
vaccines. National polls similarly show high levels of
hesitancy, and social media is often cited as the cause of
vaccine hesitancy.
Some platforms have turned to removing COVID misinformation
that can cause ``imminent harm'' and labeling the rest.
Research shows that introducing additional information to
someone that believes medical or science-related misinformation
can backfire and cause them to further entrench in their
preexisting views. The implication is clear: Labels just don't
cut it. When it comes to COVID-19 misinformation, companies
must rely on removals.

[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

[all]
