- FEDERAL SCIENCE AGENCIES AND THE PROMISE OF AI IN DRIVING SCIENTIFIC DISCOVERIES

[House Hearing, 118 Congress]
[From the U.S. Government Publishing Office]

FEDERAL SCIENCE AGENCIES
AND THE PROMISE OF AI
IN DRIVING SCIENTIFIC DISCOVERIES

=======================================================================

JOINT HEARING

BEFORE THE

SUBCOMMITTEE ON RESEARCH AND TECHNOLOGY
SUBCOMMITTEE ON ENERGY

OF THE

COMMITTEE ON SCIENCE, SPACE,
AND TECHNOLOGY

OF THE

HOUSE OF REPRESENTATIVES

ONE HUNDRED EIGHTEENTH CONGRESS

SECOND SESSION

__________

FEBRUARY 6, 2024

__________

Serial No. 118-32

__________

Printed for the use of the Committee on Science, Space, and Technology

[GRAPHIC NOT AVAILABLE IN TIFF FORMAT]

Available via the World Wide Web: http://science.house.gov

__________

U.S. GOVERNMENT PUBLISHING OFFICE
54-724 PDF                  WASHINGTON : 2025

-----------------------------------------------------------------------------------

COMMITTEE ON SCIENCE, SPACE, AND TECHNOLOGY

HON. FRANK LUCAS, Oklahoma, Chairman
BILL POSEY, Florida                  ZOE LOFGREN, California, Ranking
RANDY WEBER, Texas                       Member
BRIAN BABIN, Texas                   SUZANNE BONAMICI, Oregon
JIM BAIRD, Indiana                   HALEY STEVENS, Michigan
DANIEL WEBSTER, Florida              JAMAAL BOWMAN, New York
MIKE GARCIA, California              DEBORAH ROSS, North Carolina
STEPHANIE BICE, Oklahoma             ERIC SORENSEN, Illinois
JAY OBERNOLTE, California            ANDREA SALINAS, Oregon
CHUCK FLEISCHMANN, Tennessee         VALERIE FOUSHEE, North Carolina
DARRELL ISSA, California             KEVIN MULLIN, California
RICK CRAWFORD, Arkansas              JEFF JACKSON, North Carolina
CLAUDIA TENNEY, New York             EMILIA SYKES, Ohio
RYAN ZINKE, Montana                  MAXWELL FROST, Florida
SCOTT FRANKLIN, Florida              YADIRA CARAVEO, Colorado
DALE STRONG, Alabama                 SUMMER LEE, Pennsylvania
MAX MILLER, Ohio                     JENNIFER McCLELLAN, Virginia
RICH McCORMICK, Georgia              GABE AMO, Rhode Island
MIKE COLLINS, Georgia                SEAN CASTEN, Illinois,
BRANDON WILLIAMS, New York             Vice Ranking Member
TOM KEAN, New Jersey                 PAUL TONKO, New York
VACANCY
------

Subcommittee on Research and Technology

HON. MIKE COLLINS, Georgia, Chairman
JIM BAIRD, Indiana                   HALEY STEVENS, Michigan,
DARRELL ISSA, California                 Ranking Member
RICK CRAWFORD, Arkansas              ANDREA SALINAS, Oregon
SCOTT FRANKLIN, Florida              KEVIN MULLIN, California
BRANDON WILLIAMS, New York           EMILIA SYKES, Ohio
TOM KEAN, New Jersey                 SUZANNE BONAMICI, Oregon
------

Subcommittee on Energy

HON. BRANDON WILLIAMS, New York, Chairman
RANDY WEBER, Texas                   JAMAAL BOWMAN, New York
JIM BAIRD, Indiana                       Ranking Member
STEPHANIE BICE, Oklahoma             SUMMER LEE, Pennsylvania
CHUCK FLEISCHMANN, Tennessee         DEBORAH ROSS, North Carolina
CLAUDIA TENNEY, New York             ERIC SORENSEN, Illinois
MAX MILLER, Ohio                     ANDREA SALINAS, Oregon
TOM KEAN, New Jersey                 VALERIE FOUSHEE, North Carolina

C  O  N  T  E  N  T  S

February 6, 2024

Page

Hearing Charter..................................................     2

Opening Statements

Statement by Representative Mike Collins, Chairman, Subcommittee
on Research and Technology, Committee on Science, Space, and
Technology, U.S. House of Representatives......................    11
Written Statement............................................    12

Statement by Representative Haley Stevens, Ranking Member,
Subcommittee on Research and Technology, Committee on Science,
Space, and Technology, U.S. House of Representatives...........    12
Written Statement............................................    13

Statement by Representative Brandon Williams, Chairman,
Subcommittee on Energy, Committee on Science, Space, and
Technology, U.S. House of Representatives......................    14
Written Statement............................................    16

Statement by Representative Jamaal Bowman, Ranking Member,
Subcommittee on Energy, Committee on Science, Space, and
Technology, U.S. House of Representatives......................    17
Written Statement............................................    18

Statement by Representative Zoe Lofgren, Ranking Member,
Committee on Science, Space, and Technology, U.S. House of
Representatives................................................    18
Written Statement............................................    19

Written statement by Representative Frank Lucas, Chairman,
Committee on Science, Space, and Technology, U.S. House of
Representatives................................................    20

Written statement by Representative Anna G. Eshoo, U.S. House of
Representatives................................................    95

Witnesses:

Ms. Tess DeBlanc-Knowles, Special Assistant to the Director for
Artificial Intelligence, National Science Foundation
Oral Statement...............................................    21
Written Statement............................................    24

Dr. Georgia Tourassi, Associate Laboratory Director, Computing
and Computational Sciences, Oak Ridge National Laboratory
Oral Statement...............................................    32
Written Statement............................................    34

Dr. Chaouki Abdallah, Executive Vice President for Research,
Georgia Institute of Technology
Oral Statement...............................................    47
Written Statement............................................    49

Dr. Louay Charma, Dean, School of Engineering and Computer
Science, Oakland University
Oral Statement...............................................    54
Written Statement............................................    56

Mr. Jack Clark, Co-Founder and Head of Policy, Anthropic
Oral Statement...............................................    60
Written Statement............................................    62

Discussion.......................................................    68

Appendix I: Answers to Post-Hearing Questions

Ms. Tess DeBlanc-Knowles, Special Assistant to the Director for
Artificial Intelligence, National Science Foundation...........   102

Dr. Georgia Tourassi, Associate Laboratory Director, Computing
and Computational Sciences, Oak Ridge National Laboratory......   114

Dr. Chaouki Abdallah, Executive Vice President for Research,
Georgia Institute of Technology................................   117

Dr. Louay Charma, Dean, School of Engineering and Computer
Science, Oakland University....................................   121

Mr. Jack Clark, Co-Founder and Head of Policy, Anthropic.........   127

Appendix II: Additional Material for the Record

Article submitted by Representative Tom Kean, Committee on
Science, Space, and Technology, U.S. House of Representatives
``Labeling AI-Generated Content: Promises, Perils, and Future
Directions,'' Chloe Wittenberg, et al., MIT Schwarzman
College of Computing.......................................   134

Reports submitted by Representative Suzanne Bonamici, Committee
on Science, Space, and Technology, U.S. House of
Representatives
``Recommendation on the Ethics of Artificial Intelligence,''
UNESCO.....................................................   150
``Electricity 2024: Analysis and forecast to 2026,''
Executive Summary, International Energy Agency.............   194

Documents submitted by Representative Anna G. Eshoo, U.S. House
of Representatives
Letter dated Nov. 9, 2023, to the Honorable Anna Eshoo, U.S.
House of Representatives, from Theresa A. Maldonado, Ph.D.,
P.E, Vice President for Research and Innovation, University
of California..............................................   195
Letter dated Nov. 15, 2023, to ``Dear Representative,'' from
TechNet, et al.............................................   196
Letter dated July 19, 2023, to Chairman Frank Lucas, House
Committee on Science, Space, and Technology, et al., from
TechNet, et al.............................................   198
Letter dated July 19, 2023, to the Hon. Kevin McCarthy,
Speaker of the House, et al., from Microsoft, et al........   200
Letter dated Feb. 5, 2024, to the House Committee on Science,
Space, and Technology from Paul Lekas, Senior Vice
President, and Anton van Seventer, Counsel, Software &
Information Industry Association...........................   202
Article, ``The U.S. Just Took a Crucial Step Toward
Democratizing AI Access,'' by Will Henshall, Jan. 26, 2024,
Tech Artificial Intelligence...............................   204

FEDERAL SCIENCE AGENCIES
AND THE PROMISE OF AI
IN DRIVING SCIENTIFIC DISCOVERIES

----------

TUESDAY, FEBRUARY 6, 2024

House of Representatives, Subcommittee on Research
and Technology, joint with the Subcommittee on
Energy, Committee on Science, Space, and
Technology,
Washington, D.C.

The Subcommittees met, pursuant to notice, at 10:05 a.m.,
in room 2318, Rayburn House Office Building, Hon. Mike Collins
[Chairman of the Subcommittee on Research and Technology]
presiding.
[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

Chairman Collins. The joint hearing will come to order.
Before I get started, I'd like to say, man, what a
difference a weeks make. And thank you, Ms. Onita and lemon
juice. This time last week, I didn't know if I'd be vertical
this week, but feel like a new man today.
Without objection, the Chair is authorized to declare a
recess of the Subcommittee at any time. I also ask unanimous
consent that Reps. Beyer and Eshoo be allowed to sit in for
this hearing. Without objection, so ordered.
Welcome to today's hearing entitled ``Federal Science
Agencies and the Promise of AI (Artificial Intelligence) in
Driving Scientific Discoveries.'' I am going to now recognize
myself for five minutes for an opening statement.
Good morning. I would like to thank our witnesses for
taking the time to join us. Today's joint Subcommittee hearing
will examine how we can harness artificial intelligence to
drive new scientific discoveries. We will also discuss the
obstacles academic researchers and startups face in gaining
access to these AI research resources and the proper role of
the Federal Government in ensuring they are readily accessible.
All of us have heard about the rapid pace of technological
process and AI. I have seen it firsthand how applying AI to the
trucking industry has profoundly improved driver productivity
and efficiency. America is a world leader in AI development,
and according to the Stanford University AI Index Report of
2023, private businesses have invested roughly 3 1/2 times the
amount invested by China in cutting-edge AI systems. The United
States is also the global leader in newly funded AI companies.
The Federal Government spent nearly $3 billion in 2022 on
AI research and development (R&D). The Federal Government is
the leading source of support for basic research in areas
critical to national security. Congress, led by this Committee,
passed the National AI Initiative Act in 2020. This initiative
laid the groundwork for the research the National Institute of
Standards and Technology and the National Science Foundation
(NSF) are conducting in AI.
I am pleased to see Georgia Tech represented among the
panelists as it houses three of the 25 NSF AI institutes in the
U.S. These institutes are applying AI to the real-world
challenges. Solving these challenges is limited by the high
cost of compute infrastructure. It is estimated that the cost
of computing has increased annually by a factor of three
between 2009 and 2022. These costs have widened the gap between
big tech, academic AI researchers, and entrepreneurs.
Facilitating public-private partnerships can help narrow this
gap in efficiency, maximize the development and use of
responsible AI systems.
This Committee looks forward to seeing how the NAIRR
(National Artificial Intelligence Research Resource) pilot at
the National Science Foundation progresses over the next two
years. With 11 Federal agencies and 25 private sector and
nonprofit organizations partnering in the pilot, it looks to be
off to a good, promising start.
At the end of the day, our adversaries are not waiting for
us. The Chinese Communist Party is implementing AI industrial
policy on a national scale. It is Congress' responsibility to
ensure that America maintains its leadership role in AI. That
will require the academic community, industry partners, and
small businesses to all work together to shape the future of
this technology.
I want to again thank the witnesses for being here today,
and I look forward to a productive discussion.
[The prepared statement of Chairman Collins follows:]

Good morning. I would like to thank all our witnesses for
taking the time to join us.
Today's joint subcommittee hearing will examine how we can
harness artificial intelligence (AI) to drive new scientific
discoveries. We will also discuss the obstacles academic
researchers and start-ups face in gaining access to these AI
research resources and the proper role of the federal
government in ensuring they are readily accessible.
All of us have heard about the rapid pace of technological
progress in AI. I have seen how applying AI to the trucking
industry has profoundly improved driver productivity and
efficiency.
America is a world leader in AI development. According to
the Stanford University AI Index Report of 2023, private
businesses have invested roughly three and a half times the
amount invested by China in cutting-edge AI systems.
The U.S. is also the global leader in newly funded AI
companies.
The federal government spent nearly $3 billion in 2022 on
AI research and development (R&D). The federal government is
the leading source of support for basic research and areas
critical to national security.
Congress, led by this Committee, passed the National AI
Initiative Act in 2020. This initiative laid the groundwork for
the research the National Institute of Standards and Technology
(NIST) and the National Science Foundation are conducting in
AI.
I am pleased to see Georgia Tech represented among the
panelists as it houses three of the twenty-five NSF AI
institutes in the U.S. These institutes are applying AI to
real-world challenges.
Solving these challenges is limited by the high cost of
compute infrastructure. It is estimated that the cost of
computing has increased annually by a factor of three between
2009 and 2022.
These costs have widened the gap between Big Tech, academic
AI researchers, and entrepreneurs. Facilitating public-private
partnerships can help narrow this gap and efficiently maximize
the development and use of responsible AI systems.
This Committee looks forward to seeing how the NAIRR pilot
at the National Science Foundation progresses over the next two
years. With 11 federal agencies and 25 private sector and
nonprofit organizations partnering in the pilot, it looks to be
off to a promising start.
At the end of the day, our adversaries are not waiting for
us. The Chinese Communist Party is implementing AI industrial
policy on a national scale.
It is Congress's responsibility to ensure that America
maintains its leadership role in AI.
That will require the academic community, industry
partners, and small businesses to all work together to shape
the future of this technology. I want to again thank the
witnesses for being here today and I look forward to a
productive discussion.

Chairman Collins. I now recognize the Ranking Member, the
gentlewoman from Michigan, for an opening statement.
Ms. Stevens. Thank you, Chairman Collins. You've had a
remarkable first term in Congress, and you're such a valued
voice in this institution. And it's a delight to work with you
on this Committee. And certainly thank you, Chairman Williams,
as well for hosting today's hearing, AI, the conversation that
possesses Congress but compels action.
And we're here to explore the promises of artificial
intelligence for scientific discovery and how the incredible
scientific agencies of the U.S. Government can harness and
enable these opportunities. So we've got just a remarkable set
of witnesses who are going to provide testimony, and it's a
real delight to have Louay Chamra here from--Dr. Louay Chamra
here from Oakland University (OU), the pride and joy of
Michigan and really the School of Engineering that is doing so
much in Oakland County. So thank you, Dr. Chamra.
And, look, the Science Committee has just had a great track
record in terms of passing legislation to minimize the
downsides of artificial intelligence and maximize the good for
this revolutionary technology. And while responsible
development of AI will continue to be a--certainly, a long-term
challenge and something that this Committee will work on for a
long time to come, AI has also given us new and exciting
opportunities, many that just haven't been tapped into yet. So
we're going to hear about that today.
And in my home State of Michigan, advances in artificial
intelligence by automakers are accelerating the development of
autonomous vehicle technology that could potentially--you know,
that has some real significant opportunity to minimize traffic
and certainly increase safety. You know, the goal of zero auto
accident fatalities is something that we should be championing
here from the halls of Congress.
And so AI systems are also going to be analyzing, as we
know, massive amounts of data to accelerate research in fields
from cosmology to engineering and biology and neurology. And
those examples present just a tiny slice of the ways in which
artificial intelligence is already benefiting many aspects of
our lives and supporting our economic and national security.
There's another Committee here in the U.S. Congress, the
Select Committee on U.S. Strategic Competition with the Chinese
Communist Party. And out of many core technology areas,
artificial intelligence is one that we are honing in on. And we
realize that it's not going to just be the private sector alone
that is going to be compelled to invest and act. It's our
partnership with academia and Federal agencies that are not
only authorized, but invested in. We passed the CHIPS and
Science bill. We did a risk management framework for artificial
intelligence. We're working here on this Committee to
reauthorize Quantum Initiative Act to harness not only the
computing power and how capital intensive that is, but also its
applications. And while we say AI, AI, AI over and over again,
and trust me, I'm in an AI meeting multiple times a week, it
feels like, when we're in session, it is so important to also
be talking about what this Committee is working on with
quantum.
And so as we have prepared testimony here today, certainly
those of us on the Committee who are dedicated to the
technology prowess of the United States of America, vis-a-vis
our grand global competitions, that we will not just sleep
through, that we will harness through our capabilities as a
free and open society, as a democracy, and as a country that
has the willingness to co-invest in strategic competition.
We're really very proud of the researchers, the efforts, and
the energy, and we look forward to what transpires in today's
hearing.
Thank you, Mr. Chair, and I yield back.
[The prepared statement of Ms. Stevens follows:]

Thank you, Chairman Collins and Chairman Williams for
hosting this hearing.
Good morning and welcome to today's joint hearing to
explore the promises of artificial intelligence for scientific
discovery and how our amazing scientific agencies can enable
these opportunities. I also welcome our distinguished panel of
witnesses, including Dr. Louay Chamra, the Dean of the School
of Engineering and Computer Science at Oakland University--a
phenomenal university in my district in Michigan. It is great
to have you here today.
The Science Committee has a long history of passing
legislation to minimize the downsides of AI and maximize the
good for this revolutionary technology. While responsible
development of AI will continue to be a long-term challenge, AI
has brought new, exciting opportunities, many of these are yet
to be tapped. I look forward to hearing from our panelists
about these opportunities and the steps that Congress must take
to realize them.
In my home state of Michigan, advances in AI by automakers
are accelerating the development of autonomous vehicles that
could potentially reduce traffic and increase safety.
Scientists increasingly use AI systems to analyze massive
amounts of data to accelerate research in fields from cosmology
to engineering biology to neurology. Those examples represent
just a tiny slice of all of the ways in which artificial
intelligence is already benefiting many aspects of our lives
and supporting our economic and national security.
To realize all of the benefits that may be possible, we
need a skilled workforce that can apply AI technologies
responsibly to our national and community needs. This means
that we need to provide hands-on learning opportunities to all
types of students and workers across sectors, including those
who want to upskill and apply new uses of AI in their current
jobs. Many of our local colleges and universities, such as
Oakland University, are well positioned to provide these
learning experiences and may even have existing programs that
do so. However, they can greatly benefit from additional
federal resources, especially computing resources, data, and
educational tools-to scale their ability to train students and
create a skilled AI workforce for our country.
The National Artificial Intelligence Research Resource or
NAIRR is intended to do just that--but in a way that reaches
institutions and researchers across the country. I look forward
to learning more about how the pilot program is proceeding, how
the program brings together federal and non-government
partners, and how it can inform a potential full-scale NAIRR
program.
Since joining this Committee, I have worked with my
colleagues on both sides of the aisle to promote trustworthy AI
innovation. I am proud that we led the development of the 2020
National AI Initiative Act to accelerate and coordinate Federal
investments in research, standards, and education in
trustworthy AI. In that Act, Congress built upon existing
National Science Foundation and Department of Energy AI
research and education programs, including authorizing NSF to
lead the National AI Research Institutes program. That Act also
created the intellectual underpinnings for the NAIRR by
creating a task force to study the issue.
I am excited that we get to focus on the amazing
contributions AI can bring to scientific discovery and
innovation across all fields, and what we here in Congress can
do to ensure the United States leads the world in trustworthy
artificial intelligence. Thank you again to our witnesses for
joining us today.
I yield back, Mr. Chairman.

Chairman Collins. Thank you, Ms. Stevens.
I now recognize the Chairman of the Energy Subcommittee,
the gentleman from New York, for an opening statement.
Mr. Williams. Thank you, Mr. Chairman. Glad to be here.
Good morning.
Today, the Subcommittee on Research and Technology and the
Subcommittee on Energy will be examining the Federal
Government's science agencies' ability to drive innovation and
deliver scientific achievements using artificial intelligence.
AI will play a crucial role and an important role in our
society and in our economy in the coming decades.
To be clear, artificial intelligence is like the first
powerful microscopes that allowed humans to see details into
the physical world hundreds of years ago. Microscopes today
continue to unlock secrets in medicine, material, and countless
other innovations. AI is also like the emergence of computer
technologies that in just the last 75 years have done amazing
things. Today, machines help us solve problems at unprecedented
speed and unimaginable complexity in just seconds, like how to
safely navigate to the Moon and get home safely or like how to
examine DNA information, looking for clues in diseases and
potential cures, just some of the things that computer
technology has done.
AI is simply a tool that allows humans to see complexity
and insight into huge amounts of data of our modern digital
age. For example, artificial intelligence may vastly reduce the
times it takes to increase the accuracy when doctors--sorry,
vastly reduced the time it takes and also to increase the
accuracy when doctors evaluate cancer cells, increasing
diagnosis and treatment options at a critical moment.
AI is a powerful and exciting tool, and like all new tools
and technologies, the risks and opportunities must be
understood. And we also must confidently move forward. Given
this untapped potential, the Federal Government and its
agencies have an important role to play. Why? Simply put, the
billions of dollars that the Federal Government has invested in
science over a very long period of time has produced invaluable
datasets that hold secrets that AI alone can unlock. These AI-
enabled discovery--AI-enabled discovery could be
transformational in energy, medicine, materials, and many other
areas. Similarly, the Federal Government has tools like high-
performance computing (HPC) resources that are unique and
powerful for creating AI-generated algorithms from this
remarkable dataset that they possess.
So let me dive in here for just a minute. The National
Science Foundation supports university research while fostering
next-generation workforce. The National Institute of Standards
and Technology, part of the Department of Energy (DOE),
developed standards for trustworthiness in collaboration with
industry. The Department of Defense uses its own research
laboratories, as well as the industrial suppliers, to develop
AI technologies to keep our Nation safe.
And of particular relevance to my Energy Subcommittee, the
Department of Energy maintains and develops the Federal
Government's AI infrastructure through the National
Laboratories. Of particular importance to the National
Laboratories are critical in developing next-generation
workforce that will be critical to our Nation's future with
artificial intelligence.
Given its unique data sources and its dedicated access to
computing and unique experimental facilities--that's where data
comes from--the Department of Energy is strategically
positioned to lead and accelerate AI development. The Advanced
Scientific Computing Research Program, located within the
Office of Science, conducts cutting-edge computational and
networking research. It also manages the most advanced
computing systems in the world.
According to the 500 list of the fastest supercomputers,
the Department of Energy--excuse me. The Department of Energy
operates 4 of the top 10 of these supercomputers, including the
only two exascale computers in the world, Frontier at Oak Ridge
and Aurora at Argonne. Because of these extraordinary tools,
the DOE is well-positioned to lead and to play a larger role in
this ecosystem as it relates to artificial intelligence.
Today's hearing, as we dive into NAIRR and other programs
that are in place, you know, we're going to try to explore
where the Federal Government should and could lead and use our
unique resources to drive AI-fueled innovation here in America,
for Americans. So, you know, as Congress continues to support
this research, I hope that there's new innovation that comes
out of even this dialog. And I look forward to our conversation
today.
I yield back.
[The prepared statement of Mr. Williams follows:]

Good morning. Today, the Subcommittee on Research and
Technology and the Subcommittee on Energy will be examining the
Federal government's science agencies' abilities to drive
innovation and deliver scientific achievements using artificial
intelligence.
AI will play a crucial and important role in our society
and our economy in the coming decades. To be clear, artificial
intelligence is like the first powerful microscopes that
allowed humans to see details into the physical world hundreds
of years ago, unlocking innovations in medicine, materials, and
countless other inventions. AI is also like the emergence of
computer technologies in just the last 75 years. Machines help
us solve problems at unprecedented speed and unimaginable
complexity in seconds--like how to safely navigate to the moon
and get home safely. Or, like how to examine DNA information
looking for clues to diseases and the potential cures. AI is
simply a tool that allows humans to see complexity and insight
into huge amounts of data of our modern digital age. For
example, artificial intelligence may vastly reduce the time it
takes and to increase the accuracy when doctors evaluate cancer
cells, increasing diagnosis and treatment options. AI is a
powerful and exciting tool. And like all new tools and
technologies, the risks and opportunities must be understood as
we also move confidently forward.
Given its untapped potential, the federal government and
its agencies have an important tole to play. Why? Simply put,
the billions of dollars the federal government has invested in
science over a long period of time has produced invaluable sets
of data that hold secrets that AI alone can unlock. These AI-
enabled discovery could be transformational to Energy,
Medicine, and Materials. Similarly, the federal government has
tools, like high performance computing resources, that are
unique and powerful for creating AI generated algorithms from
this remarkable data. Let me dive in here.
The National Science Foundation supports university
research while fostering a next generation workforce. The
National Institute of Standards and Technology, part of the
Department of Energy, develops standards for trustworthiness in
collaboration with industry. The Department of Defense uses its
advanced industrial base to develop AI technologies. And of
particular relevance to the Energy Subcommittee, the Department
of Energy maintains the federal government's AI infrastructure
while providing expertise through its National Laboratories and
hands-on workforce development.
Given its unique data sources and its dedicated access to
computing and unique experimental facilities, DOE is
strategically positioned to lead and accelerate AI development.
The Advanced Scientific Computing Research program, located
within the Office of Science, conducts cutting edge
computational and networking research. It also manages the most
advanced computing systems in the world. According to the Top
500 List of the fastest supercomputers, DOE operates four of
the top ten, including the only two exascale computers in the
world: Frontier at Oak Ridge National Laboratory and Aurora at
Argonne National Laboratory.
Developed through the Exascale Computing Project, these
supercomputers can perform life- changing work. For example,
with this compute power alongside AI, researchers can
accelerate pharmaceutical drug development by screening
billions of drugs against specific cancer cells, potentially
finding cures in seconds that were impossible before.
With this AI infrastructure, DOE is playing a larger role
in the broader ecosystem through interagency partnerships.
Recently, the National Science Foundation announced that it
will be launching the National Artificial Intelligence Research
Resource pilot, known as NAIRR. Authorized in the National AI
Initiative of 2020, NAIRR supports fundamental AI research by
bringing together academia, industry, non-profits, and
government. As a partner, DOE will extend its operation of the
Summit supercomputer at Oak Ridge and provide access for NAIRR,
empowering researchers, enhancing U.S. competitiveness in
emerging technologies, and stimulating economic growth.
In addition, DOE's computing power has supported NASA's
mission to land humans on Mars. Using Summit, NASA scientists
simulated six different flight scenarios, which are informing
future missions to the planet. My bill, H.R. 2988, the DOE and
NASA Interagency Research Coordination Act, codifies these
types of successful interagency partnerships using advanced
computing and artificial intelligence.
To make the best use of AI, Congress must continue to
support research that accelerates innovation, improves
interagency collaboration, and strengthens workforce
development opportunities. As the Chairman of the Energy
Subcommittee, I understand the world leading resources
available at the Department of Energy and firmly believe they
need to have a leading role in the government's approach to AI.
With that, I look forward to our conversation and yield
back.

Chairman Collins. Thank you, Mr. Will--Williams. I don't
know why I couldn't get that out.
I now recognize the Ranking Member of the Energy
Subcommittee, the gentleman from New York, for an opening
statement.
Mr. Bowman. Thank you so much. Good morning, and thank you
to all of the distinguished witnesses for joining us here
today, as well as to Chairman Collins and Chairman Williams for
holding this important hearing.
While we have all gained awareness of some of the risks
associated with AI, and we will certainly explore these risks
further in our discussion this morning, this hearing will also
present us with an opportunity to discuss the benefits of using
these capabilities to further drive innovation and advance our
national scientific expertise.
DOE and its network of national laboratories employ
advanced computational systems and powerful supercomputers that
enable them to be at the forefront of AI development. With
their computational resources and tools, DOE researchers are
well-positioned to fully benefit from the capabilities of
artificial intelligence. These advances may help us solve
humanity's most pressing problems by enabling researchers to
analyze huge datasets, rapidly generate and test new designs of
lifesaving medical treatments, and optimize new advanced
manufacturing techniques.
DOE's supercomputing ecosystem and AI tools serve as a
critical resource for academic and industry users from the
United States and around the world. However, outside of a
handful of well-resourced tech companies and universities,
there's a general lack of access to computing resources that
would allow them to train AI systems of comparable complexity
with ChatGPT. This is particularly concerning with regard to
institutions serving marginalized communities. To ensure that
we are sharing the benefits of AI and advanced computing
equally, we need to pursue an agenda of scientific computing
for the people. As I have said before, we need a skilled and
diverse workforce to maintain the vitality of DOE's scientific
computing ecosystem long into the future. To that end, I'm
looking forward to discussing with our witnesses how expanding
access to these resources can tackle these challenges.
I will also note that while DOE's AI and supercomputing
capabilities hold tremendous promise for accelerating
scientific discovery, we need to use these capabilities
responsibly and ethically. As the use of artificial
intelligence becomes more commonplace in our everyday lives, we
must ensure that its fundamental algorithms are designed to
protect people's privacy and eradicate bias. I repeat, and
eradicate bias.
We must also stop these tools from fortifying the
structures of systemic racism, as we have seen happen with
things like predictive policing and facial recognition
technology. This will only become more important as AI is
further trained to be able to process, analyze, and store
sensitive information such as biomedical datasets.
All that said, I want to thank, again, our panel of
witnesses assembled today, and I look forward to hearing your
testimony. And I just want to further emphasize the issues of
bias and structures of systemic racism that persists in many of
our institutions. We all carry biases. As we create these new
technologies, it's important for us to be aware of that up
front and have safeguards as it relates to that going in.
Thank you, and I yield back, Mr. Chairman.
[The prepared statement of Mr. Bowman follows:]

Good morning, and thank you to all of the distinguished
witnesses for joining us today, as well as to Chairman Collins
and Chairman Williams for holding this important hearing. While
we have all gained awareness of some of the risks associated
with AI--and we will certainly explore these risks further in
our discussions this morning--this hearing will also present us
with an opportunity to discuss the benefits of using these
capabilities to further drive innovation and advance our
national scientific enterprise.
DOE and its network of National Laboratories employ
advanced computational systems and powerful supercomputers that
enable them to be at the forefront of AI development. With
their computational resources and tools, DOE researchers are
well positioned to fully benefit from the capabilities of
artificial intelligence. These advances may help us solve
humanity's most pressing problems by enabling researchers to
analyze huge data sets, rapidly generate and test new designs
of life-saving medical treatments, and optimize new advanced
manufacturing techniques.
DOE's supercomputing ecosystem and AI tools serve as a
critical resource for academic and industry users from the U.S.
and around the world. However, outside of a handful of well-
resourced tech companies and universities, there is a general
lack of access to computing resources that would allow them to
train AI systems of comparable complexity with ChatGPT. This is
particularly concerning with regard to serving marginalized
communities. To ensure that we are sharing the benefits of AI
and advanced computing equally, we need to pursue an agenda of
scientific computing for the people. As I have said before, we
need a skilled and diverse workforce to maintain the vitality
of DOE's scientific computing ecosystem long into the future.
To that end, I am looking forward to discussing with our
witnesses how expanding access to these resources can tackle
these challenges.
I would also note that while DOE's AI and supercomputing
capabilities hold tremendous promise for accelerating
scientific discovery, we need to use these capabilities
responsibly and ethically. As the use of artificial
intelligence becomes more commonplace in our everyday lives, we
must ensure that its fundamental algorithms are designed to
protect people's privacy and eradicate bias. We must also stop
these tools from fortifying the structures of systemic racism,
as we have seen happen with things like predictive policing and
facial recognition technology. This will only become more
important as AI is further trained to be able to process,
analyze, and store sensitive information, such as biomedical
datasets.
All that said, I want to again thank our panel of witnesses
assembled today, and I look forward to hearing your testimony.
With that, I yield back.

Chairman Collins. Thank you, Mr. Bowman.
The Chair now recognizes the Ranking Member of the Full
Committee for a statement.
Ms. Lofgren. Thank you, Mr. Chairman.
Today's hearing will explore the promise of artificial
intelligence in supporting scientific innovation. Now, this is
a topic the Science Committee knows well. In 2020, this
Committee led the development of the National AI Initiative Act
to support research, development, and standardization for
trustworthy AI. The bill created a whole-of-government approach
to fostering AI-driven innovation, and since it became law, the
initiative has resulted in some truly wonderful outcomes.
Near my district, NSF and the Department of Agriculture
supported the University of California (UC) at Davis to launch
an AI research institute dedicated to next-generation food
systems that are more resilient to climate change, disease, and
supply chain disruptions, healthier for our communities, and
more productive for our farmers. AI is also being applied to
minimize resource consumption in waste and food systems.
One of the most interesting aspects of these AI institutes,
which we authorized in the initiative, is that each of them
fosters wide-reaching ecosystems around their respective topic.
Not only does UC Davis include partnerships with six
institutions, but it supports agricultural competitions,
hackathons, and internships to teach students from the
surrounding area to learn about AI and robotics for farming.
These competitions include participants such as Hartnell
College, a wonderful community college in my district, well to
the south of Davis. Colleges like Hartnell will play an
important role in AI ecosystems. They'll train technical
workers to use AI technology in fields like food and
agriculture. However, small universities and community colleges
face significant resource constraints and are often reliant on
large universities like UC Davis to give their students
opportunities for hands-on learning. Even most research
universities run into barriers with access to computing and
data resources that's going to be required to conduct AI
research.
Now, a major focus of this hearing will be the National AI
Research Resource, or NAIRR. NSF launched a pilot for this
program a few weeks ago. The goal of NAIRR is to democratize
access to AI tools. To date, most of these resources exist in
industry, specifically, in a handful of very large companies.
To truly achieve the promise of AI for societal benefit and
develop effective guardrails against harm, talented and
passionate researchers, students, startups from across the
Nation will need access to the kind of computational and data
resources that are currently available only to a few, to the
biggest companies. Achieving that kind of scale will require
significant Federal investment. To justify this investment, we
need to make sure our resources can go as far as possible, but
also make sure they're used efficiently and judiciously.
I look forward to the discussion today to learn more about
the NAIRR program and how Congress can help address the
resource needs of the AI community, including startups, large
research universities, as well as community colleges like
Hartnell.
Thank you to our distinguished witnesses, and, Mr.
Chairman, I yield back.
[The prepared statement of Ms. Lofgren follows:]

Thank you, Chairman Collins and Ranking Member Stevens of
our Research and Technology Subcommittee, and Chairman Williams
and Ranking Member Bowman of our Energy Subcommittee, for
holding today's hearing. I would also like to welcome our
distinguished panel of witnesses.
Today's hearing will explore the promise of artificial
intelligence in supporting scientific innovation. This is a
topic that the Science Committee knows well. In 2020, this
Committee led the development of the National AI Initiative Act
to support research, development, and standardization for
trustworthy AI. The bill created a whole-of-government approach
to fostering AI-driven innovation. And since it became law, the
initiative has resulted in some truly wonderful outcomes.
Near my district, NSF and the Department of Agriculture
supported the University of California, Davis, to launch an AI
research institute dedicated to next-generation food systems.
This institute integrates AI and bioinformatics to enable food
systems that are more resilient to climate change, disease, and
supply chain disruptions, healthier for our local communities,
and more productive for our farmers. AI is also being applied
to minimize resource consumption and waste in food systems.
One of the most interesting aspects of these AI institutes,
which we authorized in the National AI Initiative Act, is that
each of them fosters wide-reaching ecosystems around their
respective topic. Not only does the UC Davis institute include
partnerships with six institutions, but it supports
agricultural competitions, hackathons, and internships to teach
students from the surrounding area to learn about AI and
robotics for farming. These competitions include participants
such as Hartnell College, a small community college in my
district well to the south of Davis.
Colleges like Hartnell College will play an important role
in our AI ecosystem, training technical workers to use AI
technology in fields like food and agriculture. However,
smaller universities and community colleges face significant
resource constraints and are often reliant on larger
universities like UC Davis to give their students opportunities
for hands-on learning. Even most research universities run into
barriers with access to computing and data resources required
to conduct AI research.
A major focus of this hearing will be the National AI
Research Resource or NAIRR (rhymes with ``air''). NSF launched
a pilot for this program a few weeks ago. The goal of NAIRR is
to democratize access to AI tools. To date, most of these
resources exist in industry--and specifically, in a handful of
large companies. To truly achieve the promise of AI for
societal benefit--and develop effective guardrails against
harm--talented and passionate researchers, startups, and
students from across the nation will need access to the kind of
computational and data resources that are currently available
to only a few. Achieving that kind of scale will require
significant federal investment.
To justify this investment, we need to both make sure our
resources can go as far as possible but also make sure they are
used efficiently and judiciously.
I look forward to the discussion today to learn more about
the NAIRR program and how Congress can help address the
resource needs of the AI community, including AI startups,
large research universities, and community colleges like
Hartnell.
Thank you and I yield back.

Chairman Collins. Thank you, Ms. Lofgren.
[The prepared statement of Chairman Lucas follows:]

Good morning, and thank you all for joining us for this
important hearing on artificial intelligence and our federal
science agencies.
This is one in a series of hearings this committee is
holding on AI. In October we held one on effective risk
management, and another in June on how we can advance
trustworthy AI to support American competitiveness.
Along with those hearings, today's will help inform future
legislation on AI.
I can't emphasize enough the importance of the committee
process when it comes to crafting legislation. We've had
detailed discussions with government agencies, industry--large
and small--and academics about what is working and what more
needs to be done to ensure the development of safe, trustworthy
AI.
All those discussions will be considered when this
committee drafts legislation, giving everyone input into this
important debate.
Today's hearing will delve into how AI is being utilized by
our federal science agencies and how it's driving progress in
our broader research ecosystem.
There are three critical components in the formula for
successful AI innovation: access to a skilled workforce, access
to computing power, and access to data.
Our federal science agencies play an important role in all
three of these areas.
The National Science Foundation is working with our
universities to address the workforce challenge. I expect we'll
hear from Georgia Tech today about the importance of educating
and inspiring the next generation of AI talent.
Having capable, trained STEM workers at all points of the
chain in the AI workforce is going to be crucial if we are to
compete with China.
Our federal science agencies also play a large role when it
comes to access to compute. The Department of Energy and our
National Labs have some of the most high-powered computers in
the world. Their computing resources provide an unmatched
ability to develop new and innovative AI models.
They'll also be providing user access to the Argonne
Leadership Computing Facility's AI Testbed. This will allow
users to run new and complex models on everything from energy
production to drug development.
When it comes to access to data, I expect that we'll have a
lot of discussion today about the National AI Research
Resource, or NAIRR.
We authorized the NAIRR task force as part of the National
AI Initiative to consider how to create a shared infrastructure
that U.S. researchers could use to conduct better AI research.
The NAIRR Pilot is off to a strong start already, with
broad interagency and industry support. I'm excited to see how
it will deliver resources to the full range of AI researchers
in this country, from universities to small startups.
Staying at the head of the competition as we develop
trustworthy AI has been a high priority for this Committee for
years.
We emphasized it with the National AI Initiative and again
with CHIPS and Science. And we've long recognized the dangers
of having AI development take place in just a few select
companies with access to critical resources.
NAIRR is an effort to expand our development of AI and to
ensure good ideas aren't being lost in the shuffle due to lack
of resources.
So I'm looking forward to hearing more about this pilot and
how it's developing.
AI is the next frontier in technological development. It is
going to reshape how we do business, how we learn, and how we
interact with each other. So it's critical that we get this
right.
I'd like to thank the witnesses for your time today, and
I'm eager to hear your thoughts on this important subject.

Chairman Collins. I will now introduce our witnesses. Our
first witness today is Ms. Tess DeBlanc-Knowles, who is the
Special Assistant to the Director for Artificial Intelligence
at the National Science Foundation. Our next witness is Dr.
Georgia Tourassi, who was the Associate Laboratory Director for
Computing and Computational Sciences at the Oak Ridge National
Laboratory. Next, we have Dr. Abdallah, who is the Executive
Vice President for Research at the Georgia Institute of
Technology. Then, we have Dr. Chamra, who is the Dean for the
School of Engineering and Computer Science at Oakland
University. And our final witness is Mr. Clark, who is the Co-
Founder and Head of Policy of Anthropic.
With that, I now recognize Ms. DeBlanc-Knowles for five
minutes to present her testimony.

TESTIMONY OF MS. TESS DeBLANC-KNOWLES,

SPECIAL ASSISTANT TO THE DIRECTOR

FOR ARTIFICIAL INTELLIGENCE,

NATIONAL SCIENCE FOUNDATION

Ms. DeBlanc-Knowles. Chairman Collins, Chairman Williams,
Ranking Member Stevens, Ranking Member Bowman, and Ranking
Member Lofgren, and the Members of the Subcommittees, it's a
privilege to appear before you today to discuss the important
role the U.S. National Science Foundation plays in pursuing
leading-edge AI research and harnessing AI to drive discoveries
in scientific domains.
For more than seven decades, NSF has invested in research,
researchers, innovations, and innovators, and world-class
scientific research infrastructure that has garnered incredible
benefits to the Nation. Many of the technologies and the
industries that are the focus of national conversations around
competitiveness today, including artificial intelligence, are
rooted in sustained NSF support, in many cases, over several
decades.
As a leading nondefense Federal funder of AI research, NSF
invests more than $800 million each year on AI research,
education, and infrastructure across all 50 States, D.C., and
Puerto Rico. NSF's ability to leverage expertise across
disciplines allows the agency to bring diverse groups of
scientists and engineers together with private industry,
communities, and others to identify problems and use science,
engineering, and technology to develop solutions.
NSF is driving cutting-edge innovations that expand our
understanding of AI concepts and techniques, accelerating
trustworthy AI development, applying AI across scientific
domains, democratizing access to AI resources, and preparing
the next-generation AI workforce. For example, in the field of
biotechnology, NSF-funded researchers are using AI to identify
strains of crops with favorable characteristics to improve crop
yields. In engineering, NSF-funded researchers are leveraging
AI to address supply chain gaps, test quantum networking
hardware, and optimize aviation maintenance and inspection. In
the health sector, NSF-funded researchers are developing AI
tools to monitor patients with lung disease and alert medical
staff to patients at risk for sepsis.
NSF has also invested in large-scale transformative
efforts. In 2020, NSF launched the National AI Research
Institutes, bringing together government, industry, academia,
and others to advanced AI-based technologies across a wide
range of important application areas.
Today, there are 25 AI institutes representing a $500
million investment throughout the country, working to advance
weather and climate modeling, education, healthcare,
agriculture, and many other critical national priorities.
Importantly, they're also developing the AI leaders of
tomorrow. And just last week, we announced the first-ever NSF
regional innovation engines, investing in 10 teams spanning 18
States. These investments intend to harness science and
technology and regional-level resources to spur innovation,
leading to breakthrough technologies and new jobs. Among these
10 inaugural NSF engines, seven involve a significant focus on
the application of AI in areas such as sustainable water-
intensive industry, next-generation agriculture, and
regenerative medicine.
However, our ability to continue to lead in AI and innovate
with AI requires an investment in the infrastructure required
for current and future generations to harness the power of this
technology. Access to such infrastructure is currently limited
to well-resourced institutions and companies. And Congress
recognized this issue in the passage of the National AI
Initiative Act of 2020, which spurred the creation of the
National AI Research Resource, or NAIRR Task Force. That task
force recommended the creation of a NAIRR to expand access to
the resources and tools that make AI innovation and discovery
possible.
Just a few weeks ago, NSF and collaborating agencies across
the Federal Government launched the NAIRR pilot. This pilot is
a first step toward realizing the vision for a shared research
infrastructure that will strengthen and democratize access to
critical resources necessary to power responsible AI discovery
and innovation. The NAIRR pilot will bring together computing,
data, software, and training resources contributed by 11
agencies and 25 private sector nonprofit and philanthropic
partners to support work that pushes the boundaries of AI
technology and that applies AI to other fields of science and
engineering. The pilot will run for two years, serving as the
proof-of-concept for a full-scale NAIRR that will allow for
researchers throughout the country to access world-class
infrastructure to use AI to accelerate innovation.
While AI raises significant challenges that must be
addressed and risks that needs to be mitigated, we cannot lose
sight of the extraordinary promise it holds. More thorough and
faster cancer screening, more accurate weather modeling and
forecasting, more secure cyber infrastructure, these are the
benefits we're already seeing today. By providing more access
to AI tools and fostering innovation across fields of science
and engineering, we can unlock even greater advancements for
the Nation.
Thank you for the opportunity to testify before you today.
[The prepared statement of Ms. DeBlanc-Knowles follows:]
[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

Chairman Collins. Thank you.
I now recognize Dr. Tourassi for five minutes to present
her testimony.

TESTIMONY OF DR. GEORGIA TOURASSI,

ASSOCIATE LABORATORY DIRECTOR,

COMPUTING AND COMPUTATIONAL SCIENCES,

OAK RIDGE NATIONAL LABORATORY

Dr. Tourassi. Chairman Collins, Chairman Williams, Ranking
Member Stevens, Ranking Member Bowman, Ranking Member Lofgren,
and distinguished Members of the Committee, thank you for the
opportunity to discuss the important role the Department of
Energy and its national laboratories play in advancing a
national artificial intelligence capability.
I'm a biomedical engineer and computational scientist by
training with three decades of experience as a translational AI
scientist. I was also privileged to direct the Oak Ridge
Leadership Computing Facility and helped deploy Frontier in
2022, the first exascale system in the United States and the
world's most powerful supercomputer dedicated to open science.
Frontier marked an impressive trajectory for our facility,
for DOE, and for the Nation, demonstrating that in the past
decade, we improved computational power by a factor of 500,
while limiting the growth of energy consumption, which
increased only by a factor of four. Frontier currently supports
researchers from academia, industry, and Federal agencies in
training very large AI models to advance both basic and applied
science and offer new insights into quantum materials,
chemistry, physics, biology, fusion, and more.
Leveraging its unique scientific user facilities and
research capabilities, DOE has supported multiagency
collaborative projects to advance shared national priorities
throughout the years. Now, DOE is supporting NSF's NAIRR pilot
by providing access to its leadership computing resources, AI
testbeds, and data assets. This includes the Oak Ridge
Leadership Computing Facility's Summit supercomputer, currently
ranked number seven fastest supercomputer in the world. Summit
offers an accredited environment well-suited for the NAIRR
Secure focus area. Co-led by NIH (National Institutes of
Health) and DOE, NAIRR Secure enables academics, scientists to
pursue AI research using data requiring privacy protections and
extra security.
In addition to working with NSF to provide greater access
to AI resources, DOE is also taking steps to fill the gaps in
performance, efficiency, and trustworthiness needed to fully
deliver on the promise of AI. The immense computing power
required to train increasingly complex AI models demands even
more energy-efficient, high-performance computing solutions.
DOE has been making vital R&D investments to address these
challenges and extend the transformative efficiency and
performance gains achieved through its exascale computing
project, but more progress is needed.
That's why the DOE national labs collaborated to develop a
programmatic roadmap known as the Frontiers in AI for Science,
Security, and Technology, or FASST. Recognizing that AI will
accelerate innovation, vast target-complex, mission-critical
applications in energy, science, and security, it does so by
leveraging DOE's unique compute resources, vast scientific data
assets, and multidomain scientific expertise.
Although interest in AI is dominated by applications, more
research is needed to improve AI performance, efficiency,
safety, reliability, and trustworthiness. FAST aims to address
these gaps as well, leveraging DOE's long history in scientific
machine learning and deep experience in balancing risk and
opportunity when translating solutions from open science to
national security.
In addition, FAST aims to drive progress and amplify
innovation in AI through open partnerships with academia and
industry, as DOE has successfully done many times before,
including with the exascale computing project. NAIRR and FAST
take different but complementary approaches to secure the
Nation's global competitiveness in AI. While NAIRR focuses on
building AI capacity for the Nation, FAST focuses on building
AI capabilities by targeting complex, mission-driven
challenges.
In summary, as a science technology powerhouse, the DOE
system of national laboratories possesses unparalleled compute
and data resources and multidisciplinary talent pools to
advance cutting-edge AI from research to field applications in
challenging mission domains. A coordinated governmentwide
strategy leveraging DOE's capabilities will be key to the
United States maintaining its edge in the AI race unfolding
worldwide.
Thank you again for the opportunity to testify. I welcome
your questions on this very important topic.
[The prepared statement of Dr. Tourassi follows:]
[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

Chairman Collins. Thank you.
I now recognize Dr. Abdallah for five minutes to present
his testimony.

TESTIMONY OF DR. CHAOUKI ABDALLAH,

EXECUTIVE VICE PRESIDENT FOR RESEARCH,

GEORGIA INSTITUTE OF TECHNOLOGY

Dr. Abdallah. Chairmen Collins and Williams, Ranking
Members Bowman and Stevens, and Members of the Committee, thank
you for the opportunity to testify.
Today, I would like to address three points: the imperative
of long-term planning and funding to fully unlock AI's
potential; the necessity of complementing U.S. leadership in
basic science and engineering with the capability to develop AI
hardware, software, and systems; and the importance of
expanding our talent pool.
I note that the business successes of AI technologies today
are the result of decades of research at universities and
industrial laboratories funded by NSF and other Federal
agencies. While industry directs R&D funding into well-defined
businesses, universities focused on discovering and innovating
in areas not yet created.
Let me describe one example of the symbiotic relationship
between Federal agencies and labs, academia, and industry.
Georgia Tech, as you heard, was awarded three NSF AI Institutes
and an EDA (Economic Development Administration) grant for AI
in manufacturing. One such institute focuses on adult learning
and online education, using generative AI to personalize
learning and transform education for distance learners. Another
institute is combining AI and optimization tools for complex
systems design such as power grids, large supply chains, as
well as the design of the next generation of chips. The third
institute is developing collaborative AI systems to assist
aging adults through personalized interaction that will lead to
more fulfilled lives and substantial healthcare savings.
Georgia AIM (Artificial Intelligence in Manufacturing) is
an EDA-funded network of universities, technical colleges,
industries, and community organizations that is assisting 38
small manufacturing businesses around Georgia with
cybersecurity compliance. Georgia AIM also created AI robotics
technician training curricula for the Veterans Education Career
Transition Resource Center to help them transition into
civilian jobs.
Challenges faced by academia in AI research include the
need for large numbers of graphical processing units, GPUs, and
large local storage and memory. As one example, an AI institute
allocated $1,000 per month for using ChatGPT 3.5, but one
researcher exhausted all of it in one day by instead using
ChatGPT 4. As another example, a recent global ranking of AI
programs placed 11 universities, seven of which are in China,
ahead of the top American university, pointing to a growing
advantage of international competitors.
Pressures on building and sustaining large academic
computing capacity are exasperated by how universities piece
together the funding for the research computing infrastructure
from smaller grants. The AI research resource NAIRR will
broaden access for computing infrastructure in a coordinated,
equitable, and hopefully sustainable way.
Transformative advances in AI also required talented
contributors. NAIRR promises to bring together industry,
government, and academic partners to help drive equitable
access to education, training, and advances in AI. While the
establishment of NAIRR and similar activities across the
Federal and industrial funding landscape are steps in the right
direction, I believe the following are important additional
steps.
First, a commitment to the long-term funding and certainty
in supporting NAIRR. Realizing the importance and promise of
NAIRR to our national and economic security, its startup
funding should be supplemented with stable operating support.
Congress enacted CHIPS and Science, funded CHIPS, and put down
to payment on the science aspects, but now's the time to
realize that science and AI are just as critical to American
security as are semiconductors and manufacturing.
Second, reclaim our ability to translate our fundamental
research into usable products. Along with a renewed focus on
the re-shoring and friend shoring, Federal agencies are
encouraging universities to translate their fundamental
research into products, therapeutics, and companies. We must do
so, however, while accounting for the social implications of AI
development. Values such as fairness, transparency,
explainability, privacy, and accountability must be designed
for at the onset.
Third, increase our efforts to attract and retain more
talent into AI. The competitive advantage of U.S. high-tech
companies is often limited by the availability of talent. We
must regain our role as the strongest magnet for talent and
creativity from around the world. There's also an economic and
moral imperative to attract more domestic students into higher
education, and more specifically to attract underrepresented
groups into STEM (science, technology, engineering, and
mathematics) in general and AI in particular.
Last, the potential of AI for reskilling and upskilling
displaced American workers cannot be overemphasized.
I end with a strong endorsement of the stated goals for
NAIRR, namely, to spur innovation, to increase diversity of
talent, to improve capacity, and to advance trustworthy AI. And
thank you.
[The prepared statement of Dr. Abdallah follows:]
[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

Chairman Collins. Thank you.
I now recognize Dr. Chamra for five minutes to present his
testimony.

TESTIMONY OF DR. LOUAY CHARMA, DEAN,

SCHOOL OF ENGINEERING AND COMPUTER SCIENCE,

OAKLAND UNIVERSITY

Dr. Chamra. Chairman, Ranking Members, and Committee
Members, thank you for the invitation to testify before this
Committee. The opportunity to discuss the potential of
artificial intelligence in driving scientific discoveries and
enhancing Federal science agencies capabilities is both an
honor and a privilege. AI stands at the forefront of a
technological revolution. Its potential to transform research
across a spectrum of scientific fields is unparalleled.
However, realizing this potential requires a concerted effort
in harnessing AI capabilities while addressing the challenges
it represents.
Given these and related dynamics, it's crucial that we
recognize the role of R-2 research institutions similar to
Oakland University, especially for emerging technologies such
as AI. These institutions are crucial for advancing AI research
and workforce development.
The collaboration between Oakland University and the
automotive industry to train employees on cybersecurity, data
science, and AI exemplifies the synergy between academia and
industry. This partnership not only enhances workforce skills,
but also aligns with the industry's evolving needs. Federal
agencies play a crucial role in the scalability and success of
such programs by providing funding and support that can help
expand these educational initiatives, making them more
accessible to broader audience. This not only enhances the
workforce competencies, but also contribute to national
competitiveness in a global technological arena.
To further this initiative, Oakland University has
introduced stackable certificate programs targeted at both high
school and adult learners. These programs are designed to offer
flexible progressive learning pathways that enable individuals
to accumulate and buildupon their skills over time, thereby
fostering a versatile and adaptable workforce equipped to meet
the evolving demands of the tech industry.
Federal agencies and departments such as National Science
Foundation and the Department of Energy can be instrumental in
bolstering AI initiatives at R-2 institutions through targeted
funding, partnership, and resource sharing. By providing
dedicated grants and programs, these agencies can enable R-2
institutions to enhance their research capabilities in AI.
Furthermore, fostering collaboration between R-2 institutions
and industry partners can bridge the gap between academic
research and real-world applications, thus enriching the AI
workforce.
Investing in AI education and training programs at R-2
institutions is equally important. Tailored curricula,
internship, and mentorship opportunities can prepare a diverse
and skilled workforce equipped to meet the evolving demands of
the AI industry and other opportunities. We call on the House
Committee and the National Science Foundation and other
stakeholders to bolster support to AI initiatives, particularly
at R-2 institutions. This includes increasing funding for AI
research, facilitating the development of AI infrastructure,
and promoting educational programs to prepare the next
generation of AI experts. Enhanced Federal support is crucial
for maintaining America's leadership in AI and ensuring its
positive impact on society.
In conclusion, the advancement of AI offers a promising
avenue for scientific discovery and innovation. By recognizing
the critical role of R-2 research institutions, encouraging
industry-academia collaboration, and addressing the challenges
inherent in AI, we can harness the full potential of AI. We
urge the House Committee on Science, Space, and Technology to
champion these initiatives, ensuring the United States remains
at the forefront of this transformative field.
Thank you for this opportunity to highlight these critical
initiatives, and I look forward to discussing how we can
further harness these opportunities for our Nation's scientific
and technological advancement. Thank you.
[The prepared statement of Dr. Chamra follows:]
[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

Chairman Collins. Thank you.
I now recognize Mr. Clark for five minutes.

TESTIMONY OF MR. JACK CLARK,

CO-FOUNDER AND HEAD OF POLICY, ANTHROPIC

Mr. Clark. Chairman, Ranking Members, and distinguished
Members of the Committee, thank you for the opportunity to
testify for you today about the importance of American
leadership in the field of AI.
My message is simple. It has become more expensive to
develop frontier AI systems, and the Federal Government should
keep pace with these rising costs and invest in initiatives
like for the NAIRR. For this testimony I'm drawing on my
background as the Co-Founder of Anthropic, an AI research
company that builds and deploys safe and useful AI systems.
We've spent many millions of dollars developing systems that
sit at the frontier of large-scale AI work today. And before
Anthropic, I worked at OpenAI where similarly, I built and
deployed large-scale systems. Through this experience I've seen
up close the immense value and scientific possibility of AI, as
well as its rising costs.
To put it in perspective, the costs to develop cutting-edge
generative AI systems has risen staggeringly in recent years.
In 2020, it would cost you between $1-5 million to develop a
large-scale system. In 2021 and 2022 that rose to between $10-
20 million. In 2023 last year, it cost between $50-100 million
to stay on the frontier, and the costs keep rising. To
illustrate the scale, Meta CEO (Chief Executive Officer) Mark
Zuckerberg said last month that his company plans to acquire
350,000 AI chips by the end of 2024. That is a retail price of
about $10 billion--billion. It's not inconceivable that AI
systems costing hundreds of millions apiece become commonplace
soon.
The NAIRR can serve as a counterweight to industry's
outsized role in AI development by providing crucial
infrastructure for public interest AI research. Specifically,
the NAIRR should fund research into beneficial applications
neglected by industry such as education, healthcare,
fundamental science, and so on. It should enable computational
resource access for studying the safety properties of large AI
systems and support research into ways to strengthen oversight
of these systems and reduce their potential harms. And it
should facilitate the study of open source and openly
accessible AI systems to include benefits measurement, societal
impact and bias analysis, evaluation science, misuse
assessment, model robustness, and more. In essence, the NAIRR
can diversify the AI future so progress benefits for common
good and also be a sustainable source of scientific advancement
for positive applications of AI.
The NAIRR can also expand government capacity to develop
its own cutting-edge systems. By doing this, the NAIRR can
provide an essential infrastructure to unlock targeted research
of positive applications of AI and a better talent base for the
Federal Government by creating valuable infrastructure where
researchers can develop and hone their skills. And it can
reduce dependencies between the government and the private
sector when it comes to understanding the state of art of AI.
Information asymmetries are dangerous, and the NAIRR represents
a way to reduce them.
I'm honored to be here, and based on my experience working
on the frontier of AI in industry, I ask the Committee to
consider the following policies. No. 1, make targeted
investments in the National Science Foundation, the Department
of Energy, and the National Institute of Standards and
Technology. No. 2, find ways to better utilize the government's
supercomputing assets for large-scale AI training, as Oak Ridge
has recently done with its Frontier supercomputer. And finally,
be bold. We are at the start of a technological revolution, and
the more ambitious the government is here, the greater
influence the public will have over this powerful technology.
Thank you for your time.
[The prepared statement of Mr. Clark follows:]
[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

Chairman Collins. Thank you. I want to thank all the
witnesses for their testimony.
The Chair now recognizes himself for five minutes.
You know, as I was sitting there listening, I was writing
down some things just from my personal experience of being in
the trucking industry for over 30 years, and a lot of the
advancements that we've seen, I mean, it's been an incredible
industry to be a part of, but to see the advancements. You
know, we've got equipment now that AI is embedded inside the
transmissions that will actually put the transmission in
neutral, and then when it knows it's coming to a hill, it knows
which gear to put it in.
I was just told about a meeting that we had last week where
there's new technology, AI technology out there that'll be able
to read and help make better dispatch decisions. So as the
truck approaches the place where he's unloading or she's
unloading, it'll be able to better make a decision on the next
load to make them more efficient.
And, you know, I was reading an article here recently where
soon, in the near future, the trucking industry will have the
ability to--I don't want to put any onus on you four-wheelers
out there, but we'll be able to read what you're actually doing
at any given time so that we can make better adjustments as
we're going down the road so that we can avoid obstacles or
incidents.
Also, I have a small university in my district, and Dr.
Abdallah, I'm sure you're aware of--University of Georgia, and
the Agriculture Department there has made so many significant
gains. And it's crazy about the AI when you go up there and you
look at how they're spot fertilizing each individual weed or
whether there are advancements in tractor technology and how
they're able to better make improvements in soil and yields.
And I just had a meeting yesterday with the technical
schools there in Georgia. I'm a big technical school fan. And
their main concern was artificial intelligence. And the reason
that was their concern is because they don't have educators
that know how to teach what the technical schools are going to
need to provide in the future. So it's a very worthwhile
meeting. This is a huge hearing in my opinion, and a personal
one.
Ms. DeBlanc-Knowles, how is the NAIRR pilot program
supporting small businesses in Georgia, and how will NAIRR
balance the interests of basic research and entrepreneurs who
need access to these technologies?
Ms. DeBlanc-Knowles. So we talked a lot about this resource
divide between researchers in well-resourced institutions and
private sector companies and academia, and that resource divide
applies as well to researchers and startups and small
businesses who don't have access to the adequate computational
resources as they try to prototype and scale and really
commercialize the products that they're developing.
And so per the recommendations of the NAIRR task force that
we're using as the framework for the NAIRR pilot, small
businesses and startups who have existing Federal grants, so
SBIR (Small Business Innovation Research), STTR (Small Business
Technology Transfer), and similar grants will be eligible to
apply for access to resources through the NAIRR pilot. I do
want to emphasize that the first R in there is research, so
even as we are equipping small businesses to do this kind of
access through the NAIRR pilot, it is focused on the earlier
stage prototyping and initial scaling of the product versus
support for kind of production-level development.
Chairman Collins. Thank you. Dr. Abdallah, the Baptist came
out in me. I took up a lot of time. Can you elaborate on how
Georgia Tech is leading the way in AI basic research to new
technologies and industries?
Dr. Abdallah. Yes, thank you for that, Mr. Chair. So in our
space, we've been doing AI when it wasn't cool. You know, there
were multiple AI winters, as you probably know, but some of
that work--probably one of the most famous one is something we
call Jill Watson. Jill Watson was actually an AI agent that
helped in a scaling up our computing program. Right now, we
have a computer--a master's in computing, online master's in
computing, that has almost 15,000 students in it. And we're
using AI tools in that, for example.
Jill Watson was--when it was implemented initially, it
started out as a TA (Teaching Assistant) in a class, and the
students initially did not like how this TA was behaving. By
the end of the semester, they felt it was one of the most
empathetic TA's. It was such a great thing that they're used
to. Some of them even they didn't know it was an AI agent. They
asked her out on a date, for example, because at that point, it
was delivering such great response. So that's one of the areas.
Of course, I mentioned in the supply chains and
microelectronics design, all the things that our colleagues at
other universities are working on, too.
Chairman Collins. Thank you. I appreciate that.
I now recognize Ms. Stevens for five minutes for
questioning.
Ms. Stevens. I am here for the truckers for AI caucus. This
is so exciting to hear about that. And as a metro Detroiter,
you know, we salute your interest in autonomous or AI
innovations for the mobility sector.
Lots to dig on here. And, Dr. Chamra, I'd love to start
with you because it's just--again, just such a treat to have
you here representing Michigan and Oakland University. And, you
know, the challenges faced by the non-Research-21 institutions
in States with major R-21 institutions, you know, we've got a
lot of diverse research institutions in Michigan, each
bringing, you know, a kind of importance and a voice to the
Federal research ecosystem. And it's critical that all of these
institutions have access to Federal resources and funding. So
what do you think of the NSF, DOE, and other Federal agencies--
what should they do to ensure that non-R-2 institutions like OU
and its amazing researchers have to get access to Federal
funding resources, and how do you see NAIRR helping with these
resources or these efforts?
Dr. Chamra. Thank you. And I really think the No. 1
challenge we have right now is access to high-computing
computers because when we talk about AI and research, a lot of
these institutions, especially similar to Oakland University,
we have a challenge about access to these computing powers. So
this is extremely important for us to work and develop a
workforce actually of the future. And the other thing is in
terms of funding to develop curriculum and curricula to expand
our training and our opportunity to diverse workforce that we
need for AI and moving forward. So Federal agencies can be
important in terms of funding these initiatives.
Ms. Stevens. Would that be a consortium type of model or--
--
Dr. Chamra. Sharing resources is very important, so
consortium could be where even R-1 schools can collaborate with
R-2 schools and give them access to high-computing powers. So I
really think all it's about collaborating and all putting our
resources together in order to move forward and to always stay
competitive at the national level. So the Federal agency could
be a catalyst to bring all these constituents together as a
consortium working together and improving access to these
technologies.
Ms. Stevens. And also scaling the AI certificate program,
which you mentioned in your testimony, is there a role for NSF
or DOE to play? Obviously, we always think of Department of
Labor with certificates, but what about scaling what you've
been able to do with these AI certificates?
Dr. Chamra. So basically, what we do right now with the
industry, when we do these trainings, we have about 20 seats.
And Federal agency can scale all of this to hundreds or
thousands. And I really think this is important, especially in
areas like Detroit where the need for technology jobs are
increasing day after day, and even they're demanding that we
have these trained employees----
Ms. Stevens. Yes.
Dr. Chamra [continuing]. In the automotive industry. And
when we talk----
Ms. Stevens. Train the trainer.
Dr. Chamra. Right.
Ms. Stevens. And we also want to get Ms. DeBlanc-Knowles in
because you're obviously overseeing some of this effort at NSF.
And so how does NSF engage institutions like OU to address the
barriers to access?
Ms. DeBlanc-Knowles. So that's one of the fundamental, you
know, driving motivations behind the NAIRR pilot and then the
full-scale NAIRR is really overcoming some of these barriers,
so less well-resourced institutions have access to the
necessary computational dataset. And also really important in
this space is the training to equip those researchers to use
those resources effectively, whether they're pushing the
frontiers of AI or applying AI to their fields of study.
Ms. Stevens. Yes. Well, you've certainly given us a lot to
think about here. And just let it be known for the record yet
again that Oakland University in Rochester Hills, Michigan, has
an AI certificate. Thank you, and I yield back.
Chairman Collins. Thank you, Ms. Stevens.
I now recognize Mr. Williams for five minutes.
Mr. Williams. Thank you, Mr. Chairman.
Dr. Abdallah, I was concerned about your statement that
Georgia Tech students were duped by AI into thinking it might
be available for a date. Do you think that reflects more of the
dating culture at Georgia Tech than it does the advancement of
your AI? And before you answer, I'll warn you my son is a
senior at Georgia Tech in aerospace engineering.
You don't really have to answer that, but----
Dr. Abdallah. Thank you. Thank you.
Mr. Williams. So I've worked with GTRI (Georgia Tech
Research Institute) in the past and seen the excellent work
that you do both commercially, as well as inside the
institution. How much Federal funding flows through Georgia
Tech each year related to research?
Dr. Abdallah. So Georgia Tech does about $1.5 billion in
research expenditures. About 80-plus percent of that is
Federal.
Mr. Williams. Thank you. And how much of that is currently
going toward AI or AI-related projects?
Dr. Abdallah. A few 100 million. In fact, I think the
latest numbers that I sent with my statement is about 200
million.
Mr. Williams. And just so you can flex, what kind of work
is Georgia Tech doing in AI with those Federal dollars
Dr. Abdallah. So, as I mentioned, we have the three AI
institutes that do work in learning. We do in manufacturing. We
do work in the supply chain and design for materials and
others. GTRI, as you mentioned, it's a UARC. It's a University
Affiliated Research Center. They do a lot of work for
supporting national security and AI also. And we do also have
teams or researchers focusing on trustworthiness and ethical
AI.
Mr. Williams. Thank you. Dr. Tourassi, I'm interested in
the role that memory plays in the architecture of an AI system
relative to compute. We all talk about the GPUs and, you know,
the crunching capability of creating these models. Can you
explain the importance of particularly chip-based resident
memory, RAM (random-access memory), that kind of thing?
Dr. Tourassi. So there is--certainly for the deployment of
the next generation of high-performance computing resources in
the Department of Energy, memory bandwidth is what is at the
forefront of our attention because we've seen the number of
applications that either are directly artificial intelligence
or they integrate artificial intelligence with modeling and
simulation, which has been primarily driven by more FLOPS.
So this is something that the Department of Energy is
making strategic investments because we're--this is a new
frontier, and that's what exactly differentiates the Department
of Energy in terms of how they leverage their investments. We
have to be always at the bleeding edge of technology,
understanding where the gaps are, and keep pushing forward.
Right now, memory bandwidth is where we will pay our
attention, in addition, of course, to energy efficiency. Many
of you brought it up. This is something that we cannot ignore.
And the Department of Energy has always been driven by
investments in technology advances that speak to energy
efficiency. I gave the example for Frontier.
Mr. Williams. Thank you for that. That's very helpful. And
it's also important to note that the global leader in memory
technology is Micron, a U.S.-based company that coincidentally
happens to be investing $100 billion in my district for memory
manufacturing. But thank you for those answers. It's very
helpful to understand that importance.
Mr. Clark, I have maybe an unusual question for you. How
many automobile manufacturing plants does the Federal
Government currently own?
Mr. Clark. I couldn't tell you, Congressman.
Mr. Williams. Do you want to guess how many automobiles the
Federal Government creates each year?
Mr. Clark. I'd hazard we're close to zero.
Mr. Williams. I bet it's a multiple of that number would be
my guess. And, you know, I think that's true, actually,
throughout its entire history. So when you talk about the
escalating costs and the incredible innovation that's happening
around AI systems, why is it that you suggest that the Federal
Government needs to own a significant amount of the leading AI
systems in order for America to compete?
Mr. Clark. Excellent question. As you buildup these
systems, you discover 100 different ways that they break and
you discover 100 different ways to fix them. We've seen this
with Frontier's own work, scaling itself up to the frontier of
possibility. If you don't build this stuff and develop the
skills and the cuts and bruises from learning how to build it,
you're not going to----
Mr. Williams. Sorry, my time's expired, but only the
government can do that? Private industry is not doing that at
Google? They don't do that at Microsoft or----
Mr. Clark. Industry does a fantastic----
Mr. Williams [continuing]. Nvidia?
Mr. Clark [continuing]. Job of this, and it leads to those
skills mostly sitting within industry, and you have less of a
talent base that can be shared across government and academia.
Mr. Williams. I think your colleagues have shared really
excellent examples of Federal dollars being used for the most
impact for America to continue to lead in AI. And maybe owning
the automobile factory is not the best way. I yield back.
Chairman Collins. Thank you, Mr. Williams.
I now recognizes Mr. Bowman for five minutes.
Mr. Bowman. Thank you, Mr. Chairman. This first question is
for Ms. DeBlanc-Knowles and Dr. Tourassi. Much of the
educational background that informs AI research and development
can be taught well before the college and university level.
Concepts such as what data is and how to logically go from a
general idea to a specific conclusion can be taught as early as
elementary school. What course materials, tools, and resources
can NSF and DOE provide through the AI programs to equip our K
to 12 teachers with the ability to instill this insight?
Ms. DeBlanc-Knowles. So NSF is focused on building the
skills and technical capacity at each level that we see as
needed to really move toward this AI-ready workforce and the
incorporation of AI as we see coming across different sectors
of society and the economy. We just recently launched the
Educate AI Initiative that focuses on making opportunities for
the development of more inclusive AI educational resources at
the K through 12 level, community colleges, undergraduate
levels, as well as for adults who are interested in reskilling.
And this builds on work that we've already done through our
AI4K12 Initiative, and that developed guidelines to help
teachers who are looking to incorporate AI into their
classrooms and created a repository of open resources that, as
teachers look to build these baseline skills that are critical
not just for those who want to pursue AI careers, but for
students as they learn how to understand outputs of AI systems
or integrate AI just into everyday use. And we're going to
continue to build on this work going forward.
Dr. Tourassi. So the Department of Energy offers many
training opportunities and internships across different levels
of development, starting with high school students to
undergraduate, graduate, and faculty. These resources, we're
making them available now by expanding our educational programs
and internship programs to institutions that are minority
institutions because we know that there are huge gaps there.
And our resources are really at the bleeding edge of
technology, so in order to elevate everyone, we are
establishing--we have established programs such as Pathways to
High-Performance Computing that help bring individuals along to
make the most of our resources.
For educators specifically, we do not have to the best of
my knowledge a program that is related to AI, something for us
to discuss, but our user community is targeted scientists, and
we try to create the culture of science as early as possible
with high school students and engaging also with our local
communities. Pretty much every laboratory has a strong network
of collaborations with local schools, community colleges, and
universities.
Mr. Bowman. OK. Thank you. Will the NAIRR pilot program--
excuse me. Will the NAIRR pilot and its programs provide
education resources for K to 12 educators?
Ms. DeBlanc-Knowles. Educational resources are a key theme
that we're launching the NAIRR pilot with in terms of
supporting access of educators to the resources needed to bring
into their classrooms and educate the next generation of
leaders. For the NAIRR pilot, because of its limited scope, we
are focused on undergraduate institutions really because of
that connection to the computing resources. We've heard from
professors that they have to scale down their instruction to
kind of fit within their limited computing and data frameworks,
and students don't have enough computing to finish their AI
term papers. So we really want to pilot equipping these
university professors with the resources that they need so that
American students are being able to train, experiment with,
evaluate models at the scale that's at the cutting edge right
now.
Mr. Bowman. Anyone else care to comment? Thank you, Mr.
Chairman.
Chairman Collins. Thank you.
The Chair now recognizes the very stealthy Chairman of the
Full Committee, Mr. Lucas, for five minutes.
Chairman Lucas. Just watch and learn, Mr. Chairman, just
watch and learn.
Mr. Clark, cutting-edge AI research used in universities,
but today, this research is dominated by the industry,
particularly due to the high cost of computing needed to train
advanced models. To address this problem, some have advocated
of course for the creation of NAIRR. Given the fast pace of
progress in AI, how can we ensure that the development of NAIRR
keeps up with the rapidly evolving industry standards for
advanced computational power?
Mr. Clark. Thank you. The key thing will be to make sure
that researchers in academia are able to do research that they
consider appropriately ambitious and large scale. They should
not be able to run into a situation where they're unable to do
their research due to running into computational limits. And
how you achieve that in a fiscally responsible way is to make
sure that the NAIRR is allocating a portion of its resources
for a small number of big-ticket projects each year and adopt a
consortium approach for picking what those are.
Chairman Lucas. Would anyone else like to touch on that
question?
Dr. Tourassi. I would agree with the notion of the
consortium because we've seen its success with the HPC COVID
consortium a few years ago. We all leaned in with the resources
that we had available, but there was a good coordination of the
projects as they were coming in to match the scale of the
project and the complexity of the project with the appropriate
resource.
Chairman Lucas. Continuing with you, Doctor, the NAIRR
pilot program is a two-year program. However, the Summit
supercomputer is due to be decommissioned in less than nine
months, October 24. What are NSF and DOE's plans to address
this computation gap?
Dr. Tourassi. That's a very good question. I want to
emphasize that the Department of Energy and the Oak Ridge
Leadership Computing Facility leaned in to donate effectively
the supercomputer and keep its operations without additional
funding. That is a question now to see how the NSF NAIRR will
evolve. And if there is interest and support, we will lean in
once again.
Chairman Lucas. OK. Following up on that, if the pilot is
being shifted to another supercomputer, how will this move
affect the current research being run on that computer?
Dr. Tourassi. So transition from one supercomputer to
another, this is something very common for us because every
four to five years, we're deploying new supercomputers, and we
work with the scientific community to ensure that their codes
can transition from one system to the next. This was actually
part of the Exascale Computing Project that worked with
different scientific communities, different scientific codes to
make sure that when Frontier and Aurora are deployed, the
systems are usable on day one. So this is DOE's philosophy of
how to deploy and operate resources and make sure that they are
impactful from the go. And we've seen that with Frontier, with
so many applications, and great successes for the Nation just
with the Gordon Bell award a couple of months ago in
supercomputing. That was possible because Frontier became
available in April, the beginning of April 2023, and these
teams were able to run largest scale computation since day one.
It takes a village, and the Department of Energy and the
national labs provide not only the hardware, but actually the
computational scientists who work with the users.
Chairman Lucas. That may be the most heartwarming answer of
the day right there. Thank you.
Ms. DeBlanc-Knowles, the American scientific enterprise is
open and collaborative with basic research published without
restrictions. How can we maintain a balance between ensuring
the openness of basic AI research while mitigating potential
threats to national security that could arise from sharing such
information?
Ms. DeBlanc-Knowles. So in alignment with NSF policies that
that generally apply to NSF funding opportunities, NAIRR pilot
resources that require access requests, so these are the
allocatable resources that are being made through--available
through the pilot, the computing resources, our proprietary
datasets, software licenses, those will be subject to our
standard eligibility requirements, so researchers who are
applying for funding must be based at U.S. institutions.
As we move forward in this process, the NAIRR program pilot
management office based out of NSF that involves interagency
partners will work very closely with NSF's Office for the Chief
of Research Strategy and Security Policy to make sure that
we're integrating best practices and research security as we
move forward to scale the pilot and optimize our resource
allocation processes.
Chairman Lucas. Thank you very much, and I yield back, Mr.
Chairman.
Chairman Collins. Thank you, Mr. Chairman.
The Chair now recognizes the Ranking Member of the Full
Committee, Ms. Lofgren, for five minutes.
Ms. Lofgren. Thank you, Mr. Chairman. This has been a very
important hearing I think. There's so many issues here, but I
want to pick one, Dr. Tourassi. In your testimony, you
highlighted the application of AI to potentially improving the
performance of fusion reactors. Specifically, you note that
scientists from several national labs are using the Leadership
Computing Facility at Oak Ridge to train AI models that can
predict and potentially prevent plasma disruptions in the
reactor. Can you discuss this in more detail? And are you
seeing interest from fusion's emerging private sector in taking
advantage of these models yet?
Dr. Tourassi. So this is certainly one of the most active
areas of research across the DOE complex, and certainly, we see
that in our supercomputing center with Frontier. You know that
the modeling and simulation of nuclear reactors, it's an
activity that has been going on for decades. And with every
generation of supercomputer, we are pushing boundaries one step
further. Now with Frontier, we are able to simulate the full
lifetime of a nuclear reactor. And AI plays a very important
role in terms of being able to optimize the design of the
nuclear reactors, predict its lifetime, and different events
that need to be prevented. So what that means effectively is
that the certification of nuclear reactors, you know, that we
design them, but then the process of certification for
deployment is extremely lengthy. And this is now an environment
where we can do the digital design process of building,
exploring different optimization designs to identify the ones
that need to move forward for production with the appropriate
certification. This is a turning point for the industry in
terms of accelerating production.
Ms. Lofgren. If I can just follow up with that, a few weeks
ago, I went up for a day trip from San Jose to Seattle to visit
a number of the startup fusion companies, Helion, they've been
a witness here, Zap, and some others. What--how do we connect
those startup companies exploring fusion with the resources
that you have? I didn't get the sense in talking to any of them
that they were aware of the resources that you have, nor had
they used them as they are developing really very interesting
efforts in fusion, which is, you know, one of the toughest nuts
to crack.
Dr. Tourassi. Yes, well, that's a very good question
because as great as these resources are across the DOE complex,
certainly, there are many blind spots in communities that do
not know us very well. We work with industry, big industry and
startup companies. It is part of engaging broadly and speaking
to different communities. The demand is huge. Our systems are
oversubscribed, but we are ready to support particularly
startup companies and particularly new users through the--what
we call the director's allocation program, discretionary
allocation program because we can bring them on board.
Ms. Lofgren. Right.
Dr. Tourassi. So certainly, there's more work for us to do
in terms of socializing these great resources across so many
communities.
Ms. Lofgren. Let me just--you know, the San Jose Sharks
play in my district, so I get to ask this question. Wayne
Gretzky said you need to skate to where the puck is going to
be. And in this Committee, we're looking at a number of issues,
but some of the most important are fusion, quantum, and AI. And
it seems to me that quantum and AI are going to converge.
That's where the puck is going to be. How will that expand
access? And I'll just say, some of the private sector
individuals, for example, OpenAI are skeptical that we can
actually provide the computational power for non-big companies
to do the research and compete. And I don't think you have to
be opposed to the private sector to believe, as I do, that this
should not be owned by the biggest companies in the world. This
should be open to startups. It should be open to researchers,
not just the big companies. Can you address that issue, or is
that too farfetched?
Dr. Tourassi. For me, in terms of--if I understand
correctly, your question is about these emerging technologies,
AI and quantum, and access to these resources, right?
Ms. Lofgren. Correct.
Dr. Tourassi. We're talking about access to AI. With
quantum, this is a technology that is still in its infancy, but
it holds a lot of promise. I can tell you what we're doing at
the Oak Ridge National Lab because we see that promise, and we
want to build the user community that can leverage these
resources when they become production quantum computers. We
have the quantum computing user program that gives access to
users via cloud model to different quantum computing platforms.
And again, with our computational scientists who understand
both high-performance computing and quantum computing, we'll
try to lift these new users into a paradigm that will take time
to mature the same way as high-performance computing, but
certainly holds the promise.
Ms. Lofgren. Mr. Chairman, my time is expired. Thank you,
and I yield back.
Chairman Collins. Thank you.
I now recognize the gentleman from Florida, Mr. Franklin,
for five minutes.
Mr. Franklin. Thank you, Mr. Chairman.
Dr. Abdallah and Dr. Chamra, you both represent
institutions with a significant number of students. And I have
a polytechnic university in my district that has 2,000
students. How would you recommend that smaller research
institutions position themselves to better compete for the
Federal-university partnership funds that are out there?
Dr. Abdallah. Thank you for that question. So, as I
mentioned, many of our AI institutes and our work is in
collaborations with technical college systems and with smaller
institutions. I think the best way for smaller institutions to
access both the expertise and to scale up in their knowledge
and applications is to really work closely with the larger
institutions.
Now, having said that, the talent is very much distributed
everywhere. In fact, many of these advances are coming not just
from smaller institutions, but they're coming from very small
countries, very small places in the world. So this is not
something that we're competing with each other within the
United States. This is a race that anyone in the world can get
to with the exception or with the limitation of these large
resources, which NAIRR is addressing, but the knowledge to try
to--the basic knowledge, the foundational knowledge in order to
be able to use some of these tools is available a lot of
different places. What is lacking is the access of resources,
and I think the best way to do that is to team up, be part of
the NAIRR, for example, or other such initiatives.
Mr. Franklin. Dr. Chamra?
Dr. Chamra. I really believe that NAIRR and the Federal
agencies should dedicate certain funding to these smaller
schools, and--because it's important to recognize that these
smaller schools, whether 2,000 or up to 10,000 students, they
have different type of student. R-1 attract different students
than these students, and actually these smaller schools attract
students from all geographical area, from all walks of life.
And I really think Federal agencies should give them more
resources to develop curriculum, as well as research. And I
agree with Dr. Abdallah that we should collaborate, but at the
same time, they should be funding specific to these smaller
schools where actually they train a diverse group of workforce
development, and they train a lot more diverse student body.
And I really think smaller schools have an important role to
play in this arena, and this is how we ensure that workforce
development in AI and other technology are accessible to
everybody. Thank you.
Mr. Franklin. All right. Thank you. Ms. DeBlanc-Knowles,
the NAIRR task force report recommended a $2.6 billion
investment over the first six years. What criteria over the
course of this two-year pilot project should we be looking at
to evaluate success and decide is that the right number, should
we fund more? I mean, obviously, the answer to the question is
always going to be, you know, how much more can we do, but how
can we--what metric should we be establishing along the way to
gauge success?
Ms. DeBlanc-Knowles. So the NAIRR pilot is being funded out
of existing agency resources, and then bolstered by in-kind
contributions from that network of 25 partners. One of the
aspects of the pilot that we're really excited about is, as we
bring together that diversity of resources from Federal
partners, as well as private sector partners, we get to
experiment with the types of resources that work well for the
research community, as well as different modes of them
accessing that. And we think that that will help us better kind
of design and scope the plan for the full scale NAIRR.
I think some of the metrics that we can use it to evaluate
the impact of the NAIRR pilot is in terms of the number of
users served if we can reach into these communities that don't
typically have access to these resources, and if we can, on the
educational thrust, you know how many students we can train,
and then really looking at the projects themselves that we are
funding and looking at the impacts to those projects in terms
of access to the computational data resources that they are
unable to access through the pilot.
Mr. Franklin. OK. Thank you. Dr. Tourassi, I've got a
security question for you. What procedures or guardrails has
DOE put into place to ensure Summit doesn't become compromised
as we're sharing the resources with outside models from folks
like OpenAI, Meta, and others who run things on DOE assets and
infrastructure?
Dr. Tourassi. So certainly, the Department of Energy, with
the Leadership Computing Facilities, has always been very
mindful about cybersecurity because we're prime targets. There
is no doubt about that. And there are a lot of policies and
controls that are in place that we continuously revisit because
the world is a changing world.
Mr. Franklin. Right.
Dr. Tourassi. With the Summit supercomputer, that was the
first supercomputer that we established authority to operate so
that our users can use--can bring projects that have sensitive
data. And that is a capability that is the synergistic
development of technical innovation, policies, and
administrative controls because it takes all of these three.
And we're continuing that with Frontier.
Now, with the new user communities, the policies that we
are trying to put in place is--they are related in terms of the
data they bring in and--the third-party data because for us,
our users are scientific users. They bring scientific data. But
in the AI era, and particularly under the NAIRR pilot, that
scope is broader. So we need to be mindful, and we're looking
into the policies and what the expectations are from the users
who will be granted a location to the systems. There is a
thorough process where we vet the users, the project, and the
data assets that they want to bring in.
Mr. Franklin. Great. Thank you, and I'm over my time. Mr.
Clark, I had one for you, but I'll have to pass till later. And
I yield back.
Chairman Collins. All right. The Chair now recognizes the
gentlewoman from North Carolina, Ms. Ross, for five minutes.
Ms. Ross. Thank you, Chairman Collins, Chairman Williams,
Ranking Member Stevens, and Ranking Member Bowman, for holding
this very important hearing. And thank you so much to all the
panelists for joining us today.
I represent a district in North Carolina that's home to
businesses, universities, an NSF AI Institute, and other
organizations that are helping drive innovation and scientific
discovery in AI. In November, I hosted a roundtable in my
district with my fabulous colleague, Congresswoman Valerie
Foushee, where we met with local and national leaders in
artificial intelligence. And I'm looking forward to the next
one that she will be hosting at an HBCU (historically Black
colleges and universities) in her district.
Today's hearing highlights the importance of continued
collaboration between Congress and the AI sector as we stand at
the precipice of unprecedented technological advancements, and
you have really shed a lot of light today.
I want to pick up on a workforce issue that we haven't
discussed. As we know, American leadership in AI begins with a
strong workforce that both nurtures domestic talent, which
we've discussed a lot today, but also attracts the best global
minds. Many international students come to the United States to
conduct innovative research in emerging technologies. In fact,
a 2019 report by the Center for Security and Emerging
Technologies revealed that 2/3 of graduate students in AI-
related programs are international students. I myself taught
international students at Duke Law School and understand the
expertise that they bring to this area.
And the number of domestic students in these programs,
unfortunately, has not increased. And we've talked a lot today
about how to increase that, and I'm tremendously interested in
doing that. But many of these international students wish to
stay here, and they face several obstacles to permanent
residency and even citizenship. And we know that our
immigration system with its visa backlogs has--is just broken.
I've advocated for documented DREAMers, kids who come here with
their parents on H-1B visas, and then have to self-deport to
other countries with their entire education that they got here
to compete then with the United States.
I'll start first with Dr. Abdallah. Can you discuss how the
United States can better attract and ultimately retain
international talent in the American AI enterprise?
Dr. Abdallah. Thank you. I myself am an immigrant. I think
if I look around this table, I think four of us out of the five
are immigrants. So how to attract it is by continuing to be as
welcoming as we have been for the last, I don't know, hundreds
of years. How to retain them is a different question because
others right now, including competitors, allies, and
adversaries are becoming a lot more savvy about attracting even
graduates from the United States.
You know, when you apply as a foreign student or as an
applicant to a U.S. university, you have to show to the embassy
that you are going to go back. You have to prove that you are
going to go back in order to get the visa, which defeats the
whole purpose. So I think, you know, what Congress and others
have been discussing around trying to make sure that either the
H-1B or other visas are available in some targeted areas, I
think that's one approach. But really most appropriately, I
think, is to try to keep the welcome mat and to try to figure
out not just from the companies or not just from a particular
group, but to make sure that universities and graduates of
these programs, especially in the areas that we're really
interested in, have a path, have a legal path to try to
contribute in here. Canada is doing that by taking some of our
graduates and other countries are doing so, so I think just
going back on that international talent initiative is really
important.
But I do want to add to also, you know, there is an
opportunity with U.S. students. The reason I say that is
because there's not enough of them going into these areas----
Ms. Ross. Right.
Dr. Abdallah [continuing]. So focusing on that is actually
also another dial that we can use.
Ms. Ross. Yes, as we say both/and.
Dr. Abdallah. Yes.
Ms. Ross. Thank you so much, and I yield back.
Mr. Williams [presiding]. The Chair recognizes Mr.
Obernolte for five minutes.
Mr. Obernolte. Well, thank you, Mr. Chairman.
Ms. DeBlanc-Knowles, I would like to highlight something
that you touched on in your testimony. We have a rich tradition
in this country where cutting-edge research is done in our
academic institutions, and we have a tradition of publication
where that research is transparent and shared with other
people, and that leads to verification by peer review. And
people in other institutions will literally stand on the
shoulders of giants in reaching new frontiers in the
advancement of human knowledge.
But I fear we are in danger of changing the way that
advanced research in artificial intelligence is done because,
as Mr. Clark testified, the cost of training frontier AI models
is on this exponential curve, and it's already beyond the
ability of most academic institutions to pay for. So that's why
the National AI Research Resource is so important in
establishing a pool of compute and data to enable this research
to continue to be done in academia rather than by private
companies.
The pilot program for NAIRR is wonderful. Congratulations
on getting that kicked off. Obviously, we are trying to codify
that. We have the CREATE AI Act, which Congresswoman Eshoo,
Congressman Beyer, and I are co-sponsoring to try and make that
permanent and attach it to a permanent source of funding. Will
that be enough by itself to guarantee that that research
continues to be done in academic settings, as well as in
commercial settings?
Ms. DeBlanc-Knowles. So making the transition from the
NAIRR pilot to a full-scale NAIRR will make--have incredible
impacts on our academic AI research environment, as well as the
ability for scientists in other domains to apply AI to achieve
and accelerate breakthroughs. And I think the impact can't be
understated.
And you mentioned the role of the academic research
community in terms of, you know, verifying and validating
results, and so we see a lot of potential for the NAIRR, not
just enabling a small group of users to train frontier models,
but enabling many more researchers to work with the cutting-
edge models of today. We hear from researchers in academia that
even when working with an existing open large language model,
they don't have access to enough compute to perform inference
on that model and to really kind of kick the tires on how is it
working? How can we improve the safety and reliability? And so
the NAIRR is going to have an impact in terms of enabling
researchers with just--they don't need tremendous amounts of
compute, but they need adequate compute in order to work with
the cutting-edge models.
Mr. Obernolte. Right. Thank you. Mr. Clark, very nice to
see you again. I've enjoyed our conversations in the past. I
just want to highlight how remarkable I found your testimony
because one of the problems that NAIRR is designed to solve is
this problem that we might have a concentration of market power
into just a few of the biggest companies who could afford to
monopolize access to advanced GPUs and the energy needed to
feed them and the data needed to train frontier models, which
would limit competition and also limit entrepreneurialism when
it comes to AI. But, I mean, you're here as co-founder of
Anthropic saying this would be a terrible idea, you know, we
support more competition. And I find that incredibly
refreshing. Could you take a minute and explain why you think
that NAIRR and, in a larger sense, more competition is good,
not only for the industry, but for the country?
Mr. Clark. Thank you. I care about this deeply. I think
ecosystems die when they become dependent on a very small
number of entities within them, and this is true of private
sector dominance for a really important part of science. We are
fortunate to be in our position in that we publish research and
we seek to share it, but we are one type of species in an
ecosystem. There need to be others within it, and I think that
that's crucial for us to have really good ideas as a
collective.
And to your comments about open publication, the incentives
of industry do not point in the direction of full publication
of scientific information. We do our best, but we have
incentives. And you need to both change those incentives and
create people with different ones. That's why it's so important
that we fund this and take it seriously.
Mr. Obernolte. Well, thank you. I wish I had time for
another question. I could talk about this all day, but thanks
to all of our witnesses for your testimony on this really
critically important topic.
I yield back.
Mr. Williams. The Chair recognizes Ms. Salinas for five
minutes.
Ms. Salinas. Thank you, Mr. Chair, and thank you to our
Ranking Member also for holding today's hearing and to the
witnesses for sharing your valuable insights.
Ms. DeBlanc-Knowles and Dr. Tourassi, as you know, Oregon
is a global leader in the semiconductor industry. The CHIPS and
Science Act created a regional tech hubs program, and last
year, we were super excited to see the Department of Commerce
announce support for what we call the Corvallis Microfluidics,
or CorMic Tech Hub led by the University of--Oregon State
University. CorMic focuses on microfluidics technology, which
helps cool down semiconductor temperatures and improve energy
efficiency. As I understand it, this high-powered background
computing that enables AI uses an increasing amount of energy
and heating in computing. This poses a significant barrier to
expanding our AI capabilities, particularly while considering
our climate goals.
So my question, how do your agencies approach leveraging
other Federal programs like the tech hubs or tackle some of the
challenges facing AI research such as the enormous energy
requirements?
Ms. DeBlanc-Knowles. So from the NSF perspective, I
mentioned in my testimony our recent launch of the inaugural
regional innovation engines, and that's being run out of our
new Technology Innovation Partnerships (TIP) Directorate, which
was authorized in the CHIPS and Science legislation, called the
TIP Directorate. And the TIP Directorate has been working very
closely with EDA as we stand up the regional innovation engines
and the regional tech hubs so that we can create synergies
between these investments, regional innovation engines focused
on the earlier stage research and kind of seeding that
innovation environment, beginning to establish the jobs and
train the workforce with the EDA tech hubs coming in and really
building that infrastructure at scale to then magnify these
investments.
And I'll also mention on the environmental sustainability
side of things, energy-efficient computing from the hardware to
the algorithms is an important area of research and one that
NSF is supporting, and we've supported investigators that have
developed algorithms, methods for training machine learning
systems that are more efficient, and also as they explore how
to use machine learning to make computing itself more
efficient.
Ms. Salinas. Thank you.
Dr. Tourassi. The Department of Energy has a long history
of investing in microelectronics, in the design of new
hardware, actually working very closely with industry,
different vendors, setting always higher the north star, what
is the next big challenge that we need to work together. So
this is part of DOE's culture, and we're bringing that with
every new supercomputer that we are asked to design and deploy.
There is a lot more to be done because, as Tess said and you
described, we're certainly at the point where there is so much
that we can get out of the existing hardware. This is a tipping
point for science, and we all need to lean in.
At the same time, I agree that we need to be looking at the
whole ecosystem of how energy consumption is driven, not only
by the hardware and the data center, but also by the
programming languages, the software, and the behavior of the
users. This is something that the Oak Ridge National Laboratory
is looking very closely at. Actually, we are the first ones to
design a digital twin of our data center. That includes both
the building the machine and tries to understand what behaviors
and how we can improve energy efficiency, not only based on
hardware that it will take some time to get us to the next big
advancement, but also in terms of the software, hardware
applications, and user behavior.
So these are some areas of research that are very primed
for AI. Clearly, artificial intelligence can play--plays
already an important role in accelerating that. Bottom line,
DOE has an ecosystem that is driven by energy efficiency for
decades.
Ms. Salinas. Thank you both. I yield back.
Mr. Williams. The Chair recognizes Mr. Baird for five
minutes.
Mr. Baird. Thank you, Mr. Chairman, and I appreciate the
witnesses being here. I always learn something in this
Committee from having you testify.
So my first question goes to Mr. Clark. You know, you
identified money and costs as a key challenge for the AI
systems and mentioned that--and pay the cost of every search
that you run through your system. So given your organization's
experience scaling a large AI platform and the need to save
money, what recommendations do you have for the NAIRR program
to ensure operating costs are kept at a reasonable level and
make sure that there's an efficient allocation of research
resources? Mr. Clark?
Mr. Clark. OK. Thank you for your question. I was
temporarily distracted by the sound. The important thing is to
have a small number of kind of large-scale projects which use a
large number of NAIRR resources, and you closely instrument and
analyze these projects, and you make your incentive be make
them as efficient as possible. And then you use the tools and
science that you advanced there to make all projects on the
NAIRR more efficient. This is how we do it at the company, and
it can be scaled to the NAIRR.
Mr. Baird. Anyone else have any comments? If not, I have
another question. So anyone else have comments on that question
about the cost and how we pay for it?
OK. So, Dr. Tourassi, my question, this past November, we
we'd reauthorized the National Quantum Initiative with a
particular focus on the development of quantum computing and
communications. Moreover, we amended the initiative to study
the feasibility of a national quantum corridor that would
connect Federal Laboratories, institutions of higher education,
and private sector stakeholders in order to rapidly transmit
large quantities of information.
Originally, the Department of Energy recommended that the
Oak Ridge Summit supercomputer be slated for decommissioning at
the end of 2023, but now the supercomputer will run through
October of '24 and assist with NAIRR's pilot program. So could
the Oak Ridge Summit supercomputer utilize quantum technology
to drive AI machines' learning more efficiently? Dr. Tourassi?
That's a loaded question.
Dr. Tourassi. It's a loaded question, yes.
Often when we talk about these technologies, high-
performance computing, quantum, and AI, we use them
interchangeably. High-performance computing and quantum
computing are two distinct forms of computing. One is very
mature and the other in its infancy.
To your question, the existing supercomputers, Summit or
Frontier, they are already used to design new quantum materials
that are extremely important for the deployment of computers--
quantum computers. They are used to simulate and design quantum
processors that are extremely important for the evolution of
quantum computing. So certainly, there is a synergy and--
between these technologies, and I would say high-performance
computing is a building block to advance both AI and quantum
computing.
Whether it is the Summit supercomputer or the Frontier
supercomputer, this is secondary. Leadership computing is
necessary for these advances, and we need these advances as
we're looking into the 10-year horizon and the 20-year horizon
about new forms of computing that could deliver on the promise
of energy efficiency and help us with certain classes of
problems that are suited to quantum computing. As an
intermediate step, the integration of high-performance
computing with quantum computing, that's the next step we need
to take.
Mr. Baird. Anyone else have any kind comments in that
regard? Yes, sir.
Mr. Clark. I just have an addendum to the previous answer.
You can also measure the success of the NAIRR by the savings it
creates. So through using the NAIRR, scientists may not have to
spend money on resources they would have had to buy in from
outside of the NAIRR had it not existed.
Mr. Baird. So thank you, and with that, I yield back, Mr.
Chairman.
Mr. Williams. The Chair recognizes Mrs. Foushee for five
minutes.
Mrs. Foushee. Thank you, Mr. Chairman, and to the Chairs
and Ranking Members for holding this hearing today and to the
witnesses for your valuable testimonies.
Mr. Clark, in your testimony, you noted the importance of,
and I quote, ``Federal initiatives and funding that promote
equitable access to the critical inputs to generative AI
models.'' How does Anthropic's corporate governance structure
reflect equitable access or diversity, equity, and inclusion?
Mr. Clark. We are incorporated as a public benefit
corporation, and what that means is that we operate as a
private sector company and we make money and we also have the
ability to have a duty to societal benefit alongside a
fiduciary benefit. So as we grow more successful, we hope to
use that to do more things like our participation in the NAIRR
pilot and donation of in-kind resources and fair party research
access programs.
Mrs. Foushee. Are any of your initial trustees African
American?
Mr. Clark. We are participating in 10 initial NAIRR pilots,
and I would have to get back to you or your staff about the
composition of people in those pilots.
Mrs. Foushee. OK. Thank you. And how is Anthropic's
currently--how are you currently working to promote equitable
access to AI systems? Are you currently involved in any
partnerships or initiatives with HBCUs or MSIs (minority-
serving institutions) or community and tribal colleges?
Mr. Clark. We are actually in the early stages of
conversations about access partnerships with a couple of HBCUs.
I will be able to get back to you about the specific names. And
we have a job we're hiring for for a program manager to scale
up those initiatives and administer them.
Mrs. Foushee. OK. And finally, you said that we should
research techniques to strengthen oversight and to mitigate
harm? Should Federal agencies like NSF and NIST help research
and develop technical capabilities that safeguard or detect
copyrighted works from being used or trained on without consent
in generative AI models?
Mr. Clark. In short, yes. And just a brief expansion is we
believe that testing and measurement is how you make policy go
from something we talk about to something that you can enforce,
and so we should be developing tests and measures for issues
like those who mentioned, as well as, you know, discrimination,
misuse, and benefits as well.
Mrs. Foushee. Thank you.
Ms. DeBlanc-Knowles, does NSF have any projects or efforts
to develop tools or technical capabilities that safeguard or
detect copyrighted works from being used or trained on without
consent in foundation models?
Ms. DeBlanc-Knowles. So NSF has a critical role to play in
this space in terms of supporting the cutting-edge research to
develop these type of techniques, and right now, NSF-funded
researchers are working on ways to annotate documents to
provide documentation of proof of copyright, ownership, and
content authentication. At the same time, NSF-funded
researchers are developing mechanisms for detecting whether
text comes from a large language model itself. For decades, our
secure and trustworthy cyberspace program has supported
research and many methods for keeping data safe and secure
while detecting modifications.
Mrs. Foushee. Thank you. And, Dr. Tourassi, how about at
Oak Ridge National Labs?
Dr. Tourassi. So, first of all, the Department of Energy,
part of its mission is national security, so clearly,
technologies that can protect us for--from these adversaries
and these attacks are part of the research portfolio of the
laboratories. The same is true with the Department of Energy
with the Oak Ridge National Lab, and there are ongoing
activities in these domains. I come from the open science. I
can speak to how we protect scientific data and how we protect
the leadership computing centers that are dedicated to open
science. And certainly, this is something that we manage, as I
mentioned earlier, with a combination of technical solutions
that involve R&D, but also policy and administrative controls
that are absolutely necessary.
Mrs. Foushee. Thank you. Mr. Chairman, I yield back.
Mr. Williams. The Chair recognizes Mr. Kean for five
minutes.
Mr. Kean. Thank you, Mr. Chairman, and thank you to all of
our witnesses for joining us today. I am hopeful that today's
hearing will guide legislation in AI toward a brighter future
with responsible innovation, protection of children, and paving
the way for the next generation.
I'd like to start out by saying I am all for advancing AI
because of the vast and great potential it has to benefit
American society. However, we must have a balanced approach
that encourages innovation without excessive regulation by
prioritizing necessary safeguards to protect the public at
large and, most importantly, our children.
Just last year in my district, a high school was involved
in a disturbing scandal with students who were caught using
artificial intelligence to create derogatory images of their
fellow classmates. As a father, I'm deeply disturbed by this
disgusting act. The ease with which these students could alter
images of their classmates at the push of a button is
unimaginable. Schools are meant to be a place of learning. This
is not normal, and it cannot become the norm for any student at
any school. The absence of proper AI labeling systems poses a
significant challenge, as it hinders transparency and
accountability in the decisionmaking process of this
technology.
Mr. Chairman, I request unanimous consent to submit an
article for the record by MIT (Massachusetts Institute of
Technology) Schwarzman College of Computing, titled ``Labeling
AI Generated Content: Promises, Perils, and Future
Directions.''
Mr. Williams. Without objection.
Mr. Kean. Thank you, Mr. Chairman.
In this article, MIT states, ``At a time when generative AI
systems are increasingly capable of fabricating high-quality
media, the visible and transparent labeling of AI-generated
content offers one potential safeguard against deception and
confusion.'' Additionally, they highlight ``The emphasis on
labeling AI-generated content should be considered in light of
academic work, demonstrating the utility of warning labels and
addressing misleading and deceptive content online.''
This has led me to introduce H.R. 6466, the AI Labeling
Act, in the House of Representatives. It's a commonsense
approach of full transparency when interacting with AI. My bill
would require developers' generative AI incorporate a
prominently displayed disclosure to clearly identify content
generated by AI and establish a working group of government, AI
developers, academia, and social media platforms to identify
best safety practices for identifying AI-generated content.
AI is at the point now where it's--what's real and what's
fake is blurry due to how advanced the systems have become.
This creates opportunities for both good and bad actors alike,
advocating for proper guardrails and transparency to foster a
sense of responsibility among AI companies and individuals
utilizing this technology.
Ms. DeBlanc-Knowles, how is the National Science Foundation
actively supporting or funding research initiatives that aim to
develop effective and standardized AI labeling or watermarking
systems to ensure transparency for the public when the content
is generated by AI algorithms?
Ms. DeBlanc-Knowles. In this scenario, as with many
questions as we move forward toward a more responsible AI
future, there are still open issues that the research community
is poised to help address in terms of developing the
technological approaches for effectively labeling content,
making sure those labels are robust to any tampering, and also
doing the sociotechnical work to make sure that those labels
are understandable and consumable by the public.
So NSF fund--is funding a range of work in this area, from
the technical to the sociotechnical, to move forward and enable
us to take these steps----
Mr. Kean. Thank you.
Ms. DeBlanc-Knowles [continuing]. Toward labeling the
watermark.
Mr. Kean. Thank you. Mr. Clark, as AI technologies continue
to advance, what voluntary industry-led initiatives and
research do you find are most effective in promoting ethical AI
practices, privacy protection, and transparency without
imposing overly restrictive regulations that could stifle
innovation?
Mr. Clark. We're very supportive of coming to agreement on
norms for labeling AI-produced content and also developing
systems for identifying AI content that is in the wild and can
then be attributed back to the provider. We focus on text but
agree this issue covers all modalities.
Mr. Kean. Thank you, Mr. Chairman. I yield back.
Mr. Williams. The Chair recognizes Mrs. Sykes for five
minutes.
Mrs. Sykes. Thank you, Mr. Chairman and Ranking Member for
convening this joint Subcommittee hearing today. And to our
witnesses, thank you for your testimony and being with us. In
2022, the National Science Foundation awarded a $2 million
dollar grant to fund a graduate-level traineeship program for
University of Akron students studying mechanical engineering,
computer science, and polymer sciences. These sorts of cross-
sector partnerships are crucial for ensuring access to critical
resources necessary to power both responsible and innovative AI
discovery.
My question is for Dr. Abdallah and Dr. Chamra. You're both
at universities, and you both know the power and the need of
graduate students and how their studies and their postdocs
scholarship produces much of our innovative STEM research. Can
you please talk about the education and research tools needed
for Federal agency programs to best equip our trainees to learn
how to incorporate AI into their projects?
Dr. Chamra. I completely agree with you that graduate
students are essential for their innovation and technology and
actually NSF and DOE they have many programs that can fund
actually and give full scholarship for students to go for a
Ph.D. program. But schools like Oakland University and others
will always find it challenging, access to high computing
powers. So as a student actually gets that scholarship from
NSF, still, we really need the high computing power in order to
generate the research and provide an opportunity for these
students to produce quality program and learn and actually get
the outcome they need.
R-1 schools and other universities, they have resources,
and of course, Dr. Abdallah talked about Georgia Tech with over
$1 billion in research that provides an enormous resource to
spend on. These small schools don't have that access. So I
really think that a Federal agency democratizing access to high
computing power could be--could lead to a lot of advancement
for graduate students and others. Thank you.
Mrs. Sykes. Thank you.
Dr. Abdallah. So I would agree with that, that, you know,
the--providing access to compute power and other resources
across the board. You know, even at a university as well-
resourced as Georgia Tech, or many of the R-1s, we do run into
these absolute limitations, going back to the question about
what programs or what exactly we can do to help produce or
educate more students in this space.
I think, you know, in talking to some industry colleagues,
and maybe Mr. Clark could add to that, is that a lot of times
what they're interested in is not the specific training in a
particular area, but the fundamental knowledge in math,
statistics, computing, and so on. So AI is a tool. AI is now,
you know, the flavor of the year or the decade, and it's been
extremely successful, but a lot of the work that goes into
building these models, not into the training necessarily or not
into the technology or specifically the applications, have to
do with a solid foundation of an undergraduate education in
math, statistics, and sciences.
Mrs. Sykes. Thank you for that. And we talked about
specifically graduate and Ph.D. postdoc education, but what
about for folks in undergraduate, two-year degrees, maybe even
high school? What opportunities do those students have?
Dr. Chamra. I can tell you an example at Oakland
University, what we do. Actually, we offer certificate program
and summer program for where we bring actually young kids as
early as elementary school from Pontiac, from Detroit, and from
Rochester schools and introduce them not only to data science,
AI, cybersecurity, and others because we really need to prepare
our students early in order to get to the two years and four
years and get them to the point where, regardless of their
background or gender, they can be productive in this arena.
Mrs. Sykes. Thank you. I'm going to pivot a little bit, and
I appreciate you mentioning that because we talk quite a bit
about the missing million in this Committee and getting more
people of diverse backgrounds, geographical backgrounds, racial
backgrounds because we need it not only for--to be competitive,
but for our national security. But I'm from northeast Ohio. We
recently received a tech hub designation for polymers and would
be interested to know from anyone on the panel, how does AI
incorporate itself into the polymer science industry?
Dr. Abdallah. AI, as I mentioned, is a tool that is being
applied across everything, polymers, drugs, materials,
hypersonics, almost anything that you can think of that today
requires measuring something and then making a decision or a
design of something else, the availability of data and
availability of large data and being able to discover not just
the connections between this data but something that you can
project forward, including in the design of, again, polymers or
other things is extremely, extremely important.
We do--we have a saying in science and computing that says
we overestimate the short-term effects of a technology, but we
underestimate its long-term effect. This applies very much to
AI right now. We're thinking in the hype--we're in the hype
cycle where it could apply to everything or where we say it
applies to things, but in the future, it's going to be just
like the internet that started out as a means of communication.
It's now our way of doing business and conducting our business.
Thank you.
Mrs. Sykes. Thank you very much. I think we could use--we
probably use that saying in Congress as well.
Mr. Chairman, I yield back.
Mr. Williams. The Chair recognizes Ms. Lee for five
minutes.
Ms. Lee. Thank you, Mr. Chair, and thank you to all of our
witnesses for sharing your testimony today and for your
important work addressing both the potential and risks of AI as
it relates to scientific discovery.
While harnessing AI to drive scientific discoveries and
pursue leading-edge research is promising, I'd like to direct
attention to foundational and often unrecognized labor that has
underlaid this technology for so long. The exploitation of both
labor and mineral resources in Africa that fuels the AI
industry and the tech industry more broadly must be a focal
point of the AI regulatory conversation. As the National
Science Foundation and the Department of Energy look to stand
up major data and computational resources to support U.S. AI
research and education, we must ensure Federal resources don't
fuel labor exploitation.
Recent news has highlighted troubling concerns around the
exploitation of labor in the development of AI programs. Large
language models like ChatGPT requires human reviewers by
workers before they're suitable for use by the general public.
These workers often are based in the global south and working
for very little pay, are responsible for filtering through
disturbing materials to eliminate it from the answer supply by
ChatGPT. Others work for little to no pay to hand-label
thousands of images that go into the datasets, training AI
systems.
These are serious moral and ethical dilemmas. It's
documented that employees performing these tasks suffer from
anxiety, depression, and post-traumatic stress disorder due to
constant exposure to horrific content. While we race toward
innovation in the digital economy, let's not forget every
person at every step along the way to building this future.
That said, Ms. DeBlanc-Knowles and Dr. Tourassi, do your
respective agencies have a policy or a plan to ensure Federal
resources that support data annotation for artificial
intelligence research and education, including those provided
through the National AI research resource palette don't support
labor exploitation?
Ms. DeBlanc-Knowles. So NSF vets all research proposals to
the agency for responsible and ethical conduct of that research
as part of the decisionmaking process for funding. We also
require that all institutions that receive NSF funding certify
that they have a plan to provide appropriate training and
oversight in the conduct of that research.
In terms of the NAIRR pilot, together with our partners,
including NIST, we are developing guidelines and expectations
for any datasets that will be made available to the research
community through that pilot. Right now, we are starting with
Federal agency datasets that are already open to the public.
One of the benefits we see from the NAIRR pilot is really
bringing together the community to develop this consensus
around what are those bright policies for datasets, for models
as we move toward this responsible AI future. A lot of these
questions are new, and so we think that there's a benefit here
to really bring the community together and build consensus.
Ms. Lee. Thank you. Dr. Tourassi?
Dr. Tourassi. In addition to what you heard, I will pivot
differently. Data quality, when it comes to data curation,
which includes labeling, determines the quality and
trustworthiness of the AI models. This is one of the guiding
principles for the Department of Energy and the laboratories
that we believe data curation needs to be done internally. And
we're talking about scientific data with that scientific data,
and they need to be curated and occasionally labeled by domain
experts, scientific domain experts.
The example you gave is more appropriate for the NAIRR
pilot, right, because we don't know exactly what are the third-
party datasets that NAIRR users may bring in. But as you heard,
there is a vetting process. Now, whether there is an explicit
policy----
Ms. Lee. Yes.
Dr. Tourassi [continuing]. There is no such policy right
now, but something for us to think about how we can ensure that
data curation as a whole is done in a legal and ethical way.
Ms. Lee. Yes, thank you. I'm sorry, just with the remainder
of my time, reports on the AI industry exploiting African
labor, including traumatizing working conditions of data
workers, African countries like Ghana and Nigeria being used as
dumping grounds for toxic e-waste and forced evictions and
human rights abuses from cobalt and coltan mining in the
Democratic Republic of Congo. Responsible AI begins with
ethical business practices, which unfortunately are not
happening. The exploitation of Black labor is not lost on me,
especially, of course, during Black History Month.
That said, Mr. Jack Clark, while your company may not
directly produce goods or extract physical resources, the
technologies used by your firm can be considered beneficiaries
of this exploitation. How does Anthropic, a company that claims
to develop AI research and products that puts safety at the
frontier, ensures AI research and products don't benefit from
the exploitation of African labor and natural resources as part
of the AI safety mission?
Mr. Clark. Thank you for your question. We take this really
seriously. So for two main things that we do, on the technology
level, we work to make sure that our stuff doesn't generate--or
minimizes the amount of harmful or troubling content it
generates, which humans do need to review. And on the economic
side of things, the majority of our longstanding data suppliers
pay California minimum wage or above, regardless of where they
are in the world. And we're constantly seeking to improve that.
On your resource question, we are following industry best
practices here, and we've also, with the NAIRR pilot, put our
AI system access toward environmental analysis work. Thank you.
Ms. Lee. Thank you, Mr. Clark. And thank you for allowing
me that time. I yield back.
Mr. Williams. Mr. Issa is recognized for five minutes.
Mr. Issa. Thank you.
The Constitution says Congress shall make no law abridging
freedom of speech. When our Founders wrote that, they didn't
say Congress shall make no law abridging the freedom of speech,
and the NSF shall award no grant that abridges speech. But is
there any real difference between paying to abridge speech and
directly abridging speech?
Hearing no response to that, I'll take it as a yes. And for
the record, the Supreme Court's already held that Congress in
this case is equal to the executive and the judicial branch,
that all three branches are bound by the Constitution, as are
the States.
So the question is, hasn't the NSF already violated its own
transparency rule in doing this and doing it well-hidden from
sight that they were in fact abridging free speech? Thank you
for being brave.
Ms. DeBlanc-Knowles. I confess that I'm not familiar with
the scenario that you're talking about, but I'm happy to take
it back to my colleagues and come back to you with----
Mr. Issa. Well, when you openly say you're censoring, what
is that? To censor is to take down. To take down is to abridge.
Why would that not be abridging free speech?
Ms. DeBlanc-Knowles. So NSF does not censor. We do support
research----
Mr. Issa. Well, it's certainly in the words of people
addressing your people in a room, and they weren't corrected.
So if you sit in a room and, you know, people who are receiving
money say they're censoring, that that's what they're doing,
and let's be honest, anytime something does not appear as a
result of a system that limits it, or even when you pay for
students to learn how to do that, what is that if it's not, in
fact, potentially abridging free speech? And, for the record,
Mr. Chairman, I just left Judiciary. I've been going back and
forth because we're having the same hearing in Judiciary on the
same subject. And there, the witnesses were more forthcoming
that, in fact, you can take down speech based on very narrow
guidelines. Those guidelines are nowhere in the work you're
doing.
As Chairman Jordan said in no uncertain terms, if you
questioned the origin of the COVID virus, if you questioned the
six feet of separation, if you questioned the effectiveness of
the vaccine, if you did any of that, you got taken down during
COVID. So there's no question at all we would not have formed a
special Select Committee on the Weaponization by Government if
not for organizations like the National Science Foundation, in
fact, participating in what we call weaponization, but let's
just call it the abridging of free speech is what I'm choosing
to do here today.
So you have a scientific integrity policy. If words like
the study asserted that the broad swaths of the public cannot
effectively sort truth from fiction online, that means that--
and this is a direct question for you--you're making a decision
on what the truth is and deciding what people get to see as the
truth? You're making their decisions for them, is that correct?
Ms. DeBlanc-Knowles. So NSF's investments in this space
really aim to enhance authentication and trust and information,
and we're supporting the study of how information flows. Again,
in my position, I have been focused on standing up the National
AI Research Resource----
Mr. Issa. OK. But let's go through the AI. Isn't AI simply
automating what human beings do, perhaps better, perhaps
faster? But ultimately, there's nothing in AI that is going to
be different than humans other than you're attempting to have
artificial intelligence, meaning a machine do what humans are
already doing or would like to do? Is that correct?
Ms. DeBlanc-Knowles. In certain cases, AI is even more
advanced than humans in terms of--we see a lot of
complementarity between the capabilities that AI brings. We've
talked a lot today about----
Mr. Issa. OK. But let me go through--I know you talked a
lot, and I apologize, I've only a few seconds left. AI is open
to bias. If you produce or encourage or fund the creation of
bias, then in fact what you've done is create a generation of
people, artificial people, who in fact will determine what's
right or wrong, what people learn, particularly rural people,
veterans, the elderly because that's what your studies show you
think are vulnerable because they can't figure out--they're too
dumb to figure out the truth, so you're figuring out the truth
for them. That's what it says--when it says military families,
veterans, et cetera, rural communities, you're specifically
making up decisions about who gets the truth and so on. You
know, the difference is you're now going to have a machine that
I can't easily figure out how it came up with it make those
decisions.
Ms. DeBlanc-Knowles. In the case of AI, that bias often
comes from the datasets that the models are trained on, which
gets back to this conversation about the importance of high-
quality data that has been vetted for use in that model and the
training.
Mr. Issa. Vetted meaning censored?
Ms. DeBlanc-Knowles. Vetted in terms of ethical standards.
Mr. Williams. The gentleman's time has expired.
Ms. DeBlanc-Knowles. Bias is not----
Mr. Issa. I thank the gentleman. I yield back.
Mr. Williams. Ms. Bonamici is recognized for five minutes.
Ms. Bonamici. Thank you to the Chairs and the Ranking
Members, and thank you to the witnesses. We all know that
automated systems such as predictive generative artificial
intelligence present tremendous opportunities to bolster U.S.
innovation, reimagine the role of technology in our everyday
life. And as the technology and applications of AI systems
develop so rapidly, we need a durable and responsible Federal
roadmap to guide AI research.
The problem is I have five hours of questions in five
minutes. So I'm going to start with Ms. DeBlanc-Knowles. The
NAIRR task force published in its final report in January of
last year with a recommendation that a single Federal agency
should serve as an administrative home for NAIRR operations.
Should these operations be housed in an existing agency? And if
so, which one? Or is a new Federal agency best suited to
oversee NAIRR's operations?
Ms. DeBlanc-Knowles. So the NAIRR task force report
recommended that the National Science Foundation serve as that
administrative home, but that the NAIRR initiative really be an
interagency effort. I mean, you see us taking that model
forward in the NAIRR pilot where NSF is serving as that
operational home of bringing together the interagency to
provide access to resources to the research community.
Ms. Bonamici. That makes sense, and I need to move on. And
certainly, we've had conversations and my colleague
Representative Issa mentioned Judiciary. We were just talking
about AI in education, so it makes sense that there's a broad
view of where this is happening.
I'm going to go to our representatives from academia, Drs.
Abdallah and Charma. AI is already affecting all sectors of
life. The responsible deployment of AI systems will require
equipping researchers, educators, and students with core
competencies to navigate the systems. In your testimony, you
both discuss the importance of developing ethical guidelines
for AI. So what are colleges and universities doing to
incorporate AI ethics in curriculum? And is there a universal
understanding of what ethics means in this context?
Dr. Abdallah. So I'll start that we have people who are
both researching these issues, as well as implementing them in
classrooms. So we do have guidelines, for example, about how
you can use some of these tools and coursework or research, but
also, we train our students also in terms of data quality and
so on. So----
Ms. Bonamici. And is that--I'm sorry, I don't want to
interrupt, I just want clarity. Is that the definition of
ethics according to your institution, then?
Dr. Abdallah. Well, I mean, usually the ethics or the
ethical dimensions have to do with the data quality, meaning
does it apply across--has it been tested on--is the data coming
from a large pool, or is it being trained on a man's cancer and
applied across, for example.
Ms. Bonamici. And----
Dr. Abdallah. So those are some of the questions.
Ms. Bonamici. Thank you. I want to hear from Dr. Charma.
Dr. Chamra. So basically, what we do, we offer every
semester seminars to all our students about how to use ChatGPT
in the classroom in an ethical way, but at the same time, we
collaborated with the Department of Philosophy that every
student in the College of Engineering, Computer Science cannot
graduate without taking an ethics course. So this is a
requirement for graduation because I really completely agree
with you not only in AI. The ethical application of
engineering, computer science, data science, and anything we
do, our engineering students must have an ethics course before
they graduate.
Ms. Bonamici. Thank you. I appreciate that very much
because it was mentioned earlier in the testimony about how
it's important to have the math, statistics, science
background, but I also submit that philosophy, history, other
fields are going to be a big part of defining what ethical use
of AI is.
I want to follow up on Representative Salinas' question
about energy consumption. We know that energy consumption is a
concern. In fact, the International Energy Agency projected
that AI electricity demand is expected to increase by about 10
times in the next two years. So some in the industry like
Ampere Computing in Oregon in the district I'm honored to
represent are developing processors aimed at reducing energy
consumption associated with using AI.
So, Ms. DeBlanc-Knowles and Dr. Tourassi, what steps are
you taking to make AI hardware more energy efficient, and what
resources from a fully reauthorized NAIRR would help your work
in this space?
Ms. DeBlanc-Knowles. So NSF is supporting work to make
computing more energy efficient from the algorithm side of
things in terms of machine training of the machine learning
systems, as well as the application of AI to computing systems
to make them more energy efficient. There's still work to be
done in this space, and we're supporting kind of the research
foundations that can get us there.
Ms. Bonamici. Thank you. And if Dr. Tourassi could just
briefly because I'm----
Dr. Tourassi. Yes, so DOE has demonstrated that it's at the
bleeding edge of pushing energy-efficient technologies. I gave
the example about the Frontier supercomputer. You're absolutely
right. There needs to be renewed emphasis on energy-efficient
computing as a whole----
Ms. Bonamici. Absolutely.
Dr. Tourassi [continuing]. And a program that needs to
focus on this, regardless of what technology we're talking
about because this is a fast-moving field.
Ms. Bonamici. Absolutely. Thank you.
And, Mr. Chairman, as I yield back, I request unanimous
consent to enter into the record the recommendation on the
ethics of artificial intelligence by UNESCO, which encourages
developing AI literacy and ethics curricula for all ages. And I
also request unanimous consent to enter into the record the
International Energy Agency report on increasing AI energy
demand.
Mr. Williams. Without objection.
Ms. Bonamici. Thank you. I yield back.
Mr. Williams. The Chair recognizes Ms. Eshoo for five
minutes.
Ms. Eshoo. Well, thank you, Chairman Williams and Collins
and Ranking Members Bowman and Stevens, for holding what I
think is really one of the most important hearings that I've
attended in some time.
I want to add to that Chairman Lucas and Ranking Member
Lofgren have my unending gratitude for all the courtesies that
they've extended to me, including allowing me to waive on to
the Committee today. I have very fond memories of this
Committee because this is where I served in my very first term
in Congress. And as I look around the walls here, there are
many that are in these portraits that I had the privilege of
serving with in the House.
And to the witnesses, you've done a superb job today,
really outstanding job.
Now, we all know that AI can provide tremendous benefits.
They've been spoken of, so I'm not going to repeat all of that.
I think in one sentence AI holds great promise, as well as
peril, and it's up to us to shape policies that are going to
advance what is good and make sure that all Americans are the
beneficiaries of that, and to address what is in the lane of
peril because we take an oath to protect and defend. And
that's--that oath must always be upheld.
It is worth each witness repeating what it takes in terms
of the main ingredients of AI, good data, computing power and a
lot of it, and people, people that know what they're doing, and
a whole set of human beings that we are going to need to be
trained and educated in this. And that the resources that are
needed for this are really huge, and they become larger and
larger with each year.
I'm the mother of NAIRR, of the legislation, of the CREATE
Act, as well as the previous legislation that Congress passed,
the National AI Initiative Act of 2020, which really set up--
set the table for the bill that is being--having its
legislative hearing today.
Why are we doing this? First, I want to call out Stanford's
Human-Centered Institute of AI because I worked closely with
them on the previous legislation and this because it's
essential that all sectors in the country have access to this.
I thought the Chairman asked a very good question a while back
in this hearing about, you know, how many automobile companies
does the Federal Government run? Well, the answer is zero, and
that's appropriate. But it's also appropriate to recognize that
we have many sectors in this country, and they, too, need to be
a part of this, not only the public, the private, the
nonprofit, the academic, the medical. I could go on and on, all
of these sectors, the philanthropic sector as well.
And we need to be in a position where all researchers and
innovators across the United States have the tools, and that's
really in essence what the NAIRR is. And I'm so pleased to
carry the legislation. It is bipartisan. It is bicameral as
well. It should be.
So my question to Ms. Knowles, what specific--I'm going to
trim down the length of the question. What specific resources
would an applicant receive with the NAIRR? And what additional
resources could be available to researchers through a fully
authorized NAIRR in your view?
Ms. DeBlanc-Knowles. First, let me thank you for your
leadership on this concept of the NAIRR. So in terms of the
NAIRR pilot, researchers will be able to request access to
computational resources, and those are both cloud-based
computing resources, as well as resources on premise like those
in our DOE supercomputers. They also will have the ability to
request access to advanced datasets, models, both open models
and proprietary models, and training resources. And I think one
of the important resources that our partners are bringing to
the table for the pilot is the time of their own researchers to
be able to work with the research community that are provided
access to the resources to really maximize the benefit that the
research community can get from access to the resources.
As we look toward the full-scale NAIRR, those resources
that will be available will be larger, more diverse. There'll
be an integrated data discovery portal, higher levels of
computational resources, and then also a really robust user
support mechanism that will be built in to the NAIRR, as well
as a community of researchers and--that can use that platform
to collaborate and learn from each other and access training
resources.
Ms. Eshoo. Well, my time is certainly expired. Mr.
Chairman, thank you for the courtesy that's been extended me--
to me today. And I ask that the SIIA (Software & Information
Industry Association) letter to the Committee be placed in the
record along with my statement. And again, all of my thanks to
you.
Mr. Williams. Without objection.
[The prepared statement of Ms. Eshoo follows:]

Artificial intelligence (AI) has extraordinary potential to
benefit society. It also has peril. The safe use of AI can lead
to life-changing breakthroughs in medicine and science, but
unsafe use can result in bias and discrimination, exacerbating
existing inequities in society, and in the wrong hands can
present a threat to society equal to that of chemical,
biological, radiological and nuclear threats. To promote the
research and development of AI that will benefit everyone, I
introduced bipartisan, bicameral legislation, the CREATE AI Act
(Creating Resources for Every American to Experiment with
Artificial Intelligence).
Today, research and development of leading AI is primarily
in the hands of a few large technology companies. It's
essential that all sectors have access to these resources,
including startups, small businesses, the healthcare sector,
colleges and universities, nonprofits, and the public sector.
The CREATE AI Act establishes a National Artificial
Intelligence Research Resource (NAIRR), a shared cyber research
infrastructure for researchers across all sectors to access the
high-powered computing, data sets, and other resources needed
to develop cutting-edge AI technology.
Sustained investments in R&D have made American companies
the world leaders in developing advanced AI systems and
identifying cutting-edge AI applications that can benefit
society and improve our economy, but we cannot take this
leadership for granted. We will only maintain our position
through investment, competition, and active engagement with the
full breadth and diversity of U.S. AI talent. The ability of
the U.S. to fully realize the benefits of AI will require U.S.
researchers across all sectors of society to access the
necessary resources, especially researchers form communities of
color or from smaller academic institutions, who have been
historically excluded from researching and developing cutting-
edge technology, including AI. This will also help with
fostering a diverse AI workforce. The NAIRR would promote a
robust job market and talent pipeline by giving the next
generation of scientists a meaningful choice between industry,
academia, and government.
I began working on the NAIRR several years ago with
Stanford University's Institute for Human-Centered Artificial
Intelligence (HAI). We developed the concept of the NAIRR and
introduced and passed the National AI Research Resource Task
Force Act. It directed the National Science Foundation, in
consultation with the White House Office of Science and
Technology Policy, to establish a task force and develop a
roadmap for the NAIRR. The Task Force worked for over eighteen
months, then issued a report and a legislative framework that
became the CREATE AI Act.
Passing the CREATE AI Act and establishing the NAIRR is a
highly important action Congress can take to strengthen U.S. AI
R&D. As AI continues to advance, both Democrats and Republicans
can agree that we must ensure the U.S. leads the world in
responsible AI development by allowing everyone with innovative
ideas to leverage this technology. Cultivating a vibrant,
competitive, and inclusive AI innovation ecosystem that
reflects American values will protect national security, foster
scientific progress, and drive economic growth. This will in
turn increase America's future technological competitiveness.
These outcomes won't be possible through action by any single
sector or entity. It will require collaborative action among
government, academia, the private sector, and non-profits, and
that's exactly what my legislation does by putting the NAIRR in
place, thereby democratizing AI R&D to ensure America remains
the world leader.

Mr. Williams. The Chairman recognizes Mr. Beyer for five
minutes.
Mr. Beyer. Mr. Chairman, thank you very much, and thank
you, Mr. Chairman and Ranking Member, for allowing me to waive
on.
Ms. DeBlanc-Knowles, we're very excited about NAIRR. If
she's the mother, I'm the uncle. Now that it's up, what has
this done for the demand for datasets under the pilot program?
Are you getting more and more people wanting more and more
datasets as you build out the NAIRR?
Ms. DeBlanc-Knowles. So the NAIRR launched on January 24,
and with that--the NAIRR pilot launched on January 24. With
that launch, we did open the first opportunity to apply for
resources that are being made available through the pilot, and
those are NSF and DOE supercomputing resources. So in a couple
of weeks, we'll have a good sense of the level of interest from
the community to access those computational resources, and
we've scoped that call around the theme of safe, secure, and
trustworthy AI as a priority area that we want to support
research on by connecting it to those necessary computational
resources.
Mr. Beyer. I can't believe you can't give me a more
comprehensive answer after 13 days.
Ms. DeBlanc-Knowles. And as----
Mr. Beyer. Let me move on. I'm----
Ms. DeBlanc-Knowles. OK.
Mr. Beyer [continuing]. Going to come back to you in one
second. But I want to thank Mr. Clark. When we had our opening
kickoff this past year of the AI Caucus, you were our guest
speaker. Terrific. I think it was the biggest one we've ever
had, 150 people. And I want to really thank you for your
testimony today, for being brave enough to follow up on what my
pal Jay Obernolte said, to represent the private sector with
all that money involved and encouraging us to make sure that
there is the democratization of the public sector investment.
And thank you for the endorsement of the CREATE AI Act, too,
because, with no disrespect to the President's Executive order,
we also want Congress to act on most of this stuff and build it
in.
But a couple of years ago the National Science Foundation
had a really interesting report on the fact that the Federal
Government had all these amazing data bases at, you know,
Census and IRS (Internal Revenue Service) and the Bureau of
Labor Standards--BLS rather center for BEA (Bureau of Economic
Analysis)--that didn't talk to each other, completely different
file formats, different coding things, legacies. And so you
suggested that we put together a pilot program to make them
talk to each other so the researchers could do that. And we
passed the National Security Data Service Act, which set up
that pilot program. Can you give us an update on where we are
on the National Secure Data Act pilot?
Ms. DeBlanc-Knowles. I don't have deep expertise in the
National Secure Data Service pilot that's being stood up, but
I'm happy to come back to you in writing after consulting with
my colleagues.
Mr. Beyer. OK, great. You have short answers today. And so
let me move on then to one more question, and this is for Mr.
Clark. You brushed over very quickly the existential problems,
and, of course, we tend to look at use cases. We don't want to
regulate the math of the computer science, so we look at
privacy, we look at bias, we look at job elimination. When do
we begin to worry about the existential parts of it? Should we
worry? What's--you more than probably any person in this room
are deep into this, the science itself on it. We'd love your
perspective on that.
Mr. Clark. So at Anthropic, we've implemented something
called a responsible scaling policy. What that means is that
before our next really large scale, you know, tens of millions
model AI system arrives, we've built a load of tests for
potential misuses or security issues that model could generate.
And the purpose of this is to know if that kind of potential
for threat is coming and be able to intervene on it as soon as
possible.
And I think there's a lesson here, which is, mostly, we're
going to get a huge amount of benefits from AI, but if there
are risks, we want to have the tests ready so that we can run
them on frontier systems as they come along. And that's going
to tell us if there is anything to be concerned about. I don't
believe that there is concern today. I do believe we urgently
need to invest in the testing and evaluation infrastructure via
things like the NAIRR to build a large community that has the
relevant toolkit to be able to look at these systems and answer
that question in a way that is, you know, peer-reviewed and
seen as legitimate by everyone in this space.
Mr. Beyer. Mr. Clark, you didn't sign the pause letter that
Dr. Hinton and many others did. How was that pause supposed to
work?
Mr. Clark. We didn't sign the letter partly because we were
not quite sure how a pause was meant to work, but also, when
you're turning into a bend on a road, you don't slam on the
brakes. That's very bad. You actually need to accelerate into
the turn to get a handle on it. I think what we can choose to
do in America is invest aggressively in the future of AI
research so that we can study it and understand any potential
issues it creates. Pausing or not doing this just buys us
surprise, which seems risky.
Mr. Beyer. Thank you very much, Mr. Chair. I yield back.
Mr. Williams. The Chair recognizes Mr. Mullin for five
minutes.
Mr. Mullin. Thank you, Mr. Chair. I want to start by
thanking my good friend and neighbor and colleague,
Congresswoman Eshoo, for her leadership on many things, but
particularly the CREATE AI Act, of which I am a proud co-
sponsor. As we've seen here today, we should continue to take
steps to democratize access to the computational power needed
to advance AI research, and I strongly support her legislation
and her partnership over the years.
Thank you all for joining us today at this hearing. I live
in south San Francisco, which is the birthplace of
biotechnology. My district overall is home to hundreds of
biotech and life sciences companies doing vitally important
work, developing therapeutics for thousands of diseases,
improving people's lives. Given that, I am particularly
interested in learning more about the potential for the use of
AI in the development of medicines and other types of
treatments. I'd like to better understand how NSF is already
supporting this work and how we can further advance these
promising areas of study.
So, Ms. DeBlanc-Knowles, you noted in your testimony
earlier that NSF's ongoing support for R&D-heavy sectors such
as biotechnology have been instrumental in their development in
the U.S. Could you tell us just a bit more about how NSF is
funding biotech R&D that leverages AI? And how exactly does the
use of AI lead to the development of new medicines?
Ms. DeBlanc-Knowles. So it used to be the case that we
funded AI through our Computer Science Directorate, and now in
recent years, we've seen AI funding flow out through all of the
eight NSF directorates that cover the full frontier of science
and engineering domains.
In the biotechnology space, our directorate in that space
is funding work that's really applying AI to transform that
discovery process and accelerate it from the determining of,
you know, which new drug therapies to test to developing kind
of novel proteins design and drug design that can drive new
outcomes. And the opportunity in this space is really almost
endless in terms of biotechnology being such a data-rich area,
that AI can really transform the whole discovery process,
accelerate it, and lead to new discoveries.
Mr. Mullin. Thank you for that. And I'm also proud to
represent three community colleges in my district. One thing I
hear consistently from many innovative tech and life sciences
companies in my district and across the country, for that
matter, is that there aren't enough people in the pipeline to
do the jobs of the future. As we've been discussing here, job
and career pathways in AI are underdeveloped as compared to
other IT (information technology) jobs such as cybersecurity
and coding.
So, Dr. Chamra, can you talk a little bit about how we
further develop workforce in AI-based fields? Specifically,
could you speak to how we could do this at the career and
technical education level, something that is common to
community colleges, not just for workers getting advanced
degrees?
Dr. Chamra. I completely agree with you that the landscape
has to come from high school, two years community college, and
four-year colleges. And that's why actually with Oakland
University, we always do articulation agreements with community
colleges that it's seamless to get education at community
college and come to Oakland University to finish with four
years. But this is why we do stackable certificate. I really
think it's important that--for the workforce development that
we break our curriculum, and as four-year colleges, we need to
evolve our curriculum. This four years that we have to have for
a student to graduate and join the workforce, it's outdated. We
really need to start taking certificate, and as they advance,
they come back, they take another certificate. If they
accumulate four, they can graduate with an undergraduate
degree, but we really need to collaborate high school,
community colleges, and four-year colleges to ensure that the
future of workforce development right now. Instead of talking
about existentialist question, how many jobs are going to be
eliminated, we really need to be prepared right now for the
future.
Mr. Mullin. Yes, I appreciate that very much, speaking
about the collaboration and linkages from high school up the
ladder. So thank you all for your information today. Mr. Chair,
I yield back.
Mr. Williams. Thank you. As we wrap up, I just want to
offer the Ranking Member, Ms. Stevens, make a short closing
statement.
Ms. Stevens. Yes, well, thank you, Mr. Chair, and thank you
so much to our incredible Committee Members, as well as just
this fantastic panel of witnesses. I really want to commend all
of you for taking time out of your busy schedules, your
responsibilities to share with us all.
And I think of note, we had two Members waive on to this
Committee from--you know, from ``A'' Committees is what we call
them, Ways and Means and Energy and Commerce. Ms. Eshoo, as Mr.
Mullin mentioned, has had just a remarkable 30-year career in
the Congress and incredible leadership in the AI space. And so
we are on to something here on the Science Committee with this
hearing and what it has commanded from the Congress and those
who don't formally sit on this Committee.
And so with that, we took a lot of notes, looked up a lot
of great stuff, as you were all talking. We've got our marching
orders on what we need to do here and look forward to the
continued dialog with all of you as we move forward. And thank
you, Mr. Chair.
Mr. Williams. I also want to just take a minute. I come out
of the tech industry and spent time looking at infrastructure
projects for HBC across internet to networks that are shared.
The technology background is orchestration and orchestration
from full stack infrastructure management, life--you know,
lifecycle management in compute. And so what's happening in
artificial intelligence is unlike anything else. I mean, it's
unlike--it's different yet again from the dot-com boom in the
amount of investment, the speed of development in these tools.
It's absolutely extraordinary.
So, you know, my comments about an automobile manufacturing
plant are simply that this is going to overwhelm every resource
of government, and so, you know, the investments that we make
in NAIRR are absolutely essential and exciting. We build all
kinds of great tools like the National Ignition Facility. We
send probes, you know, to outer space and to the other--you
know, other planets for discovery. James Webb Space Telescope,
an extraordinary tool.
So, you know, NAIRR provides that tool for the research and
because our science community has to understand artificial
intelligence, where it's going, what the pitfalls are. But the
NAIRR, it seems, provides research and access, you know,
democratization as it's been described. You know, on the other
side, I think Dr. Tourassi and Dr. Abdallah, you mentioned, you
know, the tools that are enabling AI development, if it's
wideband memory or materials or some of the governance work at
Georgia Tech. I mean, all of these things, those are critical
as well.
So this is--I just want to try to explain the context for
both my enthusiasm, my support, but also my caution that we
can't compete even at a government scale with what's going to
happen in private industry. We're going to have to partner with
them. And, you know, fortunately, you know, if it's bare metal
access to--you know, to get resources that the government can
do, you know, its own research, it's going to be complex and
unlike anything else. The government simply cannot afford to
compete of the amount of investment that's going in.
But these are extraordinary times. I want to thank you for
your valuable testimony and for the excellent questions and
dialogs from my colleagues. The record will remain open for 10
days for additional comments and written questions from
Members.
And finally, this hearing is adjourned. Thank you so much.
[Whereupon, at 12:44 p.m., the Subcommittees were
adjourned.]

Appendix I

----------

Answers to Post-Hearing Questions
[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

Appendix II

----------

Additional Material for the Record
[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

[all]
