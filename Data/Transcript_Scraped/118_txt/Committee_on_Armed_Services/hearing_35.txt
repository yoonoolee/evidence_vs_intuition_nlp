- MAN AND MACHINE: ARTIFICIAL INTELLIGENCE ON THE BATTLEFIELD

[House Hearing, 118 Congress]
[From the U.S. Government Publishing Office]

[H.A.S.C. No. 118-37]

MAN AND MACHINE: ARTIFICIAL
INTELLIGENCE ON THE BATTLEFIELD

__________

HEARING

BEFORE THE

SUBCOMMITTEE ON CYBER, INFORMATION
TECHNOLOGIES, AND INNOVATION

OF THE

COMMITTEE ON ARMED SERVICES

HOUSE OF REPRESENTATIVES

ONE HUNDRED EIGHTEENTH CONGRESS

FIRST SESSION

__________

HEARING HELD

JULY 18, 2023

[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

-------

U.S. GOVERNMENT PUBLISHING OFFICE

53-627                    WASHINGTON : 2024

SUBCOMMITTEE ON CYBER, INFORMATION TECHNOLOGIES,
AND INNOVATION

MIKE GALLAGHER, Wisconsin, Chairman

MATT GAETZ, Florida                  RO KHANNA, California
LISA C. McCLAIN, Michigan            SETH MOULTON, Massachusetts
PAT FALLON, Texas                    WILLIAM R. KEATING, Massachusetts
DALE W. STRONG, Alabama              ANDY KIM, New Jersey
MORGAN LUTTRELL, Texas               ELISSA SLOTKIN, Michigan
JENNIFER A. KIGGANS, Virginia        JARED F. GOLDEN, Maine
NICK LaLOTA, New York                PATRICK RYAN, New York
RICHARD McCORMICK, Georgia           CHRISTOPHER R. DELUZIO,
Pennsylvania

Sarah Moxley, Professional Staff Member
Michael Hermann, Professional Staff Member
Brooke Alred, Research Assistant

C O N T E N T S

----------
Page

STATEMENTS PRESENTED BY MEMBERS OF CONGRESS

Gallagher, Hon. Mike, a Representative from Wisconsin, Chairman,
Subcommittee on Cyber, Information Technologies, and Innovation     1
Khanna, Hon. Ro, a Representative from California, Ranking
Member, Subcommittee on Cyber, Information Technologies, and
Innovation.....................................................     2

WITNESSES

Kitchen, Klon, Nonresident Senior Fellow, American Enterprise
Institute......................................................     5
Mahmoudian, Haniyeh, Global AI Ethicist, DataRobot...............     6
Wang, Alexandr, Chief Executive Officer, Scale AI................     3

APPENDIX

Prepared Statements:

Kitchen, Klon................................................    53
Mahmoudian, Haniyeh..........................................    68
Wang, Alexandr...............................................    37

Documents Submitted for the Record:

``The AI War and How to Win It,'' by Alexandr Wang...........    83
``Why AI Will Save the World,'' by Marc Andreessen...........    97

Witness Responses to Questions Asked During the Hearing:

Mr. Gaetz....................................................   123
Mr. Keating..................................................   123

Questions Submitted by Members Post Hearing:

[There were no Questions submitted post hearing.]

MAN AND MACHINE: ARTIFICIAL INTELLIGENCE ON
THE BATTLEFIELD

----------

House of Representatives,
Committee on Armed Services,
Subcommittee on Cyber, Information
Technologies, and Innovation,
Washington, DC, Tuesday, July 18, 2023.
The subcommittee met, pursuant to call, at 9:00 a.m., in
room 2118, Rayburn House Office Building, Hon. Mike Gallagher
(chairman of the subcommittee) presiding.

OPENING STATEMENT OF HON. MIKE GALLAGHER, A REPRESENTATIVE FROM
WISCONSIN, CHAIRMAN, SUBCOMMITTEE ON CYBER, INFORMATION
TECHNOLOGIES, AND INNOVATION

Mr. Gallagher. The subcommittee will come to order.
I ask for unanimous general consent that the Chair be
authorized to declare a recess at any time. Without objection,
so ordered.
I want to briefly review the three commandments of the CITI
[Cyber, Information Technologies, and Innovation] Subcommittee.
One is that we shall start on time, which we just did. So
that is good.
We are going to enforce the 5-minute rule, but if time
allows, we will entertain a second round of questions, and it
often does.
But I bring this up, I want to stress the third
commandment, which is ``Thou shalt not use acronyms or
jargon,'' which I think is particularly important in this
discussion because discussions about AI [artificial
intelligence] can quickly degenerate into jargon-laden
discussions.
We have three true experts on this topic, but just don't
assume your average Member of Congress--or let me just say,
don't assume I understand what you are talking about when you
get into the nuances of AI. So we want to have a discussion in
the open that your average American can understand today. We
are asking you to demystify a lot of the concepts surrounding
AI.
And in thinking about this topic that may sound
counterintuitive, but I have been going back to the history of
the early Cold War. In particular, I'm obsessed with the Korean
war, which is the moment in which the Cold War first turned
very hot, and at great cost to Americans, at even greater cost
to the Korean people themselves.
And I was reading this sort of obscure book about it and
came across the words of a historian named David Rees, who
said, ``At the heart of West military thought lies the belief
that machines must be used to save its men's lives. Korea would
progressively become a horrific illustration of the effects of
a limited war where one side possessed the firepower and the
other the manpower.''
There's a lot of different ways to interpret this in the
current context, and particularly in the context of this
hearing.
One is that AI could potentially increase the destructive
power of modern warfare.
The other is AI has the potential to decrease it, or at
least decrease the exposure that our soldiers, sailors, airmen,
and Marines take when they put themselves in a combat
situation.
Or the third--and what is unique, in contrast to the early
Cold War--is that the machines themselves might somehow take
power and go beyond our ability to control them.
Today, we want to dig into all of these different
hypotheses. The only thing, as I have dug into this topic, and
I want to commend the ranking member, Mr. Khanna, for the way
in which he has worked with me to really use the subcommittee
to explore AI concepts.
We had a very fascinating discussion with Elon Musk last
week. I will say there were some sources of disagreement. Mr.
Musk believes China is on ``Team Humanity.'' I'm not persuaded
of that point. And the only thing I have become convinced is
that the CCP [Chinese Communist Party], if they win this
competition or win the sort of AI component of this
competition, will likely use that technology for evil, as a way
of perfecting a oppressive totalitarian surveillance state, as
well as exporting that model around the world. Whereas, we in
the West, we in the free world at least have the chance of
using it for good.
So to make sense of all these things, we are lucky to have
three incredible witnesses.
Mr. Alex Wang is the CEO [chief executive officer] of Scale
AI. And I don't know, you might be the most successful MIT
[Massachusetts Institute of Technology] dropout of all time at
this point, but there's actually probably a unique subset of
people that qualify there.
Mr. Klon Kitchen is senior fellow at the American
Enterprise Institute and someone many of us on Capitol Hill
look for for advice when talking about the intersection of
technology and warfare.
And Dr. Haniyeh Mahmoudian of DataRobot is an absolute AI
expert as well.
So I have been looking forward to this hearing for a long
time. I look forward to an open and honest discussion. Just
remember, no acronyms, no jargon.
And with that, I yield to the ranking member, Mr. Khanna.

STATEMENT OF HON. RO KHANNA, A REPRESENTATIVE FROM CALIFORNIA,
RANKING MEMBER, SUBCOMMITTEE ON CYBER, INFORMATION
TECHNOLOGIES, AND INNOVATION

Mr. Khanna. Thank you, Mr. Chairman, and thank you for
convening this panel and your interest in a bipartisan way in
addressing AI and making sure that our military is leading with
AI. I have appreciated how you have approached this throughout
your chairmanship.
I'm not going to be long because I know people want to hear
from the witnesses. I would just say that my understanding is
that China is spending almost 10 times as much as the U.S. as a
percent of their military budget on AI, and we really need to
think about the modern technologies that are going to be needed
to have a most effective national security strategy.
So I'm particularly curious from the witnesses about how
they think America can maintain and have the lead in AI
technology going forward, what are the investments we need to
make, and what are the standards we need to have to ensure that
our AI is used most effectively. I'm looking forward to this
panel.
Mr. Gallagher. Thank you.
Mr. Wang, you are now recognized for 5 minutes.

STATEMENT OF ALEXANDR WANG, CHIEF EXECUTIVE
OFFICER, SCALE AI

Mr. Wang. Chairman Gallagher, Ranking Member Khanna, and
members of the subcommittee, my name is Alexandr Wang and I'm
the founder and CEO of Scale AI.
It is an honor to be here today to testify at the dawn of
this new era of warfare--one that will be dominated by AI--and
what the United States must do to win.
In 2016, I founded Scale with a mission to accelerate the
development of AI. From our earliest days of working with the
leading autonomous vehicle programs at General Motors and
Toyota; technology companies such as Meta, Microsoft, and Open
AI; and partnerships with the U.S. Government, including the
U.S. Department of Defense's CDAO [Chief Digital and Artificial
Intelligence Office], the U.S. Army, and the U.S. Air Force, we
have been at the forefront of AI development for more than 7
years.
The country that is able to most rapidly and effectively
integrate new technology into warfighting wins. If we don't win
on AI, we risk ceding global influence, technological
leadership, and democracy to strategic adversaries like China.
The national security mission is deeply personal for me. I
grew up in the shadow of the Los Alamos National Lab. My
parents were physicists and worked on the technology that
defined the last era of warfare, the atomic bomb.
The Chinese Communist Party deeply understands the
potential for AI to disrupt warfare and is investing heavily to
capitalize on the opportunity. I saw this firsthand 4 years ago
when I went on an investor trip to China that was both
enlightening and unsettling.
China was making rapid progress developing AI technologies
like facial recognition and computer vision and using these for
domestic surveillance and repression. That same year, President
Xi Jinping said, quote, ``We must ensure that our country
marches in the front ranks where it comes to theoretical
research in this important area of AI and occupy the high
ground in critical and AI core technologies.'' End quote.
China is investing the full power of its industrial base
for AI. This year, they are on track to spend roughly three
times the U.S. Government on AI. The PLA [People's Liberation
Army] is also heavily investing in AI-enabled autonomous drone
swarms, adaptive radar systems, autonomous vehicles, and China
has launched over 79 large-language models since 2020. AI is
China's Apollo Project.
To lead the world in the development of AI, we must lead
the world in the amount of high-quality data powering AI. Scale
is firmly committed to doing our part to support the U.S.
Government and ensure America maintains its strategic
advantage. Today, we do so in three ways.
One, Scale data engine. We annotate and prepare vast troves
of data for the U.S. Government.
Two, autonomous mission systems. We partnered with DIU
[Defense Innovation Unit] to develop a data engine that will
support the Army's Robotic Combat Vehicle program.
Three, we developed Scale Donovan, our AI-powered
decisionmaking platform that rapidly helps the U.S. Government
make sense of real-world information.
The DOD [Department of Defense] has also taken a number of
steps in the right direction, most notably with the launch of
the Chief Digital and Artificial Intelligence Office.
While this progress is promising, more must be done to
achieve AI overmatch. AI Overmatch is our five-pillar plan to
maintain the United States' security and technological edge in
this new era.
First, investment in AI. It is critical to increase
America's investment to maintain our leadership. Despite record
AI investment in the fiscal year 2024 President's budget, the
U.S. is still spending three times less than China.
Second, data supremacy. AI systems are only as good as the
data they are trained on. The DOD creates more than 22
terabytes of data daily, most of which is wasted. AI warfare
requires leading the world in developing AI-ready data.
Scale fully supports the CDAO and its legislative mandate
to establish a centralized data repository, which would enable
the DOD to harness the power of data with AI.
Third, testing and evaluation. It is one of the most
important ways to ensure that AI models are accurate, reliable,
and uphold the DOD's ethical AI principles.
The administration has embraced this concept by
highlighting Scale's role building an evaluation platform for
frontier LLMs [large language models] at DEFCON [hacker
conference].
Fourth, pathfinder projects. Congress should authorize and
fund new programs with the mission of developing innovative AI-
powered warfighting capabilities. Since Project Maven was
started more than 6 years ago, no new AI pathfinder projects
have begun.
Fifth, upscaling the workforce. The U.S. should invest in
rapidly training the DOD workforce for AI. Scale has already
worked on this with the DOD to tackle this challenge head-on.
In St. Louis, we established an AI center which has created
more than 300 AI-focused jobs, ranging from entry-level
labelers to machine learning engineers with advanced degrees.
The race for global AI leadership is well underway, and I
cannot be more excited to do everything in my power to ensure
that the United States wins. It is in moments like this that
Congress, the DOD, and the tech industry can either rise to the
challenge together or stand idle.
I have included my further remarks in a written statement
to be submitted for the record.
And thank you again for the opportunity to be here today. I
look forward to your questions.
Thank you.
[The prepared statement of Mr. Wang can be found in the
Appendix on page 37.]
Mr. Gallagher. Thank you, Mr. Wang.
Mr. Kitchen, you are recognized for 5 minutes.

STATEMENT OF KLON KITCHEN, NONRESIDENT SENIOR
FELLOW, AMERICAN ENTERPRISE INSTITUTE

Mr. Kitchen. Good morning, Chairman Gallagher, Ranking
Member Khanna, and members of the committee. Thank you for the
privilege of testifying.
I would like to use my opening statement to make three
points.
First, I believe artificial intelligence, and particularly
emerging capabilities like generative AI, are a national
security lifeline for the United States. The national security
community has discussed the potential of AI for years, but now
it seems these technologies are finally maturing to where they
can be applied at scale--with few doubting that they will soon
reshape almost every aspect of our lives, including how we
fight and win wars.
The importance of AI is felt as acutely in Beijing as it is
in Washington. But, until recently, I was not at all confident
that the United States would hold the AI advantage. If you
assume this advantage comes down to algorithms, data, and
hardware, just 1 year ago I would have given the United States
the advantage on algorithms, the Chinese the advantage on data,
and I would have called hardware a jump ball.
But this deserves another look. Large language models and
other generative AIs may be moving the competition back to the
American advantage. The U.S. dominates the underlying computer
science giving birth to these advancements and we remain the
home of choice for global talent.
On hardware, a strong, bipartisan consensus is allowing us
to meaningfully constrain China's access to cutting-edge
capabilities, like advanced graphics processing units, and even
more can and should be done. For example, limiting Chinese
cloud services would be an excellent next step.
Finally, on data, while the Chinese economy and people
continue to generate a deluge of digitized data, and while the
Chinese Communist Party continues to have unfettered access to
these data, the promise of synthetic data and the fact that
many of the new AI models are indexed on the open internet may
blunt the CCP's advantage.
It is my hope, for example, that the Chinese government's
political fragility, strict content controls, and general
oppression of its own people will compromise or bias much of
the data that it collects, diluting its utility and ultimately
limiting the development of Chinese AI. At the very least, I
think that the United States has an opportunity to surge ahead
of Beijing if we are aggressive and deliberate.
But AI offers the U.S. more than bespoke capabilities.
Large language models and other generative technologies, if
properly realized, could provide an economic base for a new era
of American prosperity and security.
For years, we have known that the United States is not
investing in its military sufficiently to meet the demands of
the Nation. The truth of this has been laid bare, as our
defense industrial base struggles to keep up with the demand of
the conflict in Ukraine, for example.
But according to one recent study, existing generative AI
capabilities could add the equivalent of $2.6 trillion to $4.4
trillion annually to the global economy, and that this estimate
would double if we include the impact of embedding generative
AI into existing software that is currently used.
The bottom line is this: I believe AI is offering us an
opportunity to get our economic house in order, to lay a
foundation for our Nation's long-term prosperity, and to build
a national security enterprise that is properly resourced.
But finally, while AI offers all this promise and more, it
is also has serious national security risks; most acutely, a
flood of misinformation and the exponential growth of
conventional and novel cyberattacks. By now, we have all seen
the photos, videos, and other media generative AIs are
creating, and these capabilities have already been
democratized. Virtually anyone can create and distribute
synthetic media that will undoubtedly be used to undermine
American confidence in our democratic institutions.
Similarly, generative AIs will offer hostile cyber actors
potent tools for generating and automating traditional and new
online attacks. In a world where we are already overwhelmed by
online threats, generative AIs will soon pour gas on these
fires.
There is much more that I could say on these matters, but I
trust we will cover them more fully on the course of this
hearing.
Thank you again for the opportunity to testify, and I look
forward to your questions.
[The prepared statement of Mr. Kitchen can be found in the
Appendix on page 53.]
Mr. Gallagher. Thank you, Mr. Kitchen.
Dr. Mahmoudian, you are recognized for 5 minutes.

STATEMENT OF HANIYEH MAHMOUDIAN, GLOBAL AI
ETHICIST, DATAROBOT

Dr. Mahmoudian. Thank you.
Chairman Gallagher, Ranking Member Khanna, and the members
of the Cyber, Information Technologies, and Innovation
Subcommittee, thank you for the opportunity today to testify
before the subcommittee on the critical issues of machine
learning and human warfare: artificial intelligence on the
battlefield.
My name is Dr. Haniyeh Mahmoudian, and I am the global AI
ethicist at DataRobot. In my personal capacity, I am an
advisory member to the National AI Advisory Committee and co-
chair the AI Future Working Group. Today, I testify in my
individual capacity.
AI holds immense potential and is increasingly becoming an
essential component of modern military strategies and
operations with potential to profoundly impact operational
efficiency and decision making.
In the realm of cybersecurity, AI can help military protect
its network and systems against increasingly sophisticated
cyber threats and also assist them in offensive cyber
operations.
AI can also play a critical role in predicting and
prevention of injuries among military personnel. AI can
efficiently track real-time fatigue and injuries, which can aid
prevention of MSK [musculoskeletal] and other bodily injuries,
which, along with consequences, is a major reason for medical
disability and consequent discharge from the service.
Thus, it is imperative that the United States expedites the
adoption of AI to sustain our strategic military leadership and
advantage. While these benefits are significant, it is crucial
to ensure that the use of AI in the military context adheres to
law and ethical guidelines.
In recent years, insufficient scrutiny of AI and evaluation
of AI systems, coupled with a limited comprehension of AI's
potential adverse effect, have led to numerous instances where
AI, despite being developed with good intentions, ended up
harming individuals and groups it was designed to help.
This suggests that consideration of AI ethics have often
been relegated to secondary thought when it comes to building
and deploying AI systems. However, it is encouraging that the
Department of Defense has taken initiatives to develop AI
ethics principles that will apply to both combat and noncombat
functions.
As former Secretary Esper has remarked, ``AI technology
will change much about the battlefield of the future, but
nothing will change America's steadfast commitment to
responsible and lawful behavior.''
Incorporation of responsible AI frameworks and fostering
trust in AI systems requires consideration of people, process,
and technology. Investment in AI and AI ethics literacy for
military personnel at all levels is a key step to ensuring
responsible and appropriate use of AI.
To successfully adopt AI and have it at scale at the
Department of Defense requires that the Department implement AI
governance frameworks and adopt risk-management processes to
manage and mitigate risks associated with AI.
One of the challenges in adoption of AI in the government,
especially in the Department of Defense, is a slow procurement
process. As mentioned earlier, AI is an evolving space.
Therefore, it is paramount for us to make sure that we have a
faster procurement cycle, but ensuring that we also have proper
evaluation of AI tools by using robust governance processes.
In conclusion, AI holds transformative potential. However,
along with these benefits, it is vital to establish ethical
frameworks and comprehensive governance processes that ensure
effectiveness, reliability, and human oversight.
Thank you.
[The prepared statement of Dr. Mahmoudian can be found in
the Appendix on page 68.]
Mr. Gallagher. Thank you to all our witnesses for your
thoughtful testimony.
I now recognize myself for 5 minutes.
Mr. Wang, I would like to begin by asking you to respond a
bit to some of what Mr. Kitchen laid out in terms of our
advantages and disadvantages relative to China in the AI race.
How do you see those advantages--relative advantages and
disadvantages?
Mr. Wang. So I certainly agree that America is the place of
choice for the most talented AI scientists in the world. So we
certainly continue to have an advantage there. And the evidence
is clear, if you look at ChatGPT, GPT-3, GPT-4, as well as the
transformer model that underpins it, all of those were invented
in the United States.
When it comes to data, I actually also agree that we have a
potential very powerful advantage here, specifically when it
pertains to military implementations. So in America we have the
largest fleet of military hardware in the world. This fleet
generates 22 terabytes of data every day. And so if we can
properly set up and instrument this data that is being
generated into pools of AI-ready datasets, then we can create a
pretty insurmountable data advantage when it comes to military
use of artificial intelligence.
Now, I think this is something that we need to work
together and actually move towards as a country. Today, most of
this data goes unused or is wasted in some manner. We need to
fix that to create a longstanding and durable advantage in
artificial intelligence data.
And when it comes to computational power, Nvidia, which is
the world's leader in chips for artificial intelligence, is an
American company. These technologies are innovated and built in
America. And so, again there, I think we have an advantage.
Thank you.
Mr. Gallagher. And, I mean, you have dealt a lot with the
Pentagon. It is a customer of yours. Why is it at present--I
know a lot of this is in your written testimony--that it is
wasted? What is preventing us from harnessing that data? And I
guess, more broadly, what is preventing us--why have we not had
new pathfinder projects since Maven?
Mr. Wang. So data is something that is significantly more
valuable with the advent of these artificial intelligence
algorithms. So, you know, a very simplistic way to look at AI
is that you have these algorithms that analyze troves and
troves of high-quality data, identify patterns in those data,
and then can emulate those patterns going forward.
So we see that with models like ChatGPT which are able to
read troves and troves of language data, things that humans
have written over years and years. Then, it can emulate how a
human might speak in a lot of these instances.
So these artificial intelligence algorithms have made data
significantly more valuable than they have in the past. And so
it is a new paradigm that the DOD needs to adapt towards. As we
all know, the DOD is a fragmented organization. There's many
different constituencies and organizations that each have their
own approach to data.
And like one of my witnesses mentioned, there's an
education process and an upscaling process that needs to
happen. Everyone within the DOD needs to understand that data
is actually the ammunition in an AI war. And if we have that
recognition as an entire Department, and as a country, I think
it becomes very clear for us to take the right actions to
actually collect all this data and move forward.
Mr. Gallagher. It sounds as though you are suggesting that,
with the right leadership and organization, DOD could actually
be a leader in this space. I wonder if it could also be a
leader in terms of the guardrails that a lot of our
constituents are asking us about, right? I think your average
American understands we need to win this competition, but is
concerned about, you know, uncontrolled AI. And everyone has
seen Terminator, et cetera, et cetera.
What is your assessment of the DOD's ethical framework? Is
that potentially a foundation that could be built upon,
expanded, to ensure we are on the same page within the Five
Eyes alliance, within the NATO [North Atlantic Treaty
Organization] alliance, and then, gradually bring more and more
people into that sort of free-world framework for AI?
Mr. Wang. I definitely agree. I think it is really critical
that the United States takes the lead on this topic,
particularly as it pertains to ensuring that artificial
intelligence is used in accordance with our values and our
principles.
The DOD has established ethical AI principles, which I
believe are great, and those principles are ones that we should
continue to adhere. And I think now it comes down to
implementation. How are we going to actually make sure that
these principles are followed?
That is where I think a test and evaluation regime is
incredibly important and critical to the increased deployment
of these AI systems. You know, as the DOD looks to apply AI to
every function within its operation, everywhere from
warfighting to back-office functions and logistics, we need to
have proper test and evaluation mechanisms that ensure that
every instance of artificial intelligence deployed follows our
ethical AI principles.
So I think we need to set up the framework by which we can
ensure all this deployment follows those principles and really
lead the world in terms of thinking on how AI can be used in
accordance with democratic principles.
Mr. Gallagher. I have questions for the other witnesses
that I will have to save for a second round.
I recognize Mr. Khanna for 5 minutes.
Mr. Khanna. Mr. Keating, would you like to go?
Mr. Keating. Thank you, Mr. Chairman, since I have to do
this. Let's see if I can do in 5 minutes here three quick
questions, and quick answers, I hope.
Mr. Kitchen mentioned global talent and we have an
advantage. But we also have immigration issues here that is
hindering that talent. Indeed, should we change some of the
immigration barriers that exist to get that global talent here
to the U.S., make sure we are not losing that talent to other
countries?
Mr. Kitchen. So immigration policy is outside of my area of
expertise. What I would say is that maintaining our access and
continuing to be the preferred home of global talent will be
essential for national security.
Mr. Keating. Okay. This question deals with the procurement
issue that the doctor mentioned. If you could, it is
fragmented, the Department of Defense. Could you give this
committee, as a follow-up, some suggestions on procurement
changes just within the area of AI? Is that something that
could be carved out? Because this is an area of great
significance. And you mentioned that, and I agree, is a major,
major problem. It is a problem generally, but can we do
something specifically with that that you could suggest to this
committee?
Dr. Mahmoudian. So one area that we can think about--and I
have to emphasize that military is not my area of expertise--
but one area that I can bring from the business perspective,
because on the business side you also go through--procurement
side goes through proof of value or proof of concept.
So one of the challenges that we also see over there is the
long process of evaluation, which, if we have standard
procedure in place, these type of processes, these type of
evaluations, as long as they are standardized, it can go much
faster.
Mr. Keating. Thank you.
Mr. Wang, you are familiar, though, on the military side.
Can you follow up on that?
Mr. Wang. Yes. I think there have been immense strides in
building fast procurement methods for the Department of
Defense. Notably, the CDAO, the Chief Digital and AI Office,
has set up a Tradewinds program which is one of the fastest
procurement methods for new technologies, new and innovative
technologies in the DOD.
DIU, as an organization, has also been actively partnering
with many innovative tech companies in bringing their
technologies into the DOD.
And so there are current programs that I think we can
double down on. Both of these instances that I mentioned at the
CDAO and at DIU are working. And I think what we need to look
towards in the next era of AI is doubling down on some of these
fast procurement methods and ensure that we continue
innovating.
Mr. Keating. Is that something that you could follow up
with the committee and provide that kind of information, how it
could be tailored, or doubled down, as you said, more
efficiently, something we could exchange with the military?
Mr. Wang. Of course.
[The information referred to can be found in the Appendix
on page 123.]
Mr. Keating. Okay. Thank you.
Then, just an overview. I think Mr. Wang might be the
proper person, but the others can comment in the 2 minutes I
have left.
Mr. Wang mentioned that we have a data advantage in the
U.S., but we are not capturing all that data. But I think
inherently in our democracy with privacy right protections, we
are at a disadvantage in terms of how Chinese operate
themselves.
And, you know, it can't just be broken down into
information, military and otherwise. All that information is
valuable that they gathered.
Is there an area where, because of our privacy
protections--which is something we shouldn't change in our
country--where we might be at an inherent disadvantage with
China?
Mr. Wang. So I actually look at our democratic values as an
advantage when it comes to artificial intelligence. If you zoom
in on the realm of large language models, this is an area where
in the United States we have clearly raced ahead, and we have
invented much of the technologies. And if you compare that to
the current, what we know of how China views this technology,
you know, they are likely going to squash a lot of the
technology because it is impossible to censor.
I mean, anyone can use ChatGPT and notice that, you know,
ChatGPT can say all sorts of different things. In the United
States, we have protection of free speech. And so we will
continue innovating when it comes to large language models. In
China, they view that as a risk to their socialist values. They
recently came out with regulations that say that their AI
technology has to adhere to socialist values.
Mr. Keating. That is interesting, huh?
Mr. Wang. Yes, it is very interesting.
Mr. Keating. And I'm glad I asked that question, and I
never looked at that aspect of the answer.
Lastly, quickly, with 30 seconds to go, you know, Vladimir
Putin has said whoever controls AI has a huge advantage, but
look at Russia right now. Is it fair to say that they are way
behind? Is it fair to say that their involvement in Ukraine and
what it is doing to the economy and the sanctions are having an
effect? Yes or no? Just in 14 seconds.
[Laughter.]
Mr. Kitchen. Yes, I think there is good reason to suspect
that the Russian AI capability, while they may have some basic
research, in terms of applied deployment is minimal.
Mr. Keating. All right. I thank the ranking member for
switching his time, so I could go to another hearing.
Thank you. I yield back.
Mr. Gallagher. Dr. McCormick is recognized for 5 minutes.
Dr. McCormick. Thank you, Mr. Chair.
And thank you to the witnesses. I wish I had time to talk
to you all day because this is fascinating. You are all,
obviously, experts. Unfortunately, we get time enough for about
two questions and that is about it. So I will go with the most
pertinent that you guys actually brought up in your opening
statements that I thought was really interesting.
Mr. Kitchen, you just discussed limiting Chinese access to
our information, which totally makes sense. We see how they can
develop very rapidly when they literally take our information
and apply it.
My concern is we have an enormous amount of foreign
students at our universities right now in some of the leading
technology areas, including AI development. Georgia Tech is
right in my back yard. I went to Georgia Tech. I did my pre-med
there. And we are literally educating them and sending them
right back there. That is access to leading technology in
America. Is that what you are discussing when you talk about
access or are you talking about in the industry itself? Or the
stuff that is out on the internet? Or is it everything?
Mr. Kitchen. Thank you, Congressman. It is an important
question.
Certainly, there is undeniable--a level of risk associated
with foreign, and particularly Chinese, student presence in the
United States. However, the research that I have seen by
organizations like Georgetown's Center for Security and
Emerging Technology actually demonstrates that the vast
majority of foreign research students, even Chinese students,
actually stay in the United States or, more broadly, in the
West, for the course of their career and amplify our
capability.
What I'm most concerned about, however, when I talk about
Chinese access to data--again, not dismissing an inherent,
built-in threat there--is, frankly, their acquisition through
purchase of American data through large data stores, but then
also things that we have all been talking about and staring at
in the face for multiple years now--things like Chinese-owned
and operated social media companies like TikTok, where every
bit and byte of data that is generated via these applications
on Americans' phones is, by law, made accessible to the Chinese
Communist Party.
And so while Chinese students and other foreign students
may have some type of risk, it pales, in my view, in comparison
to the type of data that we are just kind of giving away.
Dr. McCormick. I appreciate that and I can totally
understand where that is coming from. My other concern, though,
in regards to that--and this is just a quick comment--is that
the Chinese government is not stupid, and they, obviously,
don't really care about their people more than they do about
their government. So when they allow people to come here for
education or jobs, I think it is with nefarious intent, and
that is my worry. I'm not saying we don't need to educate
people from other foreign lands, but I'm worried about it. And
worried about anybody who is pushing their people over here,
knowing they are not coming back for a reason.
With that said, also, Mr. Wang, you made an interesting
statement about investing in AI and how China has got three
times more investment in their AI. Of course, the one thing we
do have a huge advantage is we have a lot of private people
that are investing in AI now, and China doesn't have that. They
don't have the capacity to outperform our private industry
because they don't have a private industry.
How do we compare when we combine our synergistic efforts
between government and private industry with China as far as--
and you mentioned, Mr. Kitchen, that in that effect that we
allow this freedom of flow and it is not controlled. So it does
have the potential to outpace, as long as we put the right
guardrails on it when we are talking about our competition with
China.
Mr. Wang. Certainly, if you factor in the amount of private
sector investment into AI in the United States, that is an
incredible sum. You know, large technology companies, the
venture capital industry, and now, the sort of global
enterprise is investing billions and billions of dollars into
AI. And so if you tally all that up, it is an incredible
investment into artificial intelligence in the United States.
That being said, I don't think we should rest easy on that,
because military implementations of AI are going to be
incredibly important. We need to ensure that in this next phase
that the U.S. is both economically dominant, but also has
military leadership as well when it comes to artificial
intelligence.
And so, you know, we need to consider what the overall
investment into military implementations looks like, and that
is where there is a large disparity. That is where China is
investing 3X more. And if you compare as a percentage of their
overall investment, the PLA is spending somewhere between 1 to
2 percent of their overall budget into artificial intelligence;
whereas, the DOD is spending somewhere between .1 and .2
percent of our budget into AI.
Dr. McCormick. That is a good point. And it is interesting
to watch these private industries now in the United States
pairing with the DOD to develop a lot of that stuff, which is
very cool, including yourself.
I will say, since I am out of time, just that we shouldn't
sleep on Iran and Russia, who obviously want to be players.
They have used technology in the past to disrupt other
countries, and they, of course, love misinformation. So this is
something we need to be aware of.
Thank you. With that, I yield.
Mr. Gallagher. Mr. Khanna is recognized for 5 minutes.
Mr. Khanna. Thank you, Mr. Chairman.
Mr. Kitchen, I thought it was interesting that you said
that the advantage that China may have because of data is
diminishing because things like ChatGPT are based on the entire
universe of the internet, which has both good and bad data in
it.
And then, Mr. Wang, you said that DOD is really relying on
sort of tagged, annotated data. I guess I'm trying to
understand, what is the best data that is needed for AI to be
effective in military applications? And does China have an
advantage on that kind of data or not? And I would love both of
your answers on that.
Mr. Wang. So both data are important, both sort of open
source data that is accessible on the internet--that is a key
data source for large language models like ChatGPT--as well as
high-quality, annotated datasets. ChatGPT and its precursor
InstructGPT were trained on large quantities of high-quality,
expert-generated data. And it is an important data source to
ensure that these systems are more trustworthy, truthful,
responsible, et cetera.
So both matter, but when you look towards, again, military
implementations of AI, the key is, what is the military data
that these models are trained on. Right now, the models that
are used by consumers and are present in the private sector are
trained on, essentially, no military data. As a result, you
know, if you would try to apply these without any additional
data towards military problems, they would not perform
particularly well.
So as we look towards applying artificial intelligence to
the military, we need to have military AI-ready datasets that
are ready for this kind of deployment. When it comes to that
kind of data, I think probably today you would say it is a jump
ball. I think that PLA is looking deeply at this issue and that
DOD is looking deeply at this issue.
But we have all of the fundamentals to have an
insurmountable advantage because the DOD generates 22 terabytes
of data--far more data that the PLA generates--on a daily
basis. So if you can instrument this data into one central
repository, we can come out ahead.
Mr. Khanna. So their being--and then I want Mr. Kitchen's
comments.
Their being a surveillance state of just getting data from
all their citizens is not really going to be helpful for the
military datasets that are needed to solve military problems.
Correct?
Mr. Wang. It would be of very limited help, and military
data is, you know, orders of magnitude more valuable for
military problem sets.
Mr. Khanna. Mr. Kitchen.
Mr. Kitchen. Yes, sir, I completely agree with what Alex is
saying. I think the application matters. So in military
applications, particularly anything that would be tactical or
kinetic, military-generated, well-curated data is really going
to be the key differential.
The point that I was trying to raise when I mentioned the
data advantage perhaps swinging back our way, it is in one
sense aspirational. Part of the hope of generative AI is that
over the course of time we will be able to generate what is
called synthetic data. So instead of data that has been
produced via normal economic activity or military activity,
that GenAI, generative AIs, are able to then begin generating
synthetic datasets that would be useful for training.
I suspect that we are, number one, not there yet; and
number two, that those datasets will be helpful for broad
economic application, but not at all the type of--it will be
supplemental to the type of military applications that Alex was
discussing.
Mr. Khanna. Thank you.
Dr. Mahmoudian, thank you for your testimony.
I know Secretary Esper had introduced an AI framework/
guidelines for DOD. I'm not sure if that has been updated now.
Are there things you would want the DOD to do more in terms of
the ethical guidelines/framework for the use of AI?
Dr. Mahmoudian. So the DOD, as I mentioned, they already
have AI ethics principles in place. So one comment that I would
have about that is how we can make these frameworks from
abstract to a practical form of view. And that comes with the
education of the personnel--to make sure that personnel
understand what these principles mean and how they can
actually, in practice, apply to their use cases that they are
working on. So that is a first step.
The second step is the implementation of AI governance. So
when you are talking about policies, processes that their AI
governance would have, those measurements that would be part of
this process would include the principles that they have.
So it is all about people and the process, and obviously,
the technology. How we are going to measure those risks that we
may identify in a use case. These are all part of the
technology aspect of it. Design the technology in a way that it
would provide explanation of why the system made certain
decision.
And I'm out of time.
Mr. Khanna. Thank you. Thank you.
Mr. Gallagher. Mr. Gaetz, Esquire, is recognized for 5
minutes.
Mr. Gaetz. Mr. Wang, thank you for bringing into sharp
relief the extent to which we have to think about all of these
weapon systems that we have in contested environments as data
collection platforms--almost primarily when it comes to
integration with AI. And I took great interest in your call to
the committee that, you know, we not waste that exquisite data
that is being collected.
What advice would you have for the committee about shaping
some sort of access or utilization regime for the data that we
are currently wasting?
Mr. Wang. I think this is one of the most important things
that we can do to set up America for decades and decades of
leadership in military use of AI. Right now, a lot of this data
goes onto hard drives, and what ends up happening are the hard
drives are either overwritten with new information, so the old
data gets deleted effectively and lost, or these hard drives go
into sort of closets or places where they never see the light
of day.
So first is instrumenting the data to sort of flow into one
central data repository. The CDAO has a legislative mandate to
do so and set up a central data repository for the DOD. So I
think that is of critical importance.
And then, this is a whole-of-DOD issue. Every service,
every group, every program needs to be thinking about how can
they--all of the data that their programs are collecting and
that are being generated within their purview, how can they
ensure that all these datas flow through into one central data
repository, and then, are prepared and tagged and labeled for
AI-ready use down the line.
Mr. Gaetz. And it would seem as though, under the normal
construct of a mission set, someone might reasonably be
stovepiped away from the broader utilization of some of that
data. So it almost seems like something that is an appendage to
a mission set. Very hard to weave it in because, as you are
collecting data in contested environments, it could be for all
kind of reasons and all kind of help.
I wonder aloud, what will be commoditized first, the
processing capability on some of these platforms or the data
itself?
Mr. Wang. Well, I think you are right that this is, you
know, data is a new asset for this new regime of AI warfare.
Data truly is the ammunition that will power our future efforts
in the military. So it is a new paradigm to think about data as
a key and central resource versus, as you mentioned, an
appendage that sort of doesn't feel particularly critical to
the future operation of our programs.
Mr. Gaetz. Yes, you know, we do all kind of domestic
policy/military policy around who can access rare earth
minerals; who can access various forms of energy. And I wonder
if in the future a nation-state's access to exquisite datasets
that have been properly stored and collected are viewed just as
precious.
I also wanted to reflect on the smartest hour I ever spent.
It was listening to Elon Musk with our chair and ranking member
discuss some of these issues, and I would encourage anyone
watching this who has an interest in the issue--hard to find a
conversation on the internet with a higher average IQ
[intelligence quotient] across the board than that one.
But what Mr. Musk presented as an argument was that China
understands that AI control of governance is equally a threat
to them and to the United States. And so Mr. Musk's argument
was, we really are ideal partners with China because we share a
common goal to not have the AI robots ultimately take over our
governance.
And our chairman offered, I think, a pretty strident
critique of that perspective saying that, while we view China
as typically thinking long term in the short term, they are
more ``Team Communistic Genocide'' than they are ``Team
Humanity.''
So I was just wondering if, because you had so much in your
written testimony about your time in China, and how that shaped
your perspective on the ethics of all this, do you think China
sees an overlap of interests with the United States on this? Or
do they see us as explicitly an arm's length competitor?
Mr. Wang. I think it would be a stretch to say we are on
the same team on this issue. I think that, if you look at the
last generation of AI, computer vision technology, the way that
China approached it was utilizing it--building an industrial
base that was government-funded to immediately build advanced
facial recognition technology for the suppression of their
population and the suppression of Uyghurs--ultimately sort of
tightening the grip of their totalitarian regime.
I expect them to use modern AI technologies in the same way
to the degree that they can. And that seems to be the immediate
priority of the Chinese Communist Party when it comes to
implementations of AI.
Mr. Gaetz. We will count you on Team Gallagher, not Team
Elon, on that.
And just a question for the record. I would love to know
everyone's perspective on what the most important alliances the
United States is involved in when it comes to these AI regimes.
Is it AUKUS? Is it Five Eyes? Does NATO have a role to play in
the ethics around this? I would love to submit that for----
Mr. Gallagher. Well, I will break the second commandment,
which there is a corollary--if you say something nice about me
or the ranking member, you get more time.
I just quickly, what is the answer to Mr. Gaetz's question?
That is an interesting question.
Mr. Wang. I think they are all important. I would probably
start with Five Eyes, given the strength of our partnerships
within that group.
But, you know, as we look towards artificial intelligence
as a global technology that will shape much of the future of
the world, I think we need to form as many key partnerships as
possible to ensure that particularly the governance of this
technology, both for--certainly for military use, for use in
intelligence, and for use sort of in commercial purposes are
adhering to the democratic values that we have as a country.
Mr. Gallagher. Quickly, Mr. Kitchen.
Mr. Kitchen. From a traditional security alliance, I would
say Five Eyes and NATO will be critical. However, I would say
that the broader economic partnership with our friends and
allies in the European Union is going to be critical long term
and is going in the wrong direction. Happy to talk about that
more.
Mr. Gallagher. Quickly, Dr. Mahmoudian.
Dr. Mahmoudian. I'm echoing the sentiment that the other
witnesses had. Later in the year, we are going to have our
first AI summit that is happening in the U.K. [United Kingdom]
So we need to expand these types of alliance, as mentioned
earlier, with our allies on the area of AI.
Mr. Gallagher. Great.
Ms. Slotkin is recognized for 5 minutes.
Ms. Slotkin. You know, I would just say, just following on
that last question, with Five Eyes, we have had generations of
learning how to share with each other and become interoperable.
I don't actually know if we have data-sharing arrangements when
we don't have a joint platform. And it is just fascinating to
just think about, like, getting those arrangements in place and
sharing data, given the value is going so precipitously up on
it.
So, you know, I would say what we are doing here up on the
Hill, with the help of industry who is invested in AI, is like
admiring the problem, right? We are all talking about the
problem of, like, this new tool that we know has real
potential, but also has potential real downsides. And so how do
we govern it? And our constituents are asking us, like, what
are the ground rules on this new technology because it sounds
scary?
And I would commend the Joint Artificial Intelligence
Center at DOD for putting up some basic, really 40,000-foot
guidelines on being responsible, and equitable, and traceable
and reliable, and governable, but it is like it is real top-
level stuff.
But we are up here, you know, the flip-phone generation,
trying to figure out how to govern AI, and it is complicated.
But could you give us a sense, sort of in colloquial English,
of what keeps you up at night about the military use of AI? If
China is investing at least 3 times, and in some cases 10
times, the amount that we are, what is the number one thing
that you feel like, you know, kind of worst-case scenario, if
we go unchecked, we could see in the next decade?
Mr. Kitchen, you are shaking your head.
Mr. Kitchen. Thank you.
While there are certain risks of what we would call kind of
bespoke threats, I think the most acute challenge that we are
likely to encounter in the near term is a simply more effective
and efficient enemy.
So the chairman referenced a quote from the Korean war. I
will raise him with another one from General Pershing who said,
``Infantry wins battles, but logistics wins wars.''
And I think supply chain and military logistics, and a lot
of what we call kind of back-office military capacity, is what
is likely to be reshaped by AI in the near term, which can
sound innocuous and not so scary----
Ms. Slotkin. Not after Ukraine. I mean, not after watching
Russia in Ukraine. I will be happy to invest in more improved
logistics, given what we have just seen, the buffoonery in the
Russian military.
But I just want to make sure Mr. Wang has an opportunity.
That is a good one and it is not a scary thing. It is just a
more capable and competent adversary, whoever they are.
Mr. Wang.
Mr. Wang. I would certainly agree that the application of
AI to back-office functions, logistics, and just overall
optimization is really critical. If you look towards, you know,
the areas where the PLA is investing into artificial
intelligence, it is for autonomous drone swarms, whether that
be aerial, subsurface, or ground. They are investing across all
fronts. They are investing into adaptive radar systems which
jam and blind U.S. sensors and information networks. So they
are investing across the whole spectrum in artificial
intelligence to sort of set the new tone of warfare with this
technology. And so we need to be investing across the slate.
That being said, I worry as well about the risks in
deploying these AI systems without proper guardrails. And for
me, it really comes down to implementation, which is test and
evaluation.
So how do we know that, for all of the artificial
intelligence systems that the DOD is likely to deploy over the
next few years and the next decade, how do we ensure that each
of these AI systems adhere to the DOD ethical AI principles, as
stated.
So I think it needs to be a standard part of the
procurement process, is a test and evaluation mechanism to
ensure that every instance where a program within the DOD is
looking to use artificial intelligence, that we have the right
testing and evaluation to ensure that it adheres to our
guardrails.
Ms. Slotkin. And I know that the Department is working hard
on this data-labeling problem and trying to--it is an enormous
task to ask what tends to be a stovepiped organization to share
data, make it available, label it, make it usable.
If you were king or queen for the day and could get them to
do one thing on reliability of data and availability, what
would it be?
Mr. Wang. I would say, first, establishing the central data
repository, and then creating a plan by which as much of the 22
terabytes of data generated a day goes into that central data
repository. And then creating a plan by which as much of that
data is processed and labeled and annotated to be AI-ready as
possible.
You know, these are all multiyear efforts that are not
going to be solved tomorrow at the snap of a finger. They need
to be solved through long-term planning and long-term
coordination.
Ms. Slotkin. Great.
Thank you very much. Yield back.
Mr. Gallagher. Mr. LaLota is recognized for 5 minutes.
Mr. LaLota. Thank you, Chairman. Thank you, Chairman
Gallagher, for your leadership on this issue and to our
witnesses for helping to inform Congress on these important
issues. Along with my colleagues from both sides of the aisle,
I am concerned with the rapid advances in artificial
intelligence and machine learning, specifically with our
adversaries like China.
What concerns me most is the Chinese Communist Party has
been making great strides and intends to be the world's leader
by 2030. And while we here in the United States have made
significant improvements in recent years and we continue to
advance, thankfully, we still have much work to do when it
comes to ensuring the DOD is adopting and deploying these
capabilities properly.
With that, I wanted to give a shameless plug for one piece
of legislation that I have for the AI space. My legislation
would require the Office of Management and Budget to issue
guidance to Federal agencies to implement transparency
practices relating to the use of AI and machine learning,
specifically when AI is being used to supplant a human's
decision making impacting American citizens.
While my legislation focuses more broadly, I wanted to ask
for your thoughts on where the DOD currently stands when it
comes to AI and machine learning. Where is the U.S. compared to
our adversaries such as Russia and China with respect to fully
implementing the latest capabilities? Are we years ahead? Are
we on par? Are we years behind? And what are some ways you
would plan for the DOD to speed up the adoption and
implementation of AI effectively at the Department?
Mr. Wang.
Mr. Wang. So when we look at the new technologies like
large language models, like ChatGPT, that have sort of really
come to light over the past year, I think that is a jump ball.
This is a new technology that we need to implement as quickly
as possible, they are trying to implement as quickly as
possible, and we will see how that develops.
If you look towards the last generation of AI technologies,
which is computer vision and AI for things like facial
recognition, this is an area where the original techniques were
invented in the United States, but then China quickly raced
ahead. So they built an industrial base within their country,
funded it with government money to build facial recognition
technology, which they deployed throughout their country to
suppress Uyghurs and overall, you know, tighten the grip of
their socialist regime.
If you look today at the leaderboards for computer vision
AI competitions globally, Chinese companies, Chinese
universities, dominate compared to American institutions. So if
you look at that as a case study, the Chinese system clearly
has an ability and a will to race forward when it comes to
artificial intelligence deployments.
Now, as we look towards this next field of large language
models, we have reasons to be optimistic. You know, China is
going to be more reticent to invest into large language models
because they are difficult to censor. They released recent
regulation on--that said that AI needed to adapt to their
socialist principles, which I think is a clear limitation if
you have an AI that can, you know, sometimes misspeak, like
ChatGPT.
So we have reasons for optimism. And again, the DOD
produces more data than the PLA, by orders of magnitude; we
generate 22 terabytes of data every single day. And so if we
can properly build an advantage here, it will be quite durable.
Mr. LaLota. Mr. Kitchen, would you add something to that?
Where is your scorecard at? Are we behind? Are we ahead? Are we
on par?
Mr. Kitchen. Well, I would say that the two global powers
where the competition matters most, historically, is between
the United States and China. As I mentioned at the beginning of
my testimony, a year ago, I had very real concerns as to how
the United States was going to be able to maintain its AI
advantage.
But precisely because so much of the conversation around
AI--legitimately so--the public conversation focuses on the
risks and the kind of unknown, again, meaningful conversations.
I do think--just analytically, I do believe that we have a
moment to reassert American dominance in a way that really
matters, that some of the things that I would have called a
drag on our development and deployment from a national security
perspective are actually lessening, and that if we realize this
technology deliberately, then we can seize the advantage, and
not just seize the advantage now, but actually build an
advantage that will be meaningful over the long term.
And I think that we should do everything we can to do that.
Mr. LaLota. Thanks.
And with 30 seconds to go, Doctor, I will ask you the last
question. What are the risks that this committee, and the
Department, should be aware of? And how do we address those
risks as we leap forward?
Dr. Mahmoudian. So, when it comes to risk there is
obviously a fallback if the United States falls behind with
regards to the advancement of AI in military. So the main area
that we need to focus on is to make sure that we do have the
advantage in the research, investing in the research,
especially in the military side, and making sure that we are
still a leader in the area of R&D [research and development] in
AI.
Mr. LaLota. Thanks.
Chairman, my time has expired.
Mr. Gallagher. Mr. Kim is recognized for 5 minutes.
Mr. Kim. Thank you, Mr. Chair.
Thank you so much for coming on out and talking to us
today. We spent a lot of time today talking so far about who
has got the development edge and where we are kind of building
that direction, certainly about competition with China. So I
don't want to go over those right now, as they were very well
talked through.
Mr. Wang, you talked about in your opening statement
talking about how the--some of the main technology of the past
being about nuclear development and whatnot sort of shaping
that era, and this very well likely shaping our era.
So I wanted to kind of get a sense from you all about what
you think proliferation of this technology and possible
weaponry would look like. You know, when we were in the nuclear
era, which, you know, we still are--you know, we have a
situation here where only a very few set of countries have been
able to reach that threshold of technology, and proliferation
has been, in many ways, kind of tried--effort to be kind of
contained in that capacity.
So I guess I wanted to ask you--for me, that doesn't
necessarily seem like the kind of setup that we are likely to
see over the coming decade or two. What does it look like to
you? Are we going to have a situation where the U.S. and China,
a handful of countries, are the major developers and
gatekeepers to this technology, but the actual weapon systems
and technology will be potentially mass deployed and able for
purchase by pretty much any nation that is out there?
Just give us a sense of what that proliferation and
topography and landscape looks like.
Mr. Wang. I think this is a really good question. You know,
I think in terms of impact, artificial intelligence is going to
be similar to nuclear weaponry. But as you mentioned, it is a
technology that is likely to be ubiquitous.
A, artificial intelligence can be used across every single
domain, every single function, every single activity that the
military has today, so it is not sort of contained as one
individual weapon. And it is a technology that is increasingly
becoming a global technology.
A few months ago, the UAE [United Arab Emirates] announced
their own large language model that they had built called
Falcon 40B. They actually open-sourced that model to the world
so that anybody on the internet can go and download that model,
that large language model, for use. We are seeing with the
open-source community when it comes to large language models
that this technology is likely to be accessible in some way,
shape, or form to nearly everyone in the world.
That being said, I think that is not a reason to, you know,
give up hope because of one of the things I mentioned before,
which is, for military use cases and military applications, you
need algorithms that are trained on military data. And----
Mr. Kim. I mean, Mr. Kitchen, if you don't mind, I would
like to bring you in. But would we find a situation where, yes,
you know, some country or entity or company is doing that but
then able to then sell that type of technology and weaponry to
a country or to a group?
You know, Mr. Kitchen, I would like to also get your
thoughts on potential for rogue actors, non-state actors, to be
able to get this type of technology, to be able to utilize it.
So, if you don't mind, give us some of your thoughts.
Mr. Kitchen. So I agree with Alex in the sense of this
technology having the same strategic impact of something like
nuclear weapons. But one of the peculiarities of it is that
this technology is overwhelmingly being developed in the
private sector for commercial applications, unlike nukes.
And so one of the implications of that is that, because of
that and the fact that so much is done via the open-source
model, it is instant proliferation. It is available, in terms
of the underlying technology and capacity.
But it is going to be the applications, the particular
applications, that really make the difference when it comes to
capability distinctions. And that is where Alex's points about
the United States having a potential advantage on military
data--right? How we apply the underlying capability is really,
really going to matter. And that is where the advantage comes
to us.
Now, when we think about non-state actors or kind of rogue
actors, I think it is--I think where the most acute challenge
there is probably on novel and traditional cyber exploitations
of these capabilities. So the ability to generate malicious
code and automate it and deploy it is now going to be
democratized to a level and at a scale that is going to be
difficult.
Mr. Kim. I want to just get one last question. Doctor, to
bring you in on this, you know, when we talk about this
proliferation, seeing the potential for non-state actors and
others, I guess, you know, we talked about some of these
frameworks. The U.S. needs to lead the way. But should we be
thinking about an actual international agreement here, an
international treaty? What kind of structure should we be
building towards to give our ability to try to structure that
as a whole?
Dr. Mahmoudian. I completely agree. We need to think about
both the domestic side--so within the United States, we need to
think about how we should be governing these type of
technologies, understanding its risk and having mitigation
process in place. But we do need to work with allies as an
international--at the international level.
Mr. Kim. Okay. Thank you.
I yield back.
Mr. Gallagher. Mr. Fallon is recognized for 5 minutes.
Mr. Fallon. Thank you, Mr. Chairman.
I just want to follow up real quickly with Mr. Kitchen.
Yeah, I think ransomware is an issue that--it is a huge problem
already, and it is one that largely goes under the radar
unless, you know, Colonial Pipeline is hit or something, JBS.
And that is--everybody talked about it for a week and then
forgot about it and acted as if it is not a real problem, which
it is when you have friends in industry, small companies--100,
200 people--that are getting hit.
Half-a-million-dollar ransoms now are being asked, or
million-dollar ransoms, when a lot of the times, it was 50
grand a few years back. Do you think that with AI, are we going
to face, as you just mentioned--but I want you to expand on
it--an explosion in ransomware when you say it is democratized?
Mr. Kitchen. I think that is certainly one of the potential
implications. Honestly, I think one of the key developments
over the last 2 years that has constrained ransomware to the
degree that it has been constrained is the war in Ukraine, that
many of those cyber syndicates that were prosecuting those
attacks have been repurposed by the Russian government for
attacks in Ukraine and elsewhere.
I think, if and when that ever slows down, we are going to
feel the surge again. And I think that that surge will
absolutely be enabled by generative AI because one of the key
areas--there is a study that says that there are kind of four
key areas that will constitute approximately 75 percent of the
economic increase coming with GenAI. One of those is in R&D,
and in software development being the other.
And so I think that applies, unfortunately, equally to the
bad guys as it does the good guys.
Mr. Fallon. Yeah. Nobody has ever accused the DOD of being
highly efficient. They are large. But when you have
inefficiencies, you are talking about wasting billions of
taxpayer dollars. Particularly when we are in a competition
with China, that is even more troubling, and we need to address
it.
We might envision AI with future wars being fought by
robots and such, but within the walls itself, these walls, Mr.
Wang, in your opinion, can the Department of Defense use AI to
extract efficiencies in programming and budgetary activities?
Mr. Wang. For sure. One of the areas that we have already
worked with some of our DOD customers on is using artificial
intelligence and large language models to help digest
requirements that are given by the DOD.
There are so many groups within Department of Defense that
are generating requirements, and matching those requirements up
with capabilities in the private sector or new capabilities
that the DOD develops is an incredible efficiency--potential
efficiency gain.
There is hundreds, if not thousands, of applications like
that of artificial intelligence towards making the DOD a more
efficient organization. So I am incredibly optimistic about the
ability to use AI, whether it is in logistics, back-office, you
know, in personnel-related matters, to build a more efficient
force that wastes fewer resources and ultimately is able to
have more force projection capability.
Mr. Fallon. Think that the same thing holds for, you know,
increased accountability with DOD contracting and spending?
Mr. Wang. I think that there is--you know, if you think
about what the limitations are or what the challenges are, it
is in processing huge amounts of information and data that is
being generated by the DOD to, you know, understand not only
how funds are being used but also understand what the
capabilities that are being generated are.
And so if you think about that problem set, it is one that
is naturally suited for artificial intelligence and for the use
of these large language models.
Mr. Fallon. Doctor, you know, when you talk about AI, my
mind starts to bend and hurt and break a little bit because it
is just so intriguing. But when we just talk about basic
concepts of some of the technology we have grown accustomed to,
like with social media, some folks, believe it or not, in this
building, on the other side of the building, don't grasp even
those--I mean, I remember a major State's governor saying that
we should use Tweeter more, didn't even get the name right.
And one of the Senators I think I remember saying, like,
``How can they post a picture on the line?'' Things like that.
So while that is funny, it is also troubling that if they are
not grasping basic concepts, and you talk about AI, which is
this stuff on, you know, hyper-steroids, how do we go about
best educating our colleagues and the American public on AI and
assuage some of the fears associated with it?
Dr. Mahmoudian. So when we are thinking about the education
side of it, we need to understand that this education needs to
be tailored towards people's needs. So depending on their
roles, depending on their responsibilities, we need to tailor
that education for them.
To give you an example, for senior leaders who may not be
technical, we need to come up with an education that lets them
know what AI is, exactly to your point, what it is capable of,
what its limitations are, versus someone who is technical.
Let's say a data scientist. For them, that would be a different
story. We can have a more technical education for them, but
also having this tech education in a continual form as AI
evolves.
Mr. Fallon. So almost like how it can help them
specifically and make their lives a little bit better.
Dr. Mahmoudian. Exactly.
Mr. Fallon. Yeah.
Thank you, Mr. Chairman. I yield back.
Mr. Gallagher. Mr. Ryan is recognized for 5 minutes.
Mr. Ryan. Thank you, Mr. Chair.
Good morning. Thank you all for being here and for your
insights. I wanted to build on some of your--to start building
on some of your written testimony, Mr. Wang. You talked about
data as the ammunition in AI warfare. You talked about what
some of our adversaries, particularly China, are doing.
And then you were--and I appreciate it--candid about areas
where we need to improve. Can you talk about, based on your
specific experience and your companies working with DOD, who is
doing relatively better? What are the lessons we can learn in
terms of--and also, if you could talk a little bit about CDAO
and how you see that intersecting here so that we can recognize
the imperative around wrapping our arms around our data better.
Mr. Wang. Certainly. So the groups that we work with, by
nature of, you know, us generally working with the more
forward-leaning groups within the DOD, are forward-looking.
They are extremely innovative, and they have incredible--in
terms of taking on this technology as a key part of their go-
forward strategy and building impressive capabilities.
So, you know, we have worked with many of the early
programs in the DOD for use of AI. And by and large, we have
been--I have been incredibly impressed. That being said, I
think now is an opportunity for us to build on those successes
and really take this moment in the technology and speed up our
deployment.
It is incredibly important that we build on our past
successes, that we are able to more scalably deploy this
technology across the entire DOD rather than being limited to,
you know, a few innovative cells within the DOD.
As I mentioned a bit ago, the DIU and the CDAO have been
some of these areas, some of the groups within the DOD that
have been able to have fast procurement cycles and generally
innovate when it comes to use of artificial intelligence. But
that needs to happen across the entire Department of Defense.
Lastly, just on the CDAO, I think they have done--you know,
it is a recently established organization, but they have done a
good job of pushing forward in building, you know, the right--
pushing forward the topic of data labeling and the central data
repository for the DOD. And now I think we need to ensure that
that actually happens in terms of collecting this 22 terabytes
of data that are being generated every day.
Mr. Ryan. Thank you.
And just to build on that and bring in anyone else who
wants to add here, is it even possible to do that from the top
down? I mean, I understand the importance of setting the right
tone and direction. But if we think that creating a new office
is--it is necessary, but I would argue not sufficient, to
really--if we are serious about wrapping our arms around this,
it should be emphasized and trained and reinforced that--much
more broadly.
Do you agree with that? Any ideas from anybody on how to do
that, particularly looking at how others, adversaries or
allies, are doing it?
Mr. Wang. A combination of top-down and bottoms-up is
necessary here because the individuals who are making the
decisions of, you know, when they get a new hard drive off of a
military platform and they need to make the decision on what
they are going to do with that hard drive, we need all the way
down to that individual to understand that hard drive is full
of data that will fuel the future of American military
leadership.
And so they need to understand that as viscerally as we do
from a tops-down perspective within the CDAO or the--you know,
within this conversation. So it requires a whole-of-DOD
approach to be able to properly achieve this outcome.
Mr. Kitchen. Congressman, the one thing I would add is that
as we tackle these difficult challenges--and they are legion--
that just from a mentality standpoint, I would encourage
Congress and the U.S. Government to approach these as
challenges that have to be managed, not solved.
If we make the perfect the enemy of the good, if we try to
find the exquisite solution, we will so delay ourselves as that
we will miss the opportunity. And that's one of the kind of key
narratives I am really trying to emphasize, is that we really
do have a meaningful strategic opportunity. And these
guardrails and everything, they matter. They really do.
But as we approach these things, seizing the opportunity, I
think, is probably one. And then doing it well and carefully is
a part of that, but it cannot be the goal by which we have to
leap over before we begin.
Mr. Ryan. I appreciate and agree.
Just very briefly, Dr. Mahmoudian and anyone else,
particularly talking--you hit on it all a little bit, but--we
are talking about DOD, but how--your sense of, in the research
realm, academic realm, how are we doing there? What can we do
better? I think I could guess, but----
Dr. Mahmoudian. So we can definitely--when you are
investing in the research side of it, it opens the door for us
on the innovation side to also invest in research on the safety
aspect of it, on these guardrails that was mentioned.
So we need to--when we are investing in the research, we
need to consider both in parallel in order to make sure that we
are always ahead of it.
Mr. Ryan. Thank you.
I yield back, Mr. Chair.
Mr. Gallagher. We will now move to a second round of
questions. I will begin by recognizing myself for 5 minutes.
I want to return to Mr. Gaetz's question about key allies
in the AI competition. You all mentioned, you know, our most
obvious allies. I mean, I think you are right. I am not
detracting from that answer--Five Eyes, NATO, EU [European
Union].
I would like to invoke Jared Cohen's concept of sort of
geopolitical swing states, perhaps countries that may not fit
neatly within the free world paradigm. What are the emerging AI
superpowers that we may not be thinking about, or let's just
say states that punch above their weight when it comes to AI,
that we need to be cultivating and ensuring they are not
Finlandizing in the Chinese Communist Party direction?
I will start with you, Mr. Wang.
Mr. Wang. I do think it is really important, you know, as
we--as AI sort of promises to be one of the most important
technologies both economically and militarily, there are a
myriad of countries that are all getting involved.
Kind of as I mentioned, the UAE has a very dedicated effort
towards artificial intelligence. They have open-source models.
You know, they are continuing that series of developments
towards building bigger and more powerful AI models. We don't
know if they are going to open-source them, but we will see. I
think it is important that, you know, as they develop those,
that we try as hard as we can to make sure those follow our
principles and our governance regimes.
India is another key country, obviously, you know, very
critical when we think about geopolitical allies. But also as
you think about their developments in AI, they have an
incredibly active tech sector, and they have stated efforts to
develop large language models within their country.
So, you know, these are some of the countries I would say
that, from an AI perspective, seem to be racing ahead and ones
that we want to ensure are thinking about artificial
intelligence and its impacts in the same ways that we are as a
country.
Mr. Gallagher. Mr. Kitchen.
Mr. Kitchen. I would agree completely. I think this affects
the way we think about our relationships. So right now our
technology supply chain is distributed in such a way as to
where there are critical vulnerabilities. Many of the key nodes
are deep within Chinese sphere of influence.
And where I think we are going to be going is we are going
to try to build trusted technology ecosystems amongst trusted
partners and allies; that the idea is that we identify
particularly Western democracies as being the type of
organizations that we can partner with so that we have mutually
beneficial trade and technology relationships that are the core
of future national security partnerships.
That requires, however, a common purpose and common
understanding of the opportunities and the challenges. One of
the things I am most concerned about is where many of our
friends and allies are in the European Union particularly on
this issue. So my point there being that when we think about
military interoperability in these types of alliances, we also
need to understand that military interoperability is going to
be predicated on regulatory interoperability.
And that is where we have a real gap between us and some of
our key friends. The European Union seems to have concluded
that to build their own domestic technology base, they have to
deliberately constrain, and at times even decouple, from the
American technology base. And that will not work for our shared
purposes and is going to be a real problem going forward.
Mr. Gallagher. Good point.
Dr. Mahmoudian.
Dr. Mahmoudian. So I completely agree with other witnesses
with regards to alliance. One of the things that we need to
understand, also, that for those type of swing states that was
mentioned, we need to also think about how we can align
ourselves to them to make sure that their advancement in AI is
also aligned to the United States so we would have that
alliance with them, rather, while we are ensuring that we are
still the leader in this space.
Mr. Gallagher. Mr. Kitchen, you mentioned in written and
oral testimony that we--on hardware, we have a strong
bipartisan consensus allowing us to constrain China's
advancement.
There has been some suggestion--and maybe put on the Select
Committee on China hat here--as we engage with Silicon Valley
leaders, that while we admire the GPU [graphics processing
unit] export controls--in fact, we're able to bring Japan and
the Dutch along with us was great, and I give the Biden
administration credit for that--there is loopholes whereby they
are still able to access a tranche of these sort of second-
most-advanced chips right now.
I am curious for your comments on that and, Mr. Wang, yours
as well. And I recognize I have run out of time here.
Mr. Kitchen. Yeah. So this goes to my previous point about
an iterative process. I think that you were referencing the
October 7 rules, the export control on integrated chips. That
was the first tranche, and now we are beginning to kind of
optimize and tighten those controls.
It is not a surprise that government and industry are doing
a bit of back and forth on this. I think there is a growing
recognition between both stakeholders that action is necessary,
and now we are trying to find the right way forward. I have
high confidence that we will do that.
Mr. Gallagher. Quickly, Mr. Wang.
Mr. Wang. It is true. You can see reports that ByteDance
and other Chinese companies have bought billions of dollars of
GPUs in the past, you know--in this year so far. So it is
something that we need to be extremely careful and vigilant
about.
Mr. Gallagher. Mr. Khanna.
Mr. Khanna. Thank you.
When Chairman Gallagher and I had that conversation with
Elon Musk, he said that AGI [artificial general intelligence]
was 5 to 6 years away. I was surprised by that timeline. What
is your sense of how long we are from AGI?
Mr. Wang. AGI is an ill-defined concept. And, you know, I
think many----
Mr. Gallagher. Could you define it, since we are not doing
acronyms? You are the guy. Sorry.
Mr. Wang. AGI stands for artificial general intelligence,
you know, the idea that we would build an AI that is sort of
generally intelligent in the way that humans are. It is not a
super well-defined concept because, you know, even in using the
current AI systems, you will notice clear limitations and
issues and challenges that they have with doing even things
like basic math.
AGI as a concept is an enticing one that we in Silicon
Valley talk about a lot, but I don't think it is very well
defined and not something, certainly, that should meaningfully
affect how we think about, you know, putting one foot in front
of the other for not only economic leadership as well as
military leadership.
The reality is that the technologies today--large language
models, computer vision technology, and other AI systems that
are being developed and deployed today--have immense bearing on
the future of our world, whether that is from an economic
perspective or from a military perspective. And that is why I
think it is important that we set the foundations today of
investing into data, investing in testing and evaluation, to
set up the foundations for long-term success.
My last comment as it comes to AGI prediction timelines--I
think this is often a way to sort of distract from the current
conversation, which is, in my mind, very important.
Mr. Khanna. Mr. Kitchen or Dr. Mahmoudian?
Mr. Kitchen. Yeah. I think Alex is exactly right. The idea
of artificial general intelligence--I think what we will be
seeing is increasingly agile and capable foundation models, or
these types of generative AI capabilities, that are going to be
more broadly applicable.
So one of the features of these foundational models is
something that is called emergent capabilities. It is the idea
that we created this algorithm or this foundation model to be
able to do a particular task, and lo and behold, it actually
can do this other thing without having been trained to do so.
So we are going to see that. That is a common feature.
But I would say that the timeline that was given to you
about artificial general intelligence in the next 5 years is
aspirational.
Mr. Khanna. If it is good.
Dr. Mahmoudian. Similar to the previous comments, it is
aspirational. But what I would add to that is we are headed to
that direction. We see, as mentioned, with regard to foundation
models, these type of models that can provide tasks that they
were not necessarily trained on, but they can generalize to
some extent.
However, while we are heading into that direction--
obviously, not in 5 years--but we need to also invest--while we
are investing on the research side of it, we also need to
invest in the guardrails, the safety aspects of it, to make
sure that we are able to mitigate the risks that we are
anticipating with regards to artificial general intelligence.
Mr. Khanna. Maybe I will quickly ask my last question,
which is, do you think we need any DOD clearance for any types
of AI like we have for nuclear technology? There are
safeguards. There is only so many people who can get access to
it.
Mr. Wang, is there anything analogous in the AI space?
Mr. Wang. So as we think towards military AI systems, so
much of the next generation of capabilities are going to need
to be built and trained on top of already classified data. So
there is already an existing sort of structure and regime to
protect any models that are trained on classified data, whether
it is at the secret or top secret or even beyond level, to
ensure that those capabilities sort of stay limited to certain
audiences and state controlled.
I don't know if we need to build even more on that, but I
think that it is certainly true that most of the exquisite
capabilities that the DOD looks to build are likely to be
developed at the secret or top secret level.
Mr. Khanna. Thank you.
Mr. Gallagher. Mr. Gaetz.
Mr. Gaetz. I am interested in the integration of AI and
human performance. We always are very touched whenever there
is--we have casualties that are in training or otherwise that
are preventable.
What have any of you learned about where some of the
potential lies in utilizing AI in integration with sensor
technology and other types of human performance capabilities?
Mr. Wang. You know, one of the areas where artificial
intelligence, I think, has some of the most greatest promise is
in--as Mr. Kitchen mentioned before, is actually in logistics.
So if you look at one of the largest causes of casualties,
it actually was in, you know, transporting fuel and other
resources for the military. This is an area where autonomous
vehicles or even leader-follower setups are able to greatly
improve the efficiency as well as reduce casualties for the
military and is one of the goals of the Army's Robot Combat
Vehicle program that we are collaborating with them on.
As we look further, these AI systems are assistive
technologies in--with our Scale Donovan platform, we are able
to assist in key decision-making. This is being utilized right
now in military planning exercises to help ensure that all of
the data and information that the DOD has access to is being
integrated into the correct military decisions.
So there is an incredibly bright future, I think, for
assistive use of artificial intelligence to make the DOD more
effective.
Mr. Kitchen. This is one of the most exciting things about
AI, in my view, is its ability to help expand human thriving.
So, many will have seen a commercial with one technology
provider whose--their phone could help users who have speech
pathologies or difficulties communicate more effectively. The
OpenAI--their ChatGPT has a function for vision-impaired
individuals where it describes images for them so they can
participate in knowledge gain and application.
And then, when we think about in the military context, I
mean, it is going to be the AI underlying technology and
capability that enables everything from allowing paraplegics to
walk again to bring injury prevention and recovery. I mean, the
things that this technology--again, I am not an idealist on
this, but the promise is real, and what it means for our
society just in general, I think, is very promising.
Mr. Gaetz. As the son of a paraplegic mother, that is an
inspiring concept.
Doctor, I wanted to ask a little different twist on that
question to you. I have talked with my colleague Mr. Khanna to
some degree about how we ought to measure the soft-power
capabilities of some of these AI platforms. How is it that
ethicists are thinking about what it would mean for the United
States, as opposed to China, to be the leader in deploying
100,000 AI robot doctors into Africa or Latin America or
somewhere else in the Global South?
Dr. Mahmoudian. It is all about how we want to have our
values embedded into these AI systems. When we are thinking
about these principles, one area that especially the DOD has is
these system to be governable. So depending on the level of
risk that these systems pose, we want to have oversight.
In some cases, the risk is low, so we may want to let the
AI make the decision. Imagine a benign example being
recommending a movie that might be bad. But in specific cases,
especially the ones that are lethal, we do not want the AI to
make the decision. We want human oversight.
We want AI to be used to provide us information, patterns
that we may have not seen. So we would use those information,
and us humans would be able to make the judgment. So these are
elements that we need to consider when we are thinking about
these----
[Simultaneous speaking.]
Mr. Gaetz. That will substantially impact scalability and
just the scale of being able to deploy the tech, I would think.
Dr. Mahmoudian. If we have comprehensive governance
processes, actually, this does not necessarily be viewed as an
obstacle with regards to scalability. A robust and
comprehensive governance process actually enables us to have
standards and policies in place that can easily apply to any AI
use case that we have.
So with that foundation of AI governance, we would be able
to replicate the process for any AI use case that we have.
Mr. Gaetz. Thank you.
And I haven't given you enough time to answer this
question, Mr. Wang, but one of the things that I am sure we
would like to explore with you further is, when we get into
this test and evaluation paradigm that you keep coming back to
in your testimony, that it is important for us to get a concept
of what the core principles of that test and evaluation regime
would look like. And I hope you will continue to work with the
subcommittee on that.
Yield back.
[The information referred to can be found in the Appendix
on page 123.]
Mr. Gallagher. I am sorry. I am going to do a third round,
but it will go very quick. Trust me. And I am going to apply
the--what I call the justice test, which is a reference to my
96-year-old grandmother, Virginia Justice. She is very smart
but is not even a member of the flip-phone generation, let
alone the AI generation.
So I want you to imagine you are sitting across from my
grandma. Each have an old fashioned in hand. Her late husband
is a World War II vet. You need to explain to her why a--what
she needs to know about AI, why this conversation matters both
for the future of warfare as well as her life and the lives of
her children and grandchildren. What do you say to the great
and beautiful Virginia Justice?
Mr. Wang. If we look towards World War II and the last era
of conflict, new technologies like the atomic bomb were
critical in ensuring that we both had American leadership and
that the values that America upholds were able to continue to
prosper and set the tone for the development of the world.
We are now embarking on a new era of the world, one in
which a new technology, artificial intelligence, is likely to
set the stage for, you know, the future of ideologies, the
balance of global power, and the future of the relative peace
of our world.
Artificial intelligence is an incredibly powerful
technology that underpins nearly everything that we do from an
economic and military standpoint, and therefore, it is critical
that we as a Nation think about how we not only protect our
citizens from the risks of artificial intelligence but also
protect our ideologies and democracy by ensuring we continue to
be leaders.
Mr. Gallagher. Mr. Kitchen.
Mr. Kitchen. Ma'am, there is a new technology that, under
the right circumstances, could protect your grandchildren and
this Nation, that could make this Nation economically and
militarily strong enough to defend its people and its
interests, and a technology that in the wrong hands could
imperil those same things. And it is really important that your
government and industry work together to realize those promises
and to mitigate those threats.
Mr. Gallagher. Great.
Dr. Mahmoudian.
Dr. Mahmoudian. It is a technology that is pretty much
embedded in our day-to-day lives. We are living with it. We are
breathing with it. So we want to make sure that this technology
that is part of our life has its--our values, the values that
we fought for, is incorporated into this technology so we still
would have our civil liberties and civil rights as well as
using this technology and leveraging it to have a better
quality of life.
Mr. Gallagher. Great.
By the way, it just occurred to me, though I love being a
Gallagher, if I had my mother's maiden name, Justice, I mean, I
would probably be President at this point. That is such a
better----
Mr. Khanna. And a progressive.
Mr. Gallagher. Well played.
Any other questions? Okay. A bit of housekeeping before we
adjourn. I want to enter three things into the record quickly.
The first is the article I referenced before by Jared Cohen on
geopolitical--the rise of geopolitical swing states, published
on May 15, 2023.
[The article referred to is retained in the committee files
and can be viewed upon request.]
Mr. Gallagher. The second is something that you, Mr. Wang,
wrote in November of last year on the AI war and how to win it,
in which you say, ``We must recognize that our current
operating model will result in ruin. Continuing on our
trajectory for the next 10 years could result in us falling
irrevocably far behind. Why do large organizations often
continue on the path to their demise, even if the future is
painfully obvious? The reason is inertia. Bureaucracies will
continue to glide deep into the abyss for an eternity.''
[The information referred to can be found in the Appendix
on page 83.]
Mr. Gallagher. And then the third is a recent article by
Marc Andreessen, which articulates the optimistic case for AI,
entitled ``Why AI Will Save the World,'' in which he says,
``The single greatest risk of AI is that China wins global AI
dominance and we, the United States and the West, do not. I
propose a simple strategy for what we do about this, in fact,
the same strategy President Ronald Reagan used to win the first
Cold War with the Soviet Union, which is we win and they
lose.''
[The information referred to can be found in the Appendix
on page 97.]
Mr. Gallagher. So I ask unanimous consent to enter all
three of those into the record.
Without objection, so ordered.
I ask unanimous consent that members have 5 days to submit
statements for the record.
And the hearing stands adjourned.
[Whereupon, at 10:31 a.m., the subcommittee was adjourned.]

=======================================================================

A P P E N D I X

July 18, 2023

=======================================================================

=======================================================================

PREPARED STATEMENTS SUBMITTED FOR THE RECORD

July 18, 2023

=======================================================================

[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

=======================================================================

DOCUMENTS SUBMITTED FOR THE RECORD

July 18, 2023

=======================================================================

[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

=======================================================================

WITNESS RESPONSES TO QUESTIONS ASKED DURING

THE HEARING

July 18, 2023

=======================================================================

RESPONSE TO QUESTION SUBMITTED BY MR. KEATING

Mr. Wang. Scale is committed to working with your office, and the
Committee to address this critical topic.   [See page 10.]
______

RESPONSE TO QUESTION SUBMITTED BY MR. GAETZ
Mr. Wang. Thank you for that question, and I look forward to
working with the Subcommittee and DOD to put in place a comprehensive,
risk-based, test and evaluation framework to ensure that AI is safe to
deploy.   [See page 30.]

[all]
